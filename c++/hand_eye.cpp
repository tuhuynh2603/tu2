///////////////////////////////////////////////////////////////////////////////
// File generated by HDevelop for HALCON/C++ Version 13.0.2.2
///////////////////////////////////////////////////////////////////////////////




#ifndef __APPLE__
#  include "HalconCpp.h"
#  include "HDevThread.h"
#else
#  ifndef HC_LARGE_IMAGES
#    include <HALCONCpp/HalconCpp.h>
#    include <HALCONCpp/HDevThread.h>
#  else
#    include <HALCONCppxl/HalconCpp.h>
#    include <HALCONCppxl/HDevThread.h>
#  endif
#endif



using namespace HalconCpp;

// Procedure declarations 
// Chapter: 3D Object Model / Creation
extern void gen_arrow_object_model_3d (HTuple hv_ArrowThickness, HTuple hv_ArrowStart, 
    HTuple hv_ArrowEnd, HTuple *hv_OM3DArrow);
// Chapter: Graphics / Output
// Short Description: Interactively display 3D object models 
extern void visualize_object_model_3d (HTuple hv_WindowHandle, HTuple hv_ObjectModel3D, 
    HTuple hv_CamParam, HTuple hv_PoseIn, HTuple hv_GenParamName, HTuple hv_GenParamValue, 
    HTuple hv_Title, HTuple hv_Label, HTuple hv_Information, HTuple *hv_PoseOut);
// Chapter: Develop
// Short Description: Changes the size of a graphics window with a given maximum and minimum extent such that it preserves the aspect ratio of the given image 
extern void dev_resize_window_fit_image (HObject ho_Image, HTuple hv_Row, HTuple hv_Column, 
    HTuple hv_WidthLimit, HTuple hv_HeightLimit);
// Chapter: Develop
// Short Description: Open a new graphics window that preserves the aspect ratio of the given image size. 
extern void dev_open_window_fit_size (HTuple hv_Row, HTuple hv_Column, HTuple hv_Width, 
    HTuple hv_Height, HTuple hv_WidthLimit, HTuple hv_HeightLimit, HTuple *hv_WindowHandle);
// Chapter: Graphics / Text
// Short Description: Set font independent of OS 
extern void set_display_font (HTuple hv_WindowHandle, HTuple hv_Size, HTuple hv_Font, 
    HTuple hv_Bold, HTuple hv_Slant);
// Chapter: Calibration / Camera Parameters
// Short Description: Get the value of a specified camera parameter from the camera parameter tuple. 
extern void get_cam_par_data (HTuple hv_CameraParam, HTuple hv_ParamName, HTuple *hv_ParamValue);
// Chapter: Calibration / Camera Parameters
// Short Description: Generate a camera parameter tuple for an area scan camera with distortions modeled by the division model. 
extern void gen_cam_par_area_scan_division (HTuple hv_Focus, HTuple hv_Kappa, HTuple hv_Sx, 
    HTuple hv_Sy, HTuple hv_Cx, HTuple hv_Cy, HTuple hv_ImageWidth, HTuple hv_ImageHeight, 
    HTuple *hv_CameraParam);
// Chapter: 3D Object Model / Creation
// Short Description: Generate 3D object models which visualize the cameras of a stereo model. 
extern void gen_camera_setup_object_model_3d (HTuple hv_CameraSetupModelID, HTuple hv_CameraSize, 
    HTuple hv_ConeLength, HTuple *hv_ObjectModel3DCamera, HTuple *hv_ObjectModel3DCone);
// Chapter: Calibration / Hand-Eye
// Short Description: Perform a hand-eye calibration with a stationary camera. 
void calibrate_hand_eye_stationary_cam_approx (HTuple hv_RobotTouchingPointInToolCoordinates, 
    HTuple hv_RowsTouchingPointInPlane, HTuple hv_ColumnsTouchingPointInPlane, HTupleVector/*{eTupleVector,Dim=1}*/ hvec_ToolInBasePoses, 
    HTuple hv_CalibObjectData, HTuple *hv_HandEyeCalibData);
// Chapter: Calibration / Hand-Eye
// Short Description: Perform a hand-eye calibration with a stationary camera. 
void calibrate_hand_eye_stationary_cam_approx_without_calib_plate (HTuple hv_RowsTouchingPointInPlane, 
    HTuple hv_ColumnsTouchingPointInPlane, HTupleVector/*{eTupleVector,Dim=1}*/ hvec_ToolInBasePoses, 
    HTuple hv_RobotTouchingPointInToolCoordinates, HTuple hv_DistanceObjectTouchingPointToPlane, 
    HTuple hv_DistancePlaneToCamera, HTuple hv_Width, HTuple hv_Height, HTuple *hv_HandEyeCalibData);
// Chapter: Calibration / Hand-Eye
// Short Description: Calibrate the X, Y, Z coordinates of a touching point of a robot. 
void calibrate_robot_touching_point (HTuple hv_DataDir, HTuple *hv_RobotTouchingPointInToolCoordinates);
// Chapter: Calibration / Monocular
// Short Description: Collect the data to calibrate a camera with a single image. 
void collect_single_image_calibration_data (HTuple hv_ImageCaltabFileName, HTuple hv_CalPlateDescr, 
    HTuple hv_CalPlateThickness, HTuple hv_StartCamParam, HTuple *hv_CalibObjectData);
// Chapter: Calibration / Monocular
// Short Description: Calibrate a camera with a single image. 
void calibrate_camera_and_plane_single_image (HTuple hv_CalibObjectData);
// Chapter: Transformations / Poses
// Short Description: Calculate the poses to grasp an object. 
void calculate_tool_in_base_robot_path_poses (HTupleVector/*{eTupleVector,Dim=1}*/ hvec_ToolInModelRobotPathPoses, 
    HTuple hv_ModelInBasePose, HTuple hv_Poses, HTupleVector/*{eTupleVector,Dim=1}*/ *hvec_ToolInBaseRobotPathPoses);
// Chapter: 3D Object Model / Features
void get_bounding_box_points_from_min_max (HTuple hv_BoundingBox, HTuple *hv_PX, 
    HTuple *hv_PY, HTuple *hv_PZ);
// Chapter: 3D Object Model / Transformations
void get_extent_by_axis (HTuple hv_OM3D, HTuple hv_XExtent, HTuple hv_YExtent, HTuple hv_ZExtent, 
    HTuple *hv_XExtentOut, HTuple *hv_YExtentOut, HTuple *hv_ZExtentOut);
// Chapter: Calibration / Hand-Eye
// Short Description: Get the coordinates of the central mark of the closest finder pattern. 
void get_nearest_finder_pattern_coordinates (HObject ho_CalibPlateImage, HTuple hv_RowNearFinderPattern, 
    HTuple hv_ColumNearFinderPattern, HTuple hv_CalibObjectData, HTuple *hv_RowFinderPattern, 
    HTuple *hv_ColumnFinderPattern);
// Chapter: Graphics / Text
void dev_disp_calibration_data_instructions2 (HObject ho_Image);
// Chapter: Matrix / Arithmetic
void get_rotation_axis (HTuple hv_MatRot, HTuple hv_MatRot0, HTuple *hv_RotationAxis, 
    HTuple *hv_DiffToIdentity);
// Chapter: 3D Object Model / Creation
// Short Description: Generate 3D object models for the camera, the plane, the robot's base and the robot's tool in a stationary camera setup. 
void gen_current_setup_stationary_cam_object_model_3d (HTuple hv_ArrowThickness, 
    HTuple hv_ArrowLength, HTuple hv_CameraSize, HTuple hv_HandEyeCalibData, HTuple *hv_OM3DCamera, 
    HTuple *hv_OM3DPlane, HTuple *hv_OM3DBase, HTuple *hv_OM3DToolOrigin);
// Chapter: Transformations / Misc
// Short Description: Obtain the pose of the matched model in the base coordinate system in a stationary camera setup. 
void obtain_3d_pose_of_match_stationary_cam (HTuple hv_Row, HTuple hv_Column, HTuple hv_Angle, 
    HTuple hv_HandEyeCalibData, HTuple hv_Poses, HTuple hv_RectificationData, HTuple *hv_ModelInBasePose);
// Chapter: Graphics / Window
// Short Description: Open a new window next to an existing one. 
void open_new_window (HTuple *hv_WindowHandle, HTuple *hv_WindowHandleGraphics);
// Chapter: Graphics / Text
void dev_disp_calibration_data_instructions (HObject ho_Image);
// Chapter: 3D Object Model / Creation
// Short Description: Generate 3D object models for the camera and the robot's tool. 
void gen_camera_and_tool_moving_cam_object_model_3d (HTuple hv_ToolInCamPose, HTuple hv_ToolInBasePose, 
    HTuple hv_CameraSize, HTuple hv_ConeLength, HTuple hv_OM3DToolOrig, HTuple hv_CamParam, 
    HTuple *hv_OM3DCamera, HTuple *hv_OM3DTool);
// Chapter: 3D Object Model / Creation
// Short Description: Generate the 3D object model of the plane. 
void gen_ground_plane_object_model_3d (HTuple hv_OM3DTool, HTuple hv_OM3DCamera, 
    HTuple hv_OM3DBase, HTuple hv_FactorBorder, HTuple hv_PlaneInBasePose, HTuple *hv_OM3DPlane);
// Chapter: Graphics / Text
void dev_disp_approach_pose_touching_point_instructions (HTuple hv_WindowHandle, 
    HTuple hv_WindowHandleGraphics, HTuple hv_Index);
// Chapter: 3D Object Model / Creation
// Short Description: Generate base and tool 3D models of the robot. 
void gen_robot_tool_and_base_object_model_3d (HTuple hv_ArrowThickness, HTuple hv_ArrowLength, 
    HTuple *hv_OM3DToolOrigin, HTuple *hv_OM3DBase);
// Chapter: Transformations / Misc
// Short Description: Calculate the touching point in tool coordinates. 
void get_robot_touching_point_in_tool_coordinates (HTupleVector/*{eTupleVector,Dim=1}*/ hvec_ToolInBasePosesTouchingPoint, 
    HTuple *hv_RobotTouchingPointInToolCoordinates);
// Chapter: Transformations / Misc
// Short Description: Obtain the pose of the matched model in the base coordinate system. 
void obtain_3d_pose_of_match_moving_cam (HTuple hv_Row, HTuple hv_Column, HTuple hv_Angle, 
    HTuple hv_ToolInBasePose, HTuple hv_HandEyeCalibData, HTuple hv_Poses, HTuple hv_RectificationData, 
    HTuple *hv_ModelInBasePose);
// Chapter: 3D Object Model / Creation
// Short Description: Generate 3D object models for the camera, robot's tool and plane. 
void gen_current_setup_moving_cam_object_model_3d (HTuple hv_CameraSize, HTuple hv_ToolInBasePose, 
    HTuple hv_HandEyeCalibData, HTuple hv_OM3DToolOrigin, HTuple hv_OM3DBase, HTuple *hv_OM3DCamera, 
    HTuple *hv_OM3DTool, HTuple *hv_OM3DPlane);
// Chapter: Graphics / Text
// Short Description: Display the introduction for the procedure calibrate_robot_touching_point. 
void dev_disp_introduction (HTuple hv_WindowHandle, HTuple hv_WindowHandleGraphics);
// Chapter: 3D Object Model / Creation
// Short Description: Generate a 3D object of the matched model, in the case of rectification. 
void gen_matching_object_model_3d (HTuple hv_ModelID, HTuple hv_ObjectHeight, HTuple hv_Poses, 
    HTuple hv_HandEyeCalibData, HTuple hv_RectificationData, HTuple *hv_OM3DModel);
// Chapter: 3D Object Model / Creation
void gen_tool_to_touching_point_object_model_3d (HTupleVector/*{eTupleVector,Dim=1}*/ hvec_ToolInBasePosesTouchingPoint, 
    HTuple hv_RobotTouchingPointInToolCoordinates, HTuple *hv_OM3DToolTouchingPoint);
// Chapter: Calibration / Hand-Eye
// Short Description: Prepares the model to match and grasp in a stationary camera setup. 
void prepare_poses_and_rectification_data_stationary_cam (HTuple hv_ObjectHeight, 
    HTuple hv_RectifyImage, HTuple hv_HandEyeCalibData, HTuple *hv_Poses, HTuple *hv_RectificationData);
// Chapter: System / Multithreading
void read_message_tuple (HTuple hv_MessageHandle, HTuple hv_Key, HTuple *hv_TupleData);
// Chapter: System / Multithreading
void read_message_obj (HObject *ho_ObjectData, HTuple hv_MessageHandle, HTuple hv_Key);
// Chapter: Calibration / Hand-Eye
// Short Description: Prepare the input image for matching and compute the needed pose. 
void rectify_image_and_compute_matching_plane_moving_cam (HObject ho_Image, HObject *ho_ImageRectified, 
    HTuple hv_ToolInBasePose, HTuple hv_HandEyeCalibData, HTuple hv_Poses, HTuple hv_RectificationData);
// Chapter: Graphics / 3D Scene
// Short Description: Visualize the poses that were used to calculate the touching point, and the result. 
void visualize_calibrated_touching_point (HTuple hv_RobotTouchingPointInToolCoordinates, 
    HTupleVector/*{eTupleVector,Dim=1}*/ hvec_ToolInBasePosesTouchingPoint, HTuple hv_WindowHandle);
// Chapter: Calibration / Hand-Eye
// Short Description: Prepares the model to match and grasp. 
void prepare_poses_and_rectification_data_moving_cam (HTuple hv_ToolInBasePose, HTuple hv_ObjectHeight, 
    HTuple hv_RectifyImage, HTuple hv_HandEyeCalibData, HTuple *hv_Poses, HTuple *hv_RectificationData);

// Procedures 
// Chapter: Calibration / Hand-Eye
// Short Description: Perform a hand-eye calibration with a stationary camera. 
void calibrate_hand_eye_stationary_cam_approx (HTuple hv_RobotTouchingPointInToolCoordinates, 
    HTuple hv_RowsTouchingPointInPlane, HTuple hv_ColumnsTouchingPointInPlane, HTupleVector/*{eTupleVector,Dim=1}*/ hvec_ToolInBasePoses, 
    HTuple hv_CalibObjectData, HTuple *hv_HandEyeCalibData)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_CamParam, hv_CalPlateThickness, hv_PlaneInCamPose;
  HTuple  hv_OrderOfTransform0, hv_OrderOfRotation0, hv_ViewOfTransform0;
  HTuple  hv_Index, hv_OrderOfTransform, hv_OrderOfRotation;
  HTuple  hv_ViewOfTransform, hv_TouchingPointInToolPose;
  HTuple  hv_XBase, hv_YBase, hv_ZBase, hv_TouchingPointInBasePose;
  HTuple  hv_XPlane, hv_YPlane, hv_ZPlane, hv_HomMat3DPlaneToBase;
  HTuple  hv_PlaneInBasePose, hv_BaseInPlanePose, hv_BaseInCamPose;
  HTuple  hv_XPlaneBase, hv_YPlaneBase, hv_ZPlaneBase, hv_DiffX;
  HTuple  hv_DiffY, hv_DiffZ, hv_SqrDiff, hv_PlanePointsRMS;
  HTuple  hv_PlanePointsMaxDiff;

  //
  read_message_tuple(hv_CalibObjectData, "CamParam", &hv_CamParam);
  read_message_tuple(hv_CalibObjectData, "CalPlateThickness", &hv_CalPlateThickness);
  read_message_tuple(hv_CalibObjectData, "PlaneInCamPose", &hv_PlaneInCamPose);
  //
  //Check input
  if (0 != (HTuple(HTuple((hv_RowsTouchingPointInPlane.TupleLength())<3).TupleOr((hv_ColumnsTouchingPointInPlane.TupleLength())<3)).TupleOr(HTuple(hvec_ToolInBasePoses.Length())<3)))
  {
    throw HException("Please specify at least three image coordinates and robot poses.");
  }
  if (0 != (HTuple((hv_RowsTouchingPointInPlane.TupleLength())!=(hv_ColumnsTouchingPointInPlane.TupleLength())).TupleOr((hv_RowsTouchingPointInPlane.TupleLength())!=HTuple(hvec_ToolInBasePoses.Length()))))
  {
    throw HException("The number of image coordinates and robot poses have to be equal.");
  }
  if (0 != (HTuple(hv_CamParam[0])==HTuple("line_scan")))
  {
    throw HException("Line-scan cameras are not supported");
  }
  //
  //If points on top of the calibration plate are approached, we have to adapt the PlaneInCamPose accordingly.
  SetOriginPose(hv_PlaneInCamPose, 0, 0, -hv_CalPlateThickness, &hv_PlaneInCamPose);
  //Keep track of the pose type used by the robot.
  GetPoseType(hvec_ToolInBasePoses[0].T(), &hv_OrderOfTransform0, &hv_OrderOfRotation0, 
      &hv_ViewOfTransform0);
  {
  HTuple ExpTmpOutVar_0;
  ConvertPoseType(hvec_ToolInBasePoses[0].T(), "Rp+T", "gba", "point", &ExpTmpOutVar_0);
  hvec_ToolInBasePoses[0].T() = ExpTmpOutVar_0;
  }
  {
  HTuple end_val21 = HTuple(hvec_ToolInBasePoses.Length())-1;
  HTuple step_val21 = 1;
  for (hv_Index=1; hv_Index.Continue(end_val21, step_val21); hv_Index += step_val21)
  {
    GetPoseType(hvec_ToolInBasePoses[hv_Index].T(), &hv_OrderOfTransform, &hv_OrderOfRotation, 
        &hv_ViewOfTransform);
    if (0 != (HTuple(HTuple(hv_OrderOfTransform0!=hv_OrderOfTransform).TupleOr(hv_OrderOfRotation0!=hv_OrderOfRotation)).TupleOr(hv_ViewOfTransform0!=hv_ViewOfTransform)))
    {
      throw HException("ToolInBasePoses have different pose types.");
    }
    //Convert to default pose type.
    {
    HTuple ExpTmpOutVar_0;
    ConvertPoseType(hvec_ToolInBasePoses[hv_Index].T(), "Rp+T", "gba", "point", &ExpTmpOutVar_0);
    hvec_ToolInBasePoses[hv_Index].T() = ExpTmpOutVar_0;
    }
  }
  }
  //
  //Collect the robot translations.
  CreatePose(HTuple(hv_RobotTouchingPointInToolCoordinates[0]), HTuple(hv_RobotTouchingPointInToolCoordinates[1]), 
      HTuple(hv_RobotTouchingPointInToolCoordinates[2]), 0, 0, 0, "Rp+T", "gba", 
      "point", &hv_TouchingPointInToolPose);
  hv_XBase = HTuple();
  hv_YBase = HTuple();
  hv_ZBase = HTuple();
  {
  HTuple end_val35 = (hv_RowsTouchingPointInPlane.TupleLength())-1;
  HTuple step_val35 = 1;
  for (hv_Index=0; hv_Index.Continue(end_val35, step_val35); hv_Index += step_val35)
  {
    PoseCompose(hvec_ToolInBasePoses[hv_Index].T(), hv_TouchingPointInToolPose, &hv_TouchingPointInBasePose);
    hv_XBase = hv_XBase.TupleConcat(HTuple(hv_TouchingPointInBasePose[0]));
    hv_YBase = hv_YBase.TupleConcat(HTuple(hv_TouchingPointInBasePose[1]));
    hv_ZBase = hv_ZBase.TupleConcat(HTuple(hv_TouchingPointInBasePose[2]));
  }
  }
  //
  //Get the plane coordinates of the input image points.
  ImagePointsToWorldPlane(hv_CamParam, hv_PlaneInCamPose, hv_RowsTouchingPointInPlane, 
      hv_ColumnsTouchingPointInPlane, "m", &hv_XPlane, &hv_YPlane);
  TupleGenConst(hv_XPlane.TupleLength(), 0, &hv_ZPlane);
  VectorToHomMat3d("rigid", hv_XPlane, hv_YPlane, hv_ZPlane, hv_XBase, hv_YBase, 
      hv_ZBase, &hv_HomMat3DPlaneToBase);
  HomMat3dToPose(hv_HomMat3DPlaneToBase, &hv_PlaneInBasePose);
  //If points on top of the calibration plate are approached, we have to readapt the Plane accordingly.
  SetOriginPose(hv_PlaneInCamPose, 0, 0, hv_CalPlateThickness, &hv_PlaneInCamPose);
  SetOriginPose(hv_PlaneInBasePose, 0, 0, hv_CalPlateThickness, &hv_PlaneInBasePose);
  PoseInvert(hv_PlaneInBasePose, &hv_BaseInPlanePose);
  PoseCompose(hv_PlaneInCamPose, hv_BaseInPlanePose, &hv_BaseInCamPose);
  //
  //Get the BaseInCamPose.
  PoseInvert(hv_PlaneInBasePose, &hv_BaseInPlanePose);
  PoseCompose(hv_PlaneInCamPose, hv_BaseInPlanePose, &hv_BaseInCamPose);
  //Convert to output pose type.
  ConvertPoseType(hv_BaseInCamPose, hv_OrderOfTransform0, hv_OrderOfRotation0, hv_ViewOfTransform0, 
      &hv_BaseInCamPose);
  ConvertPoseType(hv_PlaneInBasePose, hv_OrderOfTransform0, hv_OrderOfRotation0, 
      hv_ViewOfTransform0, &hv_PlaneInBasePose);

  //Get the difference of the points in the plane as seen by the camera
  //to the points in the plane as approached by the robot.
  AffineTransPoint3d(hv_HomMat3DPlaneToBase, hv_XPlane, hv_YPlane, hv_ZPlane, &hv_XPlaneBase, 
      &hv_YPlaneBase, &hv_ZPlaneBase);
  hv_DiffX = hv_XPlaneBase-hv_XBase;
  hv_DiffY = hv_YPlaneBase-hv_YBase;
  hv_DiffZ = hv_ZPlaneBase-hv_ZBase;
  hv_SqrDiff = ((hv_DiffX*hv_DiffX)+(hv_DiffY*hv_DiffY))+(hv_DiffZ*hv_DiffZ);
  hv_PlanePointsRMS = ((hv_SqrDiff.TupleSum())/(hv_DiffX.TupleLength())).TupleSqrt();
  hv_PlanePointsMaxDiff = (hv_SqrDiff.TupleSqrt()).TupleMax();
  //
  //Create output message.
  CreateMessage(&(*hv_HandEyeCalibData));
  SetMessageTuple((*hv_HandEyeCalibData), "CamParam", hv_CamParam);
  SetMessageTuple((*hv_HandEyeCalibData), "BaseInCamPose", hv_BaseInCamPose);
  SetMessageTuple((*hv_HandEyeCalibData), "PlaneInBasePose", hv_PlaneInBasePose);
  SetMessageTuple((*hv_HandEyeCalibData), "PlaneInCamPose0", hv_PlaneInCamPose);
  SetMessageTuple((*hv_HandEyeCalibData), "PlanePointsRMS", hv_PlanePointsRMS);
  SetMessageTuple((*hv_HandEyeCalibData), "PlanePointsMaxDiff", hv_PlanePointsMaxDiff);
  return;
}

// Chapter: Calibration / Hand-Eye
// Short Description: Perform a hand-eye calibration with a stationary camera. 
void calibrate_hand_eye_stationary_cam_approx_without_calib_plate (HTuple hv_RowsTouchingPointInPlane, 
    HTuple hv_ColumnsTouchingPointInPlane, HTupleVector/*{eTupleVector,Dim=1}*/ hvec_ToolInBasePoses, 
    HTuple hv_RobotTouchingPointInToolCoordinates, HTuple hv_DistanceObjectTouchingPointToPlane, 
    HTuple hv_DistancePlaneToCamera, HTuple hv_Width, HTuple hv_Height, HTuple *hv_HandEyeCalibData)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_OrderOfTransform0, hv_OrderOfRotation0;
  HTuple  hv_ViewOfTransform0, hv_Index, hv_OrderOfTransform;
  HTuple  hv_OrderOfRotation, hv_ViewOfTransform, hv_RobotTouchingPointToToolXYZPose;
  HTuple  hv_XBase, hv_YBase, hv_ZBase, hv_TouchingPointInBasePose;
  HTuple  hv_OM3DPlanePoints, hv_OM3DPlane, hv_TouchingPointPlaneInBasePose;
  HTuple  hv_FocusOrig, hv_DiffRow, hv_DiffCol, hv_DistPixel;
  HTuple  hv_DiffX, hv_DiffY, hv_DiffZ, hv_DistWorld, hv_Quotient;
  HTuple  hv_SX, hv_SY, hv_FocusShift, hv_BestIndex, hv_ErrorBasePoseInPixel;
  HTuple  hv_NumFocus, hv_Focus, hv_CamParam0, hv_BaseInCamPose0;
  HTuple  hv_ErrorBasePoseInPixelTmp, hv_BaseInCamPose, hv_CamParam;
  HTuple  hv_TouchingPointPlaneInCamPose, hv_TouchingPointPlaneInCamPose0Rot;
  HTuple  hv_HomMat3D, hv_Qx, hv_Qy, hv_CosAngleBetweenZAxis;
  HTuple  hv_SwitchZDirection, hv_TouchingPointPlaneInCamPose1;
  HTuple  hv_CamInBasePose, hv_TouchingPointPlanePointsCamX;
  HTuple  hv_TouchingPointPlanePointsCamY, hv_TouchingPointPlanePointsCamZ;
  HTuple  hv_BaseInTouchingPointPlanePose, hv_HomMat3D1, hv_TouchingPointPlanePointsToolX;
  HTuple  hv_TouchingPointPlanePointsToolY, hv_TouchingPointPlanePointsToolZ;
  HTuple  hv_SqrDiff, hv_PlanePointsRMS, hv_PlanePointsMaxDiff;
  HTuple  hv_PlaneInBasePose, hv_PlaneInCamPose;

  //Check input.
  if (0 != (HTuple(HTuple((hv_RowsTouchingPointInPlane.TupleLength())<4).TupleOr((hv_ColumnsTouchingPointInPlane.TupleLength())<4)).TupleOr(HTuple(hvec_ToolInBasePoses.Length())<4)))
  {
    throw HException("Please specify at least four image coordinates and robot poses.");
  }
  if (0 != (HTuple((hv_RowsTouchingPointInPlane.TupleLength())!=(hv_ColumnsTouchingPointInPlane.TupleLength())).TupleOr((hv_RowsTouchingPointInPlane.TupleLength())!=HTuple(hvec_ToolInBasePoses.Length()))))
  {
    throw HException("The number of image coordinates and robot poses have to be equal.");
  }
  if (0 != (HTuple(hv_Width<=0).TupleOr(hv_Height<=0)))
  {
    throw HException("Width or Height must be greater than 0.");
  }
  if (0 != (hv_DistancePlaneToCamera<=0))
  {
    throw HException("DistancePlaneToCamera must be greater than 0.");
  }
  if (0 != (hv_DistancePlaneToCamera<=0))
  {
    throw HException("DistanceObjectTouchingPointToPlane must be greater than 0.");
  }
  //
  //Keep track of the pose type used by the robot.
  GetPoseType(hvec_ToolInBasePoses[0].T(), &hv_OrderOfTransform0, &hv_OrderOfRotation0, 
      &hv_ViewOfTransform0);
  {
  HTuple ExpTmpOutVar_0;
  ConvertPoseType(hvec_ToolInBasePoses[0].T(), "Rp+T", "gba", "point", &ExpTmpOutVar_0);
  hvec_ToolInBasePoses[0].T() = ExpTmpOutVar_0;
  }
  {
  HTuple end_val20 = HTuple(hvec_ToolInBasePoses.Length())-1;
  HTuple step_val20 = 1;
  for (hv_Index=1; hv_Index.Continue(end_val20, step_val20); hv_Index += step_val20)
  {
    GetPoseType(hvec_ToolInBasePoses[hv_Index].T(), &hv_OrderOfTransform, &hv_OrderOfRotation, 
        &hv_ViewOfTransform);
    if (0 != (HTuple(HTuple(hv_OrderOfTransform0!=hv_OrderOfTransform).TupleOr(hv_OrderOfRotation0!=hv_OrderOfRotation)).TupleOr(hv_ViewOfTransform0!=hv_ViewOfTransform)))
    {
      throw HException("ToolInBasePoses have different pose types.");
    }
    //Convert to default pose type.
    {
    HTuple ExpTmpOutVar_0;
    ConvertPoseType(hvec_ToolInBasePoses[hv_Index].T(), "Rp+T", "gba", "point", &ExpTmpOutVar_0);
    hvec_ToolInBasePoses[hv_Index].T() = ExpTmpOutVar_0;
    }
  }
  }
  //
  //Collect the robot translations.
  CreatePose(HTuple(hv_RobotTouchingPointInToolCoordinates[0]), HTuple(hv_RobotTouchingPointInToolCoordinates[1]), 
      HTuple(hv_RobotTouchingPointInToolCoordinates[2]), 0, 0, 0, "Rp+T", "gba", 
      "point", &hv_RobotTouchingPointToToolXYZPose);
  hv_XBase = HTuple();
  hv_YBase = HTuple();
  hv_ZBase = HTuple();
  {
  HTuple end_val34 = (hv_RowsTouchingPointInPlane.TupleLength())-1;
  HTuple step_val34 = 1;
  for (hv_Index=0; hv_Index.Continue(end_val34, step_val34); hv_Index += step_val34)
  {
    PoseCompose(hvec_ToolInBasePoses[hv_Index].T(), hv_RobotTouchingPointToToolXYZPose, 
        &hv_TouchingPointInBasePose);
    hv_XBase = hv_XBase.TupleConcat(HTuple(hv_TouchingPointInBasePose[0]));
    hv_YBase = hv_YBase.TupleConcat(HTuple(hv_TouchingPointInBasePose[1]));
    hv_ZBase = hv_ZBase.TupleConcat(HTuple(hv_TouchingPointInBasePose[2]));
  }
  }
  //
  // Use the specified robot translations to obtain the PlaneInBasePose.
  GenObjectModel3dFromPoints(hv_XBase, hv_YBase, hv_ZBase, &hv_OM3DPlanePoints);
  FitPrimitivesObjectModel3d(hv_OM3DPlanePoints, "primitive_type", "plane", &hv_OM3DPlane);
  GetObjectModel3dParams(hv_OM3DPlane, "primitive_pose", &hv_TouchingPointPlaneInBasePose);
  //
  //Obtain fictitious camera parameters.
  hv_FocusOrig = 0.008;
  hv_DiffRow = (hv_RowsTouchingPointInPlane.TupleSelectRange(0,(hv_RowsTouchingPointInPlane.TupleLength())-2))-(hv_RowsTouchingPointInPlane.TupleSelectRange(1,(hv_RowsTouchingPointInPlane.TupleLength())-1));
  hv_DiffCol = (hv_ColumnsTouchingPointInPlane.TupleSelectRange(0,(hv_ColumnsTouchingPointInPlane.TupleLength())-2))-(hv_ColumnsTouchingPointInPlane.TupleSelectRange(1,(hv_ColumnsTouchingPointInPlane.TupleLength())-1));
  hv_DistPixel = ((hv_DiffRow*hv_DiffRow)+(hv_DiffCol*hv_DiffCol)).TupleSqrt();
  hv_DiffX = (hv_XBase.TupleSelectRange(0,(hv_XBase.TupleLength())-2))-(hv_XBase.TupleSelectRange(1,(hv_XBase.TupleLength())-1));
  hv_DiffY = (hv_YBase.TupleSelectRange(0,(hv_YBase.TupleLength())-2))-(hv_YBase.TupleSelectRange(1,(hv_YBase.TupleLength())-1));
  hv_DiffZ = (hv_ZBase.TupleSelectRange(0,(hv_ZBase.TupleLength())-2))-(hv_ZBase.TupleSelectRange(1,(hv_ZBase.TupleLength())-1));
  hv_DistWorld = (((hv_DiffX*hv_DiffX)+(hv_DiffY*hv_DiffY))+(hv_DiffZ*hv_DiffZ)).TupleSqrt();
  hv_Quotient = (hv_DistWorld/hv_DistPixel).TupleMedian();
  //Camera parameter will be generated in the following form:
  //SX := Quotient * FocusOrig / DistancePlaneToCamera
  //SY := SX
  //gen_cam_par_area_scan_division (FocusOrig, 0, SX, SY, Width / 2.0, Height / 2.0, Width, Height, HandEyeCalibData)
  //
  //Use the specified image points and robot translations to obtain the BaseInCamPose.
  hv_FocusShift.Clear();
  hv_FocusShift[0] = 0.1;
  hv_FocusShift[1] = 0.2;
  hv_FocusShift[2] = 0.33;
  hv_FocusShift[3] = 0.5;
  hv_FocusShift[4] = 0.75;
  hv_FocusShift[5] = 1.0;
  hv_FocusShift[6] = 1.5;
  hv_FocusShift[7] = 2;
  hv_FocusShift[8] = 3;
  hv_FocusShift[9] = 3.125;
  hv_FocusShift[10] = 3.5;
  hv_FocusShift[11] = 4;
  hv_BestIndex = -1;
  //The value of focus should not have much influence when camera and plane are parallel,
  //but just in case, check different values.
  hv_ErrorBasePoseInPixel = 1e9;
  {
  HTuple end_val67 = (hv_FocusShift.TupleLength())-1;
  HTuple step_val67 = 1;
  for (hv_NumFocus=0; hv_NumFocus.Continue(end_val67, step_val67); hv_NumFocus += step_val67)
  {
    hv_Focus = hv_FocusOrig*HTuple(hv_FocusShift[hv_NumFocus]);
    hv_SX = (hv_Quotient*hv_Focus)/hv_DistancePlaneToCamera;
    hv_SY = hv_SX;
    gen_cam_par_area_scan_division(hv_Focus, 0, hv_SX, hv_SY, hv_Width/2.0, hv_Height/2.0, 
        hv_Width, hv_Height, &hv_CamParam0);
    VectorToPose(hv_XBase, hv_YBase, hv_ZBase, hv_RowsTouchingPointInPlane, hv_ColumnsTouchingPointInPlane, 
        hv_CamParam0, "iterative", "error", &hv_BaseInCamPose0, &hv_ErrorBasePoseInPixelTmp);
    if (0 != (hv_ErrorBasePoseInPixel>hv_ErrorBasePoseInPixelTmp))
    {
      hv_BaseInCamPose = hv_BaseInCamPose0;
      hv_ErrorBasePoseInPixel = hv_ErrorBasePoseInPixelTmp;
      hv_CamParam = hv_CamParam0;
    }
  }
  }
  //Get the PlaneInCamPose.
  PoseCompose(hv_BaseInCamPose, hv_TouchingPointPlaneInBasePose, &hv_TouchingPointPlaneInCamPose);
  //
  //The z-axis of the plane should point away from the camera.
  hv_TouchingPointPlaneInCamPose0Rot = hv_TouchingPointPlaneInCamPose;
  hv_TouchingPointPlaneInCamPose0Rot[HTuple::TupleGenSequence(0,2,1)] = ((HTuple(0).Append(0)).Append(0));
  PoseToHomMat3d(hv_TouchingPointPlaneInCamPose0Rot, &hv_HomMat3D);
  AffineTransPoint3d(hv_HomMat3D, 0, 0, 1, &hv_Qx, &hv_Qy, &hv_CosAngleBetweenZAxis);
  if (0 != (hv_CosAngleBetweenZAxis<0))
  {
    CreatePose(0, 0, 0, 180, 0, 0, "Rp+T", "gba", "point", &hv_SwitchZDirection);
    PoseCompose(hv_TouchingPointPlaneInCamPose, hv_SwitchZDirection, &hv_TouchingPointPlaneInCamPose1);
    hv_TouchingPointPlaneInCamPose = hv_TouchingPointPlaneInCamPose1;
    PoseInvert(hv_BaseInCamPose, &hv_CamInBasePose);
    PoseCompose(hv_CamInBasePose, hv_TouchingPointPlaneInCamPose, &hv_TouchingPointPlaneInBasePose);
  }
  //
  //Get the difference of the points in the plane as seen by the camera
  //to the points in the plane as approached by the robot.
  ImagePointsToWorldPlane(hv_CamParam, hv_TouchingPointPlaneInCamPose, hv_RowsTouchingPointInPlane, 
      hv_ColumnsTouchingPointInPlane, "m", &hv_TouchingPointPlanePointsCamX, &hv_TouchingPointPlanePointsCamY);
  TupleGenConst(hv_TouchingPointPlanePointsCamY.TupleLength(), 0.0, &hv_TouchingPointPlanePointsCamZ);
  PoseInvert(hv_TouchingPointPlaneInBasePose, &hv_BaseInTouchingPointPlanePose);
  PoseToHomMat3d(hv_BaseInTouchingPointPlanePose, &hv_HomMat3D1);
  AffineTransPoint3d(hv_HomMat3D1, hv_XBase, hv_YBase, hv_ZBase, &hv_TouchingPointPlanePointsToolX, 
      &hv_TouchingPointPlanePointsToolY, &hv_TouchingPointPlanePointsToolZ);
  hv_DiffX = hv_TouchingPointPlanePointsCamX-hv_TouchingPointPlanePointsToolX;
  hv_DiffY = hv_TouchingPointPlanePointsCamY-hv_TouchingPointPlanePointsToolY;
  hv_DiffZ = hv_TouchingPointPlanePointsCamZ-hv_TouchingPointPlanePointsToolZ;
  hv_SqrDiff = ((hv_DiffX*hv_DiffX)+(hv_DiffY*hv_DiffY))+(hv_DiffZ*hv_DiffZ);
  hv_PlanePointsRMS = ((hv_SqrDiff.TupleSum())/(hv_DiffX.TupleLength())).TupleSqrt();
  hv_PlanePointsMaxDiff = (hv_SqrDiff.TupleSqrt()).TupleMax();
  //
  SetOriginPose(hv_TouchingPointPlaneInBasePose, 0, 0, hv_DistanceObjectTouchingPointToPlane, 
      &hv_PlaneInBasePose);
  SetOriginPose(hv_TouchingPointPlaneInCamPose, 0, 0, hv_DistanceObjectTouchingPointToPlane, 
      &hv_PlaneInCamPose);
  //
  //Convert to output pose type.
  ConvertPoseType(hv_BaseInCamPose, hv_OrderOfTransform0, hv_OrderOfRotation0, hv_ViewOfTransform0, 
      &hv_BaseInCamPose);
  ConvertPoseType(hv_PlaneInBasePose, hv_OrderOfTransform0, hv_OrderOfRotation0, 
      hv_ViewOfTransform0, &hv_PlaneInBasePose);
  ConvertPoseType(hv_PlaneInCamPose, hv_OrderOfTransform0, hv_OrderOfRotation0, hv_ViewOfTransform0, 
      &hv_PlaneInCamPose);
  //
  //Create output message.
  CreateMessage(&(*hv_HandEyeCalibData));
  SetMessageTuple((*hv_HandEyeCalibData), "CamParam", hv_CamParam);
  SetMessageTuple((*hv_HandEyeCalibData), "BaseInCamPose", hv_BaseInCamPose);
  SetMessageTuple((*hv_HandEyeCalibData), "PlaneInBasePose", hv_PlaneInBasePose);
  SetMessageTuple((*hv_HandEyeCalibData), "PlaneInCamPose0", hv_PlaneInCamPose);
  SetMessageTuple((*hv_HandEyeCalibData), "PlanePointsRMS", hv_PlanePointsRMS);
  SetMessageTuple((*hv_HandEyeCalibData), "PlanePointsMaxDiff", hv_PlanePointsMaxDiff);
  return;
}

// Chapter: Calibration / Hand-Eye
// Short Description: Calibrate the X, Y, Z coordinates of a touching point of a robot. 
void calibrate_robot_touching_point (HTuple hv_DataDir, HTuple *hv_RobotTouchingPointInToolCoordinates)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_WindowHandle, hv_WindowHandleGraphics;
  HTuple  hv_Index, hv_ToolInBasePoseTouchingPoint;
  HTupleVector  hvec_ToolInBasePosesTouchingPoint(1);

  //
  //Open a new window.
  open_new_window(&hv_WindowHandle, &hv_WindowHandleGraphics);
  //Display introduction.
  dev_disp_introduction(hv_WindowHandle, hv_WindowHandleGraphics);
  // stop(...); only in hdevelop
  //
  //Read three ToolInBasesPoses which are used
  //to calibrate the RobotTouchingPointInToolCoordinates.
  for (hv_Index=1; hv_Index<=3; hv_Index+=1)
  {
    ReadPose(((hv_DataDir+"tool_in_base_pose_touching_point_0")+hv_Index)+".dat", 
        &hv_ToolInBasePoseTouchingPoint);
    dev_disp_approach_pose_touching_point_instructions(hv_WindowHandle, hv_WindowHandleGraphics, 
        hv_Index);
    // stop(...); only in hdevelop
    //Collect poses in vector.
    hvec_ToolInBasePosesTouchingPoint[hv_Index-1] = HTupleVector(hv_ToolInBasePoseTouchingPoint);
  }
  HDevWindowStack::SetActive(hv_WindowHandleGraphics);
  if (HDevWindowStack::IsOpen())
    CloseWindow(HDevWindowStack::Pop());
  //
  //Calculate the coordinates of the touching point
  //of the robot with respect to the robot's tool.
  get_robot_touching_point_in_tool_coordinates(hvec_ToolInBasePosesTouchingPoint, 
      &(*hv_RobotTouchingPointInToolCoordinates));
  //
  //Visualize results.
  visualize_calibrated_touching_point((*hv_RobotTouchingPointInToolCoordinates), 
      hvec_ToolInBasePosesTouchingPoint, hv_WindowHandle);
  return;
}

// Chapter: Calibration / Monocular
// Short Description: Collect the data to calibrate a camera with a single image. 
void collect_single_image_calibration_data (HTuple hv_ImageCaltabFileName, HTuple hv_CalPlateDescr, 
    HTuple hv_CalPlateThickness, HTuple hv_StartCamParam, HTuple *hv_CalibObjectData)
{

  // Local iconic variables
  HObject  ho_ImageCaltab;

  // Local control variables
  HTuple  hv_FinderRow, hv_FinderColumn, hv_MarksPerRow;

  //
  //Read an image of the calibration plate
  //that is placed in the measurement plane of the robot.
  ReadImage(&ho_ImageCaltab, hv_ImageCaltabFileName);
  dev_disp_calibration_data_instructions(ho_ImageCaltab);
  // stop(...); only in hdevelop
  //
  //Specify the finder pattern of the calibration plate you used.
  //The information can usually be found in the used description file.
  hv_FinderRow.Clear();
  hv_FinderRow[0] = 13;
  hv_FinderRow[1] = 6;
  hv_FinderRow[2] = 6;
  hv_FinderRow[3] = 20;
  hv_FinderRow[4] = 20;
  hv_FinderColumn.Clear();
  hv_FinderColumn[0] = 15;
  hv_FinderColumn[1] = 6;
  hv_FinderColumn[2] = 24;
  hv_FinderColumn[3] = 6;
  hv_FinderColumn[4] = 24;
  //Specify the number of marks per row.
  hv_MarksPerRow = 31;
  //
  //Create output message.
  CreateMessage(&(*hv_CalibObjectData));
  SetMessageObj(ho_ImageCaltab, (*hv_CalibObjectData), "ImageCaltab");
  SetMessageTuple((*hv_CalibObjectData), "CalPlateDescr", hv_CalPlateDescr);
  SetMessageTuple((*hv_CalibObjectData), "CalPlateThickness", hv_CalPlateThickness);
  SetMessageTuple((*hv_CalibObjectData), "StartCamParam", hv_StartCamParam);
  SetMessageTuple((*hv_CalibObjectData), "FinderRow", hv_FinderRow);
  SetMessageTuple((*hv_CalibObjectData), "FinderColumn", hv_FinderColumn);
  SetMessageTuple((*hv_CalibObjectData), "MarksPerRow", hv_MarksPerRow);
  return;
}

// Chapter: Calibration / Monocular
// Short Description: Calibrate a camera with a single image. 
void calibrate_camera_and_plane_single_image (HTuple hv_CalibObjectData)
{

  // Local iconic variables
  HObject  ho_ImageCaltab;

  // Local control variables
  HTuple  hv_CalPlateDescr, hv_CalPlateThickness;
  HTuple  hv_StartCamParam, hv_CalibDataID, hv_ErrorCamCalibInPixel;
  HTuple  hv_CamParam, hv_PlaneInCamPose0, hv_PlaneInCamPose;

  read_message_obj(&ho_ImageCaltab, hv_CalibObjectData, "ImageCaltab");
  read_message_tuple(hv_CalibObjectData, "CalPlateDescr", &hv_CalPlateDescr);
  read_message_tuple(hv_CalibObjectData, "CalPlateThickness", &hv_CalPlateThickness);
  read_message_tuple(hv_CalibObjectData, "StartCamParam", &hv_StartCamParam);
  //
  //Check input
  if (0 != (HTuple(hv_StartCamParam[0])==HTuple("line_scan")))
  {
    throw HException("Line-scan cameras are not supported");
  }
  //
  //Create a HALCON calibration data model.
  CreateCalibData("calibration_object", 1, 1, &hv_CalibDataID);
  //Set the needed calibration information.
  SetCalibDataCamParam(hv_CalibDataID, 0, HTuple(), hv_StartCamParam);
  SetCalibDataCalibObject(hv_CalibDataID, 0, hv_CalPlateDescr);
  //Find the calibration plate.
  FindCalibObject(ho_ImageCaltab, hv_CalibDataID, 0, 0, 0, HTuple(), HTuple());
  //Calibrating from only one view requires some parameter to be excluded
  //from the optimization.
  SetCalibData(hv_CalibDataID, "camera", 0, "excluded_settings", "focus");
  //Calibrate the camera.
  CalibrateCameras(hv_CalibDataID, &hv_ErrorCamCalibInPixel);
  //Get the calibration results.
  GetCalibData(hv_CalibDataID, "camera", 0, "params", &hv_CamParam);
  GetCalibData(hv_CalibDataID, "calib_obj_pose", (HTuple(0).Append(0)), "pose", &hv_PlaneInCamPose0);
  SetOriginPose(hv_PlaneInCamPose0, 0, 0, hv_CalPlateThickness, &hv_PlaneInCamPose);
  //Convert pose to standard pose type.
  ConvertPoseType(hv_PlaneInCamPose, "Rp+T", "gba", "point", &hv_PlaneInCamPose);
  //
  //Add data to output message.
  SetMessageTuple(hv_CalibObjectData, "ErrorCamCalibInPixel", hv_ErrorCamCalibInPixel);
  SetMessageTuple(hv_CalibObjectData, "CamParam", hv_CamParam);
  SetMessageTuple(hv_CalibObjectData, "PlaneInCamPose", hv_PlaneInCamPose);
  //Clean up.
  ClearCalibData(hv_CalibDataID);
  return;
}

// Chapter: Transformations / Poses
// Short Description: Calculate the poses to grasp an object. 
void calculate_tool_in_base_robot_path_poses (HTupleVector/*{eTupleVector,Dim=1}*/ hvec_ToolInModelRobotPathPoses, 
    HTuple hv_ModelInBasePose, HTuple hv_Poses, HTupleVector/*{eTupleVector,Dim=1}*/ *hvec_ToolInBaseRobotPathPoses)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_OrderOfTransform, hv_OrderOfRotation;
  HTuple  hv_ViewOfTransform, hv_Index1, hv_ToolInBaseRobotPathPose;

  //
  read_message_tuple(hv_Poses, "OrderOfTransform", &hv_OrderOfTransform);
  read_message_tuple(hv_Poses, "OrderOfRotation", &hv_OrderOfRotation);
  read_message_tuple(hv_Poses, "ViewOfTransform", &hv_ViewOfTransform);
  //
  {
  HTuple end_val5 = HTuple(hvec_ToolInModelRobotPathPoses.Length())-1;
  HTuple step_val5 = 1;
  for (hv_Index1=0; hv_Index1.Continue(end_val5, step_val5); hv_Index1 += step_val5)
  {
    PoseCompose(hv_ModelInBasePose, hvec_ToolInModelRobotPathPoses[hv_Index1].T(), 
        &hv_ToolInBaseRobotPathPose);
    ConvertPoseType(hv_ToolInBaseRobotPathPose, hv_OrderOfTransform, hv_OrderOfRotation, 
        hv_ViewOfTransform, &hv_ToolInBaseRobotPathPose);
    (*hvec_ToolInBaseRobotPathPoses)[hv_Index1] = HTupleVector(hv_ToolInBaseRobotPathPose);
  }
  }
  return;
}

// Chapter: 3D Object Model / Features
void get_bounding_box_points_from_min_max (HTuple hv_BoundingBox, HTuple *hv_PX, 
    HTuple *hv_PY, HTuple *hv_PZ)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_Index;
  HTupleVector  hvec_Points(1);

  hvec_Points = (HTupleVector(1).Insert(0,HTupleVector(HTuple())));
  hvec_Points[0] = HTupleVector((HTuple(hv_BoundingBox[0]).TupleConcat(HTuple(hv_BoundingBox[1]))).TupleConcat(HTuple(hv_BoundingBox[2])));
  hvec_Points[1] = HTupleVector((HTuple(hv_BoundingBox[3]).TupleConcat(HTuple(hv_BoundingBox[1]))).TupleConcat(HTuple(hv_BoundingBox[2])));
  hvec_Points[2] = HTupleVector((HTuple(hv_BoundingBox[3]).TupleConcat(HTuple(hv_BoundingBox[4]))).TupleConcat(HTuple(hv_BoundingBox[2])));
  hvec_Points[3] = HTupleVector((HTuple(hv_BoundingBox[0]).TupleConcat(HTuple(hv_BoundingBox[4]))).TupleConcat(HTuple(hv_BoundingBox[2])));
  hvec_Points[4] = HTupleVector((HTuple(hv_BoundingBox[0]).TupleConcat(HTuple(hv_BoundingBox[1]))).TupleConcat(HTuple(hv_BoundingBox[5])));
  hvec_Points[5] = HTupleVector((HTuple(hv_BoundingBox[3]).TupleConcat(HTuple(hv_BoundingBox[1]))).TupleConcat(HTuple(hv_BoundingBox[5])));
  hvec_Points[6] = HTupleVector((HTuple(hv_BoundingBox[3]).TupleConcat(HTuple(hv_BoundingBox[4]))).TupleConcat(HTuple(hv_BoundingBox[5])));
  hvec_Points[7] = HTupleVector((HTuple(hv_BoundingBox[0]).TupleConcat(HTuple(hv_BoundingBox[4]))).TupleConcat(HTuple(hv_BoundingBox[5])));
  (*hv_PX) = HTuple();
  (*hv_PY) = HTuple();
  (*hv_PZ) = HTuple();
  for (hv_Index=0; hv_Index<=7; hv_Index+=1)
  {
    (*hv_PX) = (*hv_PX).TupleConcat(HTuple(hvec_Points[hv_Index].T()[0]));
    (*hv_PY) = (*hv_PY).TupleConcat(HTuple(hvec_Points[hv_Index].T()[1]));
    (*hv_PZ) = (*hv_PZ).TupleConcat(HTuple(hvec_Points[hv_Index].T()[2]));
  }
  return;
}

// Chapter: 3D Object Model / Transformations
void get_extent_by_axis (HTuple hv_OM3D, HTuple hv_XExtent, HTuple hv_YExtent, HTuple hv_ZExtent, 
    HTuple *hv_XExtentOut, HTuple *hv_YExtentOut, HTuple *hv_ZExtentOut)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_BB, hv_Index;

  (*hv_XExtentOut) = hv_XExtent;
  (*hv_YExtentOut) = hv_YExtent;
  (*hv_ZExtentOut) = hv_ZExtent;
  GetObjectModel3dParams(hv_OM3D, "bounding_box1", &hv_BB);
  {
  HTuple end_val4 = ((hv_BB.TupleLength())/6)-1;
  HTuple step_val4 = 1;
  for (hv_Index=0; hv_Index.Continue(end_val4, step_val4); hv_Index += step_val4)
  {
    (*hv_XExtentOut) = ((*hv_XExtentOut).TupleConcat(HTuple(hv_BB[hv_Index*6]))).TupleConcat(HTuple(hv_BB[(hv_Index*6)+3]));
    (*hv_YExtentOut) = ((*hv_YExtentOut).TupleConcat(HTuple(hv_BB[(hv_Index*6)+1]))).TupleConcat(HTuple(hv_BB[(hv_Index*6)+4]));
    (*hv_ZExtentOut) = ((*hv_ZExtentOut).TupleConcat(HTuple(hv_BB[(hv_Index*6)+2]))).TupleConcat(HTuple(hv_BB[(hv_Index*6)+5]));
  }
  }
  return;
}

// Chapter: Calibration / Hand-Eye
// Short Description: Get the coordinates of the central mark of the closest finder pattern. 
void get_nearest_finder_pattern_coordinates (HObject ho_CalibPlateImage, HTuple hv_RowNearFinderPattern, 
    HTuple hv_ColumNearFinderPattern, HTuple hv_CalibObjectData, HTuple *hv_RowFinderPattern, 
    HTuple *hv_ColumnFinderPattern)
{

  // Local iconic variables
  HObject  ho_Contours, ho_Region, ho_RegionUnion;

  // Local control variables
  HTuple  hv_CamParam, hv_CalPlateDescr, hv_MarksPerRow;
  HTuple  hv_FinderRow, hv_FinderColumn, hv_CalibDataID, hv_Exception;
  HTuple  hv_Row, hv_Column, hv_Index1, hv_Pose, hv_Area1;
  HTuple  hv_Row2, hv_Column2, hv_RowTmp, hv_ColTmp, hv_Diff;
  HTuple  hv_IndexFinal, hv_RowToApproach1, hv_ColToApproach1;
  HTuple  hv_XCal, hv_YCal, hv_ZCal, hv_XFP, hv_YFP, hv_HomMat3D;
  HTuple  hv_ZFP, hv_X1, hv_Y1, hv_Z1;

  //
  read_message_tuple(hv_CalibObjectData, "CamParam", &hv_CamParam);
  read_message_tuple(hv_CalibObjectData, "CalPlateDescr", &hv_CalPlateDescr);
  read_message_tuple(hv_CalibObjectData, "MarksPerRow", &hv_MarksPerRow);
  read_message_tuple(hv_CalibObjectData, "FinderRow", &hv_FinderRow);
  read_message_tuple(hv_CalibObjectData, "FinderColumn", &hv_FinderColumn);
  //
  //Check input.
  //
  //Check image coordinates.
  if (0 != (HTuple((hv_RowNearFinderPattern.TupleLength())>1).TupleOr((hv_ColumNearFinderPattern.TupleLength())>1)))
  {
    throw HException("Please specify only one image coordinate.");
  }
  //Check number of marks per row.
  if (0 != (hv_MarksPerRow<3))
  {
    throw HException("At least three marks per row are necessary for a valid finder pattern.");
  }
  //Find calibration plate.
  CreateCalibData("calibration_object", 1, 1, &hv_CalibDataID);
  SetCalibDataCamParam(hv_CalibDataID, 0, HTuple(), hv_CamParam);
  SetCalibDataCalibObject(hv_CalibDataID, 0, hv_CalPlateDescr);
  try
  {
    FindCalibObject(ho_CalibPlateImage, hv_CalibDataID, 0, 0, 0, HTuple(), HTuple());
  }
  // catch (Exception) 
  catch (HException &HDevExpDefaultException)
  {
    HDevExpDefaultException.ToHTuple(&hv_Exception);
    throw HException(HTuple("Calibration plate could not be find, please make sure that at least one finder pattern is visible."));
  }
  GetCalibDataObservPoints(hv_CalibDataID, 0, 0, 0, &hv_Row, &hv_Column, &hv_Index1, 
      &hv_Pose);
  GetCalibDataObservContours(&ho_Contours, hv_CalibDataID, "caltab", 0, 0, 0);
  //Get the finder pattern used to find the calibration plate.
  GenRegionContourXld(ho_Contours, &ho_Region, "filled");
  Union1(ho_Region, &ho_RegionUnion);
  AreaCenter(ho_RegionUnion, &hv_Area1, &hv_Row2, &hv_Column2);
  hv_RowTmp = (hv_Row-hv_Row2).TupleAbs();
  hv_ColTmp = (hv_Column-hv_Column2).TupleAbs();
  hv_Diff = ((hv_RowTmp*hv_RowTmp)+(hv_ColTmp*hv_ColTmp)).TupleSqrt();
  TupleFind(hv_Diff, hv_Diff.TupleMin(), &hv_IndexFinal);
  hv_RowToApproach1 = HTuple(hv_Row[hv_IndexFinal]);
  hv_ColToApproach1 = HTuple(hv_Column[hv_IndexFinal]);
  ClearCalibData(hv_CalibDataID);
  //Get remaining finder pattern.
  //
  //Get finder pattern in world coordinates.
  CaltabPoints(hv_CalPlateDescr, &hv_XCal, &hv_YCal, &hv_ZCal);
  hv_XFP = HTuple(hv_XCal[(hv_FinderRow*hv_MarksPerRow)+hv_FinderColumn]);
  hv_YFP = HTuple(hv_YCal[(hv_FinderRow*hv_MarksPerRow)+hv_FinderColumn]);
  //Get finder pattern in camera coordinates.
  PoseToHomMat3d(hv_Pose, &hv_HomMat3D);
  TupleGenConst(hv_XFP.TupleLength(), 0.0, &hv_ZFP);
  AffineTransPoint3d(hv_HomMat3D, hv_XFP, hv_YFP, hv_ZFP, &hv_X1, &hv_Y1, &hv_Z1);
  //Project into the image.
  Project3dPoint(hv_X1, hv_Y1, hv_Z1, hv_CamParam, &hv_Row, &hv_Column);
  //
  //Get the image coordinates that are the closest ones to the passed ones.
  hv_RowTmp = (hv_Row-hv_RowNearFinderPattern).TupleAbs();
  hv_ColTmp = (hv_Column-hv_ColumNearFinderPattern).TupleAbs();
  hv_Diff = ((hv_RowTmp*hv_RowTmp)+(hv_ColTmp*hv_ColTmp)).TupleSqrt();
  TupleFind(hv_Diff, hv_Diff.TupleMin(), &hv_IndexFinal);
  //Return the image coordinates.
  (*hv_RowFinderPattern) = HTuple(hv_Row[hv_IndexFinal]);
  (*hv_ColumnFinderPattern) = HTuple(hv_Column[hv_IndexFinal]);
  return;
}

// Chapter: Graphics / Text
void dev_disp_calibration_data_instructions2 (HObject ho_Image)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_Text;

  if (HDevWindowStack::IsOpen())
    DispObj(ho_Image, HDevWindowStack::GetActive());
  hv_Text = HTuple("If you did NOT use a standard HALCON calibration plate, ");
  hv_Text[1] = HTuple("but used create_caltab to create your own calibration plate,");
  hv_Text[2] = HTuple("please adapt the parameters FinderRow, FinderColumn, and MarksPerRow");
  hv_Text[3] = "in the code.";
  if (HDevWindowStack::IsOpen())
    DispText(HDevWindowStack::GetActive(),hv_Text, "window", "top", "left", "black", 
        HTuple(), HTuple());
  if (HDevWindowStack::IsOpen())
    DispText(HDevWindowStack::GetActive(),"Press Run (F5) to continue", "window", 
        "bottom", "right", "black", HTuple(), HTuple());
  return;
}

// Chapter: Matrix / Arithmetic
void get_rotation_axis (HTuple hv_MatRot, HTuple hv_MatRot0, HTuple *hv_RotationAxis, 
    HTuple *hv_DiffToIdentity)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_MatrixMultID, hv_Identity, hv_MatrixSubID;
  HTuple  hv_Values, hv_MatrixUID, hv_MatrixSID, hv_MatrixVID;
  HTuple  hv_SingularValues, hv_AbsSingularValues, hv_Indices;

  //
  //Get (R_i)^(-1)R_0
  MultMatrix(hv_MatRot, hv_MatRot0, "ATB", &hv_MatrixMultID);
  //Get some measure for how far the matrix is from the identity.
  CreateMatrix(3, 3, "identity", &hv_Identity);
  SubMatrix(hv_MatrixMultID, hv_Identity, &hv_MatrixSubID);
  GetFullMatrix(hv_MatrixSubID, &hv_Values);
  (*hv_DiffToIdentity) = (hv_Values*hv_Values).TupleSum();
  //Get its rotation axis.
  SvdMatrix(hv_MatrixSubID, "full", "both", &hv_MatrixUID, &hv_MatrixSID, &hv_MatrixVID);
  GetValueMatrix(hv_MatrixSID, ((HTuple(0).Append(1)).Append(2)), ((HTuple(0).Append(1)).Append(2)), 
      &hv_SingularValues);
  hv_AbsSingularValues = hv_SingularValues.TupleAbs();
  TupleSortIndex(hv_AbsSingularValues, &hv_Indices);
  GetValueMatrix(hv_MatrixVID, ((HTuple(0).Append(1)).Append(2)), (HTuple(hv_Indices[0]).TupleConcat(HTuple(hv_Indices[0]))).TupleConcat(HTuple(hv_Indices[0])), 
      &(*hv_RotationAxis));
  //Clear matrices.
  ClearMatrix(hv_MatrixMultID);
  ClearMatrix(hv_MatrixUID);
  ClearMatrix(hv_MatrixSID);
  ClearMatrix(hv_MatrixVID);
  ClearMatrix(hv_MatrixSubID);
  ClearMatrix(hv_Identity);
  return;
}

// Chapter: 3D Object Model / Creation
// Short Description: Generate 3D object models for the camera, the plane, the robot's base and the robot's tool in a stationary camera setup. 
void gen_current_setup_stationary_cam_object_model_3d (HTuple hv_ArrowThickness, 
    HTuple hv_ArrowLength, HTuple hv_CameraSize, HTuple hv_HandEyeCalibData, HTuple *hv_OM3DCamera, 
    HTuple *hv_OM3DPlane, HTuple *hv_OM3DBase, HTuple *hv_OM3DToolOrigin)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_CamParam, hv_PlaneInCamPose0, hv_BaseInCamPose;
  HTuple  hv_CX, hv_CY, hv_OptAxisPlaneX, hv_OptAxisPlaneY;
  HTuple  hv_HomMat3D, hv_OptAxisCamX, hv_OptAxisCamY, hv_OptAxisCamZ;
  HTuple  hv_ConeLength, hv_IdentityPose, hv_CameraSetupModelID;
  HTuple  hv_OM3DCameraOrigin, hv_OM3DConeOrig, hv_CamInBasePose;
  HTuple  hv_FactorBorder, hv_PlaneInBasePose;

  //This procedure generates the 3D object models of the camera and its
  //cone, the plane, the robot's base and the robot's tool at its
  //initial position.
  //
  read_message_tuple(hv_HandEyeCalibData, "CamParam", &hv_CamParam);
  read_message_tuple(hv_HandEyeCalibData, "PlaneInCamPose0", &hv_PlaneInCamPose0);
  read_message_tuple(hv_HandEyeCalibData, "BaseInCamPose", &hv_BaseInCamPose);
  //
  //Visualize base and tool in the origin.
  gen_robot_tool_and_base_object_model_3d(hv_ArrowThickness, hv_ArrowLength, &(*hv_OM3DToolOrigin), 
      &(*hv_OM3DBase));
  //Visualize camera.
  get_cam_par_data(hv_CamParam, "cx", &hv_CX);
  get_cam_par_data(hv_CamParam, "cy", &hv_CY);
  ImagePointsToWorldPlane(hv_CamParam, hv_PlaneInCamPose0, hv_CY, hv_CX, "m", &hv_OptAxisPlaneX, 
      &hv_OptAxisPlaneY);
  PoseToHomMat3d(hv_PlaneInCamPose0, &hv_HomMat3D);
  AffineTransPoint3d(hv_HomMat3D, hv_OptAxisPlaneX, hv_OptAxisPlaneY, 0, &hv_OptAxisCamX, 
      &hv_OptAxisCamY, &hv_OptAxisCamZ);
  hv_ConeLength = hv_OptAxisCamZ*1.1;
  //If the optical axis does not intersect the plane, we still want to visualize the camera.
  if (0 != (hv_ConeLength<=0.0))
  {
    hv_ConeLength = hv_CameraSize;
  }
  CreatePose(0, 0, 0, 0, 0, 0, "Rp+T", "gba", "point", &hv_IdentityPose);
  CreateCameraSetupModel(1, &hv_CameraSetupModelID);
  SetCameraSetupCamParam(hv_CameraSetupModelID, 0, HTuple(), hv_CamParam, hv_IdentityPose);
  gen_camera_setup_object_model_3d(hv_CameraSetupModelID, hv_CameraSize, hv_ConeLength, 
      &hv_OM3DCameraOrigin, &hv_OM3DConeOrig);
  ClearCameraSetupModel(hv_CameraSetupModelID);
  hv_OM3DCameraOrigin = hv_OM3DCameraOrigin.TupleConcat(hv_OM3DConeOrig);
  PoseInvert(hv_BaseInCamPose, &hv_CamInBasePose);
  RigidTransObjectModel3d(hv_OM3DCameraOrigin, hv_CamInBasePose, &(*hv_OM3DCamera));
  ClearObjectModel3d(hv_OM3DCameraOrigin);
  //
  //Create 3D object model of plane.
  hv_FactorBorder = 1.5;
  PoseCompose(hv_CamInBasePose, hv_PlaneInCamPose0, &hv_PlaneInBasePose);
  gen_ground_plane_object_model_3d((*hv_OM3DToolOrigin), (*hv_OM3DCamera), (*hv_OM3DBase), 
      hv_FactorBorder, hv_PlaneInBasePose, &(*hv_OM3DPlane));
  return;

}

// Chapter: Transformations / Misc
// Short Description: Obtain the pose of the matched model in the base coordinate system in a stationary camera setup. 
void obtain_3d_pose_of_match_stationary_cam (HTuple hv_Row, HTuple hv_Column, HTuple hv_Angle, 
    HTuple hv_HandEyeCalibData, HTuple hv_Poses, HTuple hv_RectificationData, HTuple *hv_ModelInBasePose)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_CamParam, hv_BaseInCamPose, hv_PlaneInModelPose;
  HTuple  hv_MatchingPlaneInCamPose, hv_RectifyImage, hv_ScaleRectification;
  HTuple  hv_OrderOfTransform, hv_OrderOfRotation, hv_ViewOfTransform;
  HTuple  hv_HomMat2DObject, hv_RowObject, hv_ColObject, hv_PXM;
  HTuple  hv_PYM, hv_HomMat3DObject, hv_ModelToMatchInPlanePose;
  HTuple  hv_ModelInPlanePose, hv_ModelInCamPose, hv_ModelToMatchInPlanePartRectPose;
  HTuple  hv_ModelInPlanePartRectPose, hv_CamInBasePose;

  //This procedure obtains the 3D pose from the model to the base of
  //the robot.
  read_message_tuple(hv_HandEyeCalibData, "CamParam", &hv_CamParam);
  read_message_tuple(hv_HandEyeCalibData, "BaseInCamPose", &hv_BaseInCamPose);
  read_message_tuple(hv_Poses, "PlaneInModelPose", &hv_PlaneInModelPose);
  read_message_tuple(hv_Poses, "MatchingPlaneInCamPose", &hv_MatchingPlaneInCamPose);
  read_message_tuple(hv_RectificationData, "RectifyImage", &hv_RectifyImage);
  if (0 != (hv_RectifyImage==HTuple("true")))
  {
    read_message_tuple(hv_RectificationData, "ScaleRectification", &hv_ScaleRectification);
  }
  //
  //Keep track of the pose type used by the robot.
  GetPoseType(hv_PlaneInModelPose, &hv_OrderOfTransform, &hv_OrderOfRotation, &hv_ViewOfTransform);
  //Convert to default pose type.
  ConvertPoseType(hv_MatchingPlaneInCamPose, "Rp+T", "gba", "point", &hv_MatchingPlaneInCamPose);
  ConvertPoseType(hv_PlaneInModelPose, "Rp+T", "gba", "point", &hv_PlaneInModelPose);
  if (0 != (HTuple(HTuple((hv_Row.TupleLength())==1).TupleAnd((hv_Column.TupleLength())==1)).TupleAnd((hv_Angle.TupleLength())==1)))
  {
    VectorAngleToRigid(0, 0, 0, hv_Row, hv_Column, hv_Angle, &hv_HomMat2DObject);
    //col = x, row = y
    if (0 != (hv_RectifyImage==HTuple("false")))
    {
      AffineTransPixel(hv_HomMat2DObject, 0, 0, &hv_RowObject, &hv_ColObject);
      ImagePointsToWorldPlane(hv_CamParam, hv_MatchingPlaneInCamPose, hv_RowObject, 
          hv_ColObject, "m", &hv_PXM, &hv_PYM);
      hv_HomMat3DObject.Clear();
      hv_HomMat3DObject.Append(HTuple(hv_HomMat2DObject[4]));
      hv_HomMat3DObject.Append(HTuple(hv_HomMat2DObject[3]));
      hv_HomMat3DObject.Append(0);
      hv_HomMat3DObject.Append(hv_PXM);
      hv_HomMat3DObject.Append(HTuple(hv_HomMat2DObject[1]));
      hv_HomMat3DObject.Append(HTuple(hv_HomMat2DObject[0]));
      hv_HomMat3DObject.Append(0);
      hv_HomMat3DObject.Append(hv_PYM);
      hv_HomMat3DObject.Append(0);
      hv_HomMat3DObject.Append(0);
      hv_HomMat3DObject.Append(1);
      hv_HomMat3DObject.Append(0);
      HomMat3dToPose(hv_HomMat3DObject, &hv_ModelToMatchInPlanePose);
      PoseCompose(hv_ModelToMatchInPlanePose, hv_PlaneInModelPose, &hv_ModelInPlanePose);
      PoseCompose(hv_MatchingPlaneInCamPose, hv_ModelInPlanePose, &hv_ModelInCamPose);
    }
    else if (0 != (hv_RectifyImage==HTuple("true")))
    {
      hv_HomMat3DObject.Clear();
      hv_HomMat3DObject.Append(HTuple(hv_HomMat2DObject[4]));
      hv_HomMat3DObject.Append(HTuple(hv_HomMat2DObject[3]));
      hv_HomMat3DObject.Append(0);
      hv_HomMat3DObject.Append(HTuple(hv_HomMat2DObject[5])*hv_ScaleRectification);
      hv_HomMat3DObject.Append(HTuple(hv_HomMat2DObject[1]));
      hv_HomMat3DObject.Append(HTuple(hv_HomMat2DObject[0]));
      hv_HomMat3DObject.Append(0);
      hv_HomMat3DObject.Append(HTuple(hv_HomMat2DObject[2])*hv_ScaleRectification);
      hv_HomMat3DObject.Append(0);
      hv_HomMat3DObject.Append(0);
      hv_HomMat3DObject.Append(1);
      hv_HomMat3DObject.Append(0);
      HomMat3dToPose(hv_HomMat3DObject, &hv_ModelToMatchInPlanePartRectPose);
      PoseCompose(hv_ModelToMatchInPlanePartRectPose, hv_PlaneInModelPose, &hv_ModelInPlanePartRectPose);
      PoseCompose(hv_MatchingPlaneInCamPose, hv_ModelInPlanePartRectPose, &hv_ModelInCamPose);
    }
    else
    {
      throw HException("Please set the parameter RectifyImage correctly");
    }
    PoseInvert(hv_BaseInCamPose, &hv_CamInBasePose);
    PoseCompose(hv_CamInBasePose, hv_ModelInCamPose, &(*hv_ModelInBasePose));
    //
    ConvertPoseType((*hv_ModelInBasePose), hv_OrderOfTransform, hv_OrderOfRotation, 
        hv_ViewOfTransform, &(*hv_ModelInBasePose));
  }
  else
  {
    throw HException("Exactly one match should be given as input");
  }
  return;
}

// Chapter: Graphics / Window
// Short Description: Open a new window next to an existing one. 
void open_new_window (HTuple *hv_WindowHandle, HTuple *hv_WindowHandleGraphics)
{

  // Local control variables
  HTuple  hv_Row, hv_Column, hv_Width, hv_Height;

  WaitSeconds(0.1);
  if (HDevWindowStack::IsOpen())
    (*hv_WindowHandle) = HDevWindowStack::GetActive();
  GetWindowExtents((*hv_WindowHandle), &hv_Row, &hv_Column, &hv_Width, &hv_Height);
  dev_open_window_fit_size(0, hv_Width+8, hv_Width, hv_Height, 600, -1, &(*hv_WindowHandleGraphics));
  set_display_font((*hv_WindowHandleGraphics), 14, "mono", "true", "false");
  SetPartStyle((*hv_WindowHandleGraphics), 2);
  return;
}

// Chapter: Graphics / Text
void dev_disp_calibration_data_instructions (HObject ho_Image)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_Text;

  if (HDevWindowStack::IsOpen())
    DispObj(ho_Image, HDevWindowStack::GetActive());
  hv_Text = HTuple("In the code, please");
  hv_Text[1] = HTuple("- read an image of a calibration plate in the measurement plane,");
  hv_Text[2] = HTuple("- specify the location of the calibration plate description file,");
  hv_Text[3] = "- specify the thickness of the calibration plate (in meters) and";
  hv_Text[4] = "- specify initial camera parameters.";
  hv_Text[5] = "";
  hv_Text[6] = HTuple(" (If you did NOT use a standard HALCON calibration plate, ");
  hv_Text[7] = HTuple("  but used create_caltab to create your own calibration plate,");
  hv_Text[8] = HTuple("  you also need to adapt the parameters FinderRow, FinderColumn,");
  hv_Text[9] = "  and MarksPerRow accordingly.)";
  //
  if (HDevWindowStack::IsOpen())
    DispText(HDevWindowStack::GetActive(),hv_Text, "window", "top", "left", "black", 
        HTuple(), HTuple());
  if (HDevWindowStack::IsOpen())
    DispText(HDevWindowStack::GetActive(),"Press Run (F5) to continue", "window", 
        "bottom", "right", "black", HTuple(), HTuple());
  return;
}

// Chapter: 3D Object Model / Creation
// Short Description: Generate 3D object models for the camera and the robot's tool. 
void gen_camera_and_tool_moving_cam_object_model_3d (HTuple hv_ToolInCamPose, HTuple hv_ToolInBasePose, 
    HTuple hv_CameraSize, HTuple hv_ConeLength, HTuple hv_OM3DToolOrig, HTuple hv_CamParam, 
    HTuple *hv_OM3DCamera, HTuple *hv_OM3DTool)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_IdentityPose, hv_CameraSetupModelID;
  HTuple  hv_OM3DCameraOrigin, hv_OM3DConeOrig, hv_CamInToolPose;
  HTuple  hv_CamInBasePose;

  //This procedure helps visualize the camera and its cone, as well
  //as the robot's tool in their current positions.
  //
  //Visualize Tool.
  RigidTransObjectModel3d(hv_OM3DToolOrig, hv_ToolInBasePose, &(*hv_OM3DTool));
  //
  //Visualize Camera.
  CreatePose(0, 0, 0, 0, 0, 0, "Rp+T", "gba", "point", &hv_IdentityPose);
  CreateCameraSetupModel(1, &hv_CameraSetupModelID);
  SetCameraSetupCamParam(hv_CameraSetupModelID, 0, HTuple(), hv_CamParam, hv_IdentityPose);
  gen_camera_setup_object_model_3d(hv_CameraSetupModelID, hv_CameraSize, hv_ConeLength, 
      &hv_OM3DCameraOrigin, &hv_OM3DConeOrig);
  ClearCameraSetupModel(hv_CameraSetupModelID);
  hv_OM3DCameraOrigin = hv_OM3DCameraOrigin.TupleConcat(hv_OM3DConeOrig);
  //
  PoseInvert(hv_ToolInCamPose, &hv_CamInToolPose);
  PoseCompose(hv_ToolInBasePose, hv_CamInToolPose, &hv_CamInBasePose);
  RigidTransObjectModel3d(hv_OM3DCameraOrigin, hv_CamInBasePose, &(*hv_OM3DCamera));
  ClearObjectModel3d(hv_OM3DCameraOrigin);
  return;
}

// Chapter: 3D Object Model / Creation
// Short Description: Generate the 3D object model of the plane. 
void gen_ground_plane_object_model_3d (HTuple hv_OM3DTool, HTuple hv_OM3DCamera, 
    HTuple hv_OM3DBase, HTuple hv_FactorBorder, HTuple hv_PlaneInBasePose, HTuple *hv_OM3DPlane)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_XBase, hv_YBase, hv_ZBase, hv_MinXt;
  HTuple  hv_MinYt, hv_MinZt, hv_MaxXt, hv_MaxYt, hv_MaxZt;
  HTuple  hv_Min, hv_Max, hv_MinT, hv_MaxT, hv_BoundingBox;
  HTuple  hv_PXBB, hv_PYBB, hv_PZBB, hv_BaseInPlanePose, hv_HomMat3D;
  HTuple  hv_PX, hv_PY, hv_PZ, hv_Qx, hv_Qx1, hv_Qy, hv_Qy1;
  HTuple  hv_XPlane, hv_YPlane, hv_ZPlane, hv_HomMat3D1, hv_Qx2;
  HTuple  hv_Qy2, hv_Qz, hv_Faces;

  //This procedure generates the 3D object model of
  //the plane on which objects are matched and grasped.
  //
  hv_XBase = HTuple();
  hv_YBase = HTuple();
  hv_ZBase = HTuple();
  //Extent of tool in base coordinates.
  get_extent_by_axis(hv_OM3DTool, hv_XBase, hv_YBase, hv_ZBase, &hv_XBase, &hv_YBase, 
      &hv_ZBase);
  //Extent of camera in base coordinates.
  get_extent_by_axis(hv_OM3DCamera, hv_XBase, hv_YBase, hv_ZBase, &hv_XBase, &hv_YBase, 
      &hv_ZBase);
  //Extent of base in base coordinates.
  get_extent_by_axis(hv_OM3DBase, hv_XBase, hv_YBase, hv_ZBase, &hv_XBase, &hv_YBase, 
      &hv_ZBase);
  //
  //Joint bounding box.
  hv_MinXt = hv_XBase.TupleMin();
  hv_MinYt = hv_YBase.TupleMin();
  hv_MinZt = hv_ZBase.TupleMin();
  hv_MaxXt = hv_XBase.TupleMax();
  hv_MaxYt = hv_YBase.TupleMax();
  hv_MaxZt = hv_ZBase.TupleMax();
  hv_Min.Clear();
  hv_Min.Append(hv_MinXt);
  hv_Min.Append(hv_MinYt);
  hv_Min.Append(hv_MinZt);
  hv_Max.Clear();
  hv_Max.Append(hv_MaxXt);
  hv_Max.Append(hv_MaxYt);
  hv_Max.Append(hv_MaxZt);
  //
  //Joint bounding box extended by a factor of FactorBorder.
  hv_MinT = ((hv_Max*(1.0-hv_FactorBorder))/2.0)+((hv_Min*(1.0+hv_FactorBorder))/2.0);
  hv_MaxT = ((hv_Max*(1.0+hv_FactorBorder))/2.0)+((hv_Min*(1.0-hv_FactorBorder))/2.0);
  hv_BoundingBox.Clear();
  hv_BoundingBox.Append(hv_MinT);
  hv_BoundingBox.Append(hv_MaxT);
  //
  //Get the eight corner points of the bounding box from the min/max representation.
  get_bounding_box_points_from_min_max(hv_BoundingBox, &hv_PXBB, &hv_PYBB, &hv_PZBB);

  //Transform to plane coordinates (z is direction of the normal of the plane).
  PoseInvert(hv_PlaneInBasePose, &hv_BaseInPlanePose);
  PoseToHomMat3d(hv_BaseInPlanePose, &hv_HomMat3D);
  AffineTransPoint3d(hv_HomMat3D, hv_PXBB, hv_PYBB, hv_PZBB, &hv_PX, &hv_PY, &hv_PZ);
  //
  //Get outline of projection onto the plane.
  hv_Qx = hv_PX.TupleMin();
  hv_Qx1 = hv_PX.TupleMax();
  hv_Qy = hv_PY.TupleMin();
  hv_Qy1 = hv_PY.TupleMax();
  hv_XPlane.Clear();
  hv_XPlane.Append(hv_Qx);
  hv_XPlane.Append(hv_Qx);
  hv_XPlane.Append(hv_Qx1);
  hv_XPlane.Append(hv_Qx1);
  hv_YPlane.Clear();
  hv_YPlane.Append(hv_Qy);
  hv_YPlane.Append(hv_Qy1);
  hv_YPlane.Append(hv_Qy1);
  hv_YPlane.Append(hv_Qy);
  TupleGenConst(4, 0, &hv_ZPlane);
  //
  //Transform back to base coordinates.
  PoseToHomMat3d(hv_PlaneInBasePose, &hv_HomMat3D1);
  AffineTransPoint3d(hv_HomMat3D1, hv_XPlane, hv_YPlane, hv_ZPlane, &hv_Qx2, &hv_Qy2, 
      &hv_Qz);
  //
  //Generate the visualization.
  GenObjectModel3dFromPoints(hv_Qx2, hv_Qy2, hv_Qz, &(*hv_OM3DPlane));
  hv_Faces = HTuple();
  hv_Faces = hv_Faces.TupleConcat(((((HTuple(4).Append(0)).Append(1)).Append(2)).Append(3)));
  SetObjectModel3dAttribMod((*hv_OM3DPlane), "polygons", HTuple(), hv_Faces);
  //
  return;
}

// Chapter: Graphics / Text
void dev_disp_approach_pose_touching_point_instructions (HTuple hv_WindowHandle, 
    HTuple hv_WindowHandleGraphics, HTuple hv_Index)
{

  // Local iconic variables
  HObject  ho_Image, ho_Rectangle;

  // Local control variables
  HTuple  hv_Text, hv_Color, hv_HighlighColumn;

  //
  HDevWindowStack::SetActive(hv_WindowHandle);
  if (HDevWindowStack::IsOpen())
    ClearWindow(HDevWindowStack::GetActive());
  hv_Text = "Calibrate touching point";
  hv_Text[1] = "";
  hv_Text[2] = "General workflow";
  hv_Text[3] = "----------------";
  hv_Text[4] = HTuple("Approach a fixed point in the plane with your gripper, and read the");
  hv_Text[5] = "pose as ToolInBasePoseTouchingPoint.";
  hv_Text[6] = HTuple("Then, approach the same point at least twice again, rotating the tool");
  hv_Text[7] = "around at least two axis and reading the corresponding ";
  hv_Text[8] = "ToolInBasePoseTouchingPoint.";
  hv_Text[9] = "";
  hv_Text[10] = ("Read ToolInBasePoseTouchingPoint "+hv_Index)+HTuple("/3, then press F5.");
  if (HDevWindowStack::IsOpen())
    DispText(HDevWindowStack::GetActive(),hv_Text, "window", "top", "left", "white", 
        "box", "false");
  if (HDevWindowStack::IsOpen())
    DispText(HDevWindowStack::GetActive(),"Press Run (F5) to continue", "window", 
        "bottom", "right", "black", HTuple(), HTuple());
  hv_Color = HTuple(3,"gray");
  hv_Color[hv_Index-1] = "#fbba00";
  if (HDevWindowStack::IsOpen())
    DispText(HDevWindowStack::GetActive(),"   1   ", "window", 255, 12, "black", 
        (HTuple("box_color").Append("shadow")), HTuple(hv_Color[0]).TupleConcat("false"));
  if (HDevWindowStack::IsOpen())
    DispText(HDevWindowStack::GetActive(),"   2   ", "window", 255, 112, "black", 
        (HTuple("box_color").Append("shadow")), HTuple(hv_Color[1]).TupleConcat("false"));
  if (HDevWindowStack::IsOpen())
    DispText(HDevWindowStack::GetActive(),"   3   ", "window", 255, 212, "black", 
        (HTuple("box_color").Append("shadow")), HTuple(hv_Color[2]).TupleConcat("false"));
  //
  HDevWindowStack::SetActive(hv_WindowHandleGraphics);
  if (HDevWindowStack::IsOpen())
    ClearWindow(HDevWindowStack::GetActive());
  ReadImage(&ho_Image, "3d_machine_vision/handeye/instruction_images/tool_in_base_pose_touching_point");
  if (HDevWindowStack::IsOpen())
    DispObj(ho_Image, HDevWindowStack::GetActive());
  hv_HighlighColumn = 255+(hv_Index*200);
  GenRectangle1(&ho_Rectangle, 320, hv_HighlighColumn-100, 630, hv_HighlighColumn+100);
  if (HDevWindowStack::IsOpen())
    SetLineWidth(HDevWindowStack::GetActive(),4);
  if (HDevWindowStack::IsOpen())
    SetDraw(HDevWindowStack::GetActive(),"margin");
  if (HDevWindowStack::IsOpen())
    SetColor(HDevWindowStack::GetActive(),"#fbba00");
  if (HDevWindowStack::IsOpen())
    DispObj(ho_Rectangle, HDevWindowStack::GetActive());
  if (HDevWindowStack::IsOpen())
    DispText(HDevWindowStack::GetActive(),"Read this pose", "image", 6350, hv_HighlighColumn-105, 
        "black", "box_color", "#fbba00");
  return;
}

// Chapter: 3D Object Model / Creation
// Short Description: Generate base and tool 3D models of the robot. 
void gen_robot_tool_and_base_object_model_3d (HTuple hv_ArrowThickness, HTuple hv_ArrowLength, 
    HTuple *hv_OM3DToolOrigin, HTuple *hv_OM3DBase)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_IdentityPose, hv_TransXPose, hv_OM3DToolXOrigin;
  HTuple  hv_TransYPose, hv_OM3DToolYOrigin, hv_TransZPose;
  HTuple  hv_OM3DToolZOrigin, hv_FactorVisBase, hv_OM3DBasePlate;
  HTuple  hv_OM3DBaseX, hv_OM3DBaseY, hv_OM3DBaseZ;

  //This procedure creates 3D models that represent the tool and the base
  //of the robot.
  //
  if (0 != (hv_ArrowThickness<=0))
  {
    throw HException("ArrowThickness should be > 0");
  }
  if (0 != (hv_ArrowLength<=0))
  {
    throw HException("ArrowLength should be > 0");
  }
  CreatePose(0, 0, 0, 0, 0, 0, "Rp+T", "gba", "point", &hv_IdentityPose);
  //
  //3D model for the tool.
  CreatePose(hv_ArrowLength, 0, 0, 0, 0, 0, "Rp+T", "gba", "point", &hv_TransXPose);
  gen_arrow_object_model_3d(hv_ArrowThickness, hv_IdentityPose, hv_TransXPose, &hv_OM3DToolXOrigin);
  CreatePose(0, hv_ArrowLength, 0, 0, 0, 0, "Rp+T", "gba", "point", &hv_TransYPose);
  gen_arrow_object_model_3d(hv_ArrowThickness, hv_IdentityPose, hv_TransYPose, &hv_OM3DToolYOrigin);
  CreatePose(0, 0, hv_ArrowLength, 0, 0, 0, "Rp+T", "gba", "point", &hv_TransZPose);
  gen_arrow_object_model_3d(hv_ArrowThickness, hv_IdentityPose, hv_TransZPose, &hv_OM3DToolZOrigin);
  (*hv_OM3DToolOrigin).Clear();
  (*hv_OM3DToolOrigin).Append(hv_OM3DToolXOrigin);
  (*hv_OM3DToolOrigin).Append(hv_OM3DToolYOrigin);
  (*hv_OM3DToolOrigin).Append(hv_OM3DToolZOrigin);
  //
  //3D model for the base.
  hv_FactorVisBase = hv_ArrowThickness*10;
  GenBoxObjectModel3d(hv_IdentityPose, hv_FactorVisBase*1.5, hv_FactorVisBase*1.5, 
      hv_FactorVisBase/12, &hv_OM3DBasePlate);
  CreatePose(hv_ArrowLength, 0, 0, 0, 0, 0, "Rp+T", "gba", "point", &hv_TransXPose);
  gen_arrow_object_model_3d(hv_ArrowThickness, hv_IdentityPose, hv_TransXPose, &hv_OM3DBaseX);
  CreatePose(0, hv_ArrowLength, 0, 0, 0, 0, "Rp+T", "gba", "point", &hv_TransYPose);
  gen_arrow_object_model_3d(hv_ArrowThickness, hv_IdentityPose, hv_TransYPose, &hv_OM3DBaseY);
  CreatePose(0, 0, hv_ArrowLength, 0, 0, 0, "Rp+T", "gba", "point", &hv_TransZPose);
  gen_arrow_object_model_3d(hv_ArrowThickness, hv_IdentityPose, hv_TransZPose, &hv_OM3DBaseZ);
  (*hv_OM3DBase).Clear();
  (*hv_OM3DBase).Append(hv_OM3DBaseX);
  (*hv_OM3DBase).Append(hv_OM3DBaseY);
  (*hv_OM3DBase).Append(hv_OM3DBaseZ);
  (*hv_OM3DBase).Append(hv_OM3DBasePlate);
  return;
}

// Chapter: Transformations / Misc
// Short Description: Calculate the touching point in tool coordinates. 
void get_robot_touching_point_in_tool_coordinates (HTupleVector/*{eTupleVector,Dim=1}*/ hvec_ToolInBasePosesTouchingPoint, 
    HTuple *hv_RobotTouchingPointInToolCoordinates)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_LHS, hv_RHS, hv_HomMat3D0, hv_Mat0;
  HTuple  hv_MatRot0, hv_MatTrans0, hv_Index, hv_HomMat3D;
  HTuple  hv_Mat, hv_MatRot, hv_MatTrans, hv_MatrixResultID;
  HTuple  hv_DetailedErrors, hv_MinDiffToIdentity, hv_MinCosAngle;
  HTuple  hv_Index1, hv_CosAngle, hv_MaxAngleBetweenRotationAxes;
  HTuple  hv_MatrixUID, hv_MatrixSID, hv_MatrixVID, hv_SingularValues;
  HTuple  hv_MinSingularValue;
  HTupleVector  hvec_RotationAxisRelativ(1), hvec_DiffToIdentity(1);

  //To estimate the touching point with respect to the tool coordinate system, we have to
  //arrange three equations in the following form:
  //Rp + T = q,
  //where R is a is the rotation matrix that rotates a point from the tool to the base coordinate
  //system and T is a translation that translates a point from the tool to the base coordinate.
  //q is the touching point with respect to the base coordinate system
  //and p the unknown touching point with respect to the tool coordinate system.
  //
  //Approaching the same point three times while rotating the tool leads to three rotation matrices
  //R0, R1 and R2 and three translations T0, T1 and T2.
  //Solving this equation for the unknown touching point yields therefore:
  //R0*p + T0 = q, R1*p + T1 = q and R2*p + T2 = q.
  //After building two equations in the form (R1-R0)*p = T0-T1 and (R2-R0)*p = T0-T2,
  //the DLT (direct linear transformation) can be used to efficiently solve for the unknown
  //touching point p.


  //Check input.
  if (0 != (HTuple(hvec_ToolInBasePosesTouchingPoint.Length())<3))
  {
    throw HException("Please specify at least three robot poses.");
  }

  //Initialize equation.
  CreateMatrix((HTuple(hvec_ToolInBasePosesTouchingPoint.Length())-1)*3, 3, 0, &hv_LHS);
  CreateMatrix((HTuple(hvec_ToolInBasePosesTouchingPoint.Length())-1)*3, 1, 0, &hv_RHS);
  hvec_RotationAxisRelativ = (HTupleVector(1).Insert(0,HTupleVector(HTuple())));
  hvec_DiffToIdentity = (HTupleVector(1).Insert(0,HTupleVector(HTuple())));
  //Decompose first pose.
  PoseToHomMat3d(hvec_ToolInBasePosesTouchingPoint[0].T(), &hv_HomMat3D0);
  CreateMatrix(3, 4, hv_HomMat3D0, &hv_Mat0);
  GetSubMatrix(hv_Mat0, 0, 0, 3, 3, &hv_MatRot0);
  GetSubMatrix(hv_Mat0, 0, 3, 3, 1, &hv_MatTrans0);
  //
  {
  HTuple end_val33 = HTuple(hvec_ToolInBasePosesTouchingPoint.Length())-1;
  HTuple step_val33 = 1;
  for (hv_Index=1; hv_Index.Continue(end_val33, step_val33); hv_Index += step_val33)
  {
    //Decompose current pose.
    PoseToHomMat3d(hvec_ToolInBasePosesTouchingPoint[hv_Index].T(), &hv_HomMat3D);
    CreateMatrix(3, 4, hv_HomMat3D, &hv_Mat);
    GetSubMatrix(hv_Mat, 0, 0, 3, 3, &hv_MatRot);
    GetSubMatrix(hv_Mat, 0, 3, 3, 1, &hv_MatTrans);
    //Get rotation axis relativ to first pose.
    {
    HTuple ExpTmpOutVar_0;HTuple ExpTmpOutVar_1;
    get_rotation_axis(hv_MatRot, hv_MatRot0, &ExpTmpOutVar_0, &ExpTmpOutVar_1);
    hvec_RotationAxisRelativ[hv_Index].T() = ExpTmpOutVar_0;
    hvec_DiffToIdentity[hv_Index].T() = ExpTmpOutVar_1;
    }
    //Fill equation.
    SubMatrixMod(hv_MatRot, hv_MatRot0);
    SetSubMatrix(hv_LHS, hv_MatRot, (hv_Index-1)*3, 0);
    SubMatrixMod(hv_MatTrans, hv_MatTrans0);
    ScaleMatrixMod(hv_MatTrans, -1.0);
    SetSubMatrix(hv_RHS, hv_MatTrans, (hv_Index-1)*3, 0);
    //Clear.
    ClearMatrix(hv_Mat);
    ClearMatrix(hv_MatRot);
    ClearMatrix(hv_MatTrans);
  }
  }
  //Solve.
  SolveMatrix(hv_LHS, "general", 0, hv_RHS, &hv_MatrixResultID);
  GetFullMatrix(hv_MatrixResultID, &(*hv_RobotTouchingPointInToolCoordinates));
  //Detailed errors.
  hv_DetailedErrors = 0;
  if (0 != hv_DetailedErrors)
  {
    //Check that the tool was tilted enough compared to the first pose.
    hv_MinDiffToIdentity = 1e8;
    {
    HTuple end_val60 = HTuple(hvec_ToolInBasePosesTouchingPoint.Length())-1;
    HTuple step_val60 = 1;
    for (hv_Index=1; hv_Index.Continue(end_val60, step_val60); hv_Index += step_val60)
    {
      if (0 != (hvec_DiffToIdentity[hv_Index].T()<hv_MinDiffToIdentity))
      {
        hv_MinDiffToIdentity = hvec_DiffToIdentity[hv_Index].T();
      }
    }
    }
    //Check that different rotation axis were used when tilted away from first pose.
    hv_MinCosAngle = 1.5;
    {
    HTuple end_val67 = HTuple(hvec_ToolInBasePosesTouchingPoint.Length())-2;
    HTuple step_val67 = 1;
    for (hv_Index=1; hv_Index.Continue(end_val67, step_val67); hv_Index += step_val67)
    {
      {
      HTuple end_val68 = HTuple(hvec_ToolInBasePosesTouchingPoint.Length())-1;
      HTuple step_val68 = 1;
      for (hv_Index1=hv_Index+1; hv_Index1.Continue(end_val68, step_val68); hv_Index1 += step_val68)
      {
        hv_CosAngle = ((hvec_RotationAxisRelativ[hv_Index].T()*hvec_RotationAxisRelativ[hv_Index1].T()).TupleSum()).TupleAbs();
        if (0 != (hv_CosAngle<hv_MinCosAngle))
        {
          hv_MinCosAngle = hv_CosAngle;
        }
      }
      }
    }
    }
    hv_MaxAngleBetweenRotationAxes = (hv_MinCosAngle.TupleAcos()).TupleDeg();
  }
  SvdMatrix(hv_LHS, "full", "both", &hv_MatrixUID, &hv_MatrixSID, &hv_MatrixVID);
  GetValueMatrix(hv_MatrixSID, ((HTuple(0).Append(1)).Append(2)), ((HTuple(0).Append(1)).Append(2)), 
      &hv_SingularValues);
  hv_MinSingularValue = (hv_SingularValues.TupleAbs()).TupleMin();
  if (0 != (hv_MinSingularValue<0.15))
  {
    //Consider the rotations of the tool from its first position to each following position.
    //Please rotate the tool enough away from the first position.
    //Furthermore, please use at least two significantly different rotation axis when rotating the tool
    //from its first position (preferably orthogonal directions?).
    //The maximum angle between the corresponding rotation axis is MaxAngleBetweenRotationAxes.
    //
    throw HException("The estimated touching point might not be reliable. Try to use at least two different rotation axis and/or increase the rotations around these axis.");
  }
  //
  //Clear.
  ClearMatrix(hv_MatrixUID);
  ClearMatrix(hv_MatrixSID);
  ClearMatrix(hv_MatrixVID);
  ClearMatrix(hv_Mat0);
  ClearMatrix(hv_MatRot0);
  ClearMatrix(hv_MatTrans0);
  ClearMatrix(hv_LHS);
  ClearMatrix(hv_RHS);
  return;
}

// Chapter: Transformations / Misc
// Short Description: Obtain the pose of the matched model in the base coordinate system. 
void obtain_3d_pose_of_match_moving_cam (HTuple hv_Row, HTuple hv_Column, HTuple hv_Angle, 
    HTuple hv_ToolInBasePose, HTuple hv_HandEyeCalibData, HTuple hv_Poses, HTuple hv_RectificationData, 
    HTuple *hv_ModelInBasePose)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_CamParam, hv_ToolInCamPose, hv_PlaneInModelPose;
  HTuple  hv_RectifyImage, hv_ScaleRectification, hv_MatchingPlaneRectifiedPartInCamPose;
  HTuple  hv_OrderOfTransform, hv_OrderOfRotation, hv_ViewOfTransform;
  HTuple  hv_HomMat2DObject, hv_RowObject, hv_ColObject, hv_PXM;
  HTuple  hv_PYM, hv_HomMat3DObject, hv_ModelToMatchInPlanePose;
  HTuple  hv_ModelInPlanePose, hv_ModelInCamPose, hv_ModelToMatchInPlanePartRectPose;
  HTuple  hv_ModelInMatchingPlaneRectifiedPartPose, hv_BaseInToolPose;
  HTuple  hv_BaseInCamPose, hv_CamInBasePose;

  //This procedure obtains the 3D pose from the model to the base of
  //the robot.
  read_message_tuple(hv_HandEyeCalibData, "CamParam", &hv_CamParam);
  read_message_tuple(hv_HandEyeCalibData, "ToolInCamPose", &hv_ToolInCamPose);
  read_message_tuple(hv_Poses, "PlaneInModelPose", &hv_PlaneInModelPose);
  read_message_tuple(hv_RectificationData, "RectifyImage", &hv_RectifyImage);
  if (0 != (hv_RectifyImage!=HTuple("no_rectification")))
  {
    read_message_tuple(hv_RectificationData, "ScaleRectification", &hv_ScaleRectification);
  }
  read_message_tuple(hv_RectificationData, "MatchingPlaneRectifiedPartInCamPose", 
      &hv_MatchingPlaneRectifiedPartInCamPose);
  //
  //Keep track of the pose type used by the robot.
  GetPoseType(hv_ToolInBasePose, &hv_OrderOfTransform, &hv_OrderOfRotation, &hv_ViewOfTransform);
  //Convert to default pose type.
  ConvertPoseType(hv_MatchingPlaneRectifiedPartInCamPose, "Rp+T", "gba", "point", 
      &hv_MatchingPlaneRectifiedPartInCamPose);
  ConvertPoseType(hv_PlaneInModelPose, "Rp+T", "gba", "point", &hv_PlaneInModelPose);
  ConvertPoseType(hv_ToolInBasePose, "Rp+T", "gba", "point", &hv_ToolInBasePose);
  ConvertPoseType(hv_ToolInCamPose, "Rp+T", "gba", "point", &hv_ToolInCamPose);
  if (0 != ((hv_Row.TupleLength())==1))
  {
    VectorAngleToRigid(0, 0, 0, hv_Row, hv_Column, hv_Angle, &hv_HomMat2DObject);
    //Col = x, Row = y.
    if (0 != (hv_RectifyImage==HTuple("no_rectification")))
    {
      AffineTransPixel(hv_HomMat2DObject, 0, 0, &hv_RowObject, &hv_ColObject);
      ImagePointsToWorldPlane(hv_CamParam, hv_MatchingPlaneRectifiedPartInCamPose, 
          hv_RowObject, hv_ColObject, "m", &hv_PXM, &hv_PYM);
      hv_HomMat3DObject.Clear();
      hv_HomMat3DObject.Append(HTuple(hv_HomMat2DObject[4]));
      hv_HomMat3DObject.Append(HTuple(hv_HomMat2DObject[3]));
      hv_HomMat3DObject.Append(0);
      hv_HomMat3DObject.Append(hv_PXM);
      hv_HomMat3DObject.Append(HTuple(hv_HomMat2DObject[1]));
      hv_HomMat3DObject.Append(HTuple(hv_HomMat2DObject[0]));
      hv_HomMat3DObject.Append(0);
      hv_HomMat3DObject.Append(hv_PYM);
      hv_HomMat3DObject.Append(0);
      hv_HomMat3DObject.Append(0);
      hv_HomMat3DObject.Append(1);
      hv_HomMat3DObject.Append(0);
      HomMat3dToPose(hv_HomMat3DObject, &hv_ModelToMatchInPlanePose);
      PoseCompose(hv_ModelToMatchInPlanePose, hv_PlaneInModelPose, &hv_ModelInPlanePose);
      PoseCompose(hv_MatchingPlaneRectifiedPartInCamPose, hv_ModelInPlanePose, &hv_ModelInCamPose);
    }
    else if (0 != (HTuple(hv_RectifyImage==HTuple("only_rectify")).TupleOr(hv_RectifyImage==HTuple("align_and_rectify"))))
    {
      hv_HomMat3DObject.Clear();
      hv_HomMat3DObject.Append(HTuple(hv_HomMat2DObject[4]));
      hv_HomMat3DObject.Append(HTuple(hv_HomMat2DObject[3]));
      hv_HomMat3DObject.Append(0);
      hv_HomMat3DObject.Append(HTuple(hv_HomMat2DObject[5])*hv_ScaleRectification);
      hv_HomMat3DObject.Append(HTuple(hv_HomMat2DObject[1]));
      hv_HomMat3DObject.Append(HTuple(hv_HomMat2DObject[0]));
      hv_HomMat3DObject.Append(0);
      hv_HomMat3DObject.Append(HTuple(hv_HomMat2DObject[2])*hv_ScaleRectification);
      hv_HomMat3DObject.Append(0);
      hv_HomMat3DObject.Append(0);
      hv_HomMat3DObject.Append(1);
      hv_HomMat3DObject.Append(0);
      HomMat3dToPose(hv_HomMat3DObject, &hv_ModelToMatchInPlanePartRectPose);
      PoseCompose(hv_ModelToMatchInPlanePartRectPose, hv_PlaneInModelPose, &hv_ModelInMatchingPlaneRectifiedPartPose);
      PoseCompose(hv_MatchingPlaneRectifiedPartInCamPose, hv_ModelInMatchingPlaneRectifiedPartPose, 
          &hv_ModelInCamPose);
    }
    else
    {
      throw HException("Please set the parameter RectifyImage correctly");
    }
    PoseInvert(hv_ToolInBasePose, &hv_BaseInToolPose);
    PoseCompose(hv_ToolInCamPose, hv_BaseInToolPose, &hv_BaseInCamPose);
    PoseInvert(hv_BaseInCamPose, &hv_CamInBasePose);
    PoseCompose(hv_CamInBasePose, hv_ModelInCamPose, &(*hv_ModelInBasePose));
    //
    ConvertPoseType((*hv_ModelInBasePose), hv_OrderOfTransform, hv_OrderOfRotation, 
        hv_ViewOfTransform, &(*hv_ModelInBasePose));
  }
  else
  {
    throw HException("Exactly one match should be given as input");
  }
  return;
}

// Chapter: 3D Object Model / Creation
// Short Description: Generate 3D object models for the camera, robot's tool and plane. 
void gen_current_setup_moving_cam_object_model_3d (HTuple hv_CameraSize, HTuple hv_ToolInBasePose, 
    HTuple hv_HandEyeCalibData, HTuple hv_OM3DToolOrigin, HTuple hv_OM3DBase, HTuple *hv_OM3DCamera, 
    HTuple *hv_OM3DTool, HTuple *hv_OM3DPlane)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_ToolInCamPose, hv_CamParam, hv_PlaneInBasePose0;
  HTuple  hv_BaseInToolPose, hv_PlaneInToolPose, hv_PlaneInCamPose;
  HTuple  hv_CX, hv_CY, hv_OptAxisPlaneX, hv_OptAxisPlaneY;
  HTuple  hv_HomMat3D, hv_OptAxisCamX, hv_OptAxisCamY, hv_OptAxisCamZ;
  HTuple  hv_ConeLength, hv_FactorBorder;

  //This procedure visualizes the camera, tool, and plane in their
  //current positions.
  //
  read_message_tuple(hv_HandEyeCalibData, "ToolInCamPose", &hv_ToolInCamPose);
  read_message_tuple(hv_HandEyeCalibData, "CamParam", &hv_CamParam);
  read_message_tuple(hv_HandEyeCalibData, "PlaneInBasePose0", &hv_PlaneInBasePose0);
  //
  if (0 != (hv_CameraSize<=0))
  {
    throw HException("CameraSize should be > 0");
  }
  //
  //Visualize current camera and tool position.
  //
  //Get the intersection of the optical axis of the camera and the plane
  PoseInvert(hv_ToolInBasePose, &hv_BaseInToolPose);
  PoseCompose(hv_BaseInToolPose, hv_PlaneInBasePose0, &hv_PlaneInToolPose);
  PoseCompose(hv_ToolInCamPose, hv_PlaneInToolPose, &hv_PlaneInCamPose);
  get_cam_par_data(hv_CamParam, "cx", &hv_CX);
  get_cam_par_data(hv_CamParam, "cy", &hv_CY);
  ImagePointsToWorldPlane(hv_CamParam, hv_PlaneInCamPose, hv_CY, hv_CX, "m", &hv_OptAxisPlaneX, 
      &hv_OptAxisPlaneY);
  //Transform to camera coordinates
  PoseToHomMat3d(hv_PlaneInCamPose, &hv_HomMat3D);
  AffineTransPoint3d(hv_HomMat3D, hv_OptAxisPlaneX, hv_OptAxisPlaneY, 0, &hv_OptAxisCamX, 
      &hv_OptAxisCamY, &hv_OptAxisCamZ);
  hv_ConeLength = hv_OptAxisCamZ*1.1;
  //If the optical axis does not intersect the plane, we still want to visualize the camera.
  if (0 != (hv_ConeLength<=0.0))
  {
    hv_ConeLength = hv_CameraSize;
  }
  gen_camera_and_tool_moving_cam_object_model_3d(hv_ToolInCamPose, hv_ToolInBasePose, 
      hv_CameraSize, hv_ConeLength, hv_OM3DToolOrigin, hv_CamParam, &(*hv_OM3DCamera), 
      &(*hv_OM3DTool));
  //
  //Create 3D object model of plane.
  hv_FactorBorder = 1.5;
  gen_ground_plane_object_model_3d((*hv_OM3DTool), (*hv_OM3DCamera), hv_OM3DBase, 
      hv_FactorBorder, hv_PlaneInBasePose0, &(*hv_OM3DPlane));
  return;
}

// Chapter: Graphics / Text
// Short Description: Display the introduction for the procedure calibrate_robot_touching_point. 
void dev_disp_introduction (HTuple hv_WindowHandle, HTuple hv_WindowHandleGraphics)
{

  // Local iconic variables
  HObject  ho_InstructionImage;

  // Local control variables
  HTuple  hv_Text, hv_Row, hv_Column, hv_Width;
  HTuple  hv_Height;

  //
  HDevWindowStack::SetActive(hv_WindowHandle);
  if (HDevWindowStack::IsOpen())
    ClearWindow(HDevWindowStack::GetActive());
  hv_Text = HTuple("With this procedure, we calibrate the coordinates of the touching point");
  hv_Text[1] = "of a robot with respect to the robot's tool.";
  hv_Text[2] = "";
  hv_Text[3] = "The touching point is a point that has to be fixed with respect to";
  hv_Text[4] = HTuple("the tool coordinate system, but does not have to be located on the");
  hv_Text[5] = HTuple("surface of the gripper. It can, for example, lie halfway between");
  hv_Text[6] = "two fingers of a gripper.";
  hv_Text[7] = "";
  hv_Text[8] = "The touching point should be chosen such that it can approach ";
  hv_Text[9] = "a point in the plane easily and accurately.";
  hv_Text[10] = "";
  hv_Text[11] = "The coordinates of this point (RobotTouchingPointInToolCoordinates)";
  hv_Text[12] = HTuple("are necessary, for example, to perform a hand-eye calibration of a robot");
  hv_Text[13] = "with a stationary camera.";
  hv_Text[14] = "";
  hv_Text[15] = "This procedure is used in the example";
  hv_Text[16] = "calibrate_hand_eye_stationary_cam_approx.hdev.";
  if (HDevWindowStack::IsOpen())
    DispText(HDevWindowStack::GetActive(),hv_Text, "window", "top", "left", "white", 
        "box", "false");
  if (HDevWindowStack::IsOpen())
    DispText(HDevWindowStack::GetActive(),"Press Run (F5) to continue", "window", 
        "bottom", "right", "black", HTuple(), HTuple());
  //
  HDevWindowStack::SetActive(hv_WindowHandleGraphics);
  ReadImage(&ho_InstructionImage, "3d_machine_vision/handeye/instruction_images/robot_touching_point_in_tool_coordinates");
  GetWindowExtents(hv_WindowHandle, &hv_Row, &hv_Column, &hv_Width, &hv_Height);
  dev_resize_window_fit_image(ho_InstructionImage, 0, hv_Width+10, 600, -1);
  if (HDevWindowStack::IsOpen())
    DispObj(ho_InstructionImage, HDevWindowStack::GetActive());
  return;

}

// Chapter: 3D Object Model / Creation
// Short Description: Generate a 3D object of the matched model, in the case of rectification. 
void gen_matching_object_model_3d (HTuple hv_ModelID, HTuple hv_ObjectHeight, HTuple hv_Poses, 
    HTuple hv_HandEyeCalibData, HTuple hv_RectificationData, HTuple *hv_OM3DModel)
{

  // Local iconic variables
  HObject  ho_ModelContours, ho_ObjectSelected;

  // Local control variables
  HTuple  hv_CamParam, hv_MatchingPlaneInCamPose;
  HTuple  hv_RectifyImage, hv_ScaleRectification, hv_Number;
  HTuple  hv_ModelRows, hv_ModelCols, hv_Index, hv_Row1, hv_Col1;
  HTuple  hv_PX, hv_PY, hv_PXPlane, hv_PYPlane, hv_PXPlaneOrig;
  HTuple  hv_PYPlaneOrig, hv_PZ1, hv_PZ2, hv_PlanePartRectToModelPose;
  HTuple  hv_HomMat3D, hv_Qx, hv_Qy, hv_Qz;

  //This procedure generates a 3D model from a shape model for
  //visualization for a known (rectified) matching plane.
  //
  //The 3D model consists of the model-contours transformed to
  //their real world size. The origin of the 3D model coordinate system
  //lies in the origin of the input shape model with the z-axis
  //pointing towards the camera. The model contours are displayed
  //twice, at z = 0 and z = ObjectHeight.
  //
  read_message_tuple(hv_HandEyeCalibData, "CamParam", &hv_CamParam);
  read_message_tuple(hv_Poses, "MatchingPlaneInCamPose", &hv_MatchingPlaneInCamPose);
  read_message_tuple(hv_RectificationData, "RectifyImage", &hv_RectifyImage);
  if (0 != (HTuple(HTuple(hv_RectifyImage==HTuple("true")).TupleOr(hv_RectifyImage==HTuple("only_rectify"))).TupleOr(hv_RectifyImage==HTuple("align_and_rectify"))))
  {
    read_message_tuple(hv_RectificationData, "ScaleRectification", &hv_ScaleRectification);
  }
  //
  //Get shape model contours.
  GetShapeModelContours(&ho_ModelContours, hv_ModelID, 1);
  CountObj(ho_ModelContours, &hv_Number);
  hv_ModelRows = HTuple();
  hv_ModelCols = HTuple();
  {
  HTuple end_val21 = hv_Number;
  HTuple step_val21 = 1;
  for (hv_Index=1; hv_Index.Continue(end_val21, step_val21); hv_Index += step_val21)
  {
    SelectObj(ho_ModelContours, &ho_ObjectSelected, hv_Index);
    GetContourXld(ho_ObjectSelected, &hv_Row1, &hv_Col1);
    hv_ModelRows = hv_ModelRows.TupleConcat(hv_Row1);
    hv_ModelCols = hv_ModelCols.TupleConcat(hv_Col1);
  }
  }
  //Obtain real world size (col = x, row = y), centered around the shape model origin (0,0).
  if (0 != (HTuple(HTuple(hv_RectifyImage==HTuple("true")).TupleOr(hv_RectifyImage==HTuple("only_rectify"))).TupleOr(hv_RectifyImage==HTuple("align_and_rectify"))))
  {
    hv_PX = hv_ModelCols*hv_ScaleRectification;
    hv_PY = hv_ModelRows*hv_ScaleRectification;
  }
  else
  {
    ImagePointsToWorldPlane(hv_CamParam, hv_MatchingPlaneInCamPose, hv_ModelRows, 
        hv_ModelCols, "m", &hv_PXPlane, &hv_PYPlane);
    ImagePointsToWorldPlane(hv_CamParam, hv_MatchingPlaneInCamPose, 0, 0, "m", &hv_PXPlaneOrig, 
        &hv_PYPlaneOrig);
    hv_PX = hv_PXPlane-hv_PXPlaneOrig;
    hv_PY = hv_PYPlane-hv_PYPlaneOrig;
  }
  //Display the contours twice, once in the plane, once above.
  TupleGenConst(hv_PY.TupleLength(), 0, &hv_PZ1);
  TupleGenConst(hv_PY.TupleLength(), hv_ObjectHeight, &hv_PZ2);
  //Transform from plane to model coordinate system. The plane
  //coordinate system has previously been adapted such that its
  //z-axis points away from the camera.
  CreatePose(0, 0, hv_ObjectHeight, 180, 0, 0, "Rp+T", "gba", "point", &hv_PlanePartRectToModelPose);
  PoseToHomMat3d(hv_PlanePartRectToModelPose, &hv_HomMat3D);
  AffineTransPoint3d(hv_HomMat3D, hv_PX.TupleConcat(hv_PX), hv_PY.TupleConcat(hv_PY), 
      hv_PZ1.TupleConcat(hv_PZ2), &hv_Qx, &hv_Qy, &hv_Qz);
  GenObjectModel3dFromPoints(hv_Qx, hv_Qy, hv_Qz, &(*hv_OM3DModel));
  return;
}

// Chapter: 3D Object Model / Creation
void gen_tool_to_touching_point_object_model_3d (HTupleVector/*{eTupleVector,Dim=1}*/ hvec_ToolInBasePosesTouchingPoint, 
    HTuple hv_RobotTouchingPointInToolCoordinates, HTuple *hv_OM3DToolTouchingPoint)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_OM3DToolOrigin, hv_OM3DToolTouchingPointTmp;
  HTuple  hv_Index, hv_OM3DRigidTrans, hv_OM3DBase;

  //
  gen_robot_tool_and_base_object_model_3d(0.0025, 0.05, &hv_OM3DToolOrigin, &hv_OM3DBase);
  GenObjectModel3dFromPoints(HTuple(0).TupleConcat(HTuple(hv_RobotTouchingPointInToolCoordinates[0])), 
      HTuple(0).TupleConcat(HTuple(hv_RobotTouchingPointInToolCoordinates[1])), HTuple(0).TupleConcat(HTuple(hv_RobotTouchingPointInToolCoordinates[2])), 
      &(*hv_OM3DToolTouchingPoint));
  SetObjectModel3dAttribMod((*hv_OM3DToolTouchingPoint), "lines", HTuple(), ((HTuple(2).Append(0)).Append(1)));
  hv_OM3DToolTouchingPointTmp.Clear();
  hv_OM3DToolTouchingPointTmp.Append(hv_OM3DToolOrigin);
  hv_OM3DToolTouchingPointTmp.Append((*hv_OM3DToolTouchingPoint));
  //
  (*hv_OM3DToolTouchingPoint) = HTuple();
  {
  HTuple end_val7 = HTuple(hvec_ToolInBasePosesTouchingPoint.Length())-1;
  HTuple step_val7 = 1;
  for (hv_Index=0; hv_Index.Continue(end_val7, step_val7); hv_Index += step_val7)
  {
    RigidTransObjectModel3d(hv_OM3DToolTouchingPointTmp, hvec_ToolInBasePosesTouchingPoint[hv_Index].T(), 
        &hv_OM3DRigidTrans);
    (*hv_OM3DToolTouchingPoint) = (*hv_OM3DToolTouchingPoint).TupleConcat(hv_OM3DRigidTrans);
  }
  }
  return;
}

// Chapter: Calibration / Hand-Eye
// Short Description: Prepares the model to match and grasp in a stationary camera setup. 
void prepare_poses_and_rectification_data_stationary_cam (HTuple hv_ObjectHeight, 
    HTuple hv_RectifyImage, HTuple hv_HandEyeCalibData, HTuple *hv_Poses, HTuple *hv_RectificationData)
{

  // Local iconic variables
  HObject  ho_RegionGrid, ho_ContCircle, ho_ContCircleWorldPlane;
  HObject  ho_ImageArea, ho_RegionBorder, ho_RectificationMap;

  // Local control variables
  HTuple  hv_CamParam, hv_PlaneInCamPose0, hv_OrderOfTransform;
  HTuple  hv_OrderOfRotation, hv_ViewOfTransform, hv_PlaneInCamPose0Rot;
  HTuple  hv_HomMat3D, hv_Qx, hv_Qy, hv_CosAngleBetweenZAxis;
  HTuple  hv_SwitchZDirection, hv_PlaneInCamPose, hv_MatchingPlaneInPlanePose;
  HTuple  hv_MatchingPlaneInCamPose, hv_ScaleRectification;
  HTuple  hv_Width, hv_Height, hv_Rows, hv_Columns, hv_Row;
  HTuple  hv_Column, hv_Phi, hv_Radius1, hv_Radius2, hv_StartPhi;
  HTuple  hv_EndPhi, hv_PointOrder, hv_ClipRegion, hv_BorderRows;
  HTuple  hv_BorderColumns, hv_BorderX, hv_BorderY, hv_PoseOffset;
  HTuple  hv_WidthRect, hv_HeightRect, hv_ModelInPlanePose;
  HTuple  hv_PlaneInModelPose;

  //Prepare the needed poses to match and grasp, and compute the rectification
  //map in case rectification is set by the user.
  //
  read_message_tuple(hv_HandEyeCalibData, "CamParam", &hv_CamParam);
  read_message_tuple(hv_HandEyeCalibData, "PlaneInCamPose0", &hv_PlaneInCamPose0);
  //
  //Check input
  if (0 != (hv_ObjectHeight<0.0))
  {
    throw HException("The parameter ObjectHeight cannot be negative");
  }
  if (0 != (HTuple(hv_CamParam[0])==HTuple("line_scan")))
  {
    throw HException("Line-scan cameras are not supported");
  }
  //Keep track of the pose type used by the robot.
  GetPoseType(hv_PlaneInCamPose0, &hv_OrderOfTransform, &hv_OrderOfRotation, &hv_ViewOfTransform);
  //Convert to default pose type.
  ConvertPoseType(hv_PlaneInCamPose0, "Rp+T", "gba", "point", &hv_PlaneInCamPose0);
  //The z-axis of the plane should point away from the camera.
  hv_PlaneInCamPose0Rot = hv_PlaneInCamPose0;
  hv_PlaneInCamPose0Rot[HTuple::TupleGenSequence(0,2,1)] = ((HTuple(0).Append(0)).Append(0));
  PoseToHomMat3d(hv_PlaneInCamPose0Rot, &hv_HomMat3D);
  AffineTransPoint3d(hv_HomMat3D, 0, 0, 1, &hv_Qx, &hv_Qy, &hv_CosAngleBetweenZAxis);
  if (0 != (hv_CosAngleBetweenZAxis<0))
  {
    CreatePose(0, 0, 0, 180, 0, 0, "Rp+T", "gba", "point", &hv_SwitchZDirection);
    PoseCompose(hv_PlaneInCamPose0, hv_SwitchZDirection, &hv_PlaneInCamPose0);
  }
  //Align with the current image.
  hv_PlaneInCamPose = hv_PlaneInCamPose0;
  hv_PlaneInCamPose[5] = 0.0;
  //
  //Create the plane for matching.
  CreatePose(0, 0, -hv_ObjectHeight, 0, 0, 0, "Rp+T", "gba", "point", &hv_MatchingPlaneInPlanePose);
  PoseCompose(hv_PlaneInCamPose, hv_MatchingPlaneInPlanePose, &hv_MatchingPlaneInCamPose);
  //
  if (0 != (hv_RectifyImage==HTuple("false")))
  {
    hv_ScaleRectification = HTuple();
  }
  else if (0 != (hv_RectifyImage==HTuple("true")))
  {
    //Determine the scale such that the mapped image has at least the same
    //resolution as the current image.
    get_cam_par_data(hv_CamParam, "image_width", &hv_Width);
    get_cam_par_data(hv_CamParam, "image_height", &hv_Height);
    GenGridRegion(&ho_RegionGrid, 20, 20, "points", hv_Width, hv_Height);
    GetRegionPoints(ho_RegionGrid, &hv_Rows, &hv_Columns);
    GenCircleContourXld(&ho_ContCircle, hv_Rows, hv_Columns, HTuple(hv_Rows.TupleLength(),1.0), 
        0, 6.28318, "positive", 0.1);
    ContourToWorldPlaneXld(ho_ContCircle, &ho_ContCircleWorldPlane, hv_CamParam, 
        hv_MatchingPlaneInCamPose, "m");
    FitEllipseContourXld(ho_ContCircleWorldPlane, "fitzgibbon", -1, 0, 0, 200, 3, 
        2, &hv_Row, &hv_Column, &hv_Phi, &hv_Radius1, &hv_Radius2, &hv_StartPhi, 
        &hv_EndPhi, &hv_PointOrder);
    hv_ScaleRectification = hv_Radius2.TupleMin();
    //
    //Rectify the current image and create the shape model.
    //
    //The image dimensions should cover the entire original field of view
    //in the current rectification.
    //Look at border of the current image in the world plane.
    GetSystem("clip_region", &hv_ClipRegion);
    SetSystem("clip_region", "false");
    GenRectangle1(&ho_ImageArea, 0, 0, hv_Height-1, hv_Width-1);
    Boundary(ho_ImageArea, &ho_RegionBorder, "outer");
    SetSystem("clip_region", hv_ClipRegion);
    GetRegionPoints(ho_RegionBorder, &hv_BorderRows, &hv_BorderColumns);
    ImagePointsToWorldPlane(hv_CamParam, hv_MatchingPlaneInCamPose, hv_BorderRows, 
        hv_BorderColumns, "m", &hv_BorderX, &hv_BorderY);
    //Adapt parameters.
    CreatePose(hv_BorderX.TupleMin(), hv_BorderY.TupleMin(), 0, 0, 0, 0, "Rp+T", 
        "gba", "point", &hv_PoseOffset);
    PoseCompose(hv_MatchingPlaneInCamPose, hv_PoseOffset, &hv_MatchingPlaneInCamPose);
    hv_WidthRect = ((((hv_BorderX.TupleMax())-(hv_BorderX.TupleMin()))/hv_ScaleRectification)+0.5).TupleInt();
    hv_HeightRect = ((((hv_BorderY.TupleMax())-(hv_BorderY.TupleMin()))/hv_ScaleRectification)+0.5).TupleInt();
    //
    //Create a map for repeated use.
    GenImageToWorldPlaneMap(&ho_RectificationMap, hv_CamParam, hv_MatchingPlaneInCamPose, 
        hv_Width, hv_Height, hv_WidthRect, hv_HeightRect, hv_ScaleRectification, 
        "bilinear");
  }
  else
  {
    throw HException("Please set the parameter RectifyImage correctly");
  }
  //Convert to output pose type.
  ConvertPoseType(hv_PlaneInCamPose, hv_OrderOfTransform, hv_OrderOfRotation, hv_ViewOfTransform, 
      &hv_PlaneInCamPose);
  ConvertPoseType(hv_MatchingPlaneInCamPose, hv_OrderOfTransform, hv_OrderOfRotation, 
      hv_ViewOfTransform, &hv_MatchingPlaneInCamPose);
  //
  CreatePose(0, 0, hv_ObjectHeight, 180, 0, 0, "Rp+T", "gba", "point", &hv_ModelInPlanePose);
  //Remember the transformation.
  PoseInvert(hv_ModelInPlanePose, &hv_PlaneInModelPose);
  //
  //Create message for Poses.
  CreateMessage(&(*hv_Poses));
  SetMessageTuple((*hv_Poses), "PlaneInModelPose", hv_PlaneInModelPose);
  SetMessageTuple((*hv_Poses), "MatchingPlaneInCamPose", hv_MatchingPlaneInCamPose);
  SetMessageTuple((*hv_Poses), "PlaneInCamPose", hv_PlaneInCamPose);
  //
  //Create message for rectification data.
  CreateMessage(&(*hv_RectificationData));
  SetMessageTuple((*hv_RectificationData), "RectifyImage", hv_RectifyImage);
  if (0 != (hv_RectifyImage==HTuple("true")))
  {
    SetMessageTuple((*hv_RectificationData), "ScaleRectification", hv_ScaleRectification);
    SetMessageObj(ho_RectificationMap, (*hv_RectificationData), "RectificationMap");
  }
  return;
}

// Chapter: System / Multithreading
void read_message_tuple (HTuple hv_MessageHandle, HTuple hv_Key, HTuple *hv_TupleData)
{

  // Local control variables
  HTuple  hv_Exception;

  try
  {
    GetMessageTuple(hv_MessageHandle, hv_Key, &(*hv_TupleData));
  }
  // catch (Exception) 
  catch (HException &HDevExpDefaultException)
  {
    HDevExpDefaultException.ToHTuple(&hv_Exception);
    throw HException((("The key "+hv_Key)+" is missing from the message ")+hv_MessageHandle);
  }
  return;
}

// Chapter: System / Multithreading
void read_message_obj (HObject *ho_ObjectData, HTuple hv_MessageHandle, HTuple hv_Key)
{

  // Local control variables
  HTuple  hv_Exception;

  try
  {
    GetMessageObj(&(*ho_ObjectData), hv_MessageHandle, hv_Key);
  }
  // catch (Exception) 
  catch (HException &HDevExpDefaultException)
  {
    HDevExpDefaultException.ToHTuple(&hv_Exception);
    throw HException((("The key "+hv_Key)+" is missing from the message ")+hv_MessageHandle);
  }
  return;
}

// Chapter: Calibration / Hand-Eye
// Short Description: Prepare the input image for matching and compute the needed pose. 
void rectify_image_and_compute_matching_plane_moving_cam (HObject ho_Image, HObject *ho_ImageRectified, 
    HTuple hv_ToolInBasePose, HTuple hv_HandEyeCalibData, HTuple hv_Poses, HTuple hv_RectificationData)
{

  // Local iconic variables
  HObject  ho_ImageArea, ho_RegionBorder;

  // Local control variables
  HTuple  hv_RectifyImage, hv_OrderOfTransform;
  HTuple  hv_OrderOfRotation, hv_ViewOfTransform, hv_ToolInCamPose;
  HTuple  hv_MatchingPlaneInBasePose, hv_BaseInToolPose, hv_BaseInCamPose;
  HTuple  hv_MatchingPlaneInCamPose, hv_MatchingPlaneRectifiedPartInCamPose;
  HTuple  hv_CamParam, hv_Width, hv_Height, hv_ClipRegion;
  HTuple  hv_BorderRows, hv_BorderColumns, hv_BorderX, hv_BorderY;
  HTuple  hv_MatchingPlaneRectifiedPartInMatchingPlanePose;
  HTuple  hv_ScaleRectification, hv_WidthRect, hv_HeightRect;

  //This procedure finds the pose of the matching part on the plane
  //in the camera coordinate system. Rectification is applied if it
  //is set by the user.
  //
  read_message_tuple(hv_HandEyeCalibData, "CamParam", &hv_CamParam);
  read_message_tuple(hv_HandEyeCalibData, "ToolInCamPose", &hv_ToolInCamPose);
  read_message_tuple(hv_RectificationData, "RectifyImage", &hv_RectifyImage);
  if (0 != (HTuple(hv_RectifyImage==HTuple("only_rectify")).TupleOr(hv_RectifyImage==HTuple("align_and_rectify"))))
  {
    read_message_tuple(hv_RectificationData, "ScaleRectification", &hv_ScaleRectification);
  }
  read_message_tuple(hv_Poses, "MatchingPlaneInBasePose", &hv_MatchingPlaneInBasePose);
  //
  //Keep track of the pose type used by the robot.
  GetPoseType(hv_ToolInBasePose, &hv_OrderOfTransform, &hv_OrderOfRotation, &hv_ViewOfTransform);
  //Convert to default pose type.
  ConvertPoseType(hv_ToolInBasePose, "Rp+T", "gba", "point", &hv_ToolInBasePose);
  ConvertPoseType(hv_ToolInCamPose, "Rp+T", "gba", "point", &hv_ToolInCamPose);
  ConvertPoseType(hv_MatchingPlaneInBasePose, "Rp+T", "gba", "point", &hv_MatchingPlaneInBasePose);
  //
  PoseInvert(hv_ToolInBasePose, &hv_BaseInToolPose);
  PoseCompose(hv_ToolInCamPose, hv_BaseInToolPose, &hv_BaseInCamPose);
  PoseCompose(hv_BaseInCamPose, hv_MatchingPlaneInBasePose, &hv_MatchingPlaneInCamPose);
  //
  if (0 != (hv_RectifyImage==HTuple("no_rectification")))
  {
    hv_MatchingPlaneRectifiedPartInCamPose = hv_MatchingPlaneInCamPose;
    CopyObj(ho_Image, &(*ho_ImageRectified), 1, 1);
  }
  else if (0 != (HTuple(hv_RectifyImage==HTuple("only_rectify")).TupleOr(hv_RectifyImage==HTuple("align_and_rectify"))))
  {
    if (0 != (hv_RectifyImage==HTuple("only_rectify")))
    {
      hv_MatchingPlaneInCamPose[5] = 0.0;
    }
    //The image dimensions should cover the entire original
    //field of view in the current rectification. Look at the
    //border of the current image in the world plane.
    get_cam_par_data(hv_CamParam, "image_width", &hv_Width);
    get_cam_par_data(hv_CamParam, "image_height", &hv_Height);
    GetSystem("clip_region", &hv_ClipRegion);
    SetSystem("clip_region", "false");
    GenRectangle1(&ho_ImageArea, 0, 0, hv_Height-1, hv_Width-1);
    Boundary(ho_ImageArea, &ho_RegionBorder, "outer");
    SetSystem("clip_region", hv_ClipRegion);
    GetRegionPoints(ho_RegionBorder, &hv_BorderRows, &hv_BorderColumns);
    ImagePointsToWorldPlane(hv_CamParam, hv_MatchingPlaneInCamPose, hv_BorderRows, 
        hv_BorderColumns, "m", &hv_BorderX, &hv_BorderY);
    //Adapt parameters.
    CreatePose(hv_BorderX.TupleMin(), hv_BorderY.TupleMin(), 0, 0, 0, 0, "Rp+T", 
        "gba", "point", &hv_MatchingPlaneRectifiedPartInMatchingPlanePose);
    PoseCompose(hv_MatchingPlaneInCamPose, hv_MatchingPlaneRectifiedPartInMatchingPlanePose, 
        &hv_MatchingPlaneRectifiedPartInCamPose);
    hv_WidthRect = ((((hv_BorderX.TupleMax())-(hv_BorderX.TupleMin()))/hv_ScaleRectification)+0.5).TupleInt();
    hv_HeightRect = ((((hv_BorderY.TupleMax())-(hv_BorderY.TupleMin()))/hv_ScaleRectification)+0.5).TupleInt();
    //
    ImageToWorldPlane(ho_Image, &(*ho_ImageRectified), hv_CamParam, hv_MatchingPlaneRectifiedPartInCamPose, 
        hv_WidthRect, hv_HeightRect, hv_ScaleRectification, "bilinear");
  }
  else
  {
    throw HException("Please set the parameter RectifyImage correctly");
  }
  ConvertPoseType(hv_MatchingPlaneRectifiedPartInCamPose, hv_OrderOfTransform, hv_OrderOfRotation, 
      hv_ViewOfTransform, &hv_MatchingPlaneRectifiedPartInCamPose);
  SetMessageTuple(hv_RectificationData, "MatchingPlaneRectifiedPartInCamPose", hv_MatchingPlaneRectifiedPartInCamPose);
  return;
}

// Chapter: Graphics / 3D Scene
// Short Description: Visualize the poses that were used to calculate the touching point, and the result. 
void visualize_calibrated_touching_point (HTuple hv_RobotTouchingPointInToolCoordinates, 
    HTupleVector/*{eTupleVector,Dim=1}*/ hvec_ToolInBasePosesTouchingPoint, HTuple hv_WindowHandle)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_OM3DToolTouchingPoint, hv_Instructions;
  HTuple  hv_PoseIn, hv_GenParamName, hv_GenParamValue, hv_Title;
  HTuple  hv_NumOM3D, hv_Label, hv_PoseOut;

  //
  //Create 3D object models.
  gen_tool_to_touching_point_object_model_3d(hvec_ToolInBasePosesTouchingPoint, hv_RobotTouchingPointInToolCoordinates, 
      &hv_OM3DToolTouchingPoint);
  //
  //Prepare parameters for visualize_object_model_3d.
  //Instructions.
  hv_Instructions[0] = "Rotate: Left button";
  hv_Instructions[1] = "Zoom:   Shift + left button";
  hv_Instructions[2] = "Move:   Ctrl  + left button";
  //3D visualization pose.
  CreatePose(0.326, 0.016, 3.137, 83.33, 341.96, 99.32, "Rp+T", "gba", "point", &hv_PoseIn);
  //
  hv_GenParamName.Clear();
  hv_GenParamName[0] = "color_0";
  hv_GenParamName[1] = "color_1";
  hv_GenParamName[2] = "color_2";
  hv_GenParamName[3] = "color_3";
  hv_GenParamName[4] = "color_4";
  hv_GenParamName[5] = "color_5";
  hv_GenParamName[6] = "color_6";
  hv_GenParamName[7] = "color_7";
  hv_GenParamName[8] = "color_8";
  hv_GenParamName[9] = "color_9";
  hv_GenParamName[10] = "color_10";
  hv_GenParamName[11] = "color_11";
  hv_GenParamValue.Clear();
  hv_GenParamValue[0] = "red";
  hv_GenParamValue[1] = "green";
  hv_GenParamValue[2] = "blue";
  hv_GenParamValue[3] = "magenta";
  hv_GenParamValue[4] = "red";
  hv_GenParamValue[5] = "green";
  hv_GenParamValue[6] = "blue";
  hv_GenParamValue[7] = "magenta";
  hv_GenParamValue[8] = "red";
  hv_GenParamValue[9] = "green";
  hv_GenParamValue[10] = "blue";
  hv_GenParamValue[11] = "magenta";
  //
  hv_Title = "Visualization of the read poses. The magenta lines connect the";
  hv_Title[1] = "tool coordinate system with the touching point. They intersect";
  hv_Title[2] = "in the approached point in the plane. Calculated touching point";
  hv_Title[3] = "coordinates with respect to the robot's tool: ";
  hv_Title[4] = ((((("X: "+((HTuple(hv_RobotTouchingPointInToolCoordinates[0])*1000).TupleString(".2f")))+HTuple(" mm, Y: "))+((HTuple(hv_RobotTouchingPointInToolCoordinates[1])*1000).TupleString(".2f")))+HTuple(" mm, Z: "))+((HTuple(hv_RobotTouchingPointInToolCoordinates[2])*1000).TupleString(".2f")))+" mm";
  //Labels for the visualized 3D object models.
  hv_NumOM3D = hv_OM3DToolTouchingPoint.TupleLength();
  TupleGenConst(hv_NumOM3D, "", &hv_Label);
  hv_Label[2] = "ToolInBasePosesTouchingPoint 1";
  hv_Label[6] = "ToolInBasePosesTouchingPoint 2";
  hv_Label[10] = "ToolInBasePosesTouchingPoint 3";
  //
  visualize_object_model_3d(hv_WindowHandle, hv_OM3DToolTouchingPoint, HTuple(), 
      hv_PoseIn, hv_GenParamName, hv_GenParamValue, hv_Title, hv_Label, hv_Instructions, 
      &hv_PoseOut);
  //
  //Clean up.
  ClearObjectModel3d(hv_OM3DToolTouchingPoint);
  return;
}

// Chapter: Calibration / Hand-Eye
// Short Description: Prepares the model to match and grasp. 
void prepare_poses_and_rectification_data_moving_cam (HTuple hv_ToolInBasePose, HTuple hv_ObjectHeight, 
    HTuple hv_RectifyImage, HTuple hv_HandEyeCalibData, HTuple *hv_Poses, HTuple *hv_RectificationData)
{

  // Local iconic variables
  HObject  ho_RegionGrid, ho_ContCircle, ho_ContCircleWorldPlane;
  HObject  ho_ImageArea, ho_RegionBorder, ho_RectificationMap;

  // Local control variables
  HTuple  hv_CamParam, hv_ToolInCamPose, hv_PlaneInBasePose0;
  HTuple  hv_OrderOfTransform, hv_OrderOfRotation, hv_ViewOfTransform;
  HTuple  hv_BaseInToolPose, hv_BaseInCamPose, hv_PlaneInCamPose0;
  HTuple  hv_PlaneInCamPose0Rot, hv_HomMat3D, hv_Qx, hv_Qy;
  HTuple  hv_CosAngleBetweenZAxis, hv_SwitchZDirection, hv_PlaneInCamPose1;
  HTuple  hv_PlaneInCamPose, hv_CamInBasePose, hv_PlaneInBasePose;
  HTuple  hv_MatchingPlaneInPlanePose, hv_MatchingPlaneInBasePose;
  HTuple  hv_MatchingPlaneInCamPose, hv_MatchingPlaneRectifiedPartInCamPose;
  HTuple  hv_ScaleRectification, hv_Width, hv_Height, hv_Rows;
  HTuple  hv_Columns, hv_Row, hv_Column, hv_Phi, hv_Radius1;
  HTuple  hv_Radius2, hv_StartPhi, hv_EndPhi, hv_PointOrder;
  HTuple  hv_ClipRegion, hv_BorderRows, hv_BorderColumns;
  HTuple  hv_BorderX, hv_BorderY, hv_MatchingPlaneRectifiedPartInMatchingPlanePose;
  HTuple  hv_WidthRect, hv_HeightRect, hv_ModelInPlanePose;
  HTuple  hv_PlaneInModelPose;

  //Prepare the needed poses to match and grasp, and compute the rectification map.
  //
  //RectifyImage Parameter can have one of the following 3 values:
  //'no_rectification', 'align_and_rectify', or 'only_rectify'
  //
  read_message_tuple(hv_HandEyeCalibData, "CamParam", &hv_CamParam);
  read_message_tuple(hv_HandEyeCalibData, "ToolInCamPose", &hv_ToolInCamPose);
  read_message_tuple(hv_HandEyeCalibData, "PlaneInBasePose0", &hv_PlaneInBasePose0);
  //
  //Check input
  if (0 != (hv_ObjectHeight<0.0))
  {
    throw HException("The parameter ObjectHeight cannot be negative");
  }
  if (0 != (HTuple(hv_CamParam[0])==HTuple("line_scan")))
  {
    throw HException("Line-scan cameras are not supported");
  }
  //
  //Keep track of the pose type used by the robot.
  GetPoseType(hv_ToolInBasePose, &hv_OrderOfTransform, &hv_OrderOfRotation, &hv_ViewOfTransform);
  //Convert to default pose type.
  ConvertPoseType(hv_ToolInBasePose, "Rp+T", "gba", "point", &hv_ToolInBasePose);
  ConvertPoseType(hv_ToolInCamPose, "Rp+T", "gba", "point", &hv_ToolInCamPose);
  ConvertPoseType(hv_PlaneInBasePose0, "Rp+T", "gba", "point", &hv_PlaneInBasePose0);
  //
  //Create the plane for matching and adapt the PlaneInBasePose0 such
  //that the z-axis of the plane points away from the reference camera,
  //and x/y coordinates are aligned with the current image, i.e.
  //PlaneInCamPose0 has Rot_z=0.
  PoseInvert(hv_ToolInBasePose, &hv_BaseInToolPose);
  PoseCompose(hv_ToolInCamPose, hv_BaseInToolPose, &hv_BaseInCamPose);
  PoseCompose(hv_BaseInCamPose, hv_PlaneInBasePose0, &hv_PlaneInCamPose0);
  //The z-axis of the plane should point away from the camera.
  hv_PlaneInCamPose0Rot = hv_PlaneInCamPose0;
  hv_PlaneInCamPose0Rot[HTuple::TupleGenSequence(0,2,1)] = ((HTuple(0).Append(0)).Append(0));
  PoseToHomMat3d(hv_PlaneInCamPose0Rot, &hv_HomMat3D);
  AffineTransPoint3d(hv_HomMat3D, 0, 0, 1, &hv_Qx, &hv_Qy, &hv_CosAngleBetweenZAxis);
  if (0 != (hv_CosAngleBetweenZAxis<0))
  {
    CreatePose(0, 0, 0, 180, 0, 0, "Rp+T", "gba", "point", &hv_SwitchZDirection);
    PoseCompose(hv_PlaneInCamPose0, hv_SwitchZDirection, &hv_PlaneInCamPose1);
    hv_PlaneInCamPose0 = hv_PlaneInCamPose1;
  }
  //Align with the current image.
  hv_PlaneInCamPose = hv_PlaneInCamPose0;
  hv_PlaneInCamPose[5] = 0.0;
  //Adapt the PlaneInBasePose.
  PoseInvert(hv_BaseInCamPose, &hv_CamInBasePose);
  PoseCompose(hv_CamInBasePose, hv_PlaneInCamPose, &hv_PlaneInBasePose);
  //
  //Create the plane for matching.
  CreatePose(0, 0, -hv_ObjectHeight, 0, 0, 0, "Rp+T", "gba", "point", &hv_MatchingPlaneInPlanePose);
  PoseCompose(hv_PlaneInBasePose, hv_MatchingPlaneInPlanePose, &hv_MatchingPlaneInBasePose);
  PoseCompose(hv_PlaneInCamPose, hv_MatchingPlaneInPlanePose, &hv_MatchingPlaneInCamPose);
  //
  if (0 != (hv_RectifyImage==HTuple("no_rectification")))
  {
    hv_MatchingPlaneRectifiedPartInCamPose = hv_MatchingPlaneInCamPose;
    hv_ScaleRectification = HTuple();
  }
  else if (0 != (HTuple(hv_RectifyImage==HTuple("only_rectify")).TupleOr(hv_RectifyImage==HTuple("align_and_rectify"))))
  {
    //Determine the scale such that the mapped image has at least
    //the same resolution as the current image.
    get_cam_par_data(hv_CamParam, "image_width", &hv_Width);
    get_cam_par_data(hv_CamParam, "image_height", &hv_Height);
    GenGridRegion(&ho_RegionGrid, 20, 20, "points", hv_Width, hv_Height);
    GetRegionPoints(ho_RegionGrid, &hv_Rows, &hv_Columns);
    GenCircleContourXld(&ho_ContCircle, hv_Rows, hv_Columns, HTuple(hv_Rows.TupleLength(),1.0), 
        0, 6.28318, "positive", 0.1);
    ContourToWorldPlaneXld(ho_ContCircle, &ho_ContCircleWorldPlane, hv_CamParam, 
        hv_MatchingPlaneInCamPose, "m");
    FitEllipseContourXld(ho_ContCircleWorldPlane, "fitzgibbon", -1, 0, 0, 200, 3, 
        2, &hv_Row, &hv_Column, &hv_Phi, &hv_Radius1, &hv_Radius2, &hv_StartPhi, 
        &hv_EndPhi, &hv_PointOrder);
    hv_ScaleRectification = hv_Radius2.TupleMin();
    //
    //Rectify the current image and create the shape model.
    //
    //The image dimensions should cover the entire original field
    //of view in the current rectification.
    //Look at border of the current image in the world plane.
    GetSystem("clip_region", &hv_ClipRegion);
    SetSystem("clip_region", "false");
    GenRectangle1(&ho_ImageArea, 0, 0, hv_Height-1, hv_Width-1);
    Boundary(ho_ImageArea, &ho_RegionBorder, "outer");
    SetSystem("clip_region", hv_ClipRegion);
    GetRegionPoints(ho_RegionBorder, &hv_BorderRows, &hv_BorderColumns);
    ImagePointsToWorldPlane(hv_CamParam, hv_MatchingPlaneInCamPose, hv_BorderRows, 
        hv_BorderColumns, "m", &hv_BorderX, &hv_BorderY);
    //Adapt parameters.
    CreatePose(hv_BorderX.TupleMin(), hv_BorderY.TupleMin(), 0, 0, 0, 0, "Rp+T", 
        "gba", "point", &hv_MatchingPlaneRectifiedPartInMatchingPlanePose);
    PoseCompose(hv_MatchingPlaneInCamPose, hv_MatchingPlaneRectifiedPartInMatchingPlanePose, 
        &hv_MatchingPlaneRectifiedPartInCamPose);
    hv_WidthRect = ((((hv_BorderX.TupleMax())-(hv_BorderX.TupleMin()))/hv_ScaleRectification)+0.5).TupleInt();
    hv_HeightRect = ((((hv_BorderY.TupleMax())-(hv_BorderY.TupleMin()))/hv_ScaleRectification)+0.5).TupleInt();
    //
    //Create a map for repeated use.
    GenImageToWorldPlaneMap(&ho_RectificationMap, hv_CamParam, hv_MatchingPlaneInCamPose, 
        hv_Width, hv_Height, hv_WidthRect, hv_HeightRect, hv_ScaleRectification, 
        "bilinear");
  }
  else
  {
    throw HException("Please set the parameter RectifyImage correctly");
  }
  //Convert to output pose type.
  ConvertPoseType(hv_PlaneInCamPose, hv_OrderOfTransform, hv_OrderOfRotation, hv_ViewOfTransform, 
      &hv_PlaneInCamPose);
  ConvertPoseType(hv_CamInBasePose, hv_OrderOfTransform, hv_OrderOfRotation, hv_ViewOfTransform, 
      &hv_CamInBasePose);
  ConvertPoseType(hv_PlaneInBasePose, hv_OrderOfTransform, hv_OrderOfRotation, hv_ViewOfTransform, 
      &hv_PlaneInBasePose);
  ConvertPoseType(hv_MatchingPlaneInCamPose, hv_OrderOfTransform, hv_OrderOfRotation, 
      hv_ViewOfTransform, &hv_MatchingPlaneInCamPose);
  ConvertPoseType(hv_MatchingPlaneInBasePose, hv_OrderOfTransform, hv_OrderOfRotation, 
      hv_ViewOfTransform, &hv_MatchingPlaneInBasePose);
  ConvertPoseType(hv_MatchingPlaneRectifiedPartInCamPose, hv_OrderOfTransform, hv_OrderOfRotation, 
      hv_ViewOfTransform, &hv_MatchingPlaneRectifiedPartInCamPose);
  //
  CreatePose(0, 0, hv_ObjectHeight, 180, 0, 0, "Rp+T", "gba", "point", &hv_ModelInPlanePose);
  //Remember the transformation.
  PoseInvert(hv_ModelInPlanePose, &hv_PlaneInModelPose);
  //
  //Create message for Poses.
  CreateMessage(&(*hv_Poses));
  SetMessageTuple((*hv_Poses), "PlaneInCamPose", hv_PlaneInCamPose);
  SetMessageTuple((*hv_Poses), "CamInBasePose", hv_CamInBasePose);
  SetMessageTuple((*hv_Poses), "PlaneInBasePose", hv_PlaneInBasePose);
  SetMessageTuple((*hv_Poses), "MatchingPlaneInCamPose", hv_MatchingPlaneInCamPose);
  SetMessageTuple((*hv_Poses), "MatchingPlaneInBasePose", hv_MatchingPlaneInBasePose);
  SetMessageTuple((*hv_Poses), "PlaneInModelPose", hv_PlaneInModelPose);
  //
  //Create message for rectification data.
  CreateMessage(&(*hv_RectificationData));
  SetMessageTuple((*hv_RectificationData), "RectifyImage", hv_RectifyImage);
  if (0 != (hv_RectifyImage!=HTuple("no_rectification")))
  {
    SetMessageTuple((*hv_RectificationData), "ScaleRectification", hv_ScaleRectification);
    SetMessageObj(ho_RectificationMap, (*hv_RectificationData), "RectificationMap");
  }
  SetMessageTuple((*hv_RectificationData), "MatchingPlaneRectifiedPartInCamPose", 
      hv_MatchingPlaneRectifiedPartInCamPose);
  return;
}


