///////////////////////////////////////////////////////////////////////////////
// File generated by HDevelop for HALCON/C++ Version 13.0.2.2
///////////////////////////////////////////////////////////////////////////////




#ifndef __APPLE__
#  include "HalconCpp.h"
#  include "HDevThread.h"
#else
#  ifndef HC_LARGE_IMAGES
#    include <HALCONCpp/HalconCpp.h>
#    include <HALCONCpp/HDevThread.h>
#  else
#    include <HALCONCppxl/HalconCpp.h>
#    include <HALCONCppxl/HDevThread.h>
#  endif
#endif



using namespace HalconCpp;

HTuple  gInfoDecor;
HTuple  gInfoPos;
HTuple  gTitlePos;
HTuple  gTitleDecor;
HTuple  gAlphaDeselected;
HTuple  gTerminationButtonLabel;
HTuple  gDispObjOffset;
HTuple  gLabelsDecor;
HTuple  gUsesOpenGL;
HTuple  gIsSinglePose;
HTuple ExpGetGlobalVar_gInfoDecor(void)
{
  return gInfoDecor;
}
void ExpSetGlobalVar_gInfoDecor(HTuple val)
{
  gInfoDecor = val;
}

HTuple ExpGetGlobalVar_gInfoPos(void)
{
  return gInfoPos;
}
void ExpSetGlobalVar_gInfoPos(HTuple val)
{
  gInfoPos = val;
}

HTuple ExpGetGlobalVar_gTitlePos(void)
{
  return gTitlePos;
}
void ExpSetGlobalVar_gTitlePos(HTuple val)
{
  gTitlePos = val;
}

HTuple ExpGetGlobalVar_gTitleDecor(void)
{
  return gTitleDecor;
}
void ExpSetGlobalVar_gTitleDecor(HTuple val)
{
  gTitleDecor = val;
}

HTuple ExpGetGlobalVar_gAlphaDeselected(void)
{
  return gAlphaDeselected;
}
void ExpSetGlobalVar_gAlphaDeselected(HTuple val)
{
  gAlphaDeselected = val;
}

HTuple ExpGetGlobalVar_gTerminationButtonLabel(void)
{
  return gTerminationButtonLabel;
}
void ExpSetGlobalVar_gTerminationButtonLabel(HTuple val)
{
  gTerminationButtonLabel = val;
}

HTuple ExpGetGlobalVar_gDispObjOffset(void)
{
  return gDispObjOffset;
}
void ExpSetGlobalVar_gDispObjOffset(HTuple val)
{
  gDispObjOffset = val;
}

HTuple ExpGetGlobalVar_gLabelsDecor(void)
{
  return gLabelsDecor;
}
void ExpSetGlobalVar_gLabelsDecor(HTuple val)
{
  gLabelsDecor = val;
}

HTuple ExpGetGlobalVar_gUsesOpenGL(void)
{
  return gUsesOpenGL;
}
void ExpSetGlobalVar_gUsesOpenGL(HTuple val)
{
  gUsesOpenGL = val;
}

HTuple ExpGetGlobalVar_gIsSinglePose(void)
{
  return gIsSinglePose;
}
void ExpSetGlobalVar_gIsSinglePose(HTuple val)
{
  gIsSinglePose = val;
}

// Procedure declarations 
// Chapter: Graphics / Output
void disp_title_and_information (HTuple hv_WindowHandle, HTuple hv_Title, HTuple hv_Information);
// Chapter: Classification / Misc
// Short Description: Describe and calculate user-defined features to be used in conjunction with the calculate_feature_set procedure library. 
void get_custom_features (HObject ho_Region, HObject ho_Image, HTuple hv_CurrentName, 
    HTuple hv_Mode, HTuple *hv_Output);
// Chapter: Graphics / Text
// Short Description: This procedure writes a text message. 
void disp_text_button (HTuple hv_WindowHandle, HTuple hv_String, HTuple hv_CoordSystem, 
    HTuple hv_Row, HTuple hv_Column, HTuple hv_TextColor, HTuple hv_ButtonColor);
// Chapter: Graphics / Output
// Short Description: Renders 3D object models in a buffer window. 
void dump_image_output (HObject ho_BackgroundImage, HTuple hv_WindowHandleBuffer, 
    HTuple hv_Scene3D, HTuple hv_AlphaOrig, HTuple hv_ObjectModel3DID, HTuple hv_GenParamName, 
    HTuple hv_GenParamValue, HTuple hv_CamParam, HTuple hv_Poses, HTuple hv_ColorImage, 
    HTuple hv_Title, HTuple hv_Information, HTuple hv_Labels, HTuple hv_VisualizeTrackball, 
    HTuple hv_DisplayContinueButton, HTuple hv_TrackballCenterRow, HTuple hv_TrackballCenterCol, 
    HTuple hv_TrackballRadiusPixel, HTuple hv_SelectedObject, HTuple hv_VisualizeRotationCenter, 
    HTuple hv_RotationCenter);
// Chapter: 3D Object Model / Creation
void gen_arrow_object_model_3d (HTuple hv_ArrowThickness, HTuple hv_ArrowStart, HTuple hv_ArrowEnd, 
    HTuple *hv_OM3DArrow);
// Chapter: Graphics / Output
// Short Description: Get the center of the virtual trackback that is used to move the camera (version for inspection_mode = 'surface'). 
void get_trackball_center_fixed (HTuple hv_SelectedObject, HTuple hv_TrackballCenterRow, 
    HTuple hv_TrackballCenterCol, HTuple hv_TrackballRadiusPixel, HTuple hv_Scene3D, 
    HTuple hv_ObjectModel3DID, HTuple hv_Poses, HTuple hv_WindowHandleBuffer, HTuple hv_CamParam, 
    HTuple hv_GenParamName, HTuple hv_GenParamValue, HTuple *hv_TBCenter, HTuple *hv_TBSize);
// Chapter: Graphics / Output
// Short Description: Get string extends of several lines. 
void max_line_width (HTuple hv_WindowHandle, HTuple hv_Lines, HTuple *hv_MaxWidth);
// Chapter: Graphics / Output
// Short Description: Project an image point onto the trackball 
void project_point_on_trackball (HTuple hv_X, HTuple hv_Y, HTuple hv_VirtualTrackball, 
    HTuple hv_TrackballSize, HTuple *hv_V);
// Chapter: Tuple / Arithmetic
// Short Description: Calculates the cross product of two vectors of length 3. 
void tuple_vector_cross_product (HTuple hv_V1, HTuple hv_V2, HTuple *hv_VC);
// Chapter: Graphics / Output
// Short Description: Get the center of the virtual trackback that is used to move the camera. 
void get_trackball_center (HTuple hv_SelectedObject, HTuple hv_TrackballRadiusPixel, 
    HTuple hv_ObjectModel3D, HTuple hv_Poses, HTuple *hv_TBCenter, HTuple *hv_TBSize);
// Chapter: Graphics / Output
// Short Description: Compute the center of all given 3D object models. 
void get_object_models_center (HTuple hv_ObjectModel3DID, HTuple *hv_Center);
// Chapter: Graphics / Output
// Short Description: Compute the 3D rotation from the mouse movement 
void trackball (HTuple hv_MX1, HTuple hv_MY1, HTuple hv_MX2, HTuple hv_MY2, HTuple hv_VirtualTrackball, 
    HTuple hv_TrackballSize, HTuple hv_SensFactor, HTuple *hv_QuatRotation);
// Chapter: Graphics / Output
// Short Description: Interactively display 3D object models 
void visualize_object_model_3d (HTuple hv_WindowHandle, HTuple hv_ObjectModel3D, 
    HTuple hv_CamParam, HTuple hv_PoseIn, HTuple hv_GenParamName, HTuple hv_GenParamValue, 
    HTuple hv_Title, HTuple hv_Label, HTuple hv_Information, HTuple *hv_PoseOut);
// Chapter: Matching / Shape-Based
// Short Description: Display the results of Shape-Based Matching. 
void dev_display_shape_matching_results (HTuple hv_ModelID, HTuple hv_Color, HTuple hv_Row, 
    HTuple hv_Column, HTuple hv_Angle, HTuple hv_ScaleR, HTuple hv_ScaleC, HTuple hv_Model);
// Chapter: Develop
// Short Description: Changes the size of a graphics window with a given maximum and minimum extent such that it preserves the aspect ratio of the given image 
void dev_resize_window_fit_image (HObject ho_Image, HTuple hv_Row, HTuple hv_Column, 
    HTuple hv_WidthLimit, HTuple hv_HeightLimit);
// Chapter: Filters / Lines
// Short Description: Calculates the parameters Sigma, Low, and High for lines_gauss from the maximum width and the contrast of the lines to be extracted. 
void calculate_lines_gauss_parameters (HTuple hv_MaxLineWidth, HTuple hv_Contrast, 
    HTuple *hv_Sigma, HTuple *hv_Low, HTuple *hv_High);
// Chapter: Identification / Bar Code
// Short Description: Convert a decoded string of a bar code of type 'Code 39' to the type 'Code 32'. 
void convert_decoded_string_code39_to_code32 (HTuple hv_DecodedDataStringCode39, 
    HTuple *hv_ConvertedDataStringCode32);
// Chapter: Matching / Correlation-Based
// Short Description: Display the results of Correlation-Based Matching. 
void dev_display_ncc_matching_results (HTuple hv_ModelID, HTuple hv_Color, HTuple hv_Row, 
    HTuple hv_Column, HTuple hv_Angle, HTuple hv_Model);
// Chapter: Calibration / Hand-Eye
// Short Description: Check the input poses of the hand-eye calibration for consistency. 
void check_hand_eye_calibration_input_poses (HTuple hv_CalibDataID, HTuple hv_RotationTolerance, 
    HTuple hv_TranslationTolerance, HTuple *hv_Warnings);
// Chapter: Identification / Data Code
// Short Description: Display print quality information for individual data code modules. 
void dev_display_data_code_2d_print_quality_results (HTuple hv_DataCodeHandle, HTuple hv_ResultHandle, 
    HTuple hv_Mode, HTuple hv_QualityStandard, HTuple hv_Color, HTuple hv_GenParamName, 
    HTuple hv_GenParamValue);
// Chapter: Develop
// Short Description: Open a new graphics window that preserves the aspect ratio of the given image. 
void dev_open_window_fit_image (HObject ho_Image, HTuple hv_Row, HTuple hv_Column, 
    HTuple hv_WidthLimit, HTuple hv_HeightLimit, HTuple *hv_WindowHandle);
// Chapter: Develop
// Short Description: Open a new graphics window that preserves the aspect ratio of the given image size. 
void dev_open_window_fit_size (HTuple hv_Row, HTuple hv_Column, HTuple hv_Width, 
    HTuple hv_Height, HTuple hv_WidthLimit, HTuple hv_HeightLimit, HTuple *hv_WindowHandle);
// Chapter: Graphics / Text
// Short Description: This procedure writes a text message. 
void disp_message (HTuple hv_WindowHandle, HTuple hv_String, HTuple hv_CoordSystem, 
    HTuple hv_Row, HTuple hv_Column, HTuple hv_Color, HTuple hv_Box);
// Chapter: Graphics / Output
// Short Description:  This procedure plots tuples representing functions or curves in a coordinate system. 
void plot_tuple (HTuple hv_WindowHandle, HTuple hv_XValues, HTuple hv_YValues, HTuple hv_XLabel, 
    HTuple hv_YLabel, HTuple hv_Color, HTuple hv_GenParamNames, HTuple hv_GenParamValues);
// Chapter: Graphics / Text
// Short Description: Set font independent of OS 
void set_display_font (HTuple hv_WindowHandle, HTuple hv_Size, HTuple hv_Font, HTuple hv_Bold, 
    HTuple hv_Slant);
// Chapter: Graphics / Text
// Short Description: This procedure displays 'End of program' in the lower right corner of the screen. 
void disp_end_of_program_message (HTuple hv_WindowHandle, HTuple hv_Color, HTuple hv_Box);
// Chapter: File / Misc
// Short Description: Get all image files under the given path 
void list_image_files (HTuple hv_ImageDirectory, HTuple hv_Extensions, HTuple hv_Options, 
    HTuple *hv_ImageFiles);
// Chapter: File / Misc
// Short Description: Parse a filename into directory, base filename, and extension 
void parse_filename (HTuple hv_FileName, HTuple *hv_BaseName, HTuple *hv_Extension, 
    HTuple *hv_Directory);
// Chapter: Graphics / Output
// Short Description:  This procedure plots tuples representing functions or curves in a coordinate system. 
void plot_funct_1d (HTuple hv_WindowHandle, HTuple hv_Function, HTuple hv_XLabel, 
    HTuple hv_YLabel, HTuple hv_Color, HTuple hv_GenParamNames, HTuple hv_GenParamValues);
// Chapter: Classification / Misc
// Short Description: Auxiliary procedure for get_custom_features and get_features. 
void append_length_or_values (HTuple hv_Mode, HTuple hv_Feature, HTuple hv_AccumulatedResults, 
    HTuple *hv_ExtendedResults);
// Chapter: 3D Object Model / Transformations
// Short Description: Transform 3D points from images to a 3D object model, and add extended attributes to the points of the object model. 
void xyz_attrib_to_object_model_3d (HObject ho_X, HObject ho_Y, HObject ho_Z, HObject ho_AttribImage, 
    HTuple hv_AttribName, HTuple *hv_ObjectModel3D);
// Chapter: Classification / Misc
// Short Description: Auxiliary procedure for get_custom_features and get_features. 
void append_names_or_groups (HTuple hv_Mode, HTuple hv_Name, HTuple hv_Groups, HTuple hv_CurrentName, 
    HTuple hv_AccumulatedResults, HTuple *hv_ExtendedResults);
// Chapter: Tools / Geometry
// Short Description: Sort tuple pairs. 
void sort_pairs (HTuple hv_T1, HTuple hv_T2, HTuple hv_SortMode, HTuple *hv_Sorted1, 
    HTuple *hv_Sorted2);
// Chapter: Object / Manipulation
// Short Description: Select elements from object arrays using a mask. 
void select_mask_obj (HObject ho_Objects, HObject *ho_SelectedObjects, HTuple hv_Mask);
// Chapter: Graphics / Text
// Short Description: This procedure displays 'Click 'Run' to continue' in the lower right corner of the screen. 
void disp_continue_message (HTuple hv_WindowHandle, HTuple hv_Color, HTuple hv_Box);
// Chapter: Graphics / Output
// Short Description: Display the axes of a 3d coordinate system 
void disp_3d_coord_system (HTuple hv_WindowHandle, HTuple hv_CamParam, HTuple hv_Pose, 
    HTuple hv_CoordAxesLength);
// Chapter: XLD / Creation
// Short Description: Creates an arrow shaped XLD contour. 
void gen_arrow_contour_xld (HObject *ho_Arrow, HTuple hv_Row1, HTuple hv_Column1, 
    HTuple hv_Row2, HTuple hv_Column2, HTuple hv_HeadLength, HTuple hv_HeadWidth);
// Chapter: Filters / Arithmetic
// Short Description: Scale the gray values of an image from the interval [Min,Max] to [0,255] 
void scale_image_range (HObject ho_Image, HObject *ho_ImageScaled, HTuple hv_Min, 
    HTuple hv_Max);
// Chapter: Develop
// Short Description: Switch dev_update_pc, dev_update_var and dev_update_window to 'off'. 
void dev_update_off ();
// Chapter: Develop
// Short Description: Resizes a graphics window with a given maximum extent such that it preserves the aspect ratio of a given width and height 
void dev_resize_window_fit_size (HTuple hv_Row, HTuple hv_Column, HTuple hv_Width, 
    HTuple hv_Height, HTuple hv_WidthLimit, HTuple hv_HeightLimit);
// Chapter: Develop
// Short Description: Switch dev_update_pc, dev_update_var and dev_update_window to 'on'. 
void dev_update_on ();
// Chapter: Calibration / Hand-Eye
// Short Description: Perform a hand-eye calibration with a stationary camera. 
void calibrate_hand_eye_stationary_cam_approx (HTuple hv_RobotTouchingPointInToolCoordinates, 
    HTuple hv_RowsTouchingPointInPlane, HTuple hv_ColumnsTouchingPointInPlane, HTupleVector/*{eTupleVector,Dim=1}*/ hvec_ToolInBasePoses, 
    HTuple hv_CalibObjectData, HTuple *hv_HandEyeCalibData);
// Chapter: Calibration / Hand-Eye
// Short Description: Perform a hand-eye calibration with a stationary camera. 
void calibrate_hand_eye_stationary_cam_approx_without_calib_plate (HTuple hv_RowsTouchingPointInPlane, 
    HTuple hv_ColumnsTouchingPointInPlane, HTupleVector/*{eTupleVector,Dim=1}*/ hvec_ToolInBasePoses, 
    HTuple hv_RobotTouchingPointInToolCoordinates, HTuple hv_DistanceObjectTouchingPointToPlane, 
    HTuple hv_DistancePlaneToCamera, HTuple hv_Width, HTuple hv_Height, HTuple *hv_HandEyeCalibData);
// Chapter: Calibration / Hand-Eye
// Short Description: Calibrate the X, Y, Z coordinates of a touching point of a robot. 
void calibrate_robot_touching_point (HTuple hv_DataDir, HTuple *hv_RobotTouchingPointInToolCoordinates);
// Chapter: Calibration / Camera Parameters
// Short Description: Generate a camera parameter tuple for an area scan camera with an object-side telecentric tilt lens and with distortions modeled by the polynomial model. 
void gen_cam_par_area_scan_tilt_object_side_telecentric_polynomial (HTuple hv_Magnification, 
    HTuple hv_K1, HTuple hv_K2, HTuple hv_K3, HTuple hv_P1, HTuple hv_P2, HTuple hv_ImagePlaneDist, 
    HTuple hv_Tilt, HTuple hv_Rot, HTuple hv_Sx, HTuple hv_Sy, HTuple hv_Cx, HTuple hv_Cy, 
    HTuple hv_ImageWidth, HTuple hv_ImageHeight, HTuple *hv_CameraParam);
// Chapter: Calibration / Camera Parameters
// Short Description: Generate a camera parameter tuple for an area scan camera with a tilt lens and with distortions modeled by the polynomial model. 
void gen_cam_par_area_scan_tilt_polynomial (HTuple hv_Focus, HTuple hv_K1, HTuple hv_K2, 
    HTuple hv_K3, HTuple hv_P1, HTuple hv_P2, HTuple hv_ImagePlaneDist, HTuple hv_Tilt, 
    HTuple hv_Rot, HTuple hv_Sx, HTuple hv_Sy, HTuple hv_Cx, HTuple hv_Cy, HTuple hv_ImageWidth, 
    HTuple hv_ImageHeight, HTuple *hv_CameraParam);
// Chapter: Calibration / Camera Parameters
// Short Description: Generate a camera parameter tuple for an area scan camera with a bilateral telecentric tilt lens and with distortions modeled by the polynomial model. 
void gen_cam_par_area_scan_tilt_bilateral_telecentric_polynomial (HTuple hv_Magnification, 
    HTuple hv_K1, HTuple hv_K2, HTuple hv_K3, HTuple hv_P1, HTuple hv_P2, HTuple hv_Tilt, 
    HTuple hv_Rot, HTuple hv_Sx, HTuple hv_Sy, HTuple hv_Cx, HTuple hv_Cy, HTuple hv_ImageWidth, 
    HTuple hv_ImageHeight, HTuple *hv_CameraParam);
// Chapter: Calibration / Monocular
// Short Description: Collect the data to calibrate a camera with a single image. 
void collect_single_image_calibration_data (HTuple hv_ImageCaltabFileName, HTuple hv_CalPlateDescr, 
    HTuple hv_CalPlateThickness, HTuple hv_StartCamParam, HTuple *hv_CalibObjectData);
// Chapter: Calibration / Camera Parameters
// Short Description: Get the names of the parameters in a camera parameter tuple. 
void get_cam_par_names (HTuple hv_CameraParam, HTuple *hv_CameraType, HTuple *hv_ParamNames);
// Chapter: Calibration / Monocular
// Short Description: Calibrate a camera with a single image. 
void calibrate_camera_and_plane_single_image (HTuple hv_CalibObjectData);
// Chapter: Calibration / Camera Parameters
// Short Description: Generate a camera parameter tuple for an area scan camera with a telecentric lens and with distortions modeled by the polynomial model. 
void gen_cam_par_area_scan_telecentric_polynomial (HTuple hv_Magnification, HTuple hv_K1, 
    HTuple hv_K2, HTuple hv_K3, HTuple hv_P1, HTuple hv_P2, HTuple hv_Sx, HTuple hv_Sy, 
    HTuple hv_Cx, HTuple hv_Cy, HTuple hv_ImageWidth, HTuple hv_ImageHeight, HTuple *hv_CameraParam);
// Chapter: Calibration / Camera Parameters
// Short Description: Generate a camera parameter tuple for an area scan camera with a bilateral telecentric tilt lens and with distortions modeled by the division model. 
void gen_cam_par_area_scan_tilt_bilateral_telecentric_division (HTuple hv_Magnification, 
    HTuple hv_Kappa, HTuple hv_Tilt, HTuple hv_Rot, HTuple hv_Sx, HTuple hv_Sy, HTuple hv_Cx, 
    HTuple hv_Cy, HTuple hv_ImageWidth, HTuple hv_ImageHeight, HTuple *hv_CameraParam);
// Chapter: Calibration / Camera Parameters
// Short Description: Generate a camera parameter tuple for an area scan camera with an object-side telecentric tilt lens and with distortions modeled by the division model. 
void gen_cam_par_area_scan_tilt_object_side_telecentric_division (HTuple hv_Magnification, 
    HTuple hv_Kappa, HTuple hv_ImagePlaneDist, HTuple hv_Tilt, HTuple hv_Rot, HTuple hv_Sx, 
    HTuple hv_Sy, HTuple hv_Cx, HTuple hv_Cy, HTuple hv_ImageWidth, HTuple hv_ImageHeight, 
    HTuple *hv_CameraParam);
// Chapter: Calibration / Camera Parameters
// Short Description: Get the value of a specified camera parameter from the camera parameter tuple. 
void get_cam_par_data (HTuple hv_CameraParam, HTuple hv_ParamName, HTuple *hv_ParamValue);
// Chapter: Calibration / Camera Parameters
// Short Description: Generate a camera parameter tuple for an area scan camera with a tilt lens and with distortions modeled by the division model. 
void gen_cam_par_area_scan_tilt_division (HTuple hv_Focus, HTuple hv_Kappa, HTuple hv_ImagePlaneDist, 
    HTuple hv_Tilt, HTuple hv_Rot, HTuple hv_Sx, HTuple hv_Sy, HTuple hv_Cx, HTuple hv_Cy, 
    HTuple hv_ImageWidth, HTuple hv_ImageHeight, HTuple *hv_CameraParam);
// Chapter: Calibration / Camera Parameters
// Short Description: Generate a camera parameter tuple for an area scan camera with an image-side telecentric tilt lens and with distortions modeled by the division model. 
void gen_cam_par_area_scan_tilt_image_side_telecentric_division (HTuple hv_Focus, 
    HTuple hv_Kappa, HTuple hv_Tilt, HTuple hv_Rot, HTuple hv_Sx, HTuple hv_Sy, HTuple hv_Cx, 
    HTuple hv_Cy, HTuple hv_ImageWidth, HTuple hv_ImageHeight, HTuple *hv_CameraParam);
// Chapter: Calibration / Camera Parameters
// Short Description: Set the value of a specified camera parameter in the camera parameter tuple. 
void set_cam_par_data (HTuple hv_CameraParamIn, HTuple hv_ParamName, HTuple hv_ParamValue, 
    HTuple *hv_CameraParamOut);
// Chapter: Calibration / Camera Parameters
// Short Description: Generate a camera parameter tuple for a line scan camera. 
void gen_cam_par_line_scan (HTuple hv_Focus, HTuple hv_Kappa, HTuple hv_Sx, HTuple hv_Sy, 
    HTuple hv_Cx, HTuple hv_Cy, HTuple hv_ImageWidth, HTuple hv_ImageHeight, HTuple hv_Vx, 
    HTuple hv_Vy, HTuple hv_Vz, HTuple *hv_CameraParam);
// Chapter: Transformations / Poses
// Short Description: Calculate the poses to grasp an object. 
void calculate_tool_in_base_robot_path_poses (HTupleVector/*{eTupleVector,Dim=1}*/ hvec_ToolInModelRobotPathPoses, 
    HTuple hv_ModelInBasePose, HTuple hv_Poses, HTupleVector/*{eTupleVector,Dim=1}*/ *hvec_ToolInBaseRobotPathPoses);
// Chapter: Calibration / Camera Parameters
// Short Description: Generate a camera parameter tuple for an area scan camera with an image-side telecentric tilt lens and with distortions modeled by the polynomial model. 
void gen_cam_par_area_scan_tilt_image_side_telecentric_polynomial (HTuple hv_Focus, 
    HTuple hv_K1, HTuple hv_K2, HTuple hv_K3, HTuple hv_P1, HTuple hv_P2, HTuple hv_Tilt, 
    HTuple hv_Rot, HTuple hv_Sx, HTuple hv_Sy, HTuple hv_Cx, HTuple hv_Cy, HTuple hv_ImageWidth, 
    HTuple hv_ImageHeight, HTuple *hv_CameraParam);
// Chapter: 3D Object Model / Features
void get_bounding_box_points_from_min_max (HTuple hv_BoundingBox, HTuple *hv_PX, 
    HTuple *hv_PY, HTuple *hv_PZ);
// Chapter: 3D Object Model / Transformations
void get_extent_by_axis (HTuple hv_OM3D, HTuple hv_XExtent, HTuple hv_YExtent, HTuple hv_ZExtent, 
    HTuple *hv_XExtentOut, HTuple *hv_YExtentOut, HTuple *hv_ZExtentOut);
// Chapter: Calibration / Hand-Eye
// Short Description: Get the coordinates of the central mark of the closest finder pattern. 
void get_nearest_finder_pattern_coordinates (HObject ho_CalibPlateImage, HTuple hv_RowNearFinderPattern, 
    HTuple hv_ColumNearFinderPattern, HTuple hv_CalibObjectData, HTuple *hv_RowFinderPattern, 
    HTuple *hv_ColumnFinderPattern);
// Chapter: Graphics / Text
void dev_disp_calibration_data_instructions2 (HObject ho_Image);
// Chapter: Matrix / Arithmetic
void get_rotation_axis (HTuple hv_MatRot, HTuple hv_MatRot0, HTuple *hv_RotationAxis, 
    HTuple *hv_DiffToIdentity);
// Chapter: 3D Object Model / Creation
// Short Description: Generate 3D object models for the camera, the plane, the robot's base and the robot's tool in a stationary camera setup. 
void gen_current_setup_stationary_cam_object_model_3d (HTuple hv_ArrowThickness, 
    HTuple hv_ArrowLength, HTuple hv_CameraSize, HTuple hv_HandEyeCalibData, HTuple *hv_OM3DCamera, 
    HTuple *hv_OM3DPlane, HTuple *hv_OM3DBase, HTuple *hv_OM3DToolOrigin);
// Chapter: Transformations / Misc
// Short Description: Obtain the pose of the matched model in the base coordinate system in a stationary camera setup. 
void obtain_3d_pose_of_match_stationary_cam (HTuple hv_Row, HTuple hv_Column, HTuple hv_Angle, 
    HTuple hv_HandEyeCalibData, HTuple hv_Poses, HTuple hv_RectificationData, HTuple *hv_ModelInBasePose);
// Chapter: Graphics / Window
// Short Description: Open a new window next to an existing one. 
void open_new_window (HTuple *hv_WindowHandle, HTuple *hv_WindowHandleGraphics);
// Chapter: Graphics / Text
void dev_disp_calibration_data_instructions (HObject ho_Image);
// Chapter: 3D Object Model / Creation
// Short Description: Generate 3D object models for the camera and the robot's tool. 
void gen_camera_and_tool_moving_cam_object_model_3d (HTuple hv_ToolInCamPose, HTuple hv_ToolInBasePose, 
    HTuple hv_CameraSize, HTuple hv_ConeLength, HTuple hv_OM3DToolOrig, HTuple hv_CamParam, 
    HTuple *hv_OM3DCamera, HTuple *hv_OM3DTool);
// Chapter: 3D Object Model / Creation
// Short Description: Generate the 3D object model of the plane. 
void gen_ground_plane_object_model_3d (HTuple hv_OM3DTool, HTuple hv_OM3DCamera, 
    HTuple hv_OM3DBase, HTuple hv_FactorBorder, HTuple hv_PlaneInBasePose, HTuple *hv_OM3DPlane);
// Chapter: Graphics / Text
void dev_disp_approach_pose_touching_point_instructions (HTuple hv_WindowHandle, 
    HTuple hv_WindowHandleGraphics, HTuple hv_Index);
// Chapter: 3D Object Model / Creation
// Short Description: Generate base and tool 3D models of the robot. 
void gen_robot_tool_and_base_object_model_3d (HTuple hv_ArrowThickness, HTuple hv_ArrowLength, 
    HTuple *hv_OM3DToolOrigin, HTuple *hv_OM3DBase);
// Chapter: Transformations / Misc
// Short Description: Calculate the touching point in tool coordinates. 
void get_robot_touching_point_in_tool_coordinates (HTupleVector/*{eTupleVector,Dim=1}*/ hvec_ToolInBasePosesTouchingPoint, 
    HTuple *hv_RobotTouchingPointInToolCoordinates);
// Chapter: Transformations / Misc
// Short Description: Obtain the pose of the matched model in the base coordinate system. 
void obtain_3d_pose_of_match_moving_cam (HTuple hv_Row, HTuple hv_Column, HTuple hv_Angle, 
    HTuple hv_ToolInBasePose, HTuple hv_HandEyeCalibData, HTuple hv_Poses, HTuple hv_RectificationData, 
    HTuple *hv_ModelInBasePose);
// Chapter: 3D Object Model / Creation
// Short Description: Generate 3D object models for the camera, robot's tool and plane. 
void gen_current_setup_moving_cam_object_model_3d (HTuple hv_CameraSize, HTuple hv_ToolInBasePose, 
    HTuple hv_HandEyeCalibData, HTuple hv_OM3DToolOrigin, HTuple hv_OM3DBase, HTuple *hv_OM3DCamera, 
    HTuple *hv_OM3DTool, HTuple *hv_OM3DPlane);
// Chapter: Graphics / Text
// Short Description: Display the introduction for the procedure calibrate_robot_touching_point. 
void dev_disp_introduction (HTuple hv_WindowHandle, HTuple hv_WindowHandleGraphics);
// Chapter: 3D Object Model / Creation
// Short Description: Generate a 3D object of the matched model, in the case of rectification. 
void gen_matching_object_model_3d (HTuple hv_ModelID, HTuple hv_ObjectHeight, HTuple hv_Poses, 
    HTuple hv_HandEyeCalibData, HTuple hv_RectificationData, HTuple *hv_OM3DModel);
// Chapter: 3D Object Model / Creation
void gen_tool_to_touching_point_object_model_3d (HTupleVector/*{eTupleVector,Dim=1}*/ hvec_ToolInBasePosesTouchingPoint, 
    HTuple hv_RobotTouchingPointInToolCoordinates, HTuple *hv_OM3DToolTouchingPoint);
// Chapter: Classification / Misc
// Short Description: Returns the length of the feature vector for each feature name. 
void get_feature_lengths (HTuple hv_FeatureNames, HTuple *hv_Lengths);
// Chapter: Classification / Misc
// Short Description: List all available feature group names. 
void query_feature_group_names (HTuple *hv_GroupNames);
// Chapter: Calibration / Camera Parameters
// Short Description: Generate a camera parameter tuple for an area scan camera with distortions modeled by the polynomial model. 
void gen_cam_par_area_scan_polynomial (HTuple hv_Focus, HTuple hv_K1, HTuple hv_K2, 
    HTuple hv_K3, HTuple hv_P1, HTuple hv_P2, HTuple hv_Sx, HTuple hv_Sy, HTuple hv_Cx, 
    HTuple hv_Cy, HTuple hv_ImageWidth, HTuple hv_ImageHeight, HTuple *hv_CameraParam);
// Chapter: Classification / Misc
// Short Description: Test procedure for custom features. 
void test_features (HTuple hv_FeatureNames);
// Chapter: Classification / Misc
// Short Description: Returns a table of feature names sorted by groups. 
void query_feature_names_by_group (HTuple hv_GroupNames, HTuple *hv_FeatureNames, 
    HTuple *hv_Groups);
// Chapter: Classification / Misc
// Short Description: Calculate color intensity features. 
void calc_feature_color_intensity (HObject ho_Region, HObject ho_Image, HTuple hv_ColorSpace, 
    HTuple hv_Mode, HTuple *hv_Feature);
// Chapter: Classification / Misc
// Short Description: Returns a list of feature names that belong to the feature groups given in GroupNames. 
void get_feature_names (HTuple hv_GroupNames, HTuple *hv_Names);
// Chapter: Calibration / Camera Parameters
// Short Description: Generate a camera parameter tuple for an area scan camera with distortions modeled by the division model. 
void gen_cam_par_area_scan_division (HTuple hv_Focus, HTuple hv_Kappa, HTuple hv_Sx, 
    HTuple hv_Sy, HTuple hv_Cx, HTuple hv_Cy, HTuple hv_ImageWidth, HTuple hv_ImageHeight, 
    HTuple *hv_CameraParam);
// Chapter: Classification / Misc
// Short Description: This procedure contains all relevant information about the supported features. 
void get_features (HObject ho_Region, HObject ho_Image, HTuple hv_Namelist, HTuple hv_Mode, 
    HTuple *hv_Output);
// Chapter: Calibration / Camera Parameters
// Short Description: Generate a camera parameter tuple for an area scan camera with a telecentric lens and with distortions modeled by the division model. 
void gen_cam_par_area_scan_telecentric_division (HTuple hv_Magnification, HTuple hv_Kappa, 
    HTuple hv_Sx, HTuple hv_Sy, HTuple hv_Cx, HTuple hv_Cy, HTuple hv_ImageWidth, 
    HTuple hv_ImageHeight, HTuple *hv_CameraParam);
// Chapter: Classification / Misc
// Short Description: Auxiliary procedure for get_features. 
void append_names_or_groups_pyramid (HTuple hv_Mode, HTuple hv_Groups, HTuple hv_CurrentName, 
    HTuple hv_Names, HTuple hv_NameRegExp, HTuple hv_AccumulatedResults, HTuple *hv_ExtendedResults);
// Chapter: Classification / Misc
// Short Description: Calculate a feature on different image pyramid levels. 
void calc_feature_pyramid (HObject ho_Region, HObject ho_Image, HTuple hv_FeatureName, 
    HTuple hv_NumLevels, HTuple *hv_Feature);
// Chapter: Classification / Misc
// Short Description: Calculate gray-value projections and their histograms. 
void calc_feature_gray_proj (HObject ho_Region, HObject ho_Image, HTuple hv_Mode, 
    HTuple hv_Size, HTuple *hv_Feature);
// Chapter: Classification / Misc
// Short Description: Calculate one or more features of a given image and/or region. 
void calculate_features (HObject ho_Region, HObject ho_Image, HTuple hv_FeatureNames, 
    HTuple *hv_Features);
// Chapter: Classification / Misc
// Short Description: Calculate edge density histogram feature. 
void calc_feature_edge_density_histogram (HObject ho_Region, HObject ho_Image, HTuple hv_NumBins, 
    HTuple *hv_Feature);
// Chapter: Classification / Misc
// Short Description: Calculate the gradient direction histogram. 
void calc_feature_grad_dir_histo (HObject ho_Region, HObject ho_Image, HTuple hv_NumBins, 
    HTuple *hv_Feature);
// Chapter: Classification / Misc
// Short Description: Generate a dummy image and region that are, e.g., used to determine the lengths of the feature vectors in get_feature_lengths. 
void gen_dummy_objects (HObject *ho_Region, HObject *ho_Image);
// Chapter: Classification / Misc
// Short Description: Calculate edge density. 
void calc_feature_edge_density (HObject ho_Region, HObject ho_Image, HTuple *hv_Feature);
// Chapter: Classification / Misc
// Short Description: Calculate gray-value projections of polar-transformed image regions. 
void calc_feature_polar_gray_proj (HObject ho_Region, HObject ho_Image, HTuple hv_Mode, 
    HTuple hv_Width, HTuple hv_Height, HTuple *hv_Features);
// Chapter: 3D Object Model / Creation
// Short Description: Generate a symbolic 3D object model of a camera. 
void gen_camera_object_model_3d (HTuple hv_CameraSetupModel, HTuple hv_CamIndex, 
    HTuple hv_CameraSize, HTuple *hv_OM3DCam);
// Chapter: Graphics / Output
// Short Description: Displays a continue button. 
void disp_continue_button (HTuple hv_WindowHandle);
// Chapter: Graphics / Output
// Short Description: This procedure calls disp_object_model_3d and a fallback solution if there is no OpenGL Available. 
void disp_object_model_3d_safe (HTuple hv_WindowHandle, HTuple hv_ObjectModel3D, 
    HTuple hv_CamParam, HTuple hv_Pose, HTuple hv_GenParamName, HTuple hv_GenParamValue);
// Chapter: Calibration / Hand-Eye
// Short Description: Prepares the model to match and grasp in a stationary camera setup. 
void prepare_poses_and_rectification_data_stationary_cam (HTuple hv_ObjectHeight, 
    HTuple hv_RectifyImage, HTuple hv_HandEyeCalibData, HTuple *hv_Poses, HTuple *hv_RectificationData);
// Chapter: Graphics / Output
// Short Description: Can replace disp_object_model_3d if there is no OpenGL available. 
void disp_object_model_no_opengl (HObject *ho_ModelContours, HTuple hv_ObjectModel3DID, 
    HTuple hv_GenParamName, HTuple hv_GenParamValue, HTuple hv_WindowHandleBuffer, 
    HTuple hv_CamParam, HTuple hv_PosesOut);
// Chapter: System / Multithreading
void read_message_tuple (HTuple hv_MessageHandle, HTuple hv_Key, HTuple *hv_TupleData);
// Chapter: System / Multithreading
void read_message_obj (HObject *ho_ObjectData, HTuple hv_MessageHandle, HTuple hv_Key);
// Chapter: Calibration / Hand-Eye
// Short Description: Prepare the input image for matching and compute the needed pose. 
void rectify_image_and_compute_matching_plane_moving_cam (HObject ho_Image, HObject *ho_ImageRectified, 
    HTuple hv_ToolInBasePose, HTuple hv_HandEyeCalibData, HTuple hv_Poses, HTuple hv_RectificationData);
// Chapter: Graphics / 3D Scene
// Short Description: Visualize the poses that were used to calculate the touching point, and the result. 
void visualize_calibrated_touching_point (HTuple hv_RobotTouchingPointInToolCoordinates, 
    HTupleVector/*{eTupleVector,Dim=1}*/ hvec_ToolInBasePosesTouchingPoint, HTuple hv_WindowHandle);
// Chapter: 3D Reconstruction / Multi-View Stereo
// Short Description: Estimate a bounding box for 3D reconstruction based on a stereo setup. 
void estimate_bounding_box_3d_reconstruction (HTuple hv_StereoModelID, HTuple hv_ObjectHeight, 
    HTuple *hv_BoundingBox);
// Chapter: 3D Object Model / Creation
// Short Description: Generate a 3D object model representing the view cone of a telecentric camera. 
void gen_cone_telecentric_object_model_3d (HTuple hv_CameraSetupModelID, HTuple hv_CameraIndex, 
    HTuple hv_ConeLength, HTuple *hv_ObjectModel3D);
// Chapter: Graphics / Parameters
void color_string_to_rgb (HTuple hv_Color, HTuple *hv_RGB);
// Chapter: 3D Object Model / Creation
// Short Description: Generate a 3D object model representing the view cone of a perspective camera. 
void gen_cone_perspective_object_model_3d (HTuple hv_CameraSetupModelID, HTuple hv_CameraIndex, 
    HTuple hv_ConeLength, HTuple *hv_ObjectModel3D);
// Chapter: Graphics / Output
// Short Description: Reflect the pose change that was introduced by the user by moving the mouse 
void analyze_graph_event (HObject ho_BackgroundImage, HTuple hv_MouseMapping, HTuple hv_Button, 
    HTuple hv_Row, HTuple hv_Column, HTuple hv_WindowHandle, HTuple hv_WindowHandleBuffer, 
    HTuple hv_VirtualTrackball, HTuple hv_TrackballSize, HTuple hv_SelectedObjectIn, 
    HTuple hv_Scene3D, HTuple hv_AlphaOrig, HTuple hv_ObjectModel3DID, HTuple hv_CamParam, 
    HTuple hv_Labels, HTuple hv_Title, HTuple hv_Information, HTuple hv_GenParamName, 
    HTuple hv_GenParamValue, HTuple hv_PosesIn, HTuple hv_ButtonHoldIn, HTuple hv_TBCenter, 
    HTuple hv_TBSize, HTuple hv_WindowCenteredRotationlIn, HTuple hv_MaxNumModels, 
    HTuple *hv_PosesOut, HTuple *hv_SelectedObjectOut, HTuple *hv_ButtonHoldOut, 
    HTuple *hv_WindowCenteredRotationOut);
// Chapter: Calibration / Hand-Eye
// Short Description: Prepares the model to match and grasp. 
void prepare_poses_and_rectification_data_moving_cam (HTuple hv_ToolInBasePose, HTuple hv_ObjectHeight, 
    HTuple hv_RectifyImage, HTuple hv_HandEyeCalibData, HTuple *hv_Poses, HTuple *hv_RectificationData);
// Chapter: Graphics / Output
// Short Description: Determine the optimum distance of the object to obtain a reasonable visualization 
void determine_optimum_pose_distance (HTuple hv_ObjectModel3DID, HTuple hv_CamParam, 
    HTuple hv_ImageCoverage, HTuple hv_PoseIn, HTuple *hv_PoseOut);
// Chapter: 3D Object Model / Creation
// Short Description: Generate 3D object models which visualize the cameras of a stereo model. 
void gen_camera_setup_object_model_3d (HTuple hv_CameraSetupModelID, HTuple hv_CameraSize, 
    HTuple hv_ConeLength, HTuple *hv_ObjectModel3DCamera, HTuple *hv_ObjectModel3DCone);
// Chapter: 3D Object Model / Creation
// Short Description: Generate a 3D object model which visualizes the bounding box of a stereo model. 
void gen_bounding_box_object_model_3d (HTuple hv_StereoModelID, HTuple *hv_ObjectModel3DBoundingBox);

// Procedures 
// Chapter: Graphics / Output
void disp_title_and_information (HTuple hv_WindowHandle, HTuple hv_Title, HTuple hv_Information)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_WinRow, hv_WinColumn, hv_WinWidth;
  HTuple  hv_WinHeight, hv_NumTitleLines, hv_Row, hv_Column;
  HTuple  hv_TextWidth, hv_NumInfoLines, hv_Ascent, hv_Descent;
  HTuple  hv_Width, hv_Height;

  //global tuple gInfoDecor
  //global tuple gInfoPos
  //global tuple gTitlePos
  //global tuple gTitleDecor
  //
  GetWindowExtents(hv_WindowHandle, &hv_WinRow, &hv_WinColumn, &hv_WinWidth, &hv_WinHeight);
  hv_Title = ((""+hv_Title)+"").TupleSplit("\n");
  hv_NumTitleLines = hv_Title.TupleLength();
  if (0 != (hv_NumTitleLines>0))
  {
    hv_Row = 12;
    if (0 != (ExpGetGlobalVar_gTitlePos()==HTuple("UpperLeft")))
    {
      hv_Column = 12;
    }
    else if (0 != (ExpGetGlobalVar_gTitlePos()==HTuple("UpperCenter")))
    {
      max_line_width(hv_WindowHandle, hv_Title, &hv_TextWidth);
      hv_Column = (hv_WinWidth/2)-(hv_TextWidth/2);
    }
    else if (0 != (ExpGetGlobalVar_gTitlePos()==HTuple("UpperRight")))
    {
      if (0 != (HTuple(ExpGetGlobalVar_gTitleDecor()[1])==HTuple("true")))
      {
        max_line_width(hv_WindowHandle, hv_Title+"  ", &hv_TextWidth);
      }
      else
      {
        max_line_width(hv_WindowHandle, hv_Title, &hv_TextWidth);
      }
      hv_Column = (hv_WinWidth-hv_TextWidth)-10;
    }
    else
    {
      //Unknown position!
      // stop(...); only in hdevelop
    }
    disp_message(hv_WindowHandle, hv_Title, "window", hv_Row, hv_Column, HTuple(ExpGetGlobalVar_gTitleDecor()[0]), 
        HTuple(ExpGetGlobalVar_gTitleDecor()[1]));
  }
  hv_Information = ((""+hv_Information)+"").TupleSplit("\n");
  hv_NumInfoLines = hv_Information.TupleLength();
  if (0 != (hv_NumInfoLines>0))
  {
    if (0 != (ExpGetGlobalVar_gInfoPos()==HTuple("UpperLeft")))
    {
      hv_Row = 12;
      hv_Column = 12;
    }
    else if (0 != (ExpGetGlobalVar_gInfoPos()==HTuple("UpperRight")))
    {
      if (0 != (HTuple(ExpGetGlobalVar_gInfoDecor()[1])==HTuple("true")))
      {
        max_line_width(hv_WindowHandle, hv_Information+"  ", &hv_TextWidth);
      }
      else
      {
        max_line_width(hv_WindowHandle, hv_Information, &hv_TextWidth);
      }
      hv_Row = 12;
      hv_Column = (hv_WinWidth-hv_TextWidth)-12;
    }
    else if (0 != (ExpGetGlobalVar_gInfoPos()==HTuple("LowerLeft")))
    {
      GetStringExtents(hv_WindowHandle, hv_Information, &hv_Ascent, &hv_Descent, 
          &hv_Width, &hv_Height);
      hv_Row = (hv_WinHeight-(((HTuple(0).TupleMax2(hv_NumInfoLines-1))*(hv_Ascent+hv_Descent))+hv_Height))-12;
      hv_Column = 12;
    }
    else
    {
      //Unknown position!
      // stop(...); only in hdevelop
    }
    disp_message(hv_WindowHandle, hv_Information, "window", hv_Row, hv_Column, HTuple(ExpGetGlobalVar_gInfoDecor()[0]), 
        HTuple(ExpGetGlobalVar_gInfoDecor()[1]));
  }
  //
  return;
}

// Chapter: Classification / Misc
// Short Description: Describe and calculate user-defined features to be used in conjunction with the calculate_feature_set procedure library. 
void get_custom_features (HObject ho_Region, HObject ho_Image, HTuple hv_CurrentName, 
    HTuple hv_Mode, HTuple *hv_Output)
{

  // Local iconic variables
  HObject  ho_RegionSelected, ho_Contours, ho_ContoursSelected;
  HObject  ho_ContoursSplit;

  // Local control variables
  HTuple  hv_TmpResults, hv_Name, hv_Groups, hv_Feature;
  HTuple  hv_NumRegions, hv_I, hv_NumContours, hv_NumLines;
  HTuple  hv_J, hv_NumSplit;

  //
  //This procedure can be used to extend the functionality
  //of the calculate_feature_set procedure library by
  //user-defined features.
  //
  //Instructions:
  //
  //1. Find the template block at the beginning the procedure
  //(marked by comments) and duplicate it.
  //
  //2. In the copy edit the two marked areas as follows:
  //
  //2.1. Feature name and groups:
  //Assign a unique identifier for your feature to the variable "Name".
  //Then, assign the groups that you want your feature to belong to
  //to the variable "Groups".
  //
  //2.2. Feature calculation:
  //Enter the code that calculates your feature and
  //assign the result to the variable "Feature".
  //
  //3. Test
  //Use the "test_feature" procedure to check,
  //if the feature is calculated correctly.
  //If the procedure throws an exception,
  //maybe the order of the feature vector is wrong
  //(See note below).
  //
  //4. Integration
  //- Save your modified procedure get_custom_features.hdvp
  //  to a location of your choice.
  //  (We recommend not to overwrite the template.)
  //- Make sure, that your version of get_custom_procedures
  //  is included in the procedure directories of HDevelop.
  //  (Choose Procedures -> Manage Procedures -> Directories -> Add from the HDevelop menu bar.)
  //
  //Note:
  //The current implementation supports region arrays as input.
  //In that case, multi-dimensional feature vectors are simply concatenated.
  //Example: The feature 'center' has two dimensions [Row,Column].
  //If an array of three regions is passed, the correct order of the "Feature" variable is
  //[Row1, Column1, Row2, Column2, Row3, Column3].
  //
  hv_TmpResults = HTuple();
  //************************************************
  //************************************************
  //**** Copy the following template block     *****
  //**** and edit the two marked code sections *****
  //**** to add user-defined features          *****
  //************************************************
  //************************************************
  //
  //***************************************
  //*********** TEMPLATE BLOCK ************
  //***************************************
  //
  //********************************************************************
  //** Section 1:
  //** Enter unique feature name and groups to which it belongs here ***
  hv_Name = "custom_feature_numlines";
  hv_Groups = "custom";
  //** Enter unique feature name and groups above this line ************
  //********************************************************************
  if (0 != (hv_Name==hv_CurrentName))
  {
    //******************************************************
    //** Section 2:
    //** Enter code to calculate feature here **************
    hv_Feature = HTuple();
    CountObj(ho_Region, &hv_NumRegions);
    {
    HTuple end_val69 = hv_NumRegions;
    HTuple step_val69 = 1;
    for (hv_I=1; hv_I.Continue(end_val69, step_val69); hv_I += step_val69)
    {
      SelectObj(ho_Region, &ho_RegionSelected, hv_I);
      GenContourRegionXld(ho_RegionSelected, &ho_Contours, "border");
      CountObj(ho_Contours, &hv_NumContours);
      hv_NumLines = 0;
      {
      HTuple end_val74 = hv_NumContours;
      HTuple step_val74 = 1;
      for (hv_J=1; hv_J.Continue(end_val74, step_val74); hv_J += step_val74)
      {
        SelectObj(ho_Contours, &ho_ContoursSelected, hv_J);
        SegmentContoursXld(ho_ContoursSelected, &ho_ContoursSplit, "lines", 5, 2, 
            1);
        CountObj(ho_ContoursSplit, &hv_NumSplit);
        hv_NumLines += hv_NumSplit;
      }
      }
      hv_Feature = hv_Feature.TupleConcat(hv_NumLines);
    }
    }
    //** Enter code to calculate feature above this line ***
    //******************************************************
    append_length_or_values(hv_Mode, hv_Feature, hv_TmpResults, &hv_TmpResults);
  }
  append_names_or_groups(hv_Mode, hv_Name, hv_Groups, hv_CurrentName, hv_TmpResults, 
      &hv_TmpResults);
  //
  //************************************
  //****** END OF TEMPLATE BLOCK *******
  //************************************
  //
  (*hv_Output) = hv_TmpResults;
  return;
}

// Chapter: Graphics / Text
// Short Description: This procedure writes a text message. 
void disp_text_button (HTuple hv_WindowHandle, HTuple hv_String, HTuple hv_CoordSystem, 
    HTuple hv_Row, HTuple hv_Column, HTuple hv_TextColor, HTuple hv_ButtonColor)
{

  // Local iconic variables
  HObject  ho_UpperLeft, ho_LowerRight, ho_Rectangle;

  // Local control variables
  HTuple  hv_Red, hv_Green, hv_Blue, hv_Row1Part;
  HTuple  hv_Column1Part, hv_Row2Part, hv_Column2Part, hv_RowWin;
  HTuple  hv_ColumnWin, hv_WidthWin, hv_HeightWin, hv_Exception;
  HTuple  hv_Fac, hv_RGB, hv_RGBL, hv_RGBD, hv_ButtonColorBorderL;
  HTuple  hv_ButtonColorBorderD, hv_MaxAscent, hv_MaxDescent;
  HTuple  hv_MaxWidth, hv_MaxHeight, hv_R1, hv_C1, hv_FactorRow;
  HTuple  hv_FactorColumn, hv_Width, hv_Index, hv_Ascent;
  HTuple  hv_Descent, hv_W, hv_H, hv_FrameHeight, hv_FrameWidth;
  HTuple  hv_R2, hv_C2, hv_ClipRegion, hv_DrawMode, hv_BorderWidth;
  HTuple  hv_CurrentColor;

  //This procedure displays text in a graphics window.
  //
  //Input parameters:
  //WindowHandle: The WindowHandle of the graphics window, where
  //   the message should be displayed
  //String: A tuple of strings containing the text message to be displayed
  //CoordSystem: If set to 'window', the text position is given
  //   with respect to the window coordinate system.
  //   If set to 'image', image coordinates are used.
  //   (This may be useful in zoomed images.)
  //Row: The row coordinate of the desired text position
  //   If set to -1, a default value of 12 is used.
  //Column: The column coordinate of the desired text position
  //   If set to -1, a default value of 12 is used.
  //Color: defines the color of the text as string.
  //   If set to [], '' or 'auto' the currently set color is used.
  //   If a tuple of strings is passed, the colors are used cyclically
  //   for each new textline.
  //ButtonColor: Must be set to a color string (e.g. 'white', '#FF00CC', etc.).
  //             The text is written in a box of that color.
  //
  //Prepare window.
  GetRgb(hv_WindowHandle, &hv_Red, &hv_Green, &hv_Blue);
  GetPart(hv_WindowHandle, &hv_Row1Part, &hv_Column1Part, &hv_Row2Part, &hv_Column2Part);
  GetWindowExtents(hv_WindowHandle, &hv_RowWin, &hv_ColumnWin, &hv_WidthWin, &hv_HeightWin);
  SetPart(hv_WindowHandle, 0, 0, hv_HeightWin-1, hv_WidthWin-1);
  //
  //Default settings.
  if (0 != (hv_Row==-1))
  {
    hv_Row = 12;
  }
  if (0 != (hv_Column==-1))
  {
    hv_Column = 12;
  }
  if (0 != (hv_TextColor==HTuple()))
  {
    hv_TextColor = "";
  }
  //
  try
  {
    color_string_to_rgb(hv_ButtonColor, &hv_RGB);
  }
  // catch (Exception) 
  catch (HException &HDevExpDefaultException)
  {
    HDevExpDefaultException.ToHTuple(&hv_Exception);
    hv_Exception = "Wrong value of control parameter ButtonColor (must be a valid color string)";
    throw HException(hv_Exception);
  }
  hv_Fac = 0.4;
  hv_RGBL = hv_RGB+((((255.0-hv_RGB)*hv_Fac)+0.5).TupleInt());
  hv_RGBD = hv_RGB-(((hv_RGB*hv_Fac)+0.5).TupleInt());
  hv_ButtonColorBorderL = "#"+((""+(hv_RGBL.TupleString("02x"))).TupleSum());
  hv_ButtonColorBorderD = "#"+((""+(hv_RGBD.TupleString("02x"))).TupleSum());
  //
  hv_String = ((""+hv_String)+"").TupleSplit("\n");
  //
  //Estimate extentions of text depending on font size.
  GetFontExtents(hv_WindowHandle, &hv_MaxAscent, &hv_MaxDescent, &hv_MaxWidth, &hv_MaxHeight);
  if (0 != (hv_CoordSystem==HTuple("window")))
  {
    hv_R1 = hv_Row;
    hv_C1 = hv_Column;
  }
  else
  {
    //Transform image to window coordinates.
    hv_FactorRow = (1.*hv_HeightWin)/((hv_Row2Part-hv_Row1Part)+1);
    hv_FactorColumn = (1.*hv_WidthWin)/((hv_Column2Part-hv_Column1Part)+1);
    hv_R1 = ((hv_Row-hv_Row1Part)+0.5)*hv_FactorRow;
    hv_C1 = ((hv_Column-hv_Column1Part)+0.5)*hv_FactorColumn;
  }
  //
  //Display text box depending on text size.
  //
  //Calculate box extents.
  hv_String = (" "+hv_String)+" ";
  hv_Width = HTuple();
  {
  HTuple end_val70 = (hv_String.TupleLength())-1;
  HTuple step_val70 = 1;
  for (hv_Index=0; hv_Index.Continue(end_val70, step_val70); hv_Index += step_val70)
  {
    GetStringExtents(hv_WindowHandle, HTuple(hv_String[hv_Index]), &hv_Ascent, &hv_Descent, 
        &hv_W, &hv_H);
    hv_Width = hv_Width.TupleConcat(hv_W);
  }
  }
  hv_FrameHeight = hv_MaxHeight*(hv_String.TupleLength());
  hv_FrameWidth = (HTuple(0).TupleConcat(hv_Width)).TupleMax();
  hv_R2 = hv_R1+hv_FrameHeight;
  hv_C2 = hv_C1+hv_FrameWidth;
  //Display rectangles.
  GetSystem("clip_region", &hv_ClipRegion);
  SetSystem("clip_region", "false");
  GetDraw(hv_WindowHandle, &hv_DrawMode);
  SetDraw(hv_WindowHandle, "fill");
  hv_BorderWidth = 2;
  GenRegionPolygonFilled(&ho_UpperLeft, ((((hv_R1-hv_BorderWidth).TupleConcat(hv_R1-hv_BorderWidth)).TupleConcat(hv_R1)).TupleConcat(hv_R2)).TupleConcat(hv_R2+hv_BorderWidth), 
      ((((hv_C1-hv_BorderWidth).TupleConcat(hv_C2+hv_BorderWidth)).TupleConcat(hv_C2)).TupleConcat(hv_C1)).TupleConcat(hv_C1-hv_BorderWidth));
  GenRegionPolygonFilled(&ho_LowerRight, ((((hv_R2+hv_BorderWidth).TupleConcat(hv_R1-hv_BorderWidth)).TupleConcat(hv_R1)).TupleConcat(hv_R2)).TupleConcat(hv_R2+hv_BorderWidth), 
      ((((hv_C2+hv_BorderWidth).TupleConcat(hv_C2+hv_BorderWidth)).TupleConcat(hv_C2)).TupleConcat(hv_C1)).TupleConcat(hv_C1-hv_BorderWidth));
  GenRectangle1(&ho_Rectangle, hv_R1, hv_C1, hv_R2, hv_C2);
  SetColor(hv_WindowHandle, hv_ButtonColorBorderL);
  DispObj(ho_UpperLeft, hv_WindowHandle);
  SetColor(hv_WindowHandle, hv_ButtonColorBorderD);
  DispObj(ho_LowerRight, hv_WindowHandle);
  SetColor(hv_WindowHandle, hv_ButtonColor);
  DispObj(ho_Rectangle, hv_WindowHandle);
  SetDraw(hv_WindowHandle, hv_DrawMode);
  SetSystem("clip_region", hv_ClipRegion);
  //Write text.
  {
  HTuple end_val96 = (hv_String.TupleLength())-1;
  HTuple step_val96 = 1;
  for (hv_Index=0; hv_Index.Continue(end_val96, step_val96); hv_Index += step_val96)
  {
    hv_CurrentColor = HTuple(hv_TextColor[hv_Index%(hv_TextColor.TupleLength())]);
    if (0 != (HTuple(hv_CurrentColor!=HTuple("")).TupleAnd(hv_CurrentColor!=HTuple("auto"))))
    {
      SetColor(hv_WindowHandle, hv_CurrentColor);
    }
    else
    {
      SetRgb(hv_WindowHandle, hv_Red, hv_Green, hv_Blue);
    }
    hv_Row = hv_R1+(hv_MaxHeight*hv_Index);
    DispText(hv_WindowHandle, HTuple(hv_String[hv_Index]), "window", hv_Row, hv_C1, 
        hv_CurrentColor, "box", "false");
  }
  }
  //Reset changed window settings.
  SetRgb(hv_WindowHandle, hv_Red, hv_Green, hv_Blue);
  SetPart(hv_WindowHandle, hv_Row1Part, hv_Column1Part, hv_Row2Part, hv_Column2Part);
  return;
}

// Chapter: Graphics / Output
// Short Description: Renders 3D object models in a buffer window. 
void dump_image_output (HObject ho_BackgroundImage, HTuple hv_WindowHandleBuffer, 
    HTuple hv_Scene3D, HTuple hv_AlphaOrig, HTuple hv_ObjectModel3DID, HTuple hv_GenParamName, 
    HTuple hv_GenParamValue, HTuple hv_CamParam, HTuple hv_Poses, HTuple hv_ColorImage, 
    HTuple hv_Title, HTuple hv_Information, HTuple hv_Labels, HTuple hv_VisualizeTrackball, 
    HTuple hv_DisplayContinueButton, HTuple hv_TrackballCenterRow, HTuple hv_TrackballCenterCol, 
    HTuple hv_TrackballRadiusPixel, HTuple hv_SelectedObject, HTuple hv_VisualizeRotationCenter, 
    HTuple hv_RotationCenter)
{

  // Local iconic variables
  HObject  ho_TrackballContour, ho_CrossRotCenter;
  HObject  ho_ModelContours;

  // Local control variables
  HTuple  ExpTmpLocalVar_gUsesOpenGL, hv_Exception;
  HTuple  hv_Index, hv_Exception1, hv_DeselectedIdx, hv_DeselectedName;
  HTuple  hv_DeselectedValue, hv_Pose, hv_HomMat3D, hv_Center;
  HTuple  hv_CenterCamX, hv_CenterCamY, hv_CenterCamZ, hv_CenterRow;
  HTuple  hv_CenterCol, hv_Label, hv_Ascent, hv_Descent, hv_TextWidth;
  HTuple  hv_TextHeight, hv_RotCenterRow, hv_RotCenterCol;
  HTuple  hv_Orientation, hv_Colors;

  //global tuple gAlphaDeselected
  //global tuple gTerminationButtonLabel
  //global tuple gDispObjOffset
  //global tuple gLabelsDecor
  //global tuple gUsesOpenGL
  //
  //Display background image
  ClearWindow(hv_WindowHandleBuffer);
  if (0 != hv_ColorImage)
  {
    DispColor(ho_BackgroundImage, hv_WindowHandleBuffer);
  }
  else
  {
    DispImage(ho_BackgroundImage, hv_WindowHandleBuffer);
  }
  //
  //Display objects
  if (0 != ((hv_SelectedObject.TupleSum())==(hv_SelectedObject.TupleLength())))
  {
    if (0 != (ExpGetGlobalVar_gUsesOpenGL()==HTuple("true")))
    {
      try
      {
        DisplayScene3d(hv_WindowHandleBuffer, hv_Scene3D, 0);
      }
      // catch (Exception) 
      catch (HException &HDevExpDefaultException)
      {
        HDevExpDefaultException.ToHTuple(&hv_Exception);
        if (0 != (HTuple(HTuple(HTuple(hv_Exception[0])==5185).TupleOr(HTuple(hv_Exception[0])==5188)).TupleOr(HTuple(hv_Exception[0])==5187)))
        {
          ExpTmpLocalVar_gUsesOpenGL = "false";
          ExpSetGlobalVar_gUsesOpenGL(ExpTmpLocalVar_gUsesOpenGL);
        }
        else
        {
          throw HException(hv_Exception);
        }
      }
    }
    if (0 != (ExpGetGlobalVar_gUsesOpenGL()==HTuple("false")))
    {
      //* NO OpenGL, use fallback
      disp_object_model_no_opengl(&ho_ModelContours, hv_ObjectModel3DID, hv_GenParamName, 
          hv_GenParamValue, hv_WindowHandleBuffer, hv_CamParam, hv_Poses);
    }
  }
  else
  {
    {
    HTuple end_val32 = (hv_AlphaOrig.TupleLength())-1;
    HTuple step_val32 = 1;
    for (hv_Index=0; hv_Index.Continue(end_val32, step_val32); hv_Index += step_val32)
    {
      if (0 != (HTuple(hv_SelectedObject[hv_Index])==1))
      {
        SetScene3dInstanceParam(hv_Scene3D, hv_Index, "alpha", HTuple(hv_AlphaOrig[hv_Index]));
      }
      else
      {
        SetScene3dInstanceParam(hv_Scene3D, hv_Index, "alpha", ExpGetGlobalVar_gAlphaDeselected());
      }
    }
    }
    try
    {
      if (0 != (ExpGetGlobalVar_gUsesOpenGL()==HTuple("false")))
      {
        throw HException(HTuple());
      }
      DisplayScene3d(hv_WindowHandleBuffer, hv_Scene3D, 0);
    }
    // catch (Exception1) 
    catch (HException &HDevExpDefaultException)
    {
      HDevExpDefaultException.ToHTuple(&hv_Exception1);
      //* NO OpenGL, use fallback
      hv_DeselectedIdx = hv_SelectedObject.TupleFind(0);
      if (0 != (hv_DeselectedIdx!=-1))
      {
        hv_DeselectedName = "color_"+hv_DeselectedIdx;
        hv_DeselectedValue = HTuple(hv_DeselectedName.TupleLength(),"gray");
      }
      disp_object_model_no_opengl(&ho_ModelContours, hv_ObjectModel3DID, hv_GenParamName.TupleConcat(hv_DeselectedName), 
          hv_GenParamValue.TupleConcat(hv_DeselectedValue), hv_WindowHandleBuffer, 
          hv_CamParam, hv_Poses);
    }
    {
    HTuple end_val53 = (hv_AlphaOrig.TupleLength())-1;
    HTuple step_val53 = 1;
    for (hv_Index=0; hv_Index.Continue(end_val53, step_val53); hv_Index += step_val53)
    {
      SetScene3dInstanceParam(hv_Scene3D, hv_Index, "alpha", HTuple(hv_AlphaOrig[hv_Index]));
    }
    }
  }
  //
  //Display labels
  if (0 != (hv_Labels!=0))
  {
    SetColor(hv_WindowHandleBuffer, HTuple(ExpGetGlobalVar_gLabelsDecor()[0]));
    {
    HTuple end_val61 = (hv_ObjectModel3DID.TupleLength())-1;
    HTuple step_val61 = 1;
    for (hv_Index=0; hv_Index.Continue(end_val61, step_val61); hv_Index += step_val61)
    {
      //Project the center point of the current model
      hv_Pose = hv_Poses.TupleSelectRange(hv_Index*7,(hv_Index*7)+6);
      PoseToHomMat3d(hv_Pose, &hv_HomMat3D);
      GetObjectModel3dParams(HTuple(hv_ObjectModel3DID[hv_Index]), "center", &hv_Center);
      AffineTransPoint3d(hv_HomMat3D, HTuple(hv_Center[0]), HTuple(hv_Center[1]), 
          HTuple(hv_Center[2]), &hv_CenterCamX, &hv_CenterCamY, &hv_CenterCamZ);
      Project3dPoint(hv_CenterCamX, hv_CenterCamY, hv_CenterCamZ, hv_CamParam, &hv_CenterRow, 
          &hv_CenterCol);
      hv_Label = HTuple(hv_Labels[hv_Index]);
      if (0 != (hv_Label!=HTuple("")))
      {
        GetStringExtents(hv_WindowHandleBuffer, hv_Label, &hv_Ascent, &hv_Descent, 
            &hv_TextWidth, &hv_TextHeight);
        disp_message(hv_WindowHandleBuffer, hv_Label, "window", (hv_CenterRow-(hv_TextHeight/2))+HTuple(ExpGetGlobalVar_gDispObjOffset()[0]), 
            (hv_CenterCol-(hv_TextWidth/2))+HTuple(ExpGetGlobalVar_gDispObjOffset()[1]), 
            HTuple(), HTuple(ExpGetGlobalVar_gLabelsDecor()[1]));
      }
    }
    }
  }
  //
  //Visualize the trackball if desired
  if (0 != hv_VisualizeTrackball)
  {
    SetLineWidth(hv_WindowHandleBuffer, 1);
    GenEllipseContourXld(&ho_TrackballContour, hv_TrackballCenterRow, hv_TrackballCenterCol, 
        0, hv_TrackballRadiusPixel, hv_TrackballRadiusPixel, 0, 6.28318, "positive", 
        1.5);
    SetColor(hv_WindowHandleBuffer, "dim gray");
    DispXld(ho_TrackballContour, hv_WindowHandleBuffer);
  }
  //
  //Visualize the rotation center if desired
  if (0 != (HTuple(hv_VisualizeRotationCenter!=0).TupleAnd((hv_RotationCenter.TupleLength())==3)))
  {
    if (0 != (HTuple(hv_RotationCenter[2])<1e-10))
    {
      hv_RotationCenter[2] = 1e-10;
    }
    Project3dPoint(HTuple(hv_RotationCenter[0]), HTuple(hv_RotationCenter[1]), HTuple(hv_RotationCenter[2]), 
        hv_CamParam, &hv_RotCenterRow, &hv_RotCenterCol);
    hv_Orientation = HTuple(90).TupleRad();
    if (0 != (hv_VisualizeRotationCenter==1))
    {
      hv_Orientation = HTuple(45).TupleRad();
    }
    GenCrossContourXld(&ho_CrossRotCenter, hv_RotCenterRow, hv_RotCenterCol, hv_TrackballRadiusPixel/25.0, 
        hv_Orientation);
    SetLineWidth(hv_WindowHandleBuffer, 3);
    QueryColor(hv_WindowHandleBuffer, &hv_Colors);
    SetColor(hv_WindowHandleBuffer, "light gray");
    DispXld(ho_CrossRotCenter, hv_WindowHandleBuffer);
    SetLineWidth(hv_WindowHandleBuffer, 1);
    SetColor(hv_WindowHandleBuffer, "dim gray");
    DispXld(ho_CrossRotCenter, hv_WindowHandleBuffer);
  }
  //
  //Display title
  disp_title_and_information(hv_WindowHandleBuffer, hv_Title, hv_Information);
  //
  //Display the 'Exit' button
  if (0 != (hv_DisplayContinueButton==HTuple("true")))
  {
    disp_continue_button(hv_WindowHandleBuffer);
  }
  //
  return;
}

// Chapter: 3D Object Model / Creation
void gen_arrow_object_model_3d (HTuple hv_ArrowThickness, HTuple hv_ArrowStart, HTuple hv_ArrowEnd, 
    HTuple *hv_OM3DArrow)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_DirectionVector, hv_ArrowLength, hv_ConeRadius;
  HTuple  hv_ConeLength, hv_CylinderLength, hv_pi, hv_X, hv_Y;
  HTuple  hv_Z, hv_Index, hv_OM3DConeTmp, hv_OM3DCone, hv_ZZero;
  HTuple  hv_ZTop, hv_OM3DCylinderTmp, hv_OM3DCylinder, hv_OM3DArrowTmp;
  HTuple  hv_Scale, hv_OriginX, hv_OriginY, hv_OriginZ, hv_TargetX;
  HTuple  hv_TargetY, hv_TargetZ, hv_HomMat3D;

  //
  //This procedure draws an arrow that starts at the point ArrowStart and ends at ArrowEnd.
  //
  //Get parameters.
  hv_DirectionVector = (hv_ArrowEnd.TupleSelectRange(0,2))-(hv_ArrowStart.TupleSelectRange(0,2));
  hv_ArrowLength = (((HTuple(hv_DirectionVector[0])*HTuple(hv_DirectionVector[0]))+(HTuple(hv_DirectionVector[1])*HTuple(hv_DirectionVector[1])))+(HTuple(hv_DirectionVector[2])*HTuple(hv_DirectionVector[2]))).TupleSqrt();
  hv_ConeRadius = 2.0*hv_ArrowThickness;
  hv_ConeLength = ((2.0*hv_ConeRadius).TupleConcat(hv_ArrowLength*0.9)).TupleMin();
  hv_CylinderLength = hv_ArrowLength-hv_ConeLength;
  //
  //Create cone.
  hv_pi = HTuple(180).TupleRad();
  hv_X = 0;
  hv_Y = 0;
  hv_Z = hv_CylinderLength+hv_ConeLength;
  {
  HTuple end_val15 = 2*hv_pi;
  HTuple step_val15 = 0.1;
  for (hv_Index=0; hv_Index.Continue(end_val15, step_val15); hv_Index += step_val15)
  {
    hv_X = hv_X.TupleConcat(hv_ConeRadius*(hv_Index.TupleCos()));
    hv_Y = hv_Y.TupleConcat(hv_ConeRadius*(hv_Index.TupleSin()));
    hv_Z = hv_Z.TupleConcat(hv_CylinderLength);
  }
  }
  GenObjectModel3dFromPoints(hv_X, hv_Y, hv_Z, &hv_OM3DConeTmp);
  ConvexHullObjectModel3d(hv_OM3DConeTmp, &hv_OM3DCone);
  ClearObjectModel3d(hv_OM3DConeTmp);
  //
  //Create cylinder.
  hv_X = HTuple();
  hv_Y = HTuple();
  {
  HTuple end_val27 = 2*hv_pi;
  HTuple step_val27 = 0.1;
  for (hv_Index=0; hv_Index.Continue(end_val27, step_val27); hv_Index += step_val27)
  {
    hv_X = hv_X.TupleConcat(hv_ArrowThickness*(hv_Index.TupleCos()));
    hv_Y = hv_Y.TupleConcat(hv_ArrowThickness*(hv_Index.TupleSin()));
  }
  }
  TupleGenConst(hv_Y.TupleLength(), 0, &hv_ZZero);
  TupleGenConst(hv_Y.TupleLength(), hv_CylinderLength, &hv_ZTop);
  GenObjectModel3dFromPoints(hv_X.TupleConcat(hv_X), hv_Y.TupleConcat(hv_Y), hv_ZZero.TupleConcat(hv_ZTop), 
      &hv_OM3DCylinderTmp);
  ConvexHullObjectModel3d(hv_OM3DCylinderTmp, &hv_OM3DCylinder);
  ClearObjectModel3d(hv_OM3DCylinderTmp);
  //
  //Union cone and cylinder Create arrow.
  UnionObjectModel3d(hv_OM3DCone.TupleConcat(hv_OM3DCylinder), "points_surface", 
      &hv_OM3DArrowTmp);
  ClearObjectModel3d(hv_OM3DCone);
  ClearObjectModel3d(hv_OM3DCylinder);
  hv_Scale = hv_CylinderLength/hv_ArrowLength;
  hv_OriginX.Clear();
  hv_OriginX[0] = 0;
  hv_OriginX[1] = 0;
  hv_OriginX[2] = 0;
  hv_OriginY.Clear();
  hv_OriginY[0] = 0;
  hv_OriginY[1] = 0;
  hv_OriginY[2] = 0;
  hv_OriginZ.Clear();
  hv_OriginZ[0] = 0;
  hv_OriginZ.Append(hv_CylinderLength);
  hv_OriginZ.Append(hv_ArrowLength);
  hv_TargetX.Clear();
  hv_TargetX.Append(HTuple(hv_ArrowStart[0]));
  hv_TargetX.Append(HTuple(hv_ArrowStart[0])+(hv_Scale*HTuple(hv_DirectionVector[0])));
  hv_TargetX.Append(HTuple(hv_ArrowEnd[0]));
  hv_TargetY.Clear();
  hv_TargetY.Append(HTuple(hv_ArrowStart[1]));
  hv_TargetY.Append(HTuple(hv_ArrowStart[1])+(hv_Scale*HTuple(hv_DirectionVector[1])));
  hv_TargetY.Append(HTuple(hv_ArrowEnd[1]));
  hv_TargetZ.Clear();
  hv_TargetZ.Append(HTuple(hv_ArrowStart[2]));
  hv_TargetZ.Append(HTuple(hv_ArrowStart[2])+(hv_Scale*HTuple(hv_DirectionVector[2])));
  hv_TargetZ.Append(HTuple(hv_ArrowEnd[2]));
  VectorToHomMat3d("rigid", hv_OriginX, hv_OriginY, hv_OriginZ, hv_TargetX, hv_TargetY, 
      hv_TargetZ, &hv_HomMat3D);
  AffineTransObjectModel3d(hv_OM3DArrowTmp, hv_HomMat3D, &(*hv_OM3DArrow));
  ClearObjectModel3d(hv_OM3DArrowTmp);
  return;
}

// Chapter: Graphics / Output
// Short Description: Get the center of the virtual trackback that is used to move the camera (version for inspection_mode = 'surface'). 
void get_trackball_center_fixed (HTuple hv_SelectedObject, HTuple hv_TrackballCenterRow, 
    HTuple hv_TrackballCenterCol, HTuple hv_TrackballRadiusPixel, HTuple hv_Scene3D, 
    HTuple hv_ObjectModel3DID, HTuple hv_Poses, HTuple hv_WindowHandleBuffer, HTuple hv_CamParam, 
    HTuple hv_GenParamName, HTuple hv_GenParamValue, HTuple *hv_TBCenter, HTuple *hv_TBSize)
{

  // Local iconic variables
  HObject  ho_RegionCenter, ho_DistanceImage, ho_Domain;

  // Local control variables
  HTuple  hv_NumModels, hv_Width, hv_Height, hv_SelectPose;
  HTuple  hv_Index1, hv_Rows, hv_Columns, hv_Grayval, hv_IndicesG;
  HTuple  hv_Value, hv_Pos;

  //Determine the trackball center for the fixed trackball
  hv_NumModels = hv_ObjectModel3DID.TupleLength();
  get_cam_par_data(hv_CamParam, "image_width", &hv_Width);
  get_cam_par_data(hv_CamParam, "image_height", &hv_Height);
  //
  //Project the selected objects
  hv_SelectPose = HTuple();
  {
  HTuple end_val7 = (hv_SelectedObject.TupleLength())-1;
  HTuple step_val7 = 1;
  for (hv_Index1=0; hv_Index1.Continue(end_val7, step_val7); hv_Index1 += step_val7)
  {
    hv_SelectPose = hv_SelectPose.TupleConcat(HTuple(7,HTuple(hv_SelectedObject[hv_Index1])));
    if (0 != (HTuple(hv_SelectedObject[hv_Index1])==0))
    {
      SetScene3dInstanceParam(hv_Scene3D, hv_Index1, "visible", "false");
    }
  }
  }
  SetScene3dParam(hv_Scene3D, "depth_persistence", "true");
  DisplayScene3d(hv_WindowHandleBuffer, hv_Scene3D, 0);
  SetScene3dParam(hv_Scene3D, "visible", "true");
  //
  //determine the depth of the object point that appears closest to the trackball
  //center
  GenRegionPoints(&ho_RegionCenter, hv_TrackballCenterRow, hv_TrackballCenterCol);
  DistanceTransform(ho_RegionCenter, &ho_DistanceImage, "chamfer-3-4-unnormalized", 
      "false", hv_Width, hv_Height);
  GetDomain(ho_DistanceImage, &ho_Domain);
  GetRegionPoints(ho_Domain, &hv_Rows, &hv_Columns);
  GetGrayval(ho_DistanceImage, hv_Rows, hv_Columns, &hv_Grayval);
  TupleSortIndex(hv_Grayval, &hv_IndicesG);
  GetDisplayScene3dInfo(hv_WindowHandleBuffer, hv_Scene3D, hv_Rows.TupleSelect(hv_IndicesG), 
      hv_Columns.TupleSelect(hv_IndicesG), "depth", &hv_Value);
  TupleFind(hv_Value.TupleSgn(), 1, &hv_Pos);
  //
  SetScene3dParam(hv_Scene3D, "depth_persistence", "false");
  //
  //
  //set TBCenter
  if (0 != (hv_Pos!=-1))
  {
    //if the object is visible in the image
    (*hv_TBCenter).Clear();
    (*hv_TBCenter)[0] = 0;
    (*hv_TBCenter)[1] = 0;
    (*hv_TBCenter).Append(HTuple(hv_Value[HTuple(hv_Pos[0])]));
  }
  else
  {
    //if the object is not visible in the image, set the z coordinate to -1
    //to indicate, the the previous z value should be used instead
    (*hv_TBCenter).Clear();
    (*hv_TBCenter)[0] = 0;
    (*hv_TBCenter)[1] = 0;
    (*hv_TBCenter)[2] = -1;
  }
  //
  if (0 != ((hv_SelectedObject.TupleMax())!=0))
  {
    (*hv_TBSize) = (0.5+((0.5*(hv_SelectedObject.TupleSum()))/hv_NumModels))*hv_TrackballRadiusPixel;
  }
  else
  {
    (*hv_TBCenter) = HTuple();
    (*hv_TBSize) = 0;
  }
  return;
}

// Chapter: Graphics / Output
// Short Description: Get string extends of several lines. 
void max_line_width (HTuple hv_WindowHandle, HTuple hv_Lines, HTuple *hv_MaxWidth)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_Index, hv_Ascent, hv_Descent, hv_LineWidth;
  HTuple  hv_LineHeight;

  (*hv_MaxWidth) = 0;
  {
  HTuple end_val1 = (hv_Lines.TupleLength())-1;
  HTuple step_val1 = 1;
  for (hv_Index=0; hv_Index.Continue(end_val1, step_val1); hv_Index += step_val1)
  {
    GetStringExtents(hv_WindowHandle, HTuple(hv_Lines[hv_Index]), &hv_Ascent, &hv_Descent, 
        &hv_LineWidth, &hv_LineHeight);
    (*hv_MaxWidth) = (hv_LineWidth.TupleConcat((*hv_MaxWidth))).TupleMax();
  }
  }
  return;
}

// Chapter: Graphics / Output
// Short Description: Project an image point onto the trackball 
void project_point_on_trackball (HTuple hv_X, HTuple hv_Y, HTuple hv_VirtualTrackball, 
    HTuple hv_TrackballSize, HTuple *hv_V)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_R, hv_XP, hv_YP, hv_ZP;

  if (0 != (hv_VirtualTrackball==HTuple("shoemake")))
  {
    //Virtual Trackball according to Shoemake
    hv_R = ((hv_X*hv_X)+(hv_Y*hv_Y)).TupleSqrt();
    if (0 != (hv_R<=hv_TrackballSize))
    {
      hv_XP = hv_X;
      hv_YP = hv_Y;
      hv_ZP = ((hv_TrackballSize*hv_TrackballSize)-(hv_R*hv_R)).TupleSqrt();
    }
    else
    {
      hv_XP = (hv_X*hv_TrackballSize)/hv_R;
      hv_YP = (hv_Y*hv_TrackballSize)/hv_R;
      hv_ZP = 0;
    }
  }
  else
  {
    //Virtual Trackball according to Bell
    hv_R = ((hv_X*hv_X)+(hv_Y*hv_Y)).TupleSqrt();
    if (0 != (hv_R<=(hv_TrackballSize*0.70710678)))
    {
      hv_XP = hv_X;
      hv_YP = hv_Y;
      hv_ZP = ((hv_TrackballSize*hv_TrackballSize)-(hv_R*hv_R)).TupleSqrt();
    }
    else
    {
      hv_XP = hv_X;
      hv_YP = hv_Y;
      hv_ZP = ((0.6*hv_TrackballSize)*hv_TrackballSize)/hv_R;
    }
  }
  (*hv_V).Clear();
  (*hv_V).Append(hv_XP);
  (*hv_V).Append(hv_YP);
  (*hv_V).Append(hv_ZP);
  return;
}

// Chapter: Tuple / Arithmetic
// Short Description: Calculates the cross product of two vectors of length 3. 
void tuple_vector_cross_product (HTuple hv_V1, HTuple hv_V2, HTuple *hv_VC)
{

  // Local iconic variables

  //The caller must ensure that the length of both input vectors is 3
  (*hv_VC) = (HTuple(hv_V1[1])*HTuple(hv_V2[2]))-(HTuple(hv_V1[2])*HTuple(hv_V2[1]));
  (*hv_VC) = (*hv_VC).TupleConcat((HTuple(hv_V1[2])*HTuple(hv_V2[0]))-(HTuple(hv_V1[0])*HTuple(hv_V2[2])));
  (*hv_VC) = (*hv_VC).TupleConcat((HTuple(hv_V1[0])*HTuple(hv_V2[1]))-(HTuple(hv_V1[1])*HTuple(hv_V2[0])));
  return;
}

// Chapter: Graphics / Output
// Short Description: Get the center of the virtual trackback that is used to move the camera. 
void get_trackball_center (HTuple hv_SelectedObject, HTuple hv_TrackballRadiusPixel, 
    HTuple hv_ObjectModel3D, HTuple hv_Poses, HTuple *hv_TBCenter, HTuple *hv_TBSize)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_NumModels, hv_Centers, hv_Diameter;
  HTuple  hv_MD, hv_Weight, hv_SumW, hv_Index, hv_ObjectModel3DIDSelected;
  HTuple  hv_PoseSelected, hv_HomMat3D, hv_TBCenterCamX, hv_TBCenterCamY;
  HTuple  hv_TBCenterCamZ, hv_InvSum;

  hv_NumModels = hv_ObjectModel3D.TupleLength();
  (*hv_TBCenter)[0] = 0;
  (*hv_TBCenter)[1] = 0;
  (*hv_TBCenter)[2] = 0;
  GetObjectModel3dParams(hv_ObjectModel3D, "center", &hv_Centers);
  GetObjectModel3dParams(hv_ObjectModel3D, "diameter_axis_aligned_bounding_box", 
      &hv_Diameter);
  //Normalize Diameter to use it as weights for a weighted mean of the individual centers
  hv_MD = hv_Diameter.TupleMean();
  if (0 != (hv_MD>1e-10))
  {
    hv_Weight = hv_Diameter/hv_MD;
  }
  else
  {
    hv_Weight = hv_Diameter;
  }
  hv_SumW = (hv_Weight.TupleSelectMask((hv_SelectedObject.TupleSgn()).TupleAbs())).TupleSum();
  if (0 != (hv_SumW<1e-10))
  {
    hv_Weight = HTuple(hv_Weight.TupleLength(),1.0);
    hv_SumW = (hv_Weight.TupleSelectMask((hv_SelectedObject.TupleSgn()).TupleAbs())).TupleSum();
  }
  {
  HTuple end_val18 = hv_NumModels-1;
  HTuple step_val18 = 1;
  for (hv_Index=0; hv_Index.Continue(end_val18, step_val18); hv_Index += step_val18)
  {
    if (0 != (HTuple(hv_SelectedObject[hv_Index])))
    {
      hv_ObjectModel3DIDSelected = HTuple(hv_ObjectModel3D[hv_Index]);
      hv_PoseSelected = hv_Poses.TupleSelectRange(hv_Index*7,(hv_Index*7)+6);
      PoseToHomMat3d(hv_PoseSelected, &hv_HomMat3D);
      AffineTransPoint3d(hv_HomMat3D, HTuple(hv_Centers[(hv_Index*3)+0]), HTuple(hv_Centers[(hv_Index*3)+1]), 
          HTuple(hv_Centers[(hv_Index*3)+2]), &hv_TBCenterCamX, &hv_TBCenterCamY, 
          &hv_TBCenterCamZ);
      (*hv_TBCenter)[0] = HTuple((*hv_TBCenter)[0])+(hv_TBCenterCamX*HTuple(hv_Weight[hv_Index]));
      (*hv_TBCenter)[1] = HTuple((*hv_TBCenter)[1])+(hv_TBCenterCamY*HTuple(hv_Weight[hv_Index]));
      (*hv_TBCenter)[2] = HTuple((*hv_TBCenter)[2])+(hv_TBCenterCamZ*HTuple(hv_Weight[hv_Index]));
    }
  }
  }
  if (0 != ((hv_SelectedObject.TupleMax())!=0))
  {
    hv_InvSum = 1.0/hv_SumW;
    (*hv_TBCenter)[0] = HTuple((*hv_TBCenter)[0])*hv_InvSum;
    (*hv_TBCenter)[1] = HTuple((*hv_TBCenter)[1])*hv_InvSum;
    (*hv_TBCenter)[2] = HTuple((*hv_TBCenter)[2])*hv_InvSum;
    (*hv_TBSize) = (0.5+((0.5*(hv_SelectedObject.TupleSum()))/hv_NumModels))*hv_TrackballRadiusPixel;
  }
  else
  {
    (*hv_TBCenter) = HTuple();
    (*hv_TBSize) = 0;
  }
  return;
}

// Chapter: Graphics / Output
// Short Description: Compute the center of all given 3D object models. 
void get_object_models_center (HTuple hv_ObjectModel3DID, HTuple *hv_Center)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_Diameter, hv_MD, hv_Weight, hv_SumW;
  HTuple  hv_Index, hv_ObjectModel3DIDSelected, hv_C, hv_InvSum;

  //Compute the mean of all model centers (weighted by the diameter of the object models)
  if (0 != ((hv_ObjectModel3DID.TupleLength())>0))
  {
    GetObjectModel3dParams(hv_ObjectModel3DID, "diameter_axis_aligned_bounding_box", 
        &hv_Diameter);
    //Normalize Diameter to use it as weights for a weighted mean of the individual centers
    hv_MD = hv_Diameter.TupleMean();
    if (0 != (hv_MD>1e-10))
    {
      hv_Weight = hv_Diameter/hv_MD;
    }
    else
    {
      hv_Weight = hv_Diameter;
    }
    hv_SumW = hv_Weight.TupleSum();
    if (0 != (hv_SumW<1e-10))
    {
      hv_Weight = HTuple(hv_Weight.TupleLength(),1.0);
      hv_SumW = hv_Weight.TupleSum();
    }
    (*hv_Center).Clear();
    (*hv_Center)[0] = 0;
    (*hv_Center)[1] = 0;
    (*hv_Center)[2] = 0;
    {
    HTuple end_val16 = (hv_ObjectModel3DID.TupleLength())-1;
    HTuple step_val16 = 1;
    for (hv_Index=0; hv_Index.Continue(end_val16, step_val16); hv_Index += step_val16)
    {
      hv_ObjectModel3DIDSelected = HTuple(hv_ObjectModel3DID[hv_Index]);
      GetObjectModel3dParams(hv_ObjectModel3DIDSelected, "center", &hv_C);
      (*hv_Center)[0] = HTuple((*hv_Center)[0])+(HTuple(hv_C[0])*HTuple(hv_Weight[hv_Index]));
      (*hv_Center)[1] = HTuple((*hv_Center)[1])+(HTuple(hv_C[1])*HTuple(hv_Weight[hv_Index]));
      (*hv_Center)[2] = HTuple((*hv_Center)[2])+(HTuple(hv_C[2])*HTuple(hv_Weight[hv_Index]));
    }
    }
    hv_InvSum = 1.0/hv_SumW;
    (*hv_Center)[0] = HTuple((*hv_Center)[0])*hv_InvSum;
    (*hv_Center)[1] = HTuple((*hv_Center)[1])*hv_InvSum;
    (*hv_Center)[2] = HTuple((*hv_Center)[2])*hv_InvSum;
  }
  else
  {
    (*hv_Center) = HTuple();
  }
  return;
}

// Chapter: Graphics / Output
// Short Description: Compute the 3D rotation from the mouse movement 
void trackball (HTuple hv_MX1, HTuple hv_MY1, HTuple hv_MX2, HTuple hv_MY2, HTuple hv_VirtualTrackball, 
    HTuple hv_TrackballSize, HTuple hv_SensFactor, HTuple *hv_QuatRotation)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_P1, hv_P2, hv_RotAxis, hv_D, hv_T;
  HTuple  hv_RotAngle, hv_Len;

  //Compute the 3D rotation from the mouse movement
  //
  if (0 != (HTuple(hv_MX1==hv_MX2).TupleAnd(hv_MY1==hv_MY2)))
  {
    (*hv_QuatRotation).Clear();
    (*hv_QuatRotation)[0] = 1;
    (*hv_QuatRotation)[1] = 0;
    (*hv_QuatRotation)[2] = 0;
    (*hv_QuatRotation)[3] = 0;
    return;
  }
  //Project the image point onto the trackball
  project_point_on_trackball(hv_MX1, hv_MY1, hv_VirtualTrackball, hv_TrackballSize, 
      &hv_P1);
  project_point_on_trackball(hv_MX2, hv_MY2, hv_VirtualTrackball, hv_TrackballSize, 
      &hv_P2);
  //The cross product of the projected points defines the rotation axis
  tuple_vector_cross_product(hv_P1, hv_P2, &hv_RotAxis);
  //Compute the rotation angle
  hv_D = hv_P2-hv_P1;
  hv_T = (((hv_D*hv_D).TupleSum()).TupleSqrt())/(2.0*hv_TrackballSize);
  if (0 != (hv_T>1.0))
  {
    hv_T = 1.0;
  }
  if (0 != (hv_T<-1.0))
  {
    hv_T = -1.0;
  }
  hv_RotAngle = (2.0*(hv_T.TupleAsin()))*hv_SensFactor;
  hv_Len = ((hv_RotAxis*hv_RotAxis).TupleSum()).TupleSqrt();
  if (0 != (hv_Len>0.0))
  {
    hv_RotAxis = hv_RotAxis/hv_Len;
  }
  AxisAngleToQuat(HTuple(hv_RotAxis[0]), HTuple(hv_RotAxis[1]), HTuple(hv_RotAxis[2]), 
      hv_RotAngle, &(*hv_QuatRotation));
  return;
}

// Chapter: Graphics / Output
// Short Description: Interactively display 3D object models 
void visualize_object_model_3d (HTuple hv_WindowHandle, HTuple hv_ObjectModel3D, 
    HTuple hv_CamParam, HTuple hv_PoseIn, HTuple hv_GenParamName, HTuple hv_GenParamValue, 
    HTuple hv_Title, HTuple hv_Label, HTuple hv_Information, HTuple *hv_PoseOut)
{

  // Local iconic variables
  HObject  ho_Image, ho_ImageDump;

  // Local control variables
  HTuple  ExpTmpLocalVar_gDispObjOffset, ExpTmpLocalVar_gLabelsDecor;
  HTuple  ExpTmpLocalVar_gInfoDecor, ExpTmpLocalVar_gInfoPos;
  HTuple  ExpTmpLocalVar_gTitlePos, ExpTmpLocalVar_gTitleDecor;
  HTuple  ExpTmpLocalVar_gTerminationButtonLabel, ExpTmpLocalVar_gAlphaDeselected;
  HTuple  ExpTmpLocalVar_gIsSinglePose, ExpTmpLocalVar_gUsesOpenGL;
  HTuple  hv_Scene3DTest, hv_Scene3D, hv_WindowHandleBuffer;
  HTuple  hv_TrackballSize, hv_VirtualTrackball, hv_MouseMapping;
  HTuple  hv_WaitForButtonRelease, hv_MaxNumModels, hv_WindowCenteredRotation;
  HTuple  hv_NumModels, hv_SelectedObject, hv_ClipRegion;
  HTuple  hv_CPLength, hv_RowNotUsed, hv_ColumnNotUsed, hv_Width;
  HTuple  hv_Height, hv_WPRow1, hv_WPColumn1, hv_WPRow2, hv_WPColumn2;
  HTuple  hv_CamParamValue, hv_CamWidth, hv_CamHeight, hv_Scale;
  HTuple  hv_Indices, hv_DispBackground, hv_Mask, hv_Center;
  HTuple  hv_Poses, hv_HomMat3Ds, hv_Sequence, hv_PoseEstimated;
  HTuple  hv_Font, hv_Exception, hv_OpenGLInfo, hv_DummyObjectModel3D;
  HTuple  hv_CameraIndexTest, hv_PoseTest, hv_InstanceIndexTest;
  HTuple  hv_MinImageSize, hv_TrackballRadiusPixel, hv_Ascent;
  HTuple  hv_Descent, hv_TextWidth, hv_TextHeight, hv_NumChannels;
  HTuple  hv_ColorImage, hv_CameraIndex, hv_AllInstances;
  HTuple  hv_SetLight, hv_LightParam, hv_LightPosition, hv_LightKind;
  HTuple  hv_LightIndex, hv_PersistenceParamName, hv_PersistenceParamValue;
  HTuple  hv_AlphaOrig, hv_I, hv_ParamName, hv_ParamValue;
  HTuple  hv_ParamNameTrunk, hv_Instance, hv_HomMat3D, hv_Qx;
  HTuple  hv_Qy, hv_Qz, hv_TBCenter, hv_TBSize, hv_ButtonHold;
  HTuple  hv_VisualizeTB, hv_MaxIndex, hv_TrackballCenterRow;
  HTuple  hv_TrackballCenterCol, hv_GraphEvent, hv_Exit, hv_GraphButtonRow;
  HTuple  hv_GraphButtonColumn, hv_GraphButton, hv_ButtonReleased;
  HTuple  hv_e;

  //The procedure visualize_object_model_3d can be used to display
  //one or more 3d object models and to interactively modify
  //the object poses by using the mouse.
  //
  //The pose can be modified by moving the mouse while
  //pressing a mouse button. The default settings are:
  //
  // Rotate: Left mouse button
  // Zoom: Shift + Left mouse button (or Center mouse button)
  // Pan: Ctrl + Left mouse button
  //
  //Furthermore, it is possible to select and deselect objects,
  //to decrease the mouse sensitivity, and to toggle the
  //inspection mode (see the description of the generic parameter
  //'inspection_mode' below):
  //
  // (De-)select object(s): Right mouse button
  // Low mouse sensitivity: Alt + Mouse button
  // Toggle inspection mode: Ctrl + Alt + Left mouse button
  //
  //In GenParamName and GenParamValue all generic Parameters
  //of disp_object_model_3d are supported.
  //
  //**********************************************************
  //Define global variables
  //**********************************************************
  //
  //global def tuple gDispObjOffset
  //global def tuple gLabelsDecor
  //global def tuple gInfoDecor
  //global def tuple gInfoPos
  //global def tuple gTitlePos
  //global def tuple gTitleDecor
  //global def tuple gTerminationButtonLabel
  //global def tuple gAlphaDeselected
  //global def tuple gIsSinglePose
  //global def tuple gUsesOpenGL
  //
  //**********************************************************
  //Initialize Handles to enable correct handling in error case
  //**********************************************************
  hv_Scene3DTest = HTuple();
  hv_Scene3D = HTuple();
  hv_WindowHandleBuffer = HTuple();

  //**********************************************************
  //Some user defines that may be adapted if desired
  //**********************************************************
  //
  //TrackballSize defines the diameter of the trackball in
  //the image with respect to the smaller image dimension.
  hv_TrackballSize = 0.8;
  //
  //VirtualTrackball defines the type of virtual trackball that
  //shall be used ('shoemake' or 'bell').
  hv_VirtualTrackball = "shoemake";
  //VirtualTrackball := 'bell'
  //
  //Functionality of mouse buttons
  //    1: Left Button
  //    2: Middle Button
  //    4: Right Button
  //    5: Left+Right Mousebutton
  //  8+x: Shift + Mousebutton
  // 16+x: Ctrl + Mousebutton
  // 48+x: Ctrl + Alt + Mousebutton
  //in the order [Translate, Rotate, Scale, ScaleAlternative1, ScaleAlternative2, SelectObjects, ToggleSelectionMode]
  hv_MouseMapping.Clear();
  hv_MouseMapping[0] = 17;
  hv_MouseMapping[1] = 1;
  hv_MouseMapping[2] = 2;
  hv_MouseMapping[3] = 5;
  hv_MouseMapping[4] = 9;
  hv_MouseMapping[5] = 4;
  hv_MouseMapping[6] = 49;
  //
  //The labels of the objects appear next to their projected
  //center. With gDispObjOffset a fixed offset is added
  //                  R,  C
  ExpTmpLocalVar_gDispObjOffset.Clear();
  ExpTmpLocalVar_gDispObjOffset[0] = -30;
  ExpTmpLocalVar_gDispObjOffset[1] = 0;
  ExpSetGlobalVar_gDispObjOffset(ExpTmpLocalVar_gDispObjOffset);
  //
  //Customize the decoration of the different text elements
  //              Color,   Box
  ExpTmpLocalVar_gInfoDecor.Clear();
  ExpTmpLocalVar_gInfoDecor[0] = "white";
  ExpTmpLocalVar_gInfoDecor[1] = "false";
  ExpSetGlobalVar_gInfoDecor(ExpTmpLocalVar_gInfoDecor);
  ExpTmpLocalVar_gLabelsDecor.Clear();
  ExpTmpLocalVar_gLabelsDecor[0] = "white";
  ExpTmpLocalVar_gLabelsDecor[1] = "false";
  ExpSetGlobalVar_gLabelsDecor(ExpTmpLocalVar_gLabelsDecor);
  ExpTmpLocalVar_gTitleDecor.Clear();
  ExpTmpLocalVar_gTitleDecor[0] = "black";
  ExpTmpLocalVar_gTitleDecor[1] = "true";
  ExpSetGlobalVar_gTitleDecor(ExpTmpLocalVar_gTitleDecor);
  //
  //Customize the position of some text elements
  //  gInfoPos has one of the values
  //  {'UpperLeft', 'LowerLeft', 'UpperRight'}
  ExpTmpLocalVar_gInfoPos = "LowerLeft";
  ExpSetGlobalVar_gInfoPos(ExpTmpLocalVar_gInfoPos);
  //  gTitlePos has one of the values
  //  {'UpperLeft', 'UpperCenter', 'UpperRight'}
  ExpTmpLocalVar_gTitlePos = "UpperLeft";
  ExpSetGlobalVar_gTitlePos(ExpTmpLocalVar_gTitlePos);
  //Alpha value (=1-transparency) that is used for visualizing
  //the objects that are not selected
  ExpTmpLocalVar_gAlphaDeselected = 0.3;
  ExpSetGlobalVar_gAlphaDeselected(ExpTmpLocalVar_gAlphaDeselected);
  //Customize the label of the continue button
  ExpTmpLocalVar_gTerminationButtonLabel = " Continue ";
  ExpSetGlobalVar_gTerminationButtonLabel(ExpTmpLocalVar_gTerminationButtonLabel);
  //Define if the continue button responds to a single click event or
  //if it responds only if the mouse button is released while being placed
  //over the continue button.
  //'true':  Wait until the continue button has been released.
  //         This should be used to avoid unwanted continuations of
  //         subsequent calls of visualize_object_model_3d, which can
  //         otherwise occur if the mouse button remains pressed while the
  //         next visualization is active.
  //'false': Continue the execution already if the continue button is
  //         pressed. This option allows a fast forwarding through
  //         subsequent calls of visualize_object_model_3d.
  hv_WaitForButtonRelease = "true";
  //Number of 3D Object models that can be selected and handled individually.
  //If there are more models passed then this number, some calculations
  //are performed differently and the individual selection and handling
  //of models is not supported anymore. Note that the value of MaxNumModels
  //can be overwritten with the generic parameter max_num_selectable_models.
  hv_MaxNumModels = 1000;
  //Defines the default for the initial state of the rotation center:
  //(1) The rotation center is fixed in the center of the image and lies
  //    on the surface of the object.
  //(2) The rotation center lies in the center of the object.
  hv_WindowCenteredRotation = 2;
  //
  //**********************************************************
  //
  //Initialize some values
  hv_NumModels = hv_ObjectModel3D.TupleLength();
  hv_SelectedObject = HTuple(hv_NumModels,1);
  //
  //Apply some system settings
  // dev_set_preferences(...); only in hdevelop
  // dev_get_preferences(...); only in hdevelop
  // dev_set_preferences(...); only in hdevelop
  GetSystem("clip_region", &hv_ClipRegion);
  SetSystem("clip_region", "false");
  dev_update_off();
  //
  //Check if GenParamName matches GenParamValue
  if (0 != ((hv_GenParamName.TupleLength())!=(hv_GenParamValue.TupleLength())))
  {
    throw HException("Number of generic parameters does not match number of generic parameter values");
  }
  //
  try
  {
    //
    //Refactor camera parameters to fit to window size
    //
    hv_CPLength = hv_CamParam.TupleLength();
    GetWindowExtents(hv_WindowHandle, &hv_RowNotUsed, &hv_ColumnNotUsed, &hv_Width, 
        &hv_Height);
    GetPart(hv_WindowHandle, &hv_WPRow1, &hv_WPColumn1, &hv_WPRow2, &hv_WPColumn2);
    SetPart(hv_WindowHandle, 0, 0, hv_Height-1, hv_Width-1);
    if (0 != (hv_CPLength==0))
    {
      gen_cam_par_area_scan_division(0.06, 0, 8.5e-6, 8.5e-6, hv_Width/2, hv_Height/2, 
          hv_Width, hv_Height, &hv_CamParam);
    }
    else
    {
      get_cam_par_data(hv_CamParam, (((((HTuple("sx").Append("sy")).Append("cx")).Append("cy")).Append("image_width")).Append("image_height")), 
          &hv_CamParamValue);
      hv_CamWidth = HTuple(hv_CamParamValue[4]).TupleReal();
      hv_CamHeight = HTuple(hv_CamParamValue[5]).TupleReal();
      hv_Scale = ((hv_Width/hv_CamWidth).TupleConcat(hv_Height/hv_CamHeight)).TupleMin();
      set_cam_par_data(hv_CamParam, "sx", HTuple(hv_CamParamValue[0])/hv_Scale, &hv_CamParam);
      set_cam_par_data(hv_CamParam, "sy", HTuple(hv_CamParamValue[1])/hv_Scale, &hv_CamParam);
      set_cam_par_data(hv_CamParam, "cx", HTuple(hv_CamParamValue[2])*hv_Scale, &hv_CamParam);
      set_cam_par_data(hv_CamParam, "cy", HTuple(hv_CamParamValue[3])*hv_Scale, &hv_CamParam);
      set_cam_par_data(hv_CamParam, "image_width", (HTuple(hv_CamParamValue[4])*hv_Scale).TupleInt(), 
          &hv_CamParam);
      set_cam_par_data(hv_CamParam, "image_height", (HTuple(hv_CamParamValue[5])*hv_Scale).TupleInt(), 
          &hv_CamParam);
    }
    //
    //Check the generic parameters for max_num_selectable_models
    //(Note that the default is set above to MaxNumModels := 1000)
    hv_Indices = hv_GenParamName.TupleFind("max_num_selectable_models");
    if (0 != (HTuple(hv_Indices!=-1).TupleAnd(hv_Indices!=HTuple())))
    {
      if (0 != (HTuple(hv_GenParamValue[HTuple(hv_Indices[0])]).TupleIsNumber()))
      {
        if (0 != (((HTuple(hv_GenParamValue[HTuple(hv_Indices[0])]).TupleNumber()).TupleInt())<1))
        {
          //Wrong parameter value: Only integer values greater than 0 are allowed
          throw HException("Wrong value for parameter 'max_num_selectable_models' (must be an integer value greater than 0)");
        }
      }
      else
      {
        //Wrong parameter value: Only integer values greater than 0 are allowed
        throw HException("Wrong value for parameter 'max_num_selectable_models' (must be an integer value greater than 0)");
      }
      hv_MaxNumModels = (HTuple(hv_GenParamValue[HTuple(hv_Indices[0])]).TupleNumber()).TupleInt();
      hv_GenParamName = hv_GenParamName.TupleRemove(hv_Indices);
      hv_GenParamValue = hv_GenParamValue.TupleRemove(hv_Indices);
    }
    //
    //Check the generic parameters for window_centered_rotation
    //(Note that the default is set above to WindowCenteredRotation := 2)
    hv_Indices = hv_GenParamName.TupleFind("inspection_mode");
    if (0 != (HTuple(hv_Indices!=-1).TupleAnd(hv_Indices!=HTuple())))
    {
      if (0 != (HTuple(hv_GenParamValue[HTuple(hv_Indices[0])])==HTuple("surface")))
      {
        hv_WindowCenteredRotation = 1;
      }
      else if (0 != (HTuple(hv_GenParamValue[HTuple(hv_Indices[0])])==HTuple("standard")))
      {
        hv_WindowCenteredRotation = 2;
      }
      else
      {
        //Wrong parameter value, use default value
      }
      hv_GenParamName = hv_GenParamName.TupleRemove(hv_Indices);
      hv_GenParamValue = hv_GenParamValue.TupleRemove(hv_Indices);
    }
    //
    //Check the generic parameters for disp_background
    //(The former parameter name 'use_background' is still supported
    // for compatibility reasons)
    hv_DispBackground = "false";
    if (0 != ((hv_GenParamName.TupleLength())>0))
    {
      hv_Mask = (hv_GenParamName.TupleEqualElem("disp_background")).TupleOr(hv_GenParamName.TupleEqualElem("use_background"));
      hv_Indices = hv_Mask.TupleFind(1);
    }
    else
    {
      hv_Indices = -1;
    }
    if (0 != (HTuple(hv_Indices!=-1).TupleAnd(hv_Indices!=HTuple())))
    {
      hv_DispBackground = HTuple(hv_GenParamValue[HTuple(hv_Indices[0])]);
      if (0 != (HTuple(hv_DispBackground!=HTuple("true")).TupleAnd(hv_DispBackground!=HTuple("false"))))
      {
        //Wrong parameter value: Only 'true' and 'false' are allowed
        throw HException("Wrong value for parameter 'disp_background' (must be either 'true' or 'false')");
      }
      //Note the the background is handled explicitly in this procedure
      //and therefore, the parameter is removed from the list of
      //parameters and disp_background is always set to true (see below)
      hv_GenParamName = hv_GenParamName.TupleRemove(hv_Indices);
      hv_GenParamValue = hv_GenParamValue.TupleRemove(hv_Indices);
    }
    //
    //Read and check the parameter Label for each object
    if (0 != ((hv_Label.TupleLength())==0))
    {
      hv_Label = 0;
    }
    else if (0 != ((hv_Label.TupleLength())==1))
    {
      hv_Label = HTuple(hv_NumModels,hv_Label);
    }
    else
    {
      if (0 != ((hv_Label.TupleLength())!=hv_NumModels))
      {
        //Error: Number of elements in Label does not match the
        //number of object models
        // stop(...); only in hdevelop
      }
    }
    //
    //Read and check the parameter PoseIn for each object
    get_object_models_center(hv_ObjectModel3D, &hv_Center);
    if (0 != ((hv_PoseIn.TupleLength())==0))
    {
      //If no pose was specified by the caller, automatically calculate
      //a pose that is appropriate for the visualization.
      //Set the initial model reference pose. The orientation is parallel
      //to the object coordinate system, the position is at the center
      //of gravity of all models.
      CreatePose(-HTuple(hv_Center[0]), -HTuple(hv_Center[1]), -HTuple(hv_Center[2]), 
          0, 0, 0, "Rp+T", "gba", "point", &hv_PoseIn);
      determine_optimum_pose_distance(hv_ObjectModel3D, hv_CamParam, 0.9, hv_PoseIn, 
          &hv_PoseEstimated);
      hv_Poses = HTuple();
      hv_HomMat3Ds = HTuple();
      hv_Sequence = HTuple::TupleGenSequence(0,(hv_NumModels*7)-1,1);
      hv_Poses = HTuple(hv_PoseEstimated[hv_Sequence%7]);
      ExpTmpLocalVar_gIsSinglePose = 1;
      ExpSetGlobalVar_gIsSinglePose(ExpTmpLocalVar_gIsSinglePose);
    }
    else if (0 != ((hv_PoseIn.TupleLength())==7))
    {
      hv_Poses = HTuple();
      hv_HomMat3Ds = HTuple();
      hv_Sequence = HTuple::TupleGenSequence(0,(hv_NumModels*7)-1,1);
      hv_Poses = HTuple(hv_PoseIn[hv_Sequence%7]);
      ExpTmpLocalVar_gIsSinglePose = 1;
      ExpSetGlobalVar_gIsSinglePose(ExpTmpLocalVar_gIsSinglePose);
    }
    else
    {
      if (0 != ((hv_PoseIn.TupleLength())!=((hv_ObjectModel3D.TupleLength())*7)))
      {
        //Error: Wrong number of values of input control parameter 'PoseIn'
        // stop(...); only in hdevelop
      }
      else
      {
        hv_Poses = hv_PoseIn;
      }
      ExpTmpLocalVar_gIsSinglePose = 0;
      ExpSetGlobalVar_gIsSinglePose(ExpTmpLocalVar_gIsSinglePose);
    }

    //
    //Open (invisible) buffer window to avoid flickering
    OpenWindow(0, 0, hv_Width, hv_Height, 0, "buffer", "", &hv_WindowHandleBuffer);
    SetPart(hv_WindowHandleBuffer, 0, 0, hv_Height-1, hv_Width-1);
    GetFont(hv_WindowHandle, &hv_Font);
    try
    {
      SetFont(hv_WindowHandleBuffer, hv_Font);
    }
    // catch (Exception) 
    catch (HException &HDevExpDefaultException)
    {
      HDevExpDefaultException.ToHTuple(&hv_Exception);
    }
    //
    // Is OpenGL available and should it be used?
    ExpTmpLocalVar_gUsesOpenGL = "true";
    ExpSetGlobalVar_gUsesOpenGL(ExpTmpLocalVar_gUsesOpenGL);
    hv_Indices = hv_GenParamName.TupleFind("opengl");
    if (0 != (HTuple(hv_Indices!=-1).TupleAnd(hv_Indices!=HTuple())))
    {
      ExpTmpLocalVar_gUsesOpenGL = HTuple(hv_GenParamValue[HTuple(hv_Indices[0])]);
      ExpSetGlobalVar_gUsesOpenGL(ExpTmpLocalVar_gUsesOpenGL);
      hv_GenParamName = hv_GenParamName.TupleRemove(hv_Indices);
      hv_GenParamValue = hv_GenParamValue.TupleRemove(hv_Indices);
      if (0 != (HTuple(ExpGetGlobalVar_gUsesOpenGL()!=HTuple("true")).TupleAnd(ExpGetGlobalVar_gUsesOpenGL()!=HTuple("false"))))
      {
        //Wrong parameter value: Only 'true' and 'false' are allowed
        throw HException("Wrong value for parameter 'opengl' (must be either 'true' or 'false')");
      }
    }
    if (0 != (ExpGetGlobalVar_gUsesOpenGL()==HTuple("true")))
    {
      GetSystem("opengl_info", &hv_OpenGLInfo);
      if (0 != (hv_OpenGLInfo==HTuple("No OpenGL support included.")))
      {
        ExpTmpLocalVar_gUsesOpenGL = "false";
        ExpSetGlobalVar_gUsesOpenGL(ExpTmpLocalVar_gUsesOpenGL);
      }
      else
      {
        GenObjectModel3dFromPoints(0, 0, 0, &hv_DummyObjectModel3D);
        CreateScene3d(&hv_Scene3DTest);
        AddScene3dCamera(hv_Scene3DTest, hv_CamParam, &hv_CameraIndexTest);
        determine_optimum_pose_distance(hv_DummyObjectModel3D, hv_CamParam, 0.9, 
            ((((((HTuple(0).Append(0)).Append(0)).Append(0)).Append(0)).Append(0)).Append(0)), 
            &hv_PoseTest);
        AddScene3dInstance(hv_Scene3DTest, hv_DummyObjectModel3D, hv_PoseTest, &hv_InstanceIndexTest);
        try
        {
          DisplayScene3d(hv_WindowHandleBuffer, hv_Scene3DTest, hv_InstanceIndexTest);
        }
        // catch (Exception) 
        catch (HException &HDevExpDefaultException)
        {
          HDevExpDefaultException.ToHTuple(&hv_Exception);
          ExpTmpLocalVar_gUsesOpenGL = "false";
          ExpSetGlobalVar_gUsesOpenGL(ExpTmpLocalVar_gUsesOpenGL);
        }
        ClearScene3d(hv_Scene3DTest);
        hv_Scene3DTest = HTuple();
        ClearObjectModel3d(hv_DummyObjectModel3D);
      }
    }
    //
    //Compute the trackball
    hv_MinImageSize = (hv_Width.TupleConcat(hv_Height)).TupleMin();
    hv_TrackballRadiusPixel = (hv_TrackballSize*hv_MinImageSize)/2.0;
    //
    //Measure the text extents for the continue button in the
    //graphics window
    GetStringExtents(hv_WindowHandleBuffer, ExpGetGlobalVar_gTerminationButtonLabel()+"  ", 
        &hv_Ascent, &hv_Descent, &hv_TextWidth, &hv_TextHeight);
    //
    //Store background image
    if (0 != (hv_DispBackground==HTuple("false")))
    {
      ClearWindow(hv_WindowHandle);
    }
    DumpWindowImage(&ho_Image, hv_WindowHandle);
    //Special treatment for color background images necessary
    CountChannels(ho_Image, &hv_NumChannels);
    hv_ColorImage = hv_NumChannels==3;
    //
    CreateScene3d(&hv_Scene3D);
    AddScene3dCamera(hv_Scene3D, hv_CamParam, &hv_CameraIndex);
    AddScene3dInstance(hv_Scene3D, hv_ObjectModel3D, hv_Poses, &hv_AllInstances);
    //Always set 'disp_background' to true,  because it is handled explicitly
    //in this procedure (see above)
    SetScene3dParam(hv_Scene3D, "disp_background", "true");
    //Check if we have to set light specific parameters
    hv_SetLight = hv_GenParamName.TupleRegexpTest("light_");
    if (0 != hv_SetLight)
    {
      //set position of light source
      hv_Indices = hv_GenParamName.TupleFind("light_position");
      if (0 != (HTuple(hv_Indices!=-1).TupleAnd(hv_Indices!=HTuple())))
      {
        //If multiple light positions are given, use the last one
        hv_LightParam = (HTuple(hv_GenParamValue[HTuple(hv_Indices[(hv_Indices.TupleLength())-1])]).TupleSplit(HTuple(", "))).TupleNumber();
        if (0 != ((hv_LightParam.TupleLength())!=4))
        {
          throw HException("light_position must be given as a string that contains four space separated floating point numbers");
        }
        hv_LightPosition = hv_LightParam.TupleSelectRange(0,2);
        hv_LightKind = "point_light";
        if (0 != (HTuple(hv_LightParam[3])==0))
        {
          hv_LightKind = "directional_light";
        }
        //Currently, only one light source is supported
        RemoveScene3dLight(hv_Scene3D, 0);
        AddScene3dLight(hv_Scene3D, hv_LightPosition, hv_LightKind, &hv_LightIndex);
        TupleRemove(hv_GenParamName, hv_Indices, &hv_GenParamName);
        TupleRemove(hv_GenParamValue, hv_Indices, &hv_GenParamValue);
      }
      //set ambient part of light source
      hv_Indices = hv_GenParamName.TupleFind("light_ambient");
      if (0 != (HTuple(hv_Indices!=-1).TupleAnd(hv_Indices!=HTuple())))
      {
        //If the ambient part is set multiple times, use the last setting
        hv_LightParam = (HTuple(hv_GenParamValue[HTuple(hv_Indices[(hv_Indices.TupleLength())-1])]).TupleSplit(HTuple(", "))).TupleNumber();
        if (0 != ((hv_LightParam.TupleLength())<3))
        {
          throw HException("light_ambient must be given as a string that contains three space separated floating point numbers");
        }
        SetScene3dLightParam(hv_Scene3D, 0, "ambient", hv_LightParam.TupleSelectRange(0,2));
        TupleRemove(hv_GenParamName, hv_Indices, &hv_GenParamName);
        TupleRemove(hv_GenParamValue, hv_Indices, &hv_GenParamValue);
      }
      //Set diffuse part of light source
      hv_Indices = hv_GenParamName.TupleFind("light_diffuse");
      if (0 != (HTuple(hv_Indices!=-1).TupleAnd(hv_Indices!=HTuple())))
      {
        //If the diffuse part is set multiple times, use the last setting
        hv_LightParam = (HTuple(hv_GenParamValue[HTuple(hv_Indices[(hv_Indices.TupleLength())-1])]).TupleSplit(HTuple(", "))).TupleNumber();
        if (0 != ((hv_LightParam.TupleLength())<3))
        {
          throw HException("light_diffuse must be given as a string that contains three space separated floating point numbers");
        }
        SetScene3dLightParam(hv_Scene3D, 0, "diffuse", hv_LightParam.TupleSelectRange(0,2));
        TupleRemove(hv_GenParamName, hv_Indices, &hv_GenParamName);
        TupleRemove(hv_GenParamValue, hv_Indices, &hv_GenParamValue);
      }
    }
    //
    //Handle persistence parameters separately because persistence will
    //only be activated immediately before leaving the visualization
    //procedure
    hv_PersistenceParamName = HTuple();
    hv_PersistenceParamValue = HTuple();
    //Set position of light source
    hv_Indices = hv_GenParamName.TupleFind("object_index_persistence");
    if (0 != (HTuple(hv_Indices!=-1).TupleAnd(hv_Indices!=HTuple())))
    {
      if (0 != (HTuple(hv_GenParamValue[HTuple(hv_Indices[(hv_Indices.TupleLength())-1])])==HTuple("true")))
      {
        hv_PersistenceParamName = hv_PersistenceParamName.TupleConcat("object_index_persistence");
        hv_PersistenceParamValue = hv_PersistenceParamValue.TupleConcat("true");
      }
      else if (0 != (HTuple(hv_GenParamValue[HTuple(hv_Indices[(hv_Indices.TupleLength())-1])])==HTuple("false")))
      {
      }
      else
      {
        throw HException("Wrong value for parameter 'object_index_persistence' (must be either 'true' or 'false')");
      }
      TupleRemove(hv_GenParamName, hv_Indices, &hv_GenParamName);
      TupleRemove(hv_GenParamValue, hv_Indices, &hv_GenParamValue);
    }
    hv_Indices = hv_GenParamName.TupleFind("depth_persistence");
    if (0 != (HTuple(hv_Indices!=-1).TupleAnd(hv_Indices!=HTuple())))
    {
      if (0 != (HTuple(hv_GenParamValue[HTuple(hv_Indices[(hv_Indices.TupleLength())-1])])==HTuple("true")))
      {
        hv_PersistenceParamName = hv_PersistenceParamName.TupleConcat("depth_persistence");
        hv_PersistenceParamValue = hv_PersistenceParamValue.TupleConcat("true");
      }
      else if (0 != (HTuple(hv_GenParamValue[HTuple(hv_Indices[(hv_Indices.TupleLength())-1])])==HTuple("false")))
      {
      }
      else
      {
        throw HException("Wrong value for parameter 'depth_persistence' (must be either 'true' or 'false')");
      }
      TupleRemove(hv_GenParamName, hv_Indices, &hv_GenParamName);
      TupleRemove(hv_GenParamValue, hv_Indices, &hv_GenParamValue);
    }
    //
    //Parse the generic parameters
    //- First, all parameters that are understood by set_scene_3d_instance_param
    hv_AlphaOrig = HTuple(hv_NumModels,1);
    {
    HTuple end_val406 = (hv_GenParamName.TupleLength())-1;
    HTuple step_val406 = 1;
    for (hv_I=0; hv_I.Continue(end_val406, step_val406); hv_I += step_val406)
    {
      hv_ParamName = HTuple(hv_GenParamName[hv_I]);
      hv_ParamValue = HTuple(hv_GenParamValue[hv_I]);
      //Check if this parameter is understood by set_scene_3d_param
      if (0 != (hv_ParamName==HTuple("alpha")))
      {
        hv_AlphaOrig = HTuple(hv_NumModels,hv_ParamValue);
      }
      try
      {
        SetScene3dParam(hv_Scene3D, hv_ParamName, hv_ParamValue);
        continue;
      }
      // catch (Exception) 
      catch (HException &HDevExpDefaultException)
      {
        HDevExpDefaultException.ToHTuple(&hv_Exception);
        if (0 != (HTuple(HTuple(hv_Exception[0])==1203).TupleOr(HTuple(hv_Exception[0])==1303)))
        {
          throw HException((("Wrong type or value for parameter "+hv_ParamName)+": ")+hv_ParamValue);
        }
      }
      //Check if it is a parameter that is valid for only one instance
      //and therefore can be set only with set_scene_3d_instance_param
      hv_ParamNameTrunk = hv_ParamName.TupleRegexpReplace("_\\d+$","");
      if (0 != (hv_ParamName==hv_ParamNameTrunk))
      {
        hv_Instance = HTuple::TupleGenSequence(0,hv_NumModels-1,1);
      }
      else
      {
        hv_Instance = (hv_ParamName.TupleRegexpReplace(("^"+hv_ParamNameTrunk)+"_(\\d+)$","$1")).TupleNumber();
        if (0 != (HTuple(hv_Instance<0).TupleOr(hv_Instance>(hv_NumModels-1))))
        {
          throw HException(("Parameter "+hv_ParamName)+" refers to a non existing 3D object model");
        }
      }
      try
      {
        SetScene3dInstanceParam(hv_Scene3D, hv_Instance, hv_ParamNameTrunk, hv_ParamValue);
      }
      // catch (Exception) 
      catch (HException &HDevExpDefaultException)
      {
        HDevExpDefaultException.ToHTuple(&hv_Exception);
        if (0 != (HTuple(HTuple(hv_Exception[0])==1204).TupleOr(HTuple(hv_Exception[0])==1304)))
        {
          throw HException((("Wrong type or value for parameter "+hv_ParamName)+": ")+hv_ParamValue);
        }
        else if (0 != (HTuple(HTuple(hv_Exception[0])==1203).TupleOr(HTuple(hv_Exception[0])==1303)))
        {
          throw HException("Wrong parameter name "+hv_ParamName);
        }
        else
        {
          throw HException(hv_Exception);
        }
      }
      if (0 != (hv_ParamNameTrunk==HTuple("alpha")))
      {
        hv_AlphaOrig[hv_Instance] = hv_ParamValue;
      }
    }
    }
    //
    //Start the visualization loop
    PoseToHomMat3d(hv_Poses.TupleSelectRange(0,6), &hv_HomMat3D);
    AffineTransPoint3d(hv_HomMat3D, HTuple(hv_Center[0]), HTuple(hv_Center[1]), HTuple(hv_Center[2]), 
        &hv_Qx, &hv_Qy, &hv_Qz);
    hv_TBCenter.Clear();
    hv_TBCenter.Append(hv_Qx);
    hv_TBCenter.Append(hv_Qy);
    hv_TBCenter.Append(hv_Qz);
    hv_TBSize = (0.5+((0.5*(hv_SelectedObject.TupleSum()))/hv_NumModels))*hv_TrackballRadiusPixel;
    hv_ButtonHold = 0;
    while (0 != 1)
    {
      hv_VisualizeTB = (hv_SelectedObject.TupleMax())!=0;
      hv_MaxIndex = ((HTuple(hv_ObjectModel3D.TupleLength()).TupleConcat(hv_MaxNumModels)).TupleMin())-1;
      //Set trackball fixed in the center of the window
      hv_TrackballCenterRow = hv_Height/2;
      hv_TrackballCenterCol = hv_Width/2;
      if (0 != (hv_WindowCenteredRotation==1))
      {
        try
        {
          get_trackball_center_fixed(hv_SelectedObject.TupleSelectRange(0,hv_MaxIndex), 
              hv_TrackballCenterRow, hv_TrackballCenterCol, hv_TrackballRadiusPixel, 
              hv_Scene3D, hv_ObjectModel3D.TupleSelectRange(0,hv_MaxIndex), hv_Poses.TupleSelectRange(0,((hv_MaxIndex+1)*7)-1), 
              hv_WindowHandleBuffer, hv_CamParam, hv_GenParamName, hv_GenParamValue, 
              &hv_TBCenter, &hv_TBSize);
        }
        // catch (Exception) 
        catch (HException &HDevExpDefaultException)
        {
          HDevExpDefaultException.ToHTuple(&hv_Exception);
          disp_message(hv_WindowHandle, "Surface inspection mode is not available.", 
              "image", 5, 20, "red", "true");
          hv_WindowCenteredRotation = 2;
          get_trackball_center(hv_SelectedObject.TupleSelectRange(0,hv_MaxIndex), 
              hv_TrackballRadiusPixel, hv_ObjectModel3D.TupleSelectRange(0,hv_MaxIndex), 
              hv_Poses.TupleSelectRange(0,((hv_MaxIndex+1)*7)-1), &hv_TBCenter, &hv_TBSize);
          WaitSeconds(1);
        }
      }
      else
      {
        get_trackball_center(hv_SelectedObject.TupleSelectRange(0,hv_MaxIndex), hv_TrackballRadiusPixel, 
            hv_ObjectModel3D.TupleSelectRange(0,hv_MaxIndex), hv_Poses.TupleSelectRange(0,((hv_MaxIndex+1)*7)-1), 
            &hv_TBCenter, &hv_TBSize);
      }
      dump_image_output(ho_Image, hv_WindowHandleBuffer, hv_Scene3D, hv_AlphaOrig, 
          hv_ObjectModel3D, hv_GenParamName, hv_GenParamValue, hv_CamParam, hv_Poses, 
          hv_ColorImage, hv_Title, hv_Information, hv_Label, hv_VisualizeTB, "true", 
          hv_TrackballCenterRow, hv_TrackballCenterCol, hv_TBSize, hv_SelectedObject, 
          hv_WindowCenteredRotation, hv_TBCenter);
      DumpWindowImage(&ho_ImageDump, hv_WindowHandleBuffer);
      HDevWindowStack::SetActive(hv_WindowHandle);
      if (HDevWindowStack::IsOpen())
        DispObj(ho_ImageDump, HDevWindowStack::GetActive());
      //
      //Check for mouse events
      hv_GraphEvent = 0;
      hv_Exit = 0;
      while (0 != 1)
      {
        //
        //Check graphic event
        try
        {
          GetMpositionSubPix(hv_WindowHandle, &hv_GraphButtonRow, &hv_GraphButtonColumn, 
              &hv_GraphButton);
          if (0 != (hv_GraphButton!=0))
          {
            if (0 != (HTuple(HTuple(HTuple(hv_GraphButtonRow>((hv_Height-hv_TextHeight)-25)).TupleAnd(hv_GraphButtonRow<hv_Height)).TupleAnd(hv_GraphButtonColumn>((hv_Width-hv_TextWidth)-15))).TupleAnd(hv_GraphButtonColumn<hv_Width)))
            {
              //Wait until the continue button has been released
              if (0 != (hv_WaitForButtonRelease==HTuple("true")))
              {
                while (0 != 1)
                {
                  GetMpositionSubPix(hv_WindowHandle, &hv_GraphButtonRow, &hv_GraphButtonColumn, 
                      &hv_GraphButton);
                  if (0 != (HTuple(hv_GraphButton==0).TupleOr(hv_GraphButton==HTuple())))
                  {
                    if (0 != (HTuple(HTuple(HTuple(hv_GraphButtonRow>((hv_Height-hv_TextHeight)-25)).TupleAnd(hv_GraphButtonRow<hv_Height)).TupleAnd(hv_GraphButtonColumn>((hv_Width-hv_TextWidth)-15))).TupleAnd(hv_GraphButtonColumn<hv_Width)))
                    {
                      hv_ButtonReleased = 1;
                    }
                    else
                    {
                      hv_ButtonReleased = 0;
                    }
                    //
                    break;
                  }
                  //Keep waiting until mouse button is released or moved out of the window
                }
              }
              else
              {
                hv_ButtonReleased = 1;
              }
              //Exit the visualization loop
              if (0 != hv_ButtonReleased)
              {
                hv_Exit = 1;
                break;
              }
            }
            hv_GraphEvent = 1;
            break;
          }
          else
          {
            hv_ButtonHold = 0;
          }
        }
        // catch (Exception) 
        catch (HException &HDevExpDefaultException)
        {
          HDevExpDefaultException.ToHTuple(&hv_Exception);
          //Keep waiting
        }
      }
      if (0 != hv_GraphEvent)
      {
        analyze_graph_event(ho_Image, hv_MouseMapping, hv_GraphButton, hv_GraphButtonRow, 
            hv_GraphButtonColumn, hv_WindowHandle, hv_WindowHandleBuffer, hv_VirtualTrackball, 
            hv_TrackballSize, hv_SelectedObject, hv_Scene3D, hv_AlphaOrig, hv_ObjectModel3D, 
            hv_CamParam, hv_Label, hv_Title, hv_Information, hv_GenParamName, hv_GenParamValue, 
            hv_Poses, hv_ButtonHold, hv_TBCenter, hv_TBSize, hv_WindowCenteredRotation, 
            hv_MaxNumModels, &hv_Poses, &hv_SelectedObject, &hv_ButtonHold, &hv_WindowCenteredRotation);
      }
      if (0 != hv_Exit)
      {
        break;
      }
    }
    //
    //Display final state with persistence, if requested
    //Note that disp_object_model_3d must be used instead of the 3D scene
    if (0 != ((hv_PersistenceParamName.TupleLength())>0))
    {
      try
      {
        DispObjectModel3d(hv_WindowHandle, hv_ObjectModel3D, hv_CamParam, hv_Poses, 
            (HTuple("disp_background").Append("alpha")).TupleConcat(hv_PersistenceParamName), 
            (HTuple("true").Append(0.0)).TupleConcat(hv_PersistenceParamValue));
      }
      // catch (Exception) 
      catch (HException &HDevExpDefaultException)
      {
        HDevExpDefaultException.ToHTuple(&hv_Exception);
        // stop(...); only in hdevelop
      }
    }
    //
    //Compute the output pose
    if (0 != ExpGetGlobalVar_gIsSinglePose())
    {
      (*hv_PoseOut) = hv_Poses.TupleSelectRange(0,6);
    }
    else
    {
      (*hv_PoseOut) = hv_Poses;
    }
    //
    //Clean up
    SetSystem("clip_region", hv_ClipRegion);
    // dev_set_preferences(...); only in hdevelop
    // dev_set_preferences(...); only in hdevelop
    dump_image_output(ho_Image, hv_WindowHandleBuffer, hv_Scene3D, hv_AlphaOrig, 
        hv_ObjectModel3D, hv_GenParamName, hv_GenParamValue, hv_CamParam, hv_Poses, 
        hv_ColorImage, hv_Title, HTuple(), hv_Label, 0, "false", hv_TrackballCenterRow, 
        hv_TrackballCenterCol, hv_TBSize, hv_SelectedObject, hv_WindowCenteredRotation, 
        hv_TBCenter);
    DumpWindowImage(&ho_ImageDump, hv_WindowHandleBuffer);
    HDevWindowStack::SetActive(hv_WindowHandle);
    if (HDevWindowStack::IsOpen())
      DispObj(ho_ImageDump, HDevWindowStack::GetActive());
    CloseWindow(hv_WindowHandleBuffer);
    SetPart(hv_WindowHandle, hv_WPRow1, hv_WPColumn1, hv_WPRow2, hv_WPColumn2);
    ClearScene3d(hv_Scene3D);
    hv_Scene3D = HTuple();
  }
  // catch (Exception) 
  catch (HException &HDevExpDefaultException)
  {
    HDevExpDefaultException.ToHTuple(&hv_Exception);
    try
    {
      if (0 != (0<(hv_Scene3DTest.TupleLength())))
      {
        ClearScene3d(hv_Scene3DTest);
        hv_Scene3DTest = HTuple();
      }
      if (0 != (0<(hv_Scene3D.TupleLength())))
      {
        ClearScene3d(hv_Scene3D);
        hv_Scene3D = HTuple();
      }
      if (0 != (0<(hv_WindowHandleBuffer.TupleLength())))
      {
        CloseWindow(hv_WindowHandleBuffer);
        hv_WindowHandleBuffer = HTuple();
      }
    }
    // catch (e) 
    catch (HException &HDevExpDefaultException)
    {
      HDevExpDefaultException.ToHTuple(&hv_e);
      //suppress all further exceptions to return the original exception
    }

    throw HException(hv_Exception);
  }
  return;
}

// Chapter: Matching / Shape-Based
// Short Description: Display the results of Shape-Based Matching. 
void dev_display_shape_matching_results (HTuple hv_ModelID, HTuple hv_Color, HTuple hv_Row, 
    HTuple hv_Column, HTuple hv_Angle, HTuple hv_ScaleR, HTuple hv_ScaleC, HTuple hv_Model)
{

  // Local iconic variables
  HObject  ho_ModelContours, ho_ContoursAffinTrans;

  // Local control variables
  HTuple  hv_NumMatches, hv_Index, hv_Match, hv_HomMat2DIdentity;
  HTuple  hv_HomMat2DScale, hv_HomMat2DRotate, hv_HomMat2DTranslate;

  //This procedure displays the results of Shape-Based Matching.
  //
  hv_NumMatches = hv_Row.TupleLength();
  if (0 != (hv_NumMatches>0))
  {
    if (0 != ((hv_ScaleR.TupleLength())==1))
    {
      TupleGenConst(hv_NumMatches, hv_ScaleR, &hv_ScaleR);
    }
    if (0 != ((hv_ScaleC.TupleLength())==1))
    {
      TupleGenConst(hv_NumMatches, hv_ScaleC, &hv_ScaleC);
    }
    if (0 != ((hv_Model.TupleLength())==0))
    {
      TupleGenConst(hv_NumMatches, 0, &hv_Model);
    }
    else if (0 != ((hv_Model.TupleLength())==1))
    {
      TupleGenConst(hv_NumMatches, hv_Model, &hv_Model);
    }
    {
    HTuple end_val15 = (hv_ModelID.TupleLength())-1;
    HTuple step_val15 = 1;
    for (hv_Index=0; hv_Index.Continue(end_val15, step_val15); hv_Index += step_val15)
    {
      GetShapeModelContours(&ho_ModelContours, HTuple(hv_ModelID[hv_Index]), 1);
      if (HDevWindowStack::IsOpen())
        SetColor(HDevWindowStack::GetActive(),HTuple(hv_Color[hv_Index%(hv_Color.TupleLength())]));
      {
      HTuple end_val18 = hv_NumMatches-1;
      HTuple step_val18 = 1;
      for (hv_Match=0; hv_Match.Continue(end_val18, step_val18); hv_Match += step_val18)
      {
        if (0 != (hv_Index==HTuple(hv_Model[hv_Match])))
        {
          HomMat2dIdentity(&hv_HomMat2DIdentity);
          HomMat2dScale(hv_HomMat2DIdentity, HTuple(hv_ScaleR[hv_Match]), HTuple(hv_ScaleC[hv_Match]), 
              0, 0, &hv_HomMat2DScale);
          HomMat2dRotate(hv_HomMat2DScale, HTuple(hv_Angle[hv_Match]), 0, 0, &hv_HomMat2DRotate);
          HomMat2dTranslate(hv_HomMat2DRotate, HTuple(hv_Row[hv_Match]), HTuple(hv_Column[hv_Match]), 
              &hv_HomMat2DTranslate);
          AffineTransContourXld(ho_ModelContours, &ho_ContoursAffinTrans, hv_HomMat2DTranslate);
          if (HDevWindowStack::IsOpen())
            DispObj(ho_ContoursAffinTrans, HDevWindowStack::GetActive());
        }
      }
      }
    }
    }
  }
  return;
}

// Chapter: Develop
// Short Description: Changes the size of a graphics window with a given maximum and minimum extent such that it preserves the aspect ratio of the given image 
void dev_resize_window_fit_image (HObject ho_Image, HTuple hv_Row, HTuple hv_Column, 
    HTuple hv_WidthLimit, HTuple hv_HeightLimit)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_MinWidth, hv_MaxWidth, hv_MinHeight;
  HTuple  hv_MaxHeight, hv_ResizeFactor, hv_Pointer, hv_Type;
  HTuple  hv_ImageWidth, hv_ImageHeight, hv_TempWidth, hv_TempHeight;
  HTuple  hv_WindowWidth, hv_WindowHeight;

  //This procedure adjusts the size of the current window
  //such that it fits into the limits specified by WidthLimit
  //and HeightLimit, but also maintains the correct image aspect ratio.
  //
  //If it is impossible to match the minimum and maximum extent requirements
  //at the same time (f.e. if the image is very long but narrow),
  //the maximum value gets a higher priority,
  //
  //Parse input tuple WidthLimit
  if (0 != (HTuple((hv_WidthLimit.TupleLength())==0).TupleOr(hv_WidthLimit<0)))
  {
    hv_MinWidth = 500;
    hv_MaxWidth = 800;
  }
  else if (0 != ((hv_WidthLimit.TupleLength())==1))
  {
    hv_MinWidth = 0;
    hv_MaxWidth = hv_WidthLimit;
  }
  else
  {
    hv_MinWidth = ((const HTuple&)hv_WidthLimit)[0];
    hv_MaxWidth = ((const HTuple&)hv_WidthLimit)[1];
  }
  //Parse input tuple HeightLimit
  if (0 != (HTuple((hv_HeightLimit.TupleLength())==0).TupleOr(hv_HeightLimit<0)))
  {
    hv_MinHeight = 400;
    hv_MaxHeight = 600;
  }
  else if (0 != ((hv_HeightLimit.TupleLength())==1))
  {
    hv_MinHeight = 0;
    hv_MaxHeight = hv_HeightLimit;
  }
  else
  {
    hv_MinHeight = ((const HTuple&)hv_HeightLimit)[0];
    hv_MaxHeight = ((const HTuple&)hv_HeightLimit)[1];
  }
  //
  //Test, if window size has to be changed.
  hv_ResizeFactor = 1;
  GetImagePointer1(ho_Image, &hv_Pointer, &hv_Type, &hv_ImageWidth, &hv_ImageHeight);
  //First, expand window to the minimum extents (if necessary).
  if (0 != (HTuple(hv_MinWidth>hv_ImageWidth).TupleOr(hv_MinHeight>hv_ImageHeight)))
  {
    hv_ResizeFactor = (((hv_MinWidth.TupleReal())/hv_ImageWidth).TupleConcat((hv_MinHeight.TupleReal())/hv_ImageHeight)).TupleMax();
  }
  hv_TempWidth = hv_ImageWidth*hv_ResizeFactor;
  hv_TempHeight = hv_ImageHeight*hv_ResizeFactor;
  //Then, shrink window to maximum extents (if necessary).
  if (0 != (HTuple(hv_MaxWidth<hv_TempWidth).TupleOr(hv_MaxHeight<hv_TempHeight)))
  {
    hv_ResizeFactor = hv_ResizeFactor*((((hv_MaxWidth.TupleReal())/hv_TempWidth).TupleConcat((hv_MaxHeight.TupleReal())/hv_TempHeight)).TupleMin());
  }
  hv_WindowWidth = hv_ImageWidth*hv_ResizeFactor;
  hv_WindowHeight = hv_ImageHeight*hv_ResizeFactor;
  //Resize window
  if (HDevWindowStack::IsOpen())
    SetWindowExtents(HDevWindowStack::GetActive(),hv_Row, hv_Column, hv_WindowWidth, 
        hv_WindowHeight);
  if (HDevWindowStack::IsOpen())
    SetPart(HDevWindowStack::GetActive(),0, 0, hv_ImageHeight-1, hv_ImageWidth-1);
  return;
}

// Chapter: Filters / Lines
// Short Description: Calculates the parameters Sigma, Low, and High for lines_gauss from the maximum width and the contrast of the lines to be extracted. 
void calculate_lines_gauss_parameters (HTuple hv_MaxLineWidth, HTuple hv_Contrast, 
    HTuple *hv_Sigma, HTuple *hv_Low, HTuple *hv_High)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_ContrastHigh, hv_ContrastLow, hv_HalfWidth;
  HTuple  hv_Help;

  //Check control parameters
  if (0 != ((hv_MaxLineWidth.TupleLength())!=1))
  {
    throw HException("Wrong number of values of control parameter: 1");
  }
  if (0 != ((hv_MaxLineWidth.TupleIsNumber()).TupleNot()))
  {
    throw HException("Wrong type of control parameter: 1");
  }
  if (0 != (hv_MaxLineWidth<=0))
  {
    throw HException("Wrong value of control parameter: 1");
  }
  if (0 != (HTuple((hv_Contrast.TupleLength())!=1).TupleAnd((hv_Contrast.TupleLength())!=2)))
  {
    throw HException("Wrong number of values of control parameter: 2");
  }
  if (0 != (((hv_Contrast.TupleIsNumber()).TupleMin())==0))
  {
    throw HException("Wrong type of control parameter: 2");
  }
  //Set and check ContrastHigh
  hv_ContrastHigh = ((const HTuple&)hv_Contrast)[0];
  if (0 != (hv_ContrastHigh<0))
  {
    throw HException("Wrong value of control parameter: 2");
  }
  //Set or derive ContrastLow
  if (0 != ((hv_Contrast.TupleLength())==2))
  {
    hv_ContrastLow = ((const HTuple&)hv_Contrast)[1];
  }
  else
  {
    hv_ContrastLow = hv_ContrastHigh/3.0;
  }
  //Check ContrastLow
  if (0 != (hv_ContrastLow<0))
  {
    throw HException("Wrong value of control parameter: 2");
  }
  if (0 != (hv_ContrastLow>hv_ContrastHigh))
  {
    throw HException("Wrong value of control parameter: 2");
  }
  //
  //Calculate the parameters Sigma, Low, and High for lines_gauss
  if (0 != (hv_MaxLineWidth<(HTuple(3.0).TupleSqrt())))
  {
    //Note that LineWidthMax < sqrt(3.0) would result in a Sigma < 0.5,
    //which does not make any sense, because the corresponding smoothing
    //filter mask would be of size 1x1.
    //To avoid this, LineWidthMax is restricted to values greater or equal
    //to sqrt(3.0) and the contrast values are adapted to reflect the fact
    //that lines that are thinner than sqrt(3.0) pixels have a lower contrast
    //in the smoothed image (compared to lines that are sqrt(3.0) pixels wide).
    hv_ContrastLow = (hv_ContrastLow*hv_MaxLineWidth)/(HTuple(3.0).TupleSqrt());
    hv_ContrastHigh = (hv_ContrastHigh*hv_MaxLineWidth)/(HTuple(3.0).TupleSqrt());
    hv_MaxLineWidth = HTuple(3.0).TupleSqrt();
  }
  //Convert LineWidthMax and the given contrast values into the input parameters
  //Sigma, Low, and High required by lines_gauss
  hv_HalfWidth = hv_MaxLineWidth/2.0;
  (*hv_Sigma) = hv_HalfWidth/(HTuple(3.0).TupleSqrt());
  hv_Help = ((-2.0*hv_HalfWidth)/((HTuple(6.283185307178).TupleSqrt())*((*hv_Sigma).TuplePow(3.0))))*((-0.5*((hv_HalfWidth/(*hv_Sigma)).TuplePow(2.0))).TupleExp());
  (*hv_High) = (hv_ContrastHigh*hv_Help).TupleFabs();
  (*hv_Low) = (hv_ContrastLow*hv_Help).TupleFabs();
  return;
}

// Chapter: Identification / Bar Code
// Short Description: Convert a decoded string of a bar code of type 'Code 39' to the type 'Code 32'. 
void convert_decoded_string_code39_to_code32 (HTuple hv_DecodedDataStringCode39, 
    HTuple *hv_ConvertedDataStringCode32)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_Symbols, hv_Digit, hv_CheckDigit, hv_CheckSum;
  HTuple  hv_Value;

  //This procedure converts a decoded string of a 'Code 32'
  //barcode that was read with the bar code reader for 'Code 39'
  //to the 'Code 32' decoding.
  //
  //Basically a 'Code 32' bar code corresponds to a 'Code 39' with
  //8 digits and a checksum digit % 10 whereas even positions are
  //weighted twice.
  //The 9-digit number is represented to the base 32 and written
  //with chars (via the symbol table) analogous to a hexadecimal number.
  //
  //Initialize symbol table
  hv_Symbols.Clear();
  hv_Symbols[0] = "0";
  hv_Symbols[1] = "1";
  hv_Symbols[2] = "2";
  hv_Symbols[3] = "3";
  hv_Symbols[4] = "4";
  hv_Symbols[5] = "5";
  hv_Symbols[6] = "6";
  hv_Symbols[7] = "7";
  hv_Symbols[8] = "8";
  hv_Symbols[9] = "9";
  hv_Symbols[10] = "B";
  hv_Symbols[11] = "C";
  hv_Symbols[12] = "D";
  hv_Symbols[13] = "F";
  hv_Symbols[14] = "G";
  hv_Symbols[15] = "H";
  hv_Symbols[16] = "J";
  hv_Symbols[17] = "K";
  hv_Symbols[18] = "L";
  hv_Symbols[19] = "M";
  hv_Symbols[20] = "N";
  hv_Symbols[21] = "P";
  hv_Symbols[22] = "Q";
  hv_Symbols[23] = "R";
  hv_Symbols[24] = "S";
  hv_Symbols[25] = "T";
  hv_Symbols[26] = "U";
  hv_Symbols[27] = "V";
  hv_Symbols[28] = "W";
  hv_Symbols[29] = "X";
  hv_Symbols[30] = "Y";
  hv_Symbols[31] = "Z";
  //Check the chars in the decoded 'Code 39' string.
  //It must consist of exactly 6 chars and must not
  //contain any invalid chars. If these conditions are
  //fulfilled, convert the string to 'Code 32', else
  //return an empty string.
  if (0 != (hv_DecodedDataStringCode39.TupleRegexpTest(("^["+(hv_Symbols.TupleSum()))+"]{6}$")))
  {
    //
    //Convert the value of each digit in the decoded 'Code 39' string
    (*hv_ConvertedDataStringCode32) = 0;
    for (hv_Digit=0; hv_Digit<=5; hv_Digit+=1)
    {
      (*hv_ConvertedDataStringCode32) += hv_Symbols.TupleFind(hv_DecodedDataStringCode39.TupleStrBitSelect(hv_Digit));
      if (0 != (hv_Digit<5))
      {
        (*hv_ConvertedDataStringCode32) = (*hv_ConvertedDataStringCode32)*32;
      }
    }
    //Write the converted string as 9 digit string with leading zeros
    (*hv_ConvertedDataStringCode32) = (*hv_ConvertedDataStringCode32).TupleString("9.9d");
    //
    //Verify the checksum (last digit)
    hv_CheckDigit = ((*hv_ConvertedDataStringCode32).TupleStrBitSelect(8)).TupleNumber();
    hv_CheckSum = 0;
    for (hv_Digit=0; hv_Digit<=7; hv_Digit+=1)
    {
      //Sum first 8 digits, but even digits have weight 2
      hv_Value = (1+(hv_Digit%2))*(((*hv_ConvertedDataStringCode32).TupleStrBitSelect(hv_Digit)).TupleNumber());
      //But actually we only want the cross digit sum,
      //This 'formula' works for 0-19
      if (0 != (hv_Value>=10))
      {
        hv_Value = hv_Value-9;
      }
      hv_CheckSum += hv_Value;
    }
    hv_CheckSum = hv_CheckSum%10;
    //
    //If the checksum fits, return the converted 'Code 32' string,
    //else return an empty string
    if (0 != (hv_CheckDigit!=hv_CheckSum))
    {
      //Bad checksum
      (*hv_ConvertedDataStringCode32) = "";
    }
    else
    {
      //Always printed with leading A
      (*hv_ConvertedDataStringCode32) = "A"+(*hv_ConvertedDataStringCode32);
    }
  }
  else
  {
    //Wrong number of chars or invalid chars
    (*hv_ConvertedDataStringCode32) = "";
  }
  return;
  //
}

// Chapter: Matching / Correlation-Based
// Short Description: Display the results of Correlation-Based Matching. 
void dev_display_ncc_matching_results (HTuple hv_ModelID, HTuple hv_Color, HTuple hv_Row, 
    HTuple hv_Column, HTuple hv_Angle, HTuple hv_Model)
{

  // Local iconic variables
  HObject  ho_ModelRegion, ho_ModelContours, ho_ContoursAffinTrans;
  HObject  ho_Cross;

  // Local control variables
  HTuple  hv_NumMatches, hv_Index, hv_Match, hv_HomMat2DIdentity;
  HTuple  hv_HomMat2DRotate, hv_HomMat2DTranslate, hv_RowTrans;
  HTuple  hv_ColTrans;

  //This procedure displays the results of Correlation-Based Matching.
  //
  hv_NumMatches = hv_Row.TupleLength();
  if (0 != (hv_NumMatches>0))
  {
    if (0 != ((hv_Model.TupleLength())==0))
    {
      TupleGenConst(hv_NumMatches, 0, &hv_Model);
    }
    else if (0 != ((hv_Model.TupleLength())==1))
    {
      TupleGenConst(hv_NumMatches, hv_Model, &hv_Model);
    }
    {
    HTuple end_val9 = (hv_ModelID.TupleLength())-1;
    HTuple step_val9 = 1;
    for (hv_Index=0; hv_Index.Continue(end_val9, step_val9); hv_Index += step_val9)
    {
      GetNccModelRegion(&ho_ModelRegion, HTuple(hv_ModelID[hv_Index]));
      GenContourRegionXld(ho_ModelRegion, &ho_ModelContours, "border_holes");
      if (HDevWindowStack::IsOpen())
        SetColor(HDevWindowStack::GetActive(),HTuple(hv_Color[hv_Index%(hv_Color.TupleLength())]));
      {
      HTuple end_val13 = hv_NumMatches-1;
      HTuple step_val13 = 1;
      for (hv_Match=0; hv_Match.Continue(end_val13, step_val13); hv_Match += step_val13)
      {
        if (0 != (hv_Index==HTuple(hv_Model[hv_Match])))
        {
          HomMat2dIdentity(&hv_HomMat2DIdentity);
          HomMat2dRotate(hv_HomMat2DIdentity, HTuple(hv_Angle[hv_Match]), 0, 0, &hv_HomMat2DRotate);
          HomMat2dTranslate(hv_HomMat2DRotate, HTuple(hv_Row[hv_Match]), HTuple(hv_Column[hv_Match]), 
              &hv_HomMat2DTranslate);
          AffineTransContourXld(ho_ModelContours, &ho_ContoursAffinTrans, hv_HomMat2DTranslate);
          if (HDevWindowStack::IsOpen())
            DispObj(ho_ContoursAffinTrans, HDevWindowStack::GetActive());
          AffineTransPixel(hv_HomMat2DTranslate, 0, 0, &hv_RowTrans, &hv_ColTrans);
          GenCrossContourXld(&ho_Cross, hv_RowTrans, hv_ColTrans, 6, HTuple(hv_Angle[hv_Match]));
          if (HDevWindowStack::IsOpen())
            DispObj(ho_Cross, HDevWindowStack::GetActive());
        }
      }
      }
    }
    }
  }
  return;
}

// Chapter: Calibration / Hand-Eye
// Short Description: Check the input poses of the hand-eye calibration for consistency. 
void check_hand_eye_calibration_input_poses (HTuple hv_CalibDataID, HTuple hv_RotationTolerance, 
    HTuple hv_TranslationTolerance, HTuple *hv_Warnings)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_MinLargeRotationFraction, hv_MinLargeAnglesFraction;
  HTuple  hv_StdDevFactor, hv_Type, hv_Exception, hv_IsHandEyeScara;
  HTuple  hv_IsHandEyeArticulated, hv_NumCameras, hv_NumCalibObjs;
  HTuple  hv_I1, hv_PosesIdx, hv_RefCalibDataID, hv_UseTemporaryCopy;
  HTuple  hv_CamPoseCal, hv_SerializedItemHandle, hv_TmpCalibDataID;
  HTuple  hv_Error, hv_Index, hv_CamDualQuatCal, hv_BasePoseTool;
  HTuple  hv_BaseDualQuatTool, hv_NumCalibrationPoses, hv_LX2s;
  HTuple  hv_LY2s, hv_LZ2s, hv_TranslationToleranceSquared;
  HTuple  hv_RotationToleranceSquared, hv_Index1, hv_CamDualQuatCal1;
  HTuple  hv_Cal1DualQuatCam, hv_BaseDualQuatTool1, hv_Tool1DualQuatBase;
  HTuple  hv_Index2, hv_CamDualQuatCal2, hv_DualQuat1, hv_BaseDualQuatTool2;
  HTuple  hv_DualQuat2, hv_LX1, hv_LY1, hv_LZ1, hv_MX1, hv_MY1;
  HTuple  hv_MZ1, hv_Rot1, hv_Trans1, hv_LX2, hv_LY2, hv_LZ2;
  HTuple  hv_MX2, hv_MY2, hv_MZ2, hv_Rot2, hv_Trans2, hv_MeanRot;
  HTuple  hv_MeanTrans, hv_SinTheta2, hv_CosTheta2, hv_SinTheta2Squared;
  HTuple  hv_CosTheta2Squared, hv_ErrorRot, hv_StdDevQ0, hv_ToleranceDualQuat0;
  HTuple  hv_ErrorDualQuat0, hv_StdDevQ4, hv_ToleranceDualQuat4;
  HTuple  hv_ErrorDualQuat4, hv_Message, hv_NumPairs, hv_NumPairsMax;
  HTuple  hv_LargeRotationFraction, hv_NumPairPairs, hv_NumPairPairsMax;
  HTuple  hv_Angles, hv_Idx, hv_LXA, hv_LYA, hv_LZA, hv_LXB;
  HTuple  hv_LYB, hv_LZB, hv_ScalarProduct, hv_LargeAngles;
  HTuple  hv_LargeAnglesFraction;
  HTupleVector  hvec_CamDualQuatsCal(1), hvec_BaseDualQuatsTool(1);

  //This procedure checks the hand-eye calibration input poses that are stored in
  //the calibration data model CalibDataID for consistency.
  //
  //For this check, it is necessary to know the accuracy of the input poses.
  //Therefore, the RotationTolerance and TranslationTolerance must be
  //specified that approximately describe the error in the rotation and in the
  //translation part of the input poses, respectively. The rotation tolerance must
  //be passed in RotationTolerance in radians. The translation tolerance must be
  //passed in TranslationTolerance in the same unit in which the input poses were
  //given, i.e., typically in meters. Therefore, the more accurate the
  //input poses are, the lower the values for RotationTolerance and
  //TranslationTolerance should be chosen. If the accuracy of the robot's tool
  //poses is different from the accuracy of the calibration object poses, the
  //tolerance values of the poses with the lower accuracy (i.e., the higher
  //tolerance values) should be passed.
  //
  //Typically, check_hand_eye_calibration_input_poses is called after all
  //calibration poses have been set in the calibration data model and before the
  //hand eye calibration is performed. The procedure checks all pairs of robot
  //tool poses and compares them to the corresponding pair of calibration object
  //poses. For each inconsistent pose pair, a string is returned in Warnings that
  //indicates the inconsistent pose pair. For larger values for RotationTolerance
  //or TranslationTolerance, i.e., for less accurate input poses, fewer warnings
  //will be generated because the check is more tolerant, and vice versa. The
  //procedure is also helpful if the errors that are returned by the hand-eye
  //calibration are larger than expected to identify potentially erroneous poses.
  //Note that it is not possible to check the consistency of a single pose but
  //only of pose pairs. Nevertheless, if a certain pose occurs multiple times in
  //different warning messages, it is likely that the pose is erroneous.
  //Erroneous poses that result in inconsistent pose pairs should removed
  //from the calibration data model by using remove_calib_data_observ and
  //remove_calib_data before performing the hand-eye calibration.
  //
  //check_hand_eye_calibration_input_poses also checks whether enough calibration
  //pose pairs are passed with a significant relative rotation angle, which
  //is necessary for a robust hand-eye calibration.
  //
  //check_hand_eye_calibration_input_poses also verifies that the correct
  //calibration model was chosen in create_calib_data. If a model of type
  //'hand_eye_stationary_cam' or 'hand_eye_moving_cam' was chosen, the calibration
  //of an articulated robot is assumed. For 'hand_eye_scara_stationary_cam' or
  //'hand_eye_scara_moving_cam', the calibration of a SCARA robot is assumed.
  //Therefore, if all input poses for an articulated robot are parallel or if some
  //robot poses for a SCARA robot are tilted, a corresponding message is returned
  //in Warnings. Furthermore, if the number of tilted input poses for articulated
  //robots is below a certain value, a corresponding message in Warnings indicates
  //that the accuracy of the result of the hand-eye calibration might be low.
  //
  //If no problems have been detected in the input poses, an empty tuple is
  //returned in Warnings.
  //
  //
  //Define the minimum fraction of pose pairs with a rotation angle exceeding
  //2*RotationTolerance.
  hv_MinLargeRotationFraction = 0.1;
  //Define the minimum fraction of screw axes pairs with an angle exceeding
  //2*RotationTolerance for articulated robots.
  hv_MinLargeAnglesFraction = 0.1;
  //Factor that is used to multiply the standard deviations to obtain an error
  //threshold.
  hv_StdDevFactor = 3.0;
  //
  //Check input control parameters.
  if (0 != ((hv_CalibDataID.TupleLength())!=1))
  {
    throw HException("Wrong number of values of control parameter: 1");
  }
  if (0 != ((hv_RotationTolerance.TupleLength())!=1))
  {
    throw HException("Wrong number of values of control parameter: 2");
  }
  if (0 != ((hv_TranslationTolerance.TupleLength())!=1))
  {
    throw HException("Wrong number of values of control parameter: 3");
  }
  try
  {
    GetCalibData(hv_CalibDataID, "model", "general", "type", &hv_Type);
  }
  // catch (Exception) 
  catch (HException &HDevExpDefaultException)
  {
    HDevExpDefaultException.ToHTuple(&hv_Exception);
    throw HException("Wrong value of control parameter: 1");
  }
  if (0 != (hv_RotationTolerance<0))
  {
    throw HException("Wrong value of control parameter: 2");
  }
  if (0 != (hv_TranslationTolerance<0))
  {
    throw HException("Wrong value of control parameter: 3");
  }
  //
  //Read out the calibration data model.
  hv_IsHandEyeScara = HTuple(hv_Type==HTuple("hand_eye_scara_stationary_cam")).TupleOr(hv_Type==HTuple("hand_eye_scara_moving_cam"));
  hv_IsHandEyeArticulated = HTuple(hv_Type==HTuple("hand_eye_stationary_cam")).TupleOr(hv_Type==HTuple("hand_eye_moving_cam"));
  //This procedure only works for hand-eye calibration applications.
  if (0 != (HTuple(hv_IsHandEyeScara.TupleNot()).TupleAnd(hv_IsHandEyeArticulated.TupleNot())))
  {
    throw HException("check_hand_eye_calibration_input_poses only works for hand-eye calibrations");
  }
  GetCalibData(hv_CalibDataID, "model", "general", "num_cameras", &hv_NumCameras);
  GetCalibData(hv_CalibDataID, "model", "general", "num_calib_objs", &hv_NumCalibObjs);
  //
  //Get all valid calibration pose indices.
  QueryCalibDataObservIndices(hv_CalibDataID, "camera", 0, &hv_I1, &hv_PosesIdx);
  hv_RefCalibDataID = hv_CalibDataID;
  hv_UseTemporaryCopy = 0;
  //If necessary, calibrate the interior camera parameters.
  if (0 != hv_IsHandEyeArticulated)
  {
    //For articulated (non-SCARA) robots, we have to check whether the camera
    //is already calibrated. Otherwise, the queried poses might not be very
    //accurate.
    try
    {
      GetCalibData(hv_CalibDataID, "calib_obj_pose", HTuple(0).TupleConcat(HTuple(hv_PosesIdx[0])), 
          "pose", &hv_CamPoseCal);
    }
    // catch (Exception) 
    catch (HException &HDevExpDefaultException)
    {
      HDevExpDefaultException.ToHTuple(&hv_Exception);
      if (0 != (HTuple(hv_NumCameras!=0).TupleAnd(hv_NumCalibObjs!=0)))
      {
        //If the interior camera parameters are not calibrated yet, perform
        //the camera calibration by using a temporary copy of the calibration
        //data model.
        SerializeCalibData(hv_CalibDataID, &hv_SerializedItemHandle);
        DeserializeCalibData(hv_SerializedItemHandle, &hv_TmpCalibDataID);
        ClearSerializedItem(hv_SerializedItemHandle);
        hv_RefCalibDataID = hv_TmpCalibDataID;
        hv_UseTemporaryCopy = 1;
        CalibrateCameras(hv_TmpCalibDataID, &hv_Error);
      }
    }
  }
  //Query all robot tool and calibration object poses.
  {
  HTuple end_val120 = (hv_PosesIdx.TupleLength())-1;
  HTuple step_val120 = 1;
  for (hv_Index=0; hv_Index.Continue(end_val120, step_val120); hv_Index += step_val120)
  {
    try
    {
      //For an articulated robot with a camera and a calibration object,
      //a calibrated poses should always be available.
      GetCalibData(hv_RefCalibDataID, "calib_obj_pose", HTuple(0).TupleConcat(HTuple(hv_PosesIdx[hv_Index])), 
          "pose", &hv_CamPoseCal);
    }
    // catch (Exception) 
    catch (HException &HDevExpDefaultException)
    {
      HDevExpDefaultException.ToHTuple(&hv_Exception);
      //For a SCARA robot or for an articulated robots with a general
      //sensor and no calibration object, directly use the observed poses.
      GetCalibDataObservPose(hv_RefCalibDataID, 0, 0, HTuple(hv_PosesIdx[hv_Index]), 
          &hv_CamPoseCal);
    }
    //Transform the calibration object poses to dual quaternions.
    PoseToDualQuat(hv_CamPoseCal, &hv_CamDualQuatCal);
    hvec_CamDualQuatsCal[hv_Index] = HTupleVector(hv_CamDualQuatCal);
    //Transform the robot tool pose to dual quaternions.
    GetCalibData(hv_RefCalibDataID, "tool", HTuple(hv_PosesIdx[hv_Index]), "tool_in_base_pose", 
        &hv_BasePoseTool);
    PoseToDualQuat(hv_BasePoseTool, &hv_BaseDualQuatTool);
    hvec_BaseDualQuatsTool[hv_Index] = HTupleVector(hv_BaseDualQuatTool);
  }
  }
  hv_NumCalibrationPoses = hv_PosesIdx.TupleLength();
  if (0 != hv_UseTemporaryCopy)
  {
    ClearCalibData(hv_TmpCalibDataID);
  }
  //
  //In the first test, check the poses for consistency. The principle of
  //the hand-eye calibration is that the movement of the robot from time
  //i to time j is represented by the relative pose of the calibration
  //object from i to j in the camera coordinate system and also by the
  //relative pose of the robot tool from i to j in the robot base
  //coordinate system. Because both relative poses represent the same 3D
  //rigid transformation, but only seen from two different coordinate
  //systems, their screw axes differ but their screw angle and their
  //screw translation should be identical. This knowledge can be used to
  //check the consistency of the input poses. Furthermore, remember the
  //screw axes for all robot movements to later check whether the
  //correct calibration model (SCARA or articulated) was selected by the
  //user.
  (*hv_Warnings) = HTuple();
  hv_LX2s = HTuple();
  hv_LY2s = HTuple();
  hv_LZ2s = HTuple();
  hv_TranslationToleranceSquared = hv_TranslationTolerance*hv_TranslationTolerance;
  hv_RotationToleranceSquared = hv_RotationTolerance*hv_RotationTolerance;
  {
  HTuple end_val162 = hv_NumCalibrationPoses-2;
  HTuple step_val162 = 1;
  for (hv_Index1=0; hv_Index1.Continue(end_val162, step_val162); hv_Index1 += step_val162)
  {
    hv_CamDualQuatCal1 = hvec_CamDualQuatsCal[hv_Index1].T();
    DualQuatConjugate(hv_CamDualQuatCal1, &hv_Cal1DualQuatCam);
    hv_BaseDualQuatTool1 = hvec_BaseDualQuatsTool[hv_Index1].T();
    DualQuatConjugate(hv_BaseDualQuatTool1, &hv_Tool1DualQuatBase);
    {
    HTuple end_val167 = hv_NumCalibrationPoses-1;
    HTuple step_val167 = 1;
    for (hv_Index2=hv_Index1+1; hv_Index2.Continue(end_val167, step_val167); hv_Index2 += step_val167)
    {
      //For two robot poses, ...
      //... compute the movement of the calibration object in the
      //camera coordinate system.
      hv_CamDualQuatCal2 = hvec_CamDualQuatsCal[hv_Index2].T();
      DualQuatCompose(hv_Cal1DualQuatCam, hv_CamDualQuatCal2, &hv_DualQuat1);
      //
      //... compute the movement of the tool in the robot base
      //coordinate system.
      hv_BaseDualQuatTool2 = hvec_BaseDualQuatsTool[hv_Index2].T();
      DualQuatCompose(hv_Tool1DualQuatBase, hv_BaseDualQuatTool2, &hv_DualQuat2);
      //
      //Check whether the two movements are consistent. If the two
      //movements are consistent, the scalar parts of the corresponding
      //dual quaternions should be equal. For the equality check, we
      //have to take the accuracy of the input poses into account, which
      //are given by RotationTolerance and TranslationTolerance.
      DualQuatToScrew(hv_DualQuat1, "moment", &hv_LX1, &hv_LY1, &hv_LZ1, &hv_MX1, 
          &hv_MY1, &hv_MZ1, &hv_Rot1, &hv_Trans1);
      DualQuatToScrew(hv_DualQuat2, "moment", &hv_LX2, &hv_LY2, &hv_LZ2, &hv_MX2, 
          &hv_MY2, &hv_MZ2, &hv_Rot2, &hv_Trans2);
      while (0 != (hv_Rot1>(HTuple(180.0).TupleRad())))
      {
        hv_Rot1 = hv_Rot1-(HTuple(360.0).TupleRad());
      }
      while (0 != (hv_Rot2>(HTuple(180.0).TupleRad())))
      {
        hv_Rot2 = hv_Rot2-(HTuple(360.0).TupleRad());
      }
      //
      hv_Rot1 = hv_Rot1.TupleFabs();
      hv_Trans1 = hv_Trans1.TupleFabs();
      hv_Rot2 = hv_Rot2.TupleFabs();
      hv_Trans2 = hv_Trans2.TupleFabs();
      hv_MeanRot = 0.5*(hv_Rot1+hv_Rot2);
      hv_MeanTrans = 0.5*(hv_Trans1+hv_Trans2);
      hv_SinTheta2 = (0.5*hv_MeanRot).TupleSin();
      hv_CosTheta2 = (0.5*hv_MeanRot).TupleCos();
      hv_SinTheta2Squared = hv_SinTheta2*hv_SinTheta2;
      hv_CosTheta2Squared = hv_CosTheta2*hv_CosTheta2;
      //
      //1. Check the scalar part of the real part of the dual quaternion,
      //which encodes the rotation component of the screw:
      //  q[0] = cos(theta/2)
      //Here, theta is the screw rotation angle.
      hv_ErrorRot = (hv_Rot1-hv_Rot2).TupleFabs();
      while (0 != (hv_ErrorRot>(HTuple(180.0).TupleRad())))
      {
        hv_ErrorRot = hv_ErrorRot-(HTuple(360.0).TupleRad());
      }
      hv_ErrorRot = hv_ErrorRot.TupleFabs();
      //Compute the standard deviation of the scalar part of the real part
      //by applying the law of error propagation.
      hv_StdDevQ0 = (0.5*hv_SinTheta2)*hv_RotationTolerance;
      //Multiply the standard deviation by a factor to increase the certainty.
      hv_ToleranceDualQuat0 = hv_StdDevFactor*hv_StdDevQ0;
      hv_ErrorDualQuat0 = ((HTuple(hv_DualQuat2[0]).TupleFabs())-(HTuple(hv_DualQuat1[0]).TupleFabs())).TupleFabs();
      //
      //2. Check the scalar part of the dual part of the dual quaternion,
      //which encodes translation and rotation components of the screw:
      //  q[4] = -d/2*sin(theta/2)
      //Here, d is the screw translation.
      //
      //Compute the standard deviation of the scalar part of the dual part
      //by applying the law of error propagation.
      hv_StdDevQ4 = (((0.25*hv_SinTheta2Squared)*hv_TranslationToleranceSquared)+((((0.0625*hv_MeanTrans)*hv_MeanTrans)*hv_CosTheta2Squared)*hv_RotationToleranceSquared)).TupleSqrt();
      //Multiply the standard deviation by a factor to increase the certainty.
      hv_ToleranceDualQuat4 = hv_StdDevFactor*hv_StdDevQ4;
      hv_ErrorDualQuat4 = ((HTuple(hv_DualQuat2[4]).TupleFabs())-(HTuple(hv_DualQuat1[4]).TupleFabs())).TupleFabs();
      //If one of the two errors exceeds the computed thresholds, return
      //a warning for the current pose pair.
      if (0 != (HTuple(hv_ErrorDualQuat0>hv_ToleranceDualQuat0).TupleOr(hv_ErrorDualQuat4>hv_ToleranceDualQuat4)))
      {
        hv_Message = ((("Inconsistent pose pair ("+(HTuple(hv_PosesIdx[hv_Index1]).TupleString("2d")))+HTuple(","))+(HTuple(hv_PosesIdx[hv_Index2]).TupleString("2d")))+")";
        (*hv_Warnings) = (*hv_Warnings).TupleConcat(hv_Message);
      }
      //
      //Remember the screw axes (of the robot tool movements) for screws
      //with a significant rotation part. For movements without rotation
      //the direction of the screw axis is determined by the translation
      //part only. Hence, the direction of the screw axis cannot be used
      //to decide whether an articulated or a SCARA robot is used.
      if (0 != (hv_Rot2>(hv_StdDevFactor*hv_RotationTolerance)))
      {
        hv_LX2s = hv_LX2s.TupleConcat(hv_LX2);
        hv_LY2s = hv_LY2s.TupleConcat(hv_LY2);
        hv_LZ2s = hv_LZ2s.TupleConcat(hv_LZ2);
      }
    }
    }
  }
  }
  //
  //In the second test, we check whether enough calibration poses with a
  //significant rotation part are available for calibration.
  hv_NumPairs = hv_LX2s.TupleLength();
  hv_NumPairsMax = (hv_NumCalibrationPoses*(hv_NumCalibrationPoses-1))/2;
  if (0 != (hv_NumPairs<2))
  {
    hv_Message = "There are not enough rotated calibration poses available.";
    (*hv_Warnings) = (*hv_Warnings).TupleConcat(hv_Message);
    //In this case, we can skip further test.
    return;
  }
  hv_LargeRotationFraction = (hv_NumPairs.TupleReal())/hv_NumPairsMax;
  if (0 != (HTuple(hv_NumPairs<4).TupleOr(hv_LargeRotationFraction<hv_MinLargeRotationFraction)))
  {
    hv_Message = HTuple("Only few rotated robot poses available, which might result in a reduced accuracy of the calibration results.");
    (*hv_Warnings) = (*hv_Warnings).TupleConcat(hv_Message);
  }
  //
  //In the third test, we compute the angle between the screw axes with
  //a significant rotation part. For SCARA robots, this angle must be 0 in
  //all cases. For articulated robots, for a significant fraction of robot
  //poses, this angle should exceed a certain threshold. For this test, we
  //use the robot tool poses as they are assumed to be more accurate than the
  //calibration object poses.
  hv_NumPairPairs = (hv_NumPairs*(hv_NumPairs-1))/2;
  hv_NumPairPairsMax = (hv_NumPairsMax*(hv_NumPairsMax-1))/2;
  hv_Angles = HTuple(hv_NumPairPairs,0);
  hv_Idx = 0;
  {
  HTuple end_val277 = hv_NumPairs-2;
  HTuple step_val277 = 1;
  for (hv_Index1=0; hv_Index1.Continue(end_val277, step_val277); hv_Index1 += step_val277)
  {
    hv_LXA = HTuple(hv_LX2s[hv_Index1]);
    hv_LYA = HTuple(hv_LY2s[hv_Index1]);
    hv_LZA = HTuple(hv_LZ2s[hv_Index1]);
    {
    HTuple end_val281 = hv_NumPairs-1;
    HTuple step_val281 = 1;
    for (hv_Index2=hv_Index1+1; hv_Index2.Continue(end_val281, step_val281); hv_Index2 += step_val281)
    {
      hv_LXB = HTuple(hv_LX2s[hv_Index2]);
      hv_LYB = HTuple(hv_LY2s[hv_Index2]);
      hv_LZB = HTuple(hv_LZ2s[hv_Index2]);
      //Compute the scalar product, i.e. the cosine of the screw
      //axes. To obtain valid values, crop the cosine to the
      //interval [-1,1].
      hv_ScalarProduct = ((((((hv_LXA*hv_LXB)+(hv_LYA*hv_LYB))+(hv_LZA*hv_LZB)).TupleConcat(1)).TupleMin()).TupleConcat(-1)).TupleMax();
      //Compute the angle between the axes in the range [0,pi/2].
      hv_Angles[hv_Idx] = (hv_ScalarProduct.TupleFabs()).TupleAcos();
      hv_Idx += 1;
    }
    }
  }
  }
  //Large angles should significantly exceed the RotationTolerance.
  hv_LargeAngles = (hv_Angles.TupleGreaterElem(hv_StdDevFactor*hv_RotationTolerance)).TupleSum();
  //Calculate the fraction of pairs of movements, i.e., pairs of pose
  //pairs, that have a large angle between their corresponding screw
  //axes.
  hv_LargeAnglesFraction = (hv_LargeAngles.TupleReal())/hv_NumPairPairsMax;
  //For SCARA robots, all screw axes should be parallel, i.e., no
  //two screw axes should have a large angle.
  if (0 != (hv_IsHandEyeScara.TupleAnd(hv_LargeAngles>0)))
  {
    hv_Message = HTuple("The robot poses indicate that this might be an articulated robot, although a SCARA robot was selected in the calibration data model.");
    (*hv_Warnings) = (*hv_Warnings).TupleConcat(hv_Message);
  }
  //For articulated robots, the screw axes should have a large
  //angles.
  if (0 != hv_IsHandEyeArticulated)
  {
    if (0 != (hv_LargeAngles==0))
    {
      //If there is no pair of movements with a large angle between
      //their corresponding screw axes, this might be a SCARA robot.
      hv_Message = HTuple("The robot poses indicate that this might be a SCARA robot (no tilted robot poses available), although an articulated robot was selected in the calibration data model.");
      (*hv_Warnings) = (*hv_Warnings).TupleConcat(hv_Message);
    }
    else if (0 != (hv_LargeAngles<3))
    {
      //If there are at most 2 movements with a large angle between
      //their corresponding screw axes, the calibration might be
      //unstable.
      hv_Message = "Not enough tilted robot poses available for an accurate calibration of an articulated robot.";
      (*hv_Warnings) = (*hv_Warnings).TupleConcat(hv_Message);
    }
    else if (0 != (hv_LargeAnglesFraction<hv_MinLargeAnglesFraction))
    {
      //If there is only a low fraction of pairs of movements with
      //a large angle between their corresponding screw axes, the
      //accuracy of the calibration might be low.
      hv_Message = HTuple("Only few tilted robot poses available, which might result in a reduced accuracy of the calibration results.");
      (*hv_Warnings) = (*hv_Warnings).TupleConcat(hv_Message);
    }
  }
  return;
}

// Chapter: Identification / Data Code
// Short Description: Display print quality information for individual data code modules. 
void dev_display_data_code_2d_print_quality_results (HTuple hv_DataCodeHandle, HTuple hv_ResultHandle, 
    HTuple hv_Mode, HTuple hv_QualityStandard, HTuple hv_Color, HTuple hv_GenParamName, 
    HTuple hv_GenParamValue)
{

  // Local iconic variables
  HObject  ho_Circle, ho_Cross;

  // Local control variables
  HTuple  hv_MODE_RMMG, hv_MODE_GRID, hv_MODE_BAD;
  HTuple  hv_SupportedModes, hv_SupportedQualityStandards;
  HTuple  hv_GEN_CENTER, hv_GEN_CIRCLE, hv_GEN_LEGEND, hv_GEN_MAX_GRADE;
  HTuple  hv_DisplayCenter, hv_DisplayCircle, hv_DisplayLegend;
  HTuple  hv_MaxGrade, hv_I, hv_QualityParameter, hv_QualityRows;
  HTuple  hv_QualityCols, hv_ModuleGrades, hv_Rows, hv_Cols;
  HTuple  hv_QualityLabels, hv_Grades, hv_Labels, hv_ModuleHeight;
  HTuple  hv_ModuleWidth, hv_Aperture, hv_Radius, hv_Grade;
  HTuple  hv_GradeIdx, hv_GradeRows, hv_GradeCols, hv_GradeRadius;

  //This procedure displays the print quality results for data matrix ECC 200 codes.
  //
  //
  //Available modes
  hv_MODE_RMMG = "reflectance_margin_module_grades";
  hv_MODE_GRID = "grid";
  hv_MODE_BAD = "bad_modules";
  hv_SupportedModes.Clear();
  hv_SupportedModes.Append(hv_MODE_RMMG);
  hv_SupportedModes.Append(hv_MODE_GRID);
  hv_SupportedModes.Append(hv_MODE_BAD);
  //Available standards
  hv_SupportedQualityStandards.Clear();
  hv_SupportedQualityStandards[0] = "isoiec15415";
  hv_SupportedQualityStandards[1] = "isoiec_tr_29158";
  hv_SupportedQualityStandards[2] = "aimdpm_1_2006";
  //Available generic parameters
  hv_GEN_CENTER = "center";
  hv_GEN_CIRCLE = "circle";
  hv_GEN_LEGEND = "legend";
  hv_GEN_MAX_GRADE = "max_grade";
  //Defaults
  hv_DisplayCenter = 0;
  hv_DisplayCircle = 1;
  hv_DisplayLegend = 1;
  hv_MaxGrade = 3;
  //
  //Check modes
  if (0 != ((hv_Mode.TupleLength())!=1))
  {
    throw HException("Please specify exactly one of following modes:"+((" "+hv_SupportedModes).TupleSum()));
  }
  if (0 != ((hv_SupportedModes.TupleFind(hv_Mode))==-1))
  {
    throw HException("Unknown Mode: "+hv_Mode);
  }
  //
  //Check QualityStandard
  if (0 != ((hv_SupportedQualityStandards.TupleFind(hv_QualityStandard))==-1))
  {
    throw HException("Unknown QualityStandard: "+hv_QualityStandard);
  }
  else
  {
    hv_QualityStandard = "quality_"+hv_QualityStandard;
  }
  //
  //Check generic parameters
  //
  //Override defaults in special modes
  if (0 != (hv_Mode==hv_MODE_GRID))
  {
    hv_DisplayCenter = 1;
    hv_DisplayCircle = 0;
    hv_DisplayLegend = 0;
    hv_MaxGrade = 4;
    if (0 != ((hv_Color.TupleLength())==0))
    {
      hv_Color = "gray";
    }
  }
  else if (0 != (hv_Mode==hv_MODE_BAD))
  {
    hv_DisplayCenter = 0;
    hv_DisplayCircle = 1;
    hv_DisplayLegend = 0;
    hv_MaxGrade = 0;
  }
  //
  if (0 != ((hv_GenParamName.TupleLength())!=(hv_GenParamValue.TupleLength())))
  {
    //Check if number of values matches number of parameters
    throw HException("GenParamName and GenParamValue do not match.");
  }
  else
  {
    //Set generic parameters
    {
    HTuple end_val59 = (hv_GenParamName.TupleLength())-1;
    HTuple step_val59 = 1;
    for (hv_I=0; hv_I.Continue(end_val59, step_val59); hv_I += step_val59)
    {
      //'center'
      if (0 != (HTuple(hv_GenParamName[hv_I])==hv_GEN_CENTER))
      {
        //Check if values are valid
        if (0 != (HTuple(HTuple(hv_GenParamValue[hv_I])!=HTuple("true")).TupleAnd(HTuple(hv_GenParamValue[hv_I])!=HTuple("false"))))
        {
          throw HException(("Wrong parameter value for generic parameter 'center': "+HTuple(hv_GenParamValue[hv_I]))+" Please use 'true' or 'false'.");
        }
        //Set new value
        hv_DisplayCenter = HTuple(hv_GenParamValue[hv_I])==HTuple("true");
        //'circle'
      }
      else if (0 != (HTuple(hv_GenParamName[hv_I])==hv_GEN_CIRCLE))
      {
        //Check if values are valid
        if (0 != (HTuple(HTuple(hv_GenParamValue[hv_I])!=HTuple("true")).TupleAnd(HTuple(hv_GenParamValue[hv_I])!=HTuple("false"))))
        {
          throw HException(("Wrong parameter value for generic parameter 'circle': "+HTuple(hv_GenParamValue[hv_I]))+" Please use 'true' or 'false'.");
        }
        //Set new value
        hv_DisplayCircle = HTuple(hv_GenParamValue[hv_I])==HTuple("true");
      }
      else if (0 != (HTuple(hv_GenParamName[hv_I])==hv_GEN_LEGEND))
      {
        //Check if values are valid
        if (0 != (HTuple(HTuple(hv_GenParamValue[hv_I])!=HTuple("true")).TupleAnd(HTuple(hv_GenParamValue[hv_I])!=HTuple("false"))))
        {
          throw HException(("Wrong parameter value for generic parameter 'legend': "+HTuple(hv_GenParamValue[hv_I]))+" Please use 'true' or 'false'.");
        }
        //Set new value
        hv_DisplayLegend = HTuple(hv_GenParamValue[hv_I])==HTuple("true");
      }
      else if (0 != (HTuple(hv_GenParamName[hv_I])==hv_GEN_MAX_GRADE))
      {
        //Check if values are valid
        if (0 != (HTuple(HTuple(hv_GenParamValue[hv_I])<0).TupleOr(HTuple(hv_GenParamValue[hv_I])>4)))
        {
          throw HException(("Wrong parameter value for generic parameter 'max_grade': "+HTuple(hv_GenParamValue[hv_I]))+" Please use a value between 0 and 4.");
        }
        //Set new value
        hv_MaxGrade = HTuple(hv_GenParamValue[hv_I]).TupleInt();
      }
      else
      {
        //Unknown parameter
        throw HException("Unknown generic parameter: '"+HTuple(hv_GenParamName[hv_I]));
      }
    }
    }
  }
  //
  //Check Color
  if (0 != ((hv_Color.TupleLength())==0))
  {
    hv_Color.Clear();
    hv_Color[0] = "red";
    hv_Color[1] = "orange";
    hv_Color[2] = "yellow";
    hv_Color[3] = "cyan";
    hv_Color[4] = "green";
  }
  //Build color tuple with rotating colors if too few colors are specified
  while (0 != ((hv_Color.TupleLength())<(hv_MaxGrade+1)))
  {
    hv_Color = hv_Color.TupleConcat(hv_Color);
  }
  //
  //Visualization
  //
  //Get modulation grades, rows and cols for all symbol modules incl.
  //the 4 quiet zones adjacent to the symbol and the finder patterns.
  hv_QualityParameter = hv_QualityStandard+"_reflectance_margin_module_grades";
  hv_QualityRows = hv_QualityStandard+"_rows";
  hv_QualityCols = hv_QualityStandard+"_cols";
  GetDataCode2dResults(hv_DataCodeHandle, hv_ResultHandle, hv_QualityParameter, &hv_ModuleGrades);
  GetDataCode2dResults(hv_DataCodeHandle, hv_ResultHandle, hv_QualityRows, &hv_Rows);
  GetDataCode2dResults(hv_DataCodeHandle, hv_ResultHandle, hv_QualityCols, &hv_Cols);
  hv_QualityLabels = hv_QualityStandard+"_labels";
  GetDataCode2dResults(hv_DataCodeHandle, hv_ResultHandle, hv_QualityStandard, &hv_Grades);
  GetDataCode2dResults(hv_DataCodeHandle, hv_ResultHandle, hv_QualityLabels, &hv_Labels);
  GetDataCode2dResults(hv_DataCodeHandle, hv_ResultHandle, "module_height", &hv_ModuleHeight);
  GetDataCode2dResults(hv_DataCodeHandle, hv_ResultHandle, "module_width", &hv_ModuleWidth);
  hv_Aperture = HTuple(hv_Grades[hv_Labels.TupleFind("Aperture")]);
  hv_Radius = (0.5*hv_Aperture)*(hv_ModuleHeight.TupleMin2(hv_ModuleWidth));
  //
  //Iterate over all possible modulation grades to visualize
  {
  HTuple end_val125 = hv_MaxGrade;
  HTuple step_val125 = 1;
  for (hv_Grade=0; hv_Grade.Continue(end_val125, step_val125); hv_Grade += step_val125)
  {
    hv_GradeIdx = hv_ModuleGrades.TupleFind(hv_Grade);
    if (0 != (hv_GradeIdx<0))
    {
      continue;
    }
    hv_GradeRows = HTuple(hv_Rows[hv_GradeIdx]);
    hv_GradeCols = HTuple(hv_Cols[hv_GradeIdx]);
    hv_GradeRadius = HTuple(hv_GradeRows.TupleLength(),hv_Radius);
    if (HDevWindowStack::IsOpen())
      SetColor(HDevWindowStack::GetActive(),HTuple(hv_Color[hv_Grade]));
    if (0 != hv_DisplayCircle)
    {
      GenCircleContourXld(&ho_Circle, hv_GradeRows, hv_GradeCols, hv_GradeRadius, 
          HTuple(0).TupleRad(), HTuple(360).TupleRad(), "positive", 1);
      if (HDevWindowStack::IsOpen())
        DispObj(ho_Circle, HDevWindowStack::GetActive());
    }
    if (0 != hv_DisplayCenter)
    {
      GenCrossContourXld(&ho_Cross, hv_GradeRows, hv_GradeCols, 2*hv_Radius, HTuple(0).TupleRad());
      if (HDevWindowStack::IsOpen())
        DispObj(ho_Cross, HDevWindowStack::GetActive());
    }
  }
  }
  if (0 != hv_DisplayLegend)
  {
    //Display legend with modulation grades
    if (HDevWindowStack::IsOpen())
      DispText(HDevWindowStack::GetActive(),HTuple("Reflectance Margin").TupleConcat("Module Grade "+HTuple::TupleGenSequence(0,hv_MaxGrade,1)), 
          "window", "bottom", "left", HTuple("white").TupleConcat(hv_Color), "box_color", 
          "#00000080");
  }
  return;
}

// Chapter: Develop
// Short Description: Open a new graphics window that preserves the aspect ratio of the given image. 
void dev_open_window_fit_image (HObject ho_Image, HTuple hv_Row, HTuple hv_Column, 
    HTuple hv_WidthLimit, HTuple hv_HeightLimit, HTuple *hv_WindowHandle)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_MinWidth, hv_MaxWidth, hv_MinHeight;
  HTuple  hv_MaxHeight, hv_ResizeFactor, hv_ImageWidth, hv_ImageHeight;
  HTuple  hv_TempWidth, hv_TempHeight, hv_WindowWidth, hv_WindowHeight;

  //This procedure opens a new graphics window and adjusts the size
  //such that it fits into the limits specified by WidthLimit
  //and HeightLimit, but also maintains the correct image aspect ratio.
  //
  //If it is impossible to match the minimum and maximum extent requirements
  //at the same time (f.e. if the image is very long but narrow),
  //the maximum value gets a higher priority,
  //
  //Parse input tuple WidthLimit
  if (0 != (HTuple((hv_WidthLimit.TupleLength())==0).TupleOr(hv_WidthLimit<0)))
  {
    hv_MinWidth = 500;
    hv_MaxWidth = 800;
  }
  else if (0 != ((hv_WidthLimit.TupleLength())==1))
  {
    hv_MinWidth = 0;
    hv_MaxWidth = hv_WidthLimit;
  }
  else
  {
    hv_MinWidth = ((const HTuple&)hv_WidthLimit)[0];
    hv_MaxWidth = ((const HTuple&)hv_WidthLimit)[1];
  }
  //Parse input tuple HeightLimit
  if (0 != (HTuple((hv_HeightLimit.TupleLength())==0).TupleOr(hv_HeightLimit<0)))
  {
    hv_MinHeight = 400;
    hv_MaxHeight = 600;
  }
  else if (0 != ((hv_HeightLimit.TupleLength())==1))
  {
    hv_MinHeight = 0;
    hv_MaxHeight = hv_HeightLimit;
  }
  else
  {
    hv_MinHeight = ((const HTuple&)hv_HeightLimit)[0];
    hv_MaxHeight = ((const HTuple&)hv_HeightLimit)[1];
  }
  //
  //Test, if window size has to be changed.
  hv_ResizeFactor = 1;
  GetImageSize(ho_Image, &hv_ImageWidth, &hv_ImageHeight);
  //First, expand window to the minimum extents (if necessary).
  if (0 != (HTuple(hv_MinWidth>hv_ImageWidth).TupleOr(hv_MinHeight>hv_ImageHeight)))
  {
    hv_ResizeFactor = (((hv_MinWidth.TupleReal())/hv_ImageWidth).TupleConcat((hv_MinHeight.TupleReal())/hv_ImageHeight)).TupleMax();
  }
  hv_TempWidth = hv_ImageWidth*hv_ResizeFactor;
  hv_TempHeight = hv_ImageHeight*hv_ResizeFactor;
  //Then, shrink window to maximum extents (if necessary).
  if (0 != (HTuple(hv_MaxWidth<hv_TempWidth).TupleOr(hv_MaxHeight<hv_TempHeight)))
  {
    hv_ResizeFactor = hv_ResizeFactor*((((hv_MaxWidth.TupleReal())/hv_TempWidth).TupleConcat((hv_MaxHeight.TupleReal())/hv_TempHeight)).TupleMin());
  }
  hv_WindowWidth = hv_ImageWidth*hv_ResizeFactor;
  hv_WindowHeight = hv_ImageHeight*hv_ResizeFactor;
  //Resize window
  SetWindowAttr("background_color","black");
  OpenWindow(hv_Row,hv_Column,hv_WindowWidth,hv_WindowHeight,0,"visible","",&(*hv_WindowHandle));
  HDevWindowStack::Push((*hv_WindowHandle));
  if (HDevWindowStack::IsOpen())
    SetPart(HDevWindowStack::GetActive(),0, 0, hv_ImageHeight-1, hv_ImageWidth-1);
  return;
}

// Chapter: Develop
// Short Description: Open a new graphics window that preserves the aspect ratio of the given image size. 
void dev_open_window_fit_size (HTuple hv_Row, HTuple hv_Column, HTuple hv_Width, 
    HTuple hv_Height, HTuple hv_WidthLimit, HTuple hv_HeightLimit, HTuple *hv_WindowHandle)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_MinWidth, hv_MaxWidth, hv_MinHeight;
  HTuple  hv_MaxHeight, hv_ResizeFactor, hv_TempWidth, hv_TempHeight;
  HTuple  hv_WindowWidth, hv_WindowHeight;

  //This procedure open a new graphic window
  //such that it fits into the limits specified by WidthLimit
  //and HeightLimit, but also maintains the correct aspect ratio
  //given by Width and Height.
  //
  //If it is impossible to match the minimum and maximum extent requirements
  //at the same time (f.e. if the image is very long but narrow),
  //the maximum value gets a higher priority.
  //
  //Parse input tuple WidthLimit
  if (0 != (HTuple((hv_WidthLimit.TupleLength())==0).TupleOr(hv_WidthLimit<0)))
  {
    hv_MinWidth = 500;
    hv_MaxWidth = 800;
  }
  else if (0 != ((hv_WidthLimit.TupleLength())==1))
  {
    hv_MinWidth = 0;
    hv_MaxWidth = hv_WidthLimit;
  }
  else
  {
    hv_MinWidth = ((const HTuple&)hv_WidthLimit)[0];
    hv_MaxWidth = ((const HTuple&)hv_WidthLimit)[1];
  }
  //Parse input tuple HeightLimit
  if (0 != (HTuple((hv_HeightLimit.TupleLength())==0).TupleOr(hv_HeightLimit<0)))
  {
    hv_MinHeight = 400;
    hv_MaxHeight = 600;
  }
  else if (0 != ((hv_HeightLimit.TupleLength())==1))
  {
    hv_MinHeight = 0;
    hv_MaxHeight = hv_HeightLimit;
  }
  else
  {
    hv_MinHeight = ((const HTuple&)hv_HeightLimit)[0];
    hv_MaxHeight = ((const HTuple&)hv_HeightLimit)[1];
  }
  //
  //Test, if window size has to be changed.
  hv_ResizeFactor = 1;
  //First, expand window to the minimum extents (if necessary).
  if (0 != (HTuple(hv_MinWidth>hv_Width).TupleOr(hv_MinHeight>hv_Height)))
  {
    hv_ResizeFactor = (((hv_MinWidth.TupleReal())/hv_Width).TupleConcat((hv_MinHeight.TupleReal())/hv_Height)).TupleMax();
  }
  hv_TempWidth = hv_Width*hv_ResizeFactor;
  hv_TempHeight = hv_Height*hv_ResizeFactor;
  //Then, shrink window to maximum extents (if necessary).
  if (0 != (HTuple(hv_MaxWidth<hv_TempWidth).TupleOr(hv_MaxHeight<hv_TempHeight)))
  {
    hv_ResizeFactor = hv_ResizeFactor*((((hv_MaxWidth.TupleReal())/hv_TempWidth).TupleConcat((hv_MaxHeight.TupleReal())/hv_TempHeight)).TupleMin());
  }
  hv_WindowWidth = hv_Width*hv_ResizeFactor;
  hv_WindowHeight = hv_Height*hv_ResizeFactor;
  //Resize window
  SetWindowAttr("background_color","black");
  OpenWindow(hv_Row,hv_Column,hv_WindowWidth,hv_WindowHeight,0,"visible","",&(*hv_WindowHandle));
  HDevWindowStack::Push((*hv_WindowHandle));
  if (HDevWindowStack::IsOpen())
    SetPart(HDevWindowStack::GetActive(),0, 0, hv_Height-1, hv_Width-1);
  return;
}

// Chapter: Graphics / Text
// Short Description: This procedure writes a text message. 
void disp_message (HTuple hv_WindowHandle, HTuple hv_String, HTuple hv_CoordSystem, 
    HTuple hv_Row, HTuple hv_Column, HTuple hv_Color, HTuple hv_Box)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_GenParamName, hv_GenParamValue;

  //This procedure displays text in a graphics window.
  //
  //Input parameters:
  //WindowHandle: The WindowHandle of the graphics window, where
  //   the message should be displayed
  //String: A tuple of strings containing the text message to be displayed
  //CoordSystem: If set to 'window', the text position is given
  //   with respect to the window coordinate system.
  //   If set to 'image', image coordinates are used.
  //   (This may be useful in zoomed images.)
  //Row: The row coordinate of the desired text position
  //   A tuple of values is allowed to display text at different
  //   positions.
  //Column: The column coordinate of the desired text position
  //   A tuple of values is allowed to display text at different
  //   positions.
  //Color: defines the color of the text as string.
  //   If set to [], '' or 'auto' the currently set color is used.
  //   If a tuple of strings is passed, the colors are used cyclically...
  //   - if |Row| == |Column| == 1: for each new textline
  //   = else for each text position.
  //Box: If Box[0] is set to 'true', the text is written within an orange box.
  //     If set to' false', no box is displayed.
  //     If set to a color string (e.g. 'white', '#FF00CC', etc.),
  //       the text is written in a box of that color.
  //     An optional second value for Box (Box[1]) controls if a shadow is displayed:
  //       'true' -> display a shadow in a default color
  //       'false' -> display no shadow
  //       otherwise -> use given string as color string for the shadow color
  //
  //It is possible to display multiple text strings in a single call.
  //In this case, some restrictions apply:
  //- Multiple text positions can be defined by specifying a tuple
  //  with multiple Row and/or Column coordinates, i.e.:
  //  - |Row| == n, |Column| == n
  //  - |Row| == n, |Column| == 1
  //  - |Row| == 1, |Column| == n
  //- If |Row| == |Column| == 1,
  //  each element of String is display in a new textline.
  //- If multiple positions or specified, the number of Strings
  //  must match the number of positions, i.e.:
  //  - Either |String| == n (each string is displayed at the
  //                          corresponding position),
  //  - or     |String| == 1 (The string is displayed n times).
  //
  //
  //Convert the parameters for disp_text.
  if (0 != (HTuple(hv_Row==HTuple()).TupleOr(hv_Column==HTuple())))
  {
    return;
  }
  if (0 != (hv_Row==-1))
  {
    hv_Row = 12;
  }
  if (0 != (hv_Column==-1))
  {
    hv_Column = 12;
  }
  //
  //Convert the parameter Box to generic parameters.
  hv_GenParamName = HTuple();
  hv_GenParamValue = HTuple();
  if (0 != ((hv_Box.TupleLength())>0))
  {
    if (0 != (HTuple(hv_Box[0])==HTuple("false")))
    {
      //Display no box
      hv_GenParamName = hv_GenParamName.TupleConcat("box");
      hv_GenParamValue = hv_GenParamValue.TupleConcat("false");
    }
    else if (0 != (HTuple(hv_Box[0])!=HTuple("true")))
    {
      //Set a color other than the default.
      hv_GenParamName = hv_GenParamName.TupleConcat("box_color");
      hv_GenParamValue = hv_GenParamValue.TupleConcat(HTuple(hv_Box[0]));
    }
  }
  if (0 != ((hv_Box.TupleLength())>1))
  {
    if (0 != (HTuple(hv_Box[1])==HTuple("false")))
    {
      //Display no shadow.
      hv_GenParamName = hv_GenParamName.TupleConcat("shadow");
      hv_GenParamValue = hv_GenParamValue.TupleConcat("false");
    }
    else if (0 != (HTuple(hv_Box[1])!=HTuple("true")))
    {
      //Set a shadow color other than the default.
      hv_GenParamName = hv_GenParamName.TupleConcat("shadow_color");
      hv_GenParamValue = hv_GenParamValue.TupleConcat(HTuple(hv_Box[1]));
    }
  }
  //Restore default CoordSystem behavior.
  if (0 != (hv_CoordSystem!=HTuple("window")))
  {
    hv_CoordSystem = "image";
  }
  //
  if (0 != (hv_Color==HTuple("")))
  {
    //disp_text does not accept an empty string for Color.
    hv_Color = HTuple();
  }
  //
  DispText(hv_WindowHandle, hv_String, hv_CoordSystem, hv_Row, hv_Column, hv_Color, 
      hv_GenParamName, hv_GenParamValue);
  return;
}

// Chapter: Graphics / Output
// Short Description:  This procedure plots tuples representing functions or curves in a coordinate system. 
void plot_tuple (HTuple hv_WindowHandle, HTuple hv_XValues, HTuple hv_YValues, HTuple hv_XLabel, 
    HTuple hv_YLabel, HTuple hv_Color, HTuple hv_GenParamNames, HTuple hv_GenParamValues)
{

  // Local iconic variables
  HObject  ho_ContourXGrid, ho_ContourYGrid, ho_XArrow;
  HObject  ho_YArrow, ho_ContourXTick, ho_ContourYTick, ho_Contour;
  HObject  ho_Cross, ho_Filled;

  // Local control variables
  HTuple  hv_PreviousWindowHandle, hv_ClipRegion;
  HTuple  hv_Row, hv_Column, hv_Width, hv_Height, hv_PartRow1;
  HTuple  hv_PartColumn1, hv_PartRow2, hv_PartColumn2, hv_Red;
  HTuple  hv_Green, hv_Blue, hv_DrawMode, hv_OriginStyle;
  HTuple  hv_XAxisEndValue, hv_YAxisEndValue, hv_XAxisStartValue;
  HTuple  hv_YAxisStartValue, hv_XValuesAreStrings, hv_XTickValues;
  HTuple  hv_XTicks, hv_OriginX, hv_OriginY, hv_LeftBorder;
  HTuple  hv_RightBorder, hv_UpperBorder, hv_LowerBorder;
  HTuple  hv_AxesColor, hv_Style, hv_Clip, hv_YTicks, hv_XGrid;
  HTuple  hv_YGrid, hv_GridColor, hv_NumGenParamNames, hv_NumGenParamValues;
  HTuple  hv_SetOriginXToDefault, hv_SetOriginYToDefault;
  HTuple  hv_GenParamIndex, hv_XGridTicks, hv_XAxisWidthPx;
  HTuple  hv_XAxisWidth, hv_XScaleFactor, hv_YAxisHeightPx;
  HTuple  hv_YAxisHeight, hv_YScaleFactor, hv_YAxisOffsetPx;
  HTuple  hv_XAxisOffsetPx, hv_DotStyle, hv_XGridValues, hv_XGridStart;
  HTuple  hv_XPosition, hv_IndexGrid, hv_YGridValues, hv_YGridStart;
  HTuple  hv_YPosition, hv_Ascent, hv_Descent, hv_TextWidthXLabel;
  HTuple  hv_TextHeightXLabel, hv_XTickStart, hv_TypeTicks;
  HTuple  hv_IndexTicks, hv_YTickValues, hv_YTickStart, hv_Ascent1;
  HTuple  hv_Descent1, hv_TextWidthYTicks, hv_TextHeightYTicks;
  HTuple  hv_Num, hv_I, hv_YSelected, hv_Y1Selected, hv_X1Selected;

  //This procedure plots tuples representing functions
  //or curves in a coordinate system.
  //
  //Input parameters:
  //
  //XValues: X values of the function to be plotted
  //         If XValues is set to [], it is interally set to 0,1,2,...,|YValues|-1.
  //         If XValues is a tuple of strings, the values are taken as categories.
  //
  //YValues: Y values of the function(s) to be plotted
  //         If YValues is set to [], it is interally set to 0,1,2,...,|XValues|-1.
  //         The number of y values must be equal to the number of x values
  //         or an integral multiple. In the latter case,
  //         multiple functions are plotted, that share the same x values.
  //
  //XLabel: X axis label
  //
  //XLabel: Y axis label
  //
  //Color: Color of the plotted function
  //       If [] is given, the currently set display color is used.
  //       If 'none is given, the function is not plotted, but only
  //       the coordinate axes as specified.
  //       If more than one color is given, multiple functions
  //       can be displayed in different colors.
  //
  //GenParamNames: Generic parameters to control the presentation
  //               Possible Values:
  //   'axes_color': coordinate system color
  //                 Default: 'white'
  //                 If 'none' is given, no coordinate system is shown.
  //   'style': Graph style
  //            Possible values: 'line' (default), 'cross', 'filled'
  //   'clip': Clip graph to coordinate system area
  //           Possibile values: 'yes', 'no' (default)
  //   'ticks': Control display of ticks on the axes
  //            If 'min_max_origin' is given (default), ticks are shown
  //            at the minimum and maximum values of the axes and at the
  //            intercept point of x- and y-axis.
  //            If 'none' is given, no ticks are shown.
  //            If any number != 0 is given, it is interpreted as distance
  //            between the ticks.
  //   'ticks_x': Control display of ticks on x-axis only
  //   'ticks_y': Control display of ticks on y-axis only
  //   'grid': Control display of grid lines within the coordinate system
  //           If 'min_max_origin' is given (default), grid lines are shown
  //           at the minimum and maximum values of the axes.
  //           If 'none' is given, no grid lines are shown.
  //           If any number != 0 is given, it is interpreted as distance
  //           between the grid lines.
  //   'grid_x': Control display of grid lines for the x-axis only
  //   'grid_y': Control display of grid lines for the y-axis only
  //   'grid_color': Color of the grid (default: 'dim gray')
  //   'margin': The distance in pixels of the coordinate system area
  //             to all four window borders.
  //   'margin_left': The distance in pixels of the coordinate system area
  //                  to the left window border.
  //   'margin_right': The distance in pixels of the coordinate system area
  //                   to the right window border.
  //   'margin_top': The distance in pixels of the coordinate system area
  //                 to the upper window border.
  //   'margin_bottom': The distance in pixels of the coordinate system area
  //                    to the lower window border.
  //   'start_x': Lowest x value of the x axis
  //              Default: min(XValues)
  //   'end_x': Highest x value of the x axis
  //            Default: max(XValues)
  //   'start_y': Lowest y value of the x axis
  //              Default: min(YValues)
  //   'end_y': Highest y value of the x axis
  //            Default: max(YValues)
  //   'origin_x': X coordinate of the intercept point of x- and y-axis.
  //               Default: same as start_x
  //   'origin_y': Y coordinate of the intercept point of x- and y-axis.
  //               Default: same as start_y
  //
  //GenParamValues: Values of the generic parameters of GenericParamNames
  //
  //
  //Store current display settings
  if (HDevWindowStack::IsOpen())
    hv_PreviousWindowHandle = HDevWindowStack::GetActive();
  HDevWindowStack::SetActive(hv_WindowHandle);
  GetSystem("clip_region", &hv_ClipRegion);
  GetWindowExtents(hv_WindowHandle, &hv_Row, &hv_Column, &hv_Width, &hv_Height);
  GetPart(hv_WindowHandle, &hv_PartRow1, &hv_PartColumn1, &hv_PartRow2, &hv_PartColumn2);
  GetRgb(hv_WindowHandle, &hv_Red, &hv_Green, &hv_Blue);
  GetDraw(hv_WindowHandle, &hv_DrawMode);
  GetLineStyle(hv_WindowHandle, &hv_OriginStyle);
  //
  //Set display parameters
  SetLineStyle(hv_WindowHandle, HTuple());
  SetSystem("clip_region", "false");
  if (HDevWindowStack::IsOpen())
    SetPart(HDevWindowStack::GetActive(),0, 0, hv_Height-1, hv_Width-1);
  //
  //Check input coordinates
  //
  if (0 != (HTuple(hv_XValues==HTuple()).TupleAnd(hv_YValues==HTuple())))
  {
    //Neither XValues nor YValues are given:
    //Set axes to interval [0,1]
    hv_XAxisEndValue = 1;
    hv_YAxisEndValue = 1;
    hv_XAxisStartValue = 0;
    hv_YAxisStartValue = 0;
    hv_XValuesAreStrings = 0;
  }
  else
  {
    if (0 != (hv_XValues==HTuple()))
    {
      //XValues are omitted:
      //Set equidistant XValues
      hv_XValues = HTuple::TupleGenSequence(0,(hv_YValues.TupleLength())-1,1);
      hv_XValuesAreStrings = 0;
    }
    else if (0 != (hv_YValues==HTuple()))
    {
      //YValues are omitted:
      //Set equidistant YValues
      hv_YValues = HTuple::TupleGenSequence(0,(hv_XValues.TupleLength())-1,1);
    }
    if (0 != (((hv_YValues.TupleLength())%(hv_XValues.TupleLength()))!=0))
    {
      //Number of YValues does not match number of XValues
      throw HException("Number of YValues is no multiple of the number of XValues!");
      return;
    }
    hv_XValuesAreStrings = hv_XValues.TupleIsStringElem();
    hv_XValuesAreStrings = (hv_XValuesAreStrings.TupleSum())==(hv_XValuesAreStrings.TupleLength());
    if (0 != hv_XValuesAreStrings)
    {
      //XValues are given as strings:
      //Show XValues as ticks
      hv_XTickValues = hv_XValues;
      hv_XTicks = 1;
      //Set x-axis dimensions
      hv_XValues = HTuple::TupleGenSequence(1,hv_XValues.TupleLength(),1);
    }
    //Set default x-axis dimensions
    if (0 != ((hv_XValues.TupleLength())>1))
    {
      hv_XAxisStartValue = hv_XValues.TupleMin();
      hv_XAxisEndValue = hv_XValues.TupleMax();
    }
    else
    {
      hv_XAxisEndValue = HTuple(hv_XValues[0])+0.5;
      hv_XAxisStartValue = HTuple(hv_XValues[0])-0.5;
    }
  }
  //Set default y-axis dimensions
  if (0 != ((hv_YValues.TupleLength())>1))
  {
    hv_YAxisStartValue = hv_YValues.TupleMin();
    hv_YAxisEndValue = hv_YValues.TupleMax();
  }
  else if (0 != ((hv_YValues.TupleLength())==1))
  {
    hv_YAxisStartValue = HTuple(hv_YValues[0])-0.5;
    hv_YAxisEndValue = HTuple(hv_YValues[0])+0.5;
  }
  else
  {
    hv_YAxisStartValue = 0;
    hv_YAxisEndValue = 1;
  }
  //Set default interception point of x- and y- axis
  hv_OriginX = hv_XAxisStartValue;
  hv_OriginY = hv_YAxisStartValue;
  //
  //Set more defaults
  hv_LeftBorder = hv_Width*0.1;
  hv_RightBorder = hv_Width*0.1;
  hv_UpperBorder = hv_Height*0.1;
  hv_LowerBorder = hv_Height*0.1;
  hv_AxesColor = "white";
  hv_Style = "line";
  hv_Clip = "no";
  hv_XTicks = "min_max_origin";
  hv_YTicks = "min_max_origin";
  hv_XGrid = "none";
  hv_YGrid = "none";
  hv_GridColor = "dim gray";
  //
  //Parse generic parameters
  //
  hv_NumGenParamNames = hv_GenParamNames.TupleLength();
  hv_NumGenParamValues = hv_GenParamValues.TupleLength();
  if (0 != (hv_NumGenParamNames!=hv_NumGenParamValues))
  {
    throw HException("Number of generic parameter names does not match generic parameter values!");
    return;
  }
  //
  hv_SetOriginXToDefault = 1;
  hv_SetOriginYToDefault = 1;
  {
  HTuple end_val179 = (hv_GenParamNames.TupleLength())-1;
  HTuple step_val179 = 1;
  for (hv_GenParamIndex=0; hv_GenParamIndex.Continue(end_val179, step_val179); hv_GenParamIndex += step_val179)
  {
    //
    //Set 'axes_color'
    if (0 != (HTuple(hv_GenParamNames[hv_GenParamIndex])==HTuple("axes_color")))
    {
      hv_AxesColor = HTuple(hv_GenParamValues[hv_GenParamIndex]);
      //
      //Set 'style'
    }
    else if (0 != (HTuple(hv_GenParamNames[hv_GenParamIndex])==HTuple("style")))
    {
      hv_Style = HTuple(hv_GenParamValues[hv_GenParamIndex]);
      //
      //Set 'clip'
    }
    else if (0 != (HTuple(hv_GenParamNames[hv_GenParamIndex])==HTuple("clip")))
    {
      hv_Clip = HTuple(hv_GenParamValues[hv_GenParamIndex]);
      if (0 != (HTuple(hv_Clip!=HTuple("yes")).TupleAnd(hv_Clip!=HTuple("no"))))
      {
        throw HException(("Unsupported clipping option: '"+hv_Clip)+"'");
      }
      //
      //Set 'ticks'
    }
    else if (0 != (HTuple(hv_GenParamNames[hv_GenParamIndex])==HTuple("ticks")))
    {
      hv_XTicks = HTuple(hv_GenParamValues[hv_GenParamIndex]);
      hv_YTicks = HTuple(hv_GenParamValues[hv_GenParamIndex]);
      //
      //Set 'ticks_x'
    }
    else if (0 != (HTuple(hv_GenParamNames[hv_GenParamIndex])==HTuple("ticks_x")))
    {
      hv_XTicks = HTuple(hv_GenParamValues[hv_GenParamIndex]);
      //
      //Set 'ticks_y'
    }
    else if (0 != (HTuple(hv_GenParamNames[hv_GenParamIndex])==HTuple("ticks_y")))
    {
      hv_YTicks = HTuple(hv_GenParamValues[hv_GenParamIndex]);
      //
      //Set 'grid'
    }
    else if (0 != (HTuple(hv_GenParamNames[hv_GenParamIndex])==HTuple("grid")))
    {
      hv_XGrid = HTuple(hv_GenParamValues[hv_GenParamIndex]);
      hv_YGrid = HTuple(hv_GenParamValues[hv_GenParamIndex]);
      hv_XGridTicks = hv_XTicks;
      //
      //Set 'grid_x'
    }
    else if (0 != (HTuple(hv_GenParamNames[hv_GenParamIndex])==HTuple("grid_x")))
    {
      hv_XGrid = HTuple(hv_GenParamValues[hv_GenParamIndex]);
      //
      //Set 'grid_y'
    }
    else if (0 != (HTuple(hv_GenParamNames[hv_GenParamIndex])==HTuple("grid_y")))
    {
      hv_YGrid = HTuple(hv_GenParamValues[hv_GenParamIndex]);
      //
      //Set 'grid_color'
    }
    else if (0 != (HTuple(hv_GenParamNames[hv_GenParamIndex])==HTuple("grid_color")))
    {
      hv_GridColor = HTuple(hv_GenParamValues[hv_GenParamIndex]);
      //
      //Set 'start_x'
    }
    else if (0 != (HTuple(hv_GenParamNames[hv_GenParamIndex])==HTuple("start_x")))
    {
      hv_XAxisStartValue = HTuple(hv_GenParamValues[hv_GenParamIndex]);
      //
      //Set 'end_x'
    }
    else if (0 != (HTuple(hv_GenParamNames[hv_GenParamIndex])==HTuple("end_x")))
    {
      hv_XAxisEndValue = HTuple(hv_GenParamValues[hv_GenParamIndex]);
      //
      //Set 'start_y'
    }
    else if (0 != (HTuple(hv_GenParamNames[hv_GenParamIndex])==HTuple("start_y")))
    {
      hv_YAxisStartValue = HTuple(hv_GenParamValues[hv_GenParamIndex]);
      //
      //Set 'end_y'
    }
    else if (0 != (HTuple(hv_GenParamNames[hv_GenParamIndex])==HTuple("end_y")))
    {
      hv_YAxisEndValue = HTuple(hv_GenParamValues[hv_GenParamIndex]);
      //
      //Set 'origin_x'
    }
    else if (0 != (HTuple(hv_GenParamNames[hv_GenParamIndex])==HTuple("origin_x")))
    {
      hv_OriginX = HTuple(hv_GenParamValues[hv_GenParamIndex]);
      hv_SetOriginXToDefault = 0;
      //
      //Set 'origin_y'
    }
    else if (0 != (HTuple(hv_GenParamNames[hv_GenParamIndex])==HTuple("origin_y")))
    {
      hv_OriginY = HTuple(hv_GenParamValues[hv_GenParamIndex]);
      hv_SetOriginYToDefault = 0;
      //
      //Set 'margin'
    }
    else if (0 != (HTuple(hv_GenParamNames[hv_GenParamIndex])==HTuple("margin")))
    {
      hv_LeftBorder = HTuple(hv_GenParamValues[hv_GenParamIndex]);
      hv_RightBorder = HTuple(hv_GenParamValues[hv_GenParamIndex]);
      hv_UpperBorder = HTuple(hv_GenParamValues[hv_GenParamIndex]);
      hv_LowerBorder = HTuple(hv_GenParamValues[hv_GenParamIndex]);
      //
      //Set 'margin_left'
    }
    else if (0 != (HTuple(hv_GenParamNames[hv_GenParamIndex])==HTuple("margin_left")))
    {
      hv_LeftBorder = HTuple(hv_GenParamValues[hv_GenParamIndex]);
      //
      //Set 'margin_right'
    }
    else if (0 != (HTuple(hv_GenParamNames[hv_GenParamIndex])==HTuple("margin_right")))
    {
      hv_RightBorder = HTuple(hv_GenParamValues[hv_GenParamIndex]);
      //
      //Set 'margin_top'
    }
    else if (0 != (HTuple(hv_GenParamNames[hv_GenParamIndex])==HTuple("margin_top")))
    {
      hv_UpperBorder = HTuple(hv_GenParamValues[hv_GenParamIndex]);
      //
      //Set 'margin_bottom'
    }
    else if (0 != (HTuple(hv_GenParamNames[hv_GenParamIndex])==HTuple("margin_bottom")))
    {
      hv_LowerBorder = HTuple(hv_GenParamValues[hv_GenParamIndex]);
    }
    else
    {
      throw HException(("Unknown generic parameter: '"+HTuple(hv_GenParamNames[hv_GenParamIndex]))+"'");
    }
  }
  }
  //
  //
  //Check consistency of start and end values
  //of the axes.
  if (0 != (hv_XAxisStartValue>hv_XAxisEndValue))
  {
    throw HException("Value for 'start_x' is greater than value for 'end_x'");
  }
  if (0 != (hv_YAxisStartValue>hv_YAxisEndValue))
  {
    throw HException("Value for 'start_y' is greater than value for 'end_y'");
  }
  //
  //Set default origin to lower left corner
  if (0 != hv_SetOriginXToDefault)
  {
    hv_OriginX = hv_XAxisStartValue;
  }
  if (0 != hv_SetOriginYToDefault)
  {
    hv_OriginY = hv_YAxisStartValue;
  }
  //
  //
  //Calculate basic pixel coordinates and scale factors
  //
  hv_XAxisWidthPx = (hv_Width-hv_LeftBorder)-hv_RightBorder;
  hv_XAxisWidth = hv_XAxisEndValue-hv_XAxisStartValue;
  if (0 != (hv_XAxisWidth==0))
  {
    hv_XAxisStartValue = hv_XAxisStartValue-0.5;
    hv_XAxisEndValue += 0.5;
    hv_XAxisWidth = 1;
  }
  hv_XScaleFactor = hv_XAxisWidthPx/(hv_XAxisWidth.TupleReal());
  hv_YAxisHeightPx = (hv_Height-hv_LowerBorder)-hv_UpperBorder;
  hv_YAxisHeight = hv_YAxisEndValue-hv_YAxisStartValue;
  if (0 != (hv_YAxisHeight==0))
  {
    hv_YAxisStartValue = hv_YAxisStartValue-0.5;
    hv_YAxisEndValue += 0.5;
    hv_YAxisHeight = 1;
  }
  hv_YScaleFactor = hv_YAxisHeightPx/(hv_YAxisHeight.TupleReal());
  hv_YAxisOffsetPx = (hv_OriginX-hv_XAxisStartValue)*hv_XScaleFactor;
  hv_XAxisOffsetPx = (hv_OriginY-hv_YAxisStartValue)*hv_YScaleFactor;
  //
  //Display grid lines
  //
  if (0 != (hv_GridColor!=HTuple("none")))
  {
    hv_DotStyle.Clear();
    hv_DotStyle[0] = 5;
    hv_DotStyle[1] = 7;
    SetLineStyle(hv_WindowHandle, hv_DotStyle);
    if (HDevWindowStack::IsOpen())
      SetColor(HDevWindowStack::GetActive(),hv_GridColor);
    //
    //Display x grid lines
    if (0 != (hv_XGrid!=HTuple("none")))
    {
      if (0 != (hv_XGrid==HTuple("min_max_origin")))
      {
        //Calculate 'min_max_origin' grid line coordinates
        if (0 != (hv_OriginX==hv_XAxisStartValue))
        {
          hv_XGridValues.Clear();
          hv_XGridValues.Append(hv_XAxisStartValue);
          hv_XGridValues.Append(hv_XAxisEndValue);
        }
        else
        {
          hv_XGridValues.Clear();
          hv_XGridValues.Append(hv_XAxisStartValue);
          hv_XGridValues.Append(hv_OriginX);
          hv_XGridValues.Append(hv_XAxisEndValue);
        }
      }
      else
      {
        //Calculate equidistant grid line coordinates
        hv_XGridStart = ((hv_XAxisStartValue/hv_XGrid).TupleCeil())*hv_XGrid;
        hv_XGridValues = HTuple::TupleGenSequence(hv_XGridStart,hv_XAxisEndValue,hv_XGrid);
      }
      hv_XPosition = (hv_XGridValues-hv_XAxisStartValue)*hv_XScaleFactor;
      //Generate and display grid lines
      {
      HTuple end_val343 = (hv_XGridValues.TupleLength())-1;
      HTuple step_val343 = 1;
      for (hv_IndexGrid=0; hv_IndexGrid.Continue(end_val343, step_val343); hv_IndexGrid += step_val343)
      {
        GenContourPolygonXld(&ho_ContourXGrid, (hv_Height-hv_LowerBorder).TupleConcat(hv_UpperBorder), 
            (hv_LeftBorder+HTuple(hv_XPosition[hv_IndexGrid])).TupleConcat(hv_LeftBorder+HTuple(hv_XPosition[hv_IndexGrid])));
        if (HDevWindowStack::IsOpen())
          DispObj(ho_ContourXGrid, HDevWindowStack::GetActive());
      }
      }
    }
    //
    //Display y grid lines
    if (0 != (hv_YGrid!=HTuple("none")))
    {
      if (0 != (hv_YGrid==HTuple("min_max_origin")))
      {
        //Calculate 'min_max_origin' grid line coordinates
        if (0 != (hv_OriginY==hv_YAxisStartValue))
        {
          hv_YGridValues.Clear();
          hv_YGridValues.Append(hv_YAxisStartValue);
          hv_YGridValues.Append(hv_YAxisEndValue);
        }
        else
        {
          hv_YGridValues.Clear();
          hv_YGridValues.Append(hv_YAxisStartValue);
          hv_YGridValues.Append(hv_OriginY);
          hv_YGridValues.Append(hv_YAxisEndValue);
        }
      }
      else
      {
        //Calculate equidistant grid line coordinates
        hv_YGridStart = ((hv_YAxisStartValue/hv_YGrid).TupleCeil())*hv_YGrid;
        hv_YGridValues = HTuple::TupleGenSequence(hv_YGridStart,hv_YAxisEndValue,hv_YGrid);
      }
      hv_YPosition = (hv_YGridValues-hv_YAxisStartValue)*hv_YScaleFactor;
      //Generate and display grid lines
      {
      HTuple end_val365 = (hv_YGridValues.TupleLength())-1;
      HTuple step_val365 = 1;
      for (hv_IndexGrid=0; hv_IndexGrid.Continue(end_val365, step_val365); hv_IndexGrid += step_val365)
      {
        GenContourPolygonXld(&ho_ContourYGrid, ((hv_Height-hv_LowerBorder)-HTuple(hv_YPosition[hv_IndexGrid])).TupleConcat((hv_Height-hv_LowerBorder)-HTuple(hv_YPosition[hv_IndexGrid])), 
            hv_LeftBorder.TupleConcat(hv_Width-hv_RightBorder));
        if (HDevWindowStack::IsOpen())
          DispObj(ho_ContourYGrid, HDevWindowStack::GetActive());
      }
      }
    }
  }
  SetLineStyle(hv_WindowHandle, HTuple());
  //
  //
  //Display the coordinate sytem axes
  if (0 != (hv_AxesColor!=HTuple("none")))
  {
    //Display axes
    if (HDevWindowStack::IsOpen())
      SetColor(HDevWindowStack::GetActive(),hv_AxesColor);
    gen_arrow_contour_xld(&ho_XArrow, (hv_Height-hv_LowerBorder)-hv_XAxisOffsetPx, 
        hv_LeftBorder, (hv_Height-hv_LowerBorder)-hv_XAxisOffsetPx, hv_Width-hv_RightBorder, 
        0, 0);
    if (HDevWindowStack::IsOpen())
      DispObj(ho_XArrow, HDevWindowStack::GetActive());
    gen_arrow_contour_xld(&ho_YArrow, hv_Height-hv_LowerBorder, hv_LeftBorder+hv_YAxisOffsetPx, 
        hv_UpperBorder, hv_LeftBorder+hv_YAxisOffsetPx, 0, 0);
    if (HDevWindowStack::IsOpen())
      DispObj(ho_YArrow, HDevWindowStack::GetActive());
    //Display labels
    GetStringExtents(hv_WindowHandle, hv_XLabel, &hv_Ascent, &hv_Descent, &hv_TextWidthXLabel, 
        &hv_TextHeightXLabel);
    if (HDevWindowStack::IsOpen())
      DispText(HDevWindowStack::GetActive(),hv_XLabel, "image", ((hv_Height-hv_LowerBorder)-hv_TextHeightXLabel)-hv_XAxisOffsetPx, 
          ((hv_Width-hv_RightBorder)-hv_TextWidthXLabel)-3, hv_AxesColor, "box", 
          "false");
    if (HDevWindowStack::IsOpen())
      DispText(HDevWindowStack::GetActive()," "+hv_YLabel, "image", hv_UpperBorder, 
          (hv_LeftBorder+3)+hv_YAxisOffsetPx, hv_AxesColor, "box", "false");
  }
  //
  //Display ticks
  //
  if (0 != (hv_AxesColor!=HTuple("none")))
  {
    if (HDevWindowStack::IsOpen())
      SetColor(HDevWindowStack::GetActive(),hv_AxesColor);
    if (0 != (hv_XTicks!=HTuple("none")))
    {
      //
      //Display x ticks
      if (0 != hv_XValuesAreStrings)
      {
        //Display string XValues as categories
        hv_XTicks = (hv_XValues.TupleLength())/(hv_XTickValues.TupleLength());
        hv_XPosition = (hv_XValues-hv_XAxisStartValue)*hv_XScaleFactor;
      }
      else
      {
        //Display tick values
        if (0 != (hv_XTicks==HTuple("min_max_origin")))
        {
          //Calculate 'min_max_origin' tick coordinates
          if (0 != (hv_OriginX==hv_XAxisStartValue))
          {
            hv_XTickValues.Clear();
            hv_XTickValues.Append(hv_XAxisStartValue);
            hv_XTickValues.Append(hv_XAxisEndValue);
          }
          else
          {
            hv_XTickValues.Clear();
            hv_XTickValues.Append(hv_XAxisStartValue);
            hv_XTickValues.Append(hv_OriginX);
            hv_XTickValues.Append(hv_XAxisEndValue);
          }
        }
        else
        {
          //Calculate equidistant tick coordinates
          hv_XTickStart = ((hv_XAxisStartValue/hv_XTicks).TupleCeil())*hv_XTicks;
          hv_XTickValues = HTuple::TupleGenSequence(hv_XTickStart,hv_XAxisEndValue,hv_XTicks);
        }
        hv_XPosition = (hv_XTickValues-hv_XAxisStartValue)*hv_XScaleFactor;
        hv_TypeTicks = hv_XTicks.TupleType();
        if (0 != (hv_TypeTicks==4))
        {
          //String ('min_max_origin')
          //Format depends on actual values
          hv_TypeTicks = hv_XTickValues.TupleType();
        }
        if (0 != (hv_TypeTicks==1))
        {
          //Round to integer
          hv_XTickValues = hv_XTickValues.TupleInt();
        }
        else
        {
          //Use floating point numbers
          hv_XTickValues = hv_XTickValues.TupleString(".2f");
        }
      }
      //Generate and display ticks
      {
      HTuple end_val429 = (hv_XTickValues.TupleLength())-1;
      HTuple step_val429 = 1;
      for (hv_IndexTicks=0; hv_IndexTicks.Continue(end_val429, step_val429); hv_IndexTicks += step_val429)
      {
        GenContourPolygonXld(&ho_ContourXTick, ((hv_Height-hv_LowerBorder)-hv_XAxisOffsetPx).TupleConcat(((hv_Height-hv_LowerBorder)-hv_XAxisOffsetPx)-5), 
            (hv_LeftBorder+HTuple(hv_XPosition[hv_IndexTicks])).TupleConcat(hv_LeftBorder+HTuple(hv_XPosition[hv_IndexTicks])));
        if (HDevWindowStack::IsOpen())
          DispObj(ho_ContourXTick, HDevWindowStack::GetActive());
        if (HDevWindowStack::IsOpen())
          DispText(HDevWindowStack::GetActive(),HTuple(hv_XTickValues[hv_IndexTicks]), 
              "image", ((hv_Height-hv_LowerBorder)+2)-hv_XAxisOffsetPx, hv_LeftBorder+HTuple(hv_XPosition[hv_IndexTicks]), 
              hv_AxesColor, "box", "false");
      }
      }
    }
    //
    if (0 != (hv_YTicks!=HTuple("none")))
    {
      //
      //Display y ticks
      if (0 != (hv_YTicks==HTuple("min_max_origin")))
      {
        //Calculate 'min_max_origin' tick coordinates
        if (0 != (hv_OriginY==hv_YAxisStartValue))
        {
          hv_YTickValues.Clear();
          hv_YTickValues.Append(hv_YAxisStartValue);
          hv_YTickValues.Append(hv_YAxisEndValue);
        }
        else
        {
          hv_YTickValues.Clear();
          hv_YTickValues.Append(hv_YAxisStartValue);
          hv_YTickValues.Append(hv_OriginY);
          hv_YTickValues.Append(hv_YAxisEndValue);
        }
      }
      else
      {
        //Calculate equidistant tick coordinates
        hv_YTickStart = ((hv_YAxisStartValue/hv_YTicks).TupleCeil())*hv_YTicks;
        hv_YTickValues = HTuple::TupleGenSequence(hv_YTickStart,hv_YAxisEndValue,hv_YTicks);
      }
      hv_YPosition = (hv_YTickValues-hv_YAxisStartValue)*hv_YScaleFactor;
      hv_TypeTicks = hv_YTicks.TupleType();
      if (0 != (hv_TypeTicks==4))
      {
        //String ('min_max_origin')
        //Format depends on actual values
        hv_TypeTicks = hv_YTickValues.TupleType();
      }
      if (0 != (hv_TypeTicks==1))
      {
        //Round to integer
        hv_YTickValues = hv_YTickValues.TupleInt();
      }
      else
      {
        //Use floating point numbers
        hv_YTickValues = hv_YTickValues.TupleString(".2f");
      }
      //Generate and display ticks
      {
      HTuple end_val466 = (hv_YTickValues.TupleLength())-1;
      HTuple step_val466 = 1;
      for (hv_IndexTicks=0; hv_IndexTicks.Continue(end_val466, step_val466); hv_IndexTicks += step_val466)
      {
        GenContourPolygonXld(&ho_ContourYTick, ((hv_Height-hv_LowerBorder)-HTuple(hv_YPosition[hv_IndexTicks])).TupleConcat((hv_Height-hv_LowerBorder)-HTuple(hv_YPosition[hv_IndexTicks])), 
            (hv_LeftBorder+hv_YAxisOffsetPx).TupleConcat((hv_LeftBorder+hv_YAxisOffsetPx)+5));
        if (HDevWindowStack::IsOpen())
          DispObj(ho_ContourYTick, HDevWindowStack::GetActive());
        GetStringExtents(hv_WindowHandle, HTuple(hv_YTickValues[hv_IndexTicks]), 
            &hv_Ascent1, &hv_Descent1, &hv_TextWidthYTicks, &hv_TextHeightYTicks);
        if (HDevWindowStack::IsOpen())
          DispText(HDevWindowStack::GetActive(),HTuple(hv_YTickValues[hv_IndexTicks]), 
              "image", (((hv_Height-hv_LowerBorder)-hv_TextHeightYTicks)+3)-HTuple(hv_YPosition[hv_IndexTicks]), 
              ((hv_LeftBorder-hv_TextWidthYTicks)-2)+hv_YAxisOffsetPx, hv_AxesColor, 
              "box", "false");
      }
      }
    }
  }
  //
  //Display function plot
  //
  if (0 != (hv_Color!=HTuple("none")))
  {
    if (0 != (HTuple(hv_XValues!=HTuple()).TupleAnd(hv_YValues!=HTuple())))
    {
      hv_Num = (hv_YValues.TupleLength())/(hv_XValues.TupleLength());
      //
      //Iterate over all functions to be displayed
      {
      HTuple end_val482 = hv_Num-1;
      HTuple step_val482 = 1;
      for (hv_I=0; hv_I.Continue(end_val482, step_val482); hv_I += step_val482)
      {
        //Select y values for current function
        hv_YSelected = hv_YValues.TupleSelectRange(hv_I*(hv_XValues.TupleLength()),((hv_I+1)*(hv_XValues.TupleLength()))-1);
        //Set color
        if (0 != (hv_Color==HTuple()))
        {
          SetRgb(hv_WindowHandle, hv_Red, hv_Green, hv_Blue);
        }
        else
        {
          if (HDevWindowStack::IsOpen())
            SetColor(HDevWindowStack::GetActive(),HTuple(hv_Color[hv_I%(hv_Color.TupleLength())]));
        }
        //
        //Display in different styles
        //
        if (0 != (HTuple(hv_Style==HTuple("line")).TupleOr(hv_Style==HTuple())))
        {
          //Line
          GenContourPolygonXld(&ho_Contour, ((hv_Height-hv_LowerBorder)-(hv_YSelected*hv_YScaleFactor))+(hv_YAxisStartValue*hv_YScaleFactor), 
              ((hv_XValues*hv_XScaleFactor)+hv_LeftBorder)-(hv_XAxisStartValue*hv_XScaleFactor));
          //Clip, if necessary
          if (0 != (hv_Clip==HTuple("yes")))
          {
            ClipContoursXld(ho_Contour, &ho_Contour, hv_UpperBorder, hv_LeftBorder, 
                hv_Height-hv_LowerBorder, hv_Width-hv_RightBorder);
          }
          if (HDevWindowStack::IsOpen())
            DispObj(ho_Contour, HDevWindowStack::GetActive());
        }
        else if (0 != (hv_Style==HTuple("cross")))
        {
          //Cross
          GenCrossContourXld(&ho_Cross, ((hv_Height-hv_LowerBorder)-(hv_YSelected*hv_YScaleFactor))+(hv_YAxisStartValue*hv_YScaleFactor), 
              ((hv_XValues*hv_XScaleFactor)+hv_LeftBorder)-(hv_XAxisStartValue*hv_XScaleFactor), 
              6, 0.785398);
          //Clip, if necessary
          if (0 != (hv_Clip==HTuple("yes")))
          {
            ClipContoursXld(ho_Cross, &ho_Cross, hv_UpperBorder, hv_LeftBorder, hv_Height-hv_LowerBorder, 
                hv_Width-hv_RightBorder);
          }
          if (HDevWindowStack::IsOpen())
            DispObj(ho_Cross, HDevWindowStack::GetActive());
        }
        else if (0 != (hv_Style==HTuple("filled")))
        {
          //Filled
          hv_Y1Selected.Clear();
          hv_Y1Selected.Append(0+hv_OriginY);
          hv_Y1Selected.Append(hv_YSelected);
          hv_Y1Selected.Append(0+hv_OriginY);
          hv_X1Selected.Clear();
          hv_X1Selected.Append(hv_XValues.TupleMin());
          hv_X1Selected.Append(hv_XValues);
          hv_X1Selected.Append(hv_XValues.TupleMax());
          if (HDevWindowStack::IsOpen())
            SetDraw(HDevWindowStack::GetActive(),"fill");
          GenRegionPolygonFilled(&ho_Filled, ((hv_Height-hv_LowerBorder)-(hv_Y1Selected*hv_YScaleFactor))+(hv_YAxisStartValue*hv_YScaleFactor), 
              ((hv_X1Selected*hv_XScaleFactor)+hv_LeftBorder)-(hv_XAxisStartValue*hv_XScaleFactor));
          //Clip, if necessary
          if (0 != (hv_Clip==HTuple("yes")))
          {
            ClipRegion(ho_Filled, &ho_Filled, hv_UpperBorder, hv_LeftBorder, hv_Height-hv_LowerBorder, 
                hv_Width-hv_RightBorder);
          }
          if (HDevWindowStack::IsOpen())
            DispObj(ho_Filled, HDevWindowStack::GetActive());
        }
        else
        {
          throw HException("Unsupported style: "+hv_Style);
        }
      }
      }
    }
  }
  //
  //
  //Reset original display settings
  if (HDevWindowStack::IsOpen())
    SetPart(HDevWindowStack::GetActive(),hv_PartRow1, hv_PartColumn1, hv_PartRow2, 
        hv_PartColumn2);
  HDevWindowStack::SetActive(hv_PreviousWindowHandle);
  SetRgb(hv_WindowHandle, hv_Red, hv_Green, hv_Blue);
  if (HDevWindowStack::IsOpen())
    SetDraw(HDevWindowStack::GetActive(),hv_DrawMode);
  SetLineStyle(hv_WindowHandle, hv_OriginStyle);
  SetSystem("clip_region", hv_ClipRegion);
  return;
}

// Chapter: Graphics / Text
// Short Description: Set font independent of OS 
void set_display_font (HTuple hv_WindowHandle, HTuple hv_Size, HTuple hv_Font, HTuple hv_Bold, 
    HTuple hv_Slant)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_OS, hv_Fonts, hv_Style, hv_Exception;
  HTuple  hv_AvailableFonts, hv_Fdx, hv_Indices;

  //This procedure sets the text font of the current window with
  //the specified attributes.
  //
  //Input parameters:
  //WindowHandle: The graphics window for which the font will be set
  //Size: The font size. If Size=-1, the default of 16 is used.
  //Bold: If set to 'true', a bold font is used
  //Slant: If set to 'true', a slanted font is used
  //
  GetSystem("operating_system", &hv_OS);
  if (0 != (HTuple(hv_Size==HTuple()).TupleOr(hv_Size==-1)))
  {
    hv_Size = 16;
  }
  if (0 != ((hv_OS.TupleSubstr(0,2))==HTuple("Win")))
  {
    //Restore previous behaviour
    hv_Size = (1.13677*hv_Size).TupleInt();
  }
  else
  {
    hv_Size = hv_Size.TupleInt();
  }
  if (0 != (hv_Font==HTuple("Courier")))
  {
    hv_Fonts.Clear();
    hv_Fonts[0] = "Courier";
    hv_Fonts[1] = "Courier 10 Pitch";
    hv_Fonts[2] = "Courier New";
    hv_Fonts[3] = "CourierNew";
    hv_Fonts[4] = "Liberation Mono";
  }
  else if (0 != (hv_Font==HTuple("mono")))
  {
    hv_Fonts.Clear();
    hv_Fonts[0] = "Consolas";
    hv_Fonts[1] = "Menlo";
    hv_Fonts[2] = "Courier";
    hv_Fonts[3] = "Courier 10 Pitch";
    hv_Fonts[4] = "FreeMono";
    hv_Fonts[5] = "Liberation Mono";
  }
  else if (0 != (hv_Font==HTuple("sans")))
  {
    hv_Fonts.Clear();
    hv_Fonts[0] = "Luxi Sans";
    hv_Fonts[1] = "DejaVu Sans";
    hv_Fonts[2] = "FreeSans";
    hv_Fonts[3] = "Arial";
    hv_Fonts[4] = "Liberation Sans";
  }
  else if (0 != (hv_Font==HTuple("serif")))
  {
    hv_Fonts.Clear();
    hv_Fonts[0] = "Times New Roman";
    hv_Fonts[1] = "Luxi Serif";
    hv_Fonts[2] = "DejaVu Serif";
    hv_Fonts[3] = "FreeSerif";
    hv_Fonts[4] = "Utopia";
    hv_Fonts[5] = "Liberation Serif";
  }
  else
  {
    hv_Fonts = hv_Font;
  }
  hv_Style = "";
  if (0 != (hv_Bold==HTuple("true")))
  {
    hv_Style += HTuple("Bold");
  }
  else if (0 != (hv_Bold!=HTuple("false")))
  {
    hv_Exception = "Wrong value of control parameter Bold";
    throw HException(hv_Exception);
  }
  if (0 != (hv_Slant==HTuple("true")))
  {
    hv_Style += HTuple("Italic");
  }
  else if (0 != (hv_Slant!=HTuple("false")))
  {
    hv_Exception = "Wrong value of control parameter Slant";
    throw HException(hv_Exception);
  }
  if (0 != (hv_Style==HTuple("")))
  {
    hv_Style = "Normal";
  }
  QueryFont(hv_WindowHandle, &hv_AvailableFonts);
  hv_Font = "";
  {
  HTuple end_val48 = (hv_Fonts.TupleLength())-1;
  HTuple step_val48 = 1;
  for (hv_Fdx=0; hv_Fdx.Continue(end_val48, step_val48); hv_Fdx += step_val48)
  {
    hv_Indices = hv_AvailableFonts.TupleFind(HTuple(hv_Fonts[hv_Fdx]));
    if (0 != ((hv_Indices.TupleLength())>0))
    {
      if (0 != (HTuple(hv_Indices[0])>=0))
      {
        hv_Font = HTuple(hv_Fonts[hv_Fdx]);
        break;
      }
    }
  }
  }
  if (0 != (hv_Font==HTuple("")))
  {
    throw HException("Wrong value of control parameter Font");
  }
  hv_Font = (((hv_Font+"-")+hv_Style)+"-")+hv_Size;
  SetFont(hv_WindowHandle, hv_Font);
  return;
}

// Chapter: Graphics / Text
// Short Description: This procedure displays 'End of program' in the lower right corner of the screen. 
void disp_end_of_program_message (HTuple hv_WindowHandle, HTuple hv_Color, HTuple hv_Box)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_GenParamName, hv_GenParamValue, hv_EndMessage;

  //This procedure displays 'End of program' in the
  //lower right corner of the screen.
  //It uses the procedure disp_message.
  //
  //Input parameters:
  //WindowHandle: The window, where the text shall be displayed
  //Color: defines the text color.
  //   If set to '' or 'auto', the currently set color is used.
  //Box: If set to 'true', the text is displayed in a box.
  //
  //Convert the parameter Box to generic parameters.
  hv_GenParamName = HTuple();
  hv_GenParamValue = HTuple();
  if (0 != ((hv_Box.TupleLength())>0))
  {
    if (0 != (HTuple(hv_Box[0])==HTuple("false")))
    {
      //Display no box
      hv_GenParamName = hv_GenParamName.TupleConcat("box");
      hv_GenParamValue = hv_GenParamValue.TupleConcat("false");
    }
    else if (0 != (HTuple(hv_Box[0])!=HTuple("true")))
    {
      //Set a color other than the default.
      hv_GenParamName = hv_GenParamName.TupleConcat("box_color");
      hv_GenParamValue = hv_GenParamValue.TupleConcat(HTuple(hv_Box[0]));
    }
  }
  if (0 != ((hv_Box.TupleLength())>1))
  {
    if (0 != (HTuple(hv_Box[1])==HTuple("false")))
    {
      //Display no shadow.
      hv_GenParamName = hv_GenParamName.TupleConcat("shadow");
      hv_GenParamValue = hv_GenParamValue.TupleConcat("false");
    }
    else if (0 != (HTuple(hv_Box[1])!=HTuple("true")))
    {
      //Set a shadow color other than the default.
      hv_GenParamName = hv_GenParamName.TupleConcat("shadow_color");
      hv_GenParamValue = hv_GenParamValue.TupleConcat(HTuple(hv_Box[1]));
    }
  }
  //
  if (0 != (hv_Color==HTuple("")))
  {
    //disp_text does not accept an empty string for Color.
    hv_Color = HTuple();
  }
  //
  //Display the message.
  hv_EndMessage = "      End of program      ";
  DispText(hv_WindowHandle, hv_EndMessage, "window", "bottom", "right", hv_Color, 
      hv_GenParamName, hv_GenParamValue);
  return;
}

// Chapter: File / Misc
// Short Description: Get all image files under the given path 
void list_image_files (HTuple hv_ImageDirectory, HTuple hv_Extensions, HTuple hv_Options, 
    HTuple *hv_ImageFiles)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_HalconImages, hv_OS, hv_Directories;
  HTuple  hv_Index, hv_Length, hv_NetworkDrive, hv_Substring;
  HTuple  hv_FileExists, hv_AllFiles, hv_i, hv_Selection;

  //This procedure returns all files in a given directory
  //with one of the suffixes specified in Extensions.
  //
  //Input parameters:
  //ImageDirectory: as the name says
  //   If a tuple of directories is given, only the images in the first
  //   existing directory are returned.
  //   If a local directory is not found, the directory is searched
  //   under %HALCONIMAGES%/ImageDirectory. If %HALCONIMAGES% is not set,
  //   %HALCONROOT%/images is used instead.
  //Extensions: A string tuple containing the extensions to be found
  //   e.g. ['png','tif',jpg'] or others
  //If Extensions is set to 'default' or the empty string '',
  //   all image suffixes supported by HALCON are used.
  //Options: as in the operator list_files, except that the 'files'
  //   option is always used. Note that the 'directories' option
  //   has no effect but increases runtime, because only files are
  //   returned.
  //
  //Output parameter:
  //ImageFiles: A tuple of all found image file names
  //
  if (0 != (HTuple(HTuple(hv_Extensions==HTuple()).TupleOr(hv_Extensions==HTuple(""))).TupleOr(hv_Extensions==HTuple("default"))))
  {
    hv_Extensions.Clear();
    hv_Extensions[0] = "ima";
    hv_Extensions[1] = "tif";
    hv_Extensions[2] = "tiff";
    hv_Extensions[3] = "gif";
    hv_Extensions[4] = "bmp";
    hv_Extensions[5] = "jpg";
    hv_Extensions[6] = "jpeg";
    hv_Extensions[7] = "jp2";
    hv_Extensions[8] = "jxr";
    hv_Extensions[9] = "png";
    hv_Extensions[10] = "pcx";
    hv_Extensions[11] = "ras";
    hv_Extensions[12] = "xwd";
    hv_Extensions[13] = "pbm";
    hv_Extensions[14] = "pnm";
    hv_Extensions[15] = "pgm";
    hv_Extensions[16] = "ppm";
    //
  }
  if (0 != (hv_ImageDirectory==HTuple("")))
  {
    hv_ImageDirectory = ".";
  }
  GetSystem("image_dir", &hv_HalconImages);
  GetSystem("operating_system", &hv_OS);
  if (0 != ((hv_OS.TupleSubstr(0,2))==HTuple("Win")))
  {
    hv_HalconImages = hv_HalconImages.TupleSplit(";");
  }
  else
  {
    hv_HalconImages = hv_HalconImages.TupleSplit(":");
  }
  hv_Directories = hv_ImageDirectory;
  {
  HTuple end_val37 = (hv_HalconImages.TupleLength())-1;
  HTuple step_val37 = 1;
  for (hv_Index=0; hv_Index.Continue(end_val37, step_val37); hv_Index += step_val37)
  {
    hv_Directories = hv_Directories.TupleConcat((HTuple(hv_HalconImages[hv_Index])+"/")+hv_ImageDirectory);
  }
  }
  TupleStrlen(hv_Directories, &hv_Length);
  TupleGenConst(hv_Length.TupleLength(), 0, &hv_NetworkDrive);
  if (0 != ((hv_OS.TupleSubstr(0,2))==HTuple("Win")))
  {
    {
    HTuple end_val43 = (hv_Length.TupleLength())-1;
    HTuple step_val43 = 1;
    for (hv_Index=0; hv_Index.Continue(end_val43, step_val43); hv_Index += step_val43)
    {
      if (0 != ((HTuple(hv_Directories[hv_Index]).TupleStrlen())>1))
      {
        TupleStrFirstN(HTuple(hv_Directories[hv_Index]), 1, &hv_Substring);
        if (0 != (HTuple(hv_Substring==HTuple("//")).TupleOr(hv_Substring==HTuple("\\\\"))))
        {
          hv_NetworkDrive[hv_Index] = 1;
        }
      }
    }
    }
  }
  (*hv_ImageFiles) = HTuple();
  {
  HTuple end_val53 = (hv_Directories.TupleLength())-1;
  HTuple step_val53 = 1;
  for (hv_Index=0; hv_Index.Continue(end_val53, step_val53); hv_Index += step_val53)
  {
    FileExists(HTuple(hv_Directories[hv_Index]), &hv_FileExists);
    if (0 != hv_FileExists)
    {
      ListFiles(HTuple(hv_Directories[hv_Index]), HTuple("files").TupleConcat(hv_Options), 
          &hv_AllFiles);
      (*hv_ImageFiles) = HTuple();
      {
      HTuple end_val58 = (hv_Extensions.TupleLength())-1;
      HTuple step_val58 = 1;
      for (hv_i=0; hv_i.Continue(end_val58, step_val58); hv_i += step_val58)
      {
        TupleRegexpSelect(hv_AllFiles, ((".*"+HTuple(hv_Extensions[hv_i]))+"$").TupleConcat("ignore_case"), 
            &hv_Selection);
        (*hv_ImageFiles) = (*hv_ImageFiles).TupleConcat(hv_Selection);
      }
      }
      TupleRegexpReplace((*hv_ImageFiles), (HTuple("\\\\").Append("replace_all")), 
          "/", &(*hv_ImageFiles));
      if (0 != (HTuple(hv_NetworkDrive[hv_Index])))
      {
        TupleRegexpReplace((*hv_ImageFiles), (HTuple("//").Append("replace_all")), 
            "/", &(*hv_ImageFiles));
        (*hv_ImageFiles) = "/"+(*hv_ImageFiles);
      }
      else
      {
        TupleRegexpReplace((*hv_ImageFiles), (HTuple("//").Append("replace_all")), 
            "/", &(*hv_ImageFiles));
      }
      return;
    }
  }
  }
  return;
}

// Chapter: File / Misc
// Short Description: Parse a filename into directory, base filename, and extension 
void parse_filename (HTuple hv_FileName, HTuple *hv_BaseName, HTuple *hv_Extension, 
    HTuple *hv_Directory)
{

  // Local control variables
  HTuple  hv_DirectoryTmp, hv_Substring;

  //This procedure gets a filename (with full path) as input
  //and returns the directory path, the base filename and the extension
  //in three different strings.
  //
  //In the output path the path separators will be replaced
  //by '/' in all cases.
  //
  //The procedure shows the possibilities of regular expressions in HALCON.
  //
  //Input parameters:
  //FileName: The input filename
  //
  //Output parameters:
  //BaseName: The filename without directory description and file extension
  //Extension: The file extension
  //Directory: The directory path
  //
  //Example:
  //basename('C:/images/part_01.png',...) returns
  //BaseName = 'part_01'
  //Extension = 'png'
  //Directory = 'C:\\images\\' (on Windows systems)
  //
  //Explanation of the regular expressions:
  //
  //'([^\\\\/]*?)(?:\\.[^.]*)?$':
  //To start at the end, the '$' matches the end of the string,
  //so it is best to read the expression from right to left.
  //The part in brackets (?:\\.[^.}*) denotes a non-capturing group.
  //That means, that this part is matched, but not captured
  //in contrast to the first bracketed group ([^\\\\/], see below.)
  //\\.[^.]* matches a dot '.' followed by as many non-dots as possible.
  //So (?:\\.[^.]*)? matches the file extension, if any.
  //The '?' at the end assures, that even if no extension exists,
  //a correct match is returned.
  //The first part in brackets ([^\\\\/]*?) is a capture group,
  //which means, that if a match is found, only the part in
  //brackets is returned as a result.
  //Because both HDevelop strings and regular expressions need a '\\'
  //to describe a backslash, inside regular expressions within HDevelop
  //a backslash has to be written as '\\\\'.
  //[^\\\\/] matches any character but a slash or backslash ('\\' in HDevelop)
  //[^\\\\/]*? matches a string od 0..n characters (except '/' or '\\')
  //where the '?' after the '*' switches the greediness off,
  //that means, that the shortest possible match is returned.
  //This option is necessary to cut off the extension
  //but only if (?:\\.[^.]*)? is able to match one.
  //To summarize, the regular expression matches that part of
  //the input string, that follows after the last '/' or '\\' and
  //cuts off the extension (if any) after the last '.'.
  //
  //'\\.([^.]*)$':
  //This matches everything after the last '.' of the input string.
  //Because ([^.]) is a capturing group,
  //only the part after the dot is returned.
  //
  //'.*[\\\\/]':
  //This matches the longest substring with a '/' or a '\\' at the end.
  //
  TupleRegexpMatch(hv_FileName, ".*[\\\\/]", &hv_DirectoryTmp);
  TupleSubstr(hv_FileName, hv_DirectoryTmp.TupleStrlen(), (hv_FileName.TupleStrlen())-1, 
      &hv_Substring);
  TupleRegexpMatch(hv_Substring, "([^\\\\/]*?)(?:\\.[^.]*)?$", &(*hv_BaseName));
  TupleRegexpMatch(hv_Substring, "\\.([^.]*)$", &(*hv_Extension));
  //
  //
  //Finally all found backslashes ('\\') are converted
  //to a slash to get consistent paths
  TupleRegexpReplace(hv_DirectoryTmp, (HTuple("\\\\").Append("replace_all")), "/", 
      &(*hv_Directory));
  return;
}

// Chapter: Graphics / Output
// Short Description:  This procedure plots tuples representing functions or curves in a coordinate system. 
void plot_funct_1d (HTuple hv_WindowHandle, HTuple hv_Function, HTuple hv_XLabel, 
    HTuple hv_YLabel, HTuple hv_Color, HTuple hv_GenParamNames, HTuple hv_GenParamValues)
{

  // Local control variables
  HTuple  hv_XValues, hv_YValues;

  //This procedure plots a function in a coordinate system.
  //
  //Input parameters:
  //
  //Function: 1d function
  //
  //XLabel: X axis label
  //
  //XLabel: Y axis label
  //
  //Color: Color of the plotted function
  //       If [] is given, the currently set display color is used.
  //       If 'none is given, the function is not plotted, but only
  //       the coordinate axes as specified.
  //
  //GenParamNames: Generic parameters to control the presentation
  //               The parameters are evaluated from left to right.
  //
  //               Possible Values:
  //   'axes_color': coordinate system color
  //                 Default: 'white'
  //                 If 'none' is given, no coordinate system is shown.
  //   'style': Graph style
  //            Possible values: 'line' (default), 'cross', 'filled'
  //   'clip': Clip graph to coordinate system area
  //           Possibile values: 'yes' (default), 'no'
  //   'ticks': Control display of ticks on the axes
  //            If 'min_max_origin' is given (default), ticks are shown
  //            at the minimum and maximum values of the axes and at the
  //            intercept point of x- and y-axis.
  //            If 'none' is given, no ticks are shown.
  //            If any number != 0 is given, it is interpreted as distance
  //            between the ticks.
  //   'ticks_x': Control display of ticks on x-axis only
  //   'ticks_y': Control display of ticks on y-axis only
  //   'grid': Control display of grid lines within the coordinate system
  //           If 'min_max_origin' is given (default), grid lines are shown
  //           at the minimum and maximum values of the axes.
  //           If 'none' is given, no grid lines are shown.
  //           If any number != 0 is given, it is interpreted as distance
  //           between the grid lines.
  //   'grid_x': Control display of grid lines for the x-axis only
  //   'grid_y': Control display of grid lines for the y-axis only
  //   'grid_color': Color of the grid (default: 'dim gray')
  //   'margin': The distance in pixels of the coordinate system area
  //             to all four window borders.
  //   'margin_left': The distance in pixels of the coordinate system area
  //                  to the left window border.
  //   'margin_right': The distance in pixels of the coordinate system area
  //                   to the right window border.
  //   'margin_top': The distance in pixels of the coordinate system area
  //                 to the upper window border.
  //   'margin_bottom': The distance in pixels of the coordinate system area
  //                    to the lower window border.
  //   'start_x': Lowest x value of the x axis
  //              Default: min(XValues)
  //   'end_x': Highest x value of the x axis
  //            Default: max(XValues)
  //   'start_y': Lowest y value of the x axis
  //              Default: min(YValues)
  //   'end_y': Highest y value of the x axis
  //            Default: max(YValues)
  //   'origin_x': X coordinate of the intercept point of x- and y-axis.
  //               Default: same as start_x
  //   'origin_y': Y coordinate of the intercept point of x- and y-axis.
  //               Default: same as start_y
  //
  //GenParamValues: Values of the generic parameters of GenericParamNames
  //
  //
  Funct1dToPairs(hv_Function, &hv_XValues, &hv_YValues);
  plot_tuple(hv_WindowHandle, hv_XValues, hv_YValues, hv_XLabel, hv_YLabel, hv_Color, 
      hv_GenParamNames, hv_GenParamValues);
  return;
}

// Chapter: Classification / Misc
// Short Description: Auxiliary procedure for get_custom_features and get_features. 
void append_length_or_values (HTuple hv_Mode, HTuple hv_Feature, HTuple hv_AccumulatedResults, 
    HTuple *hv_ExtendedResults)
{

  // Local iconic variables

  //
  //Auxiliary procedure used only by get_features and get_custom_features
  //
  if (0 != (hv_Mode==HTuple("get_lengths")))
  {
    //Output in 'get_lengths' mode is the length of the feature
    (*hv_ExtendedResults).Clear();
    (*hv_ExtendedResults).Append(hv_AccumulatedResults);
    (*hv_ExtendedResults).Append(hv_Feature.TupleLength());
  }
  else if (0 != (hv_Mode==HTuple("calculate")))
  {
    //Output in 'calculate' mode is the feature vector
    (*hv_ExtendedResults).Clear();
    (*hv_ExtendedResults).Append(hv_AccumulatedResults);
    (*hv_ExtendedResults).Append(hv_Feature);
  }
  else
  {
    (*hv_ExtendedResults) = hv_AccumulatedResults;
  }
  return;
}

// Chapter: 3D Object Model / Transformations
// Short Description: Transform 3D points from images to a 3D object model, and add extended attributes to the points of the object model. 
void xyz_attrib_to_object_model_3d (HObject ho_X, HObject ho_Y, HObject ho_Z, HObject ho_AttribImage, 
    HTuple hv_AttribName, HTuple *hv_ObjectModel3D)
{

  // Local iconic variables
  HObject  ho_DomainX, ho_DomainY, ho_DomainZ, ho_RegionIntersectionTmp;
  HObject  ho_RegionIntersection, ho_Channel;

  // Local control variables
  HTuple  hv_Number, hv_Channels, hv_WidthX, hv_HeightX;
  HTuple  hv_WidthY, hv_HeightY, hv_WidthZ, hv_HeightZ, hv_WidthA;
  HTuple  hv_HeightA, hv_AvailableAttributes, hv_Selection;
  HTuple  hv_Difference, hv_InvalidParameters, hv_Exception;
  HTuple  hv_AttribValues, hv_Index, hv_Rows, hv_Columns;
  HTuple  hv_AttribValuesTmp;

  //
  //Consistency checks:
  CountObj(ho_AttribImage, &hv_Number);
  if (0 != (hv_Number!=1))
  {
    throw HException(HTuple("The attribute image must be an image array with exactly one object. If you want to set multiple attributes, use a multichannel image."));
  }
  //
  CountChannels(ho_AttribImage, &hv_Channels);
  if (0 != (hv_Channels!=(hv_AttribName.TupleLength())))
  {
    throw HException(((("The number of channels of the attribute image ("+hv_Channels)+") must be equal to the number of attribute names (")+(hv_AttribName.TupleLength()))+").");
  }
  //
  GetImageSize(ho_X, &hv_WidthX, &hv_HeightX);
  GetImageSize(ho_Y, &hv_WidthY, &hv_HeightY);
  GetImageSize(ho_Z, &hv_WidthZ, &hv_HeightZ);
  GetImageSize(ho_AttribImage, &hv_WidthA, &hv_HeightA);
  if (0 != (HTuple(HTuple(HTuple(HTuple(HTuple(hv_WidthX!=hv_WidthY).TupleOr(hv_HeightX!=hv_HeightY)).TupleOr(hv_WidthX!=hv_WidthZ)).TupleOr(hv_HeightX!=hv_HeightZ)).TupleOr(hv_WidthX!=hv_WidthA)).TupleOr(hv_HeightX!=hv_HeightA)))
  {
    throw HException("Image sizes do not match. The size of all input images must be equal.");
  }
  //
  GetParamInfo("set_object_model_3d_attrib_mod", "AttribName", "value_list", &hv_AvailableAttributes);
  TupleRegexpSelect(hv_AvailableAttributes, "point_.*", &hv_Selection);
  TupleDifference(hv_AttribName, hv_Selection, &hv_Difference);
  TupleRegexpSelect(hv_Difference, "^[^&]", &hv_InvalidParameters);
  if (0 != ((hv_InvalidParameters.TupleLength())>0))
  {
    hv_Exception = ((("The following attribute names are invalid: "+((hv_InvalidParameters+HTuple(", ")).TupleSum()))+HTuple("please use a '&' prefix for extended attributes, e.g., '&"))+HTuple(hv_InvalidParameters[0]))+HTuple("', or a standard point attribute.");
    throw HException(hv_Exception);
  }
  //
  //Get the domain of the images containing the 3D points and get the region all
  //three of them share. This is because xyz_to_object_model_3d only uses points
  //in the intersecting domains of all three images.
  GetDomain(ho_X, &ho_DomainX);
  GetDomain(ho_Y, &ho_DomainY);
  GetDomain(ho_Z, &ho_DomainZ);
  Intersection(ho_DomainX, ho_DomainY, &ho_RegionIntersectionTmp);
  Intersection(ho_RegionIntersectionTmp, ho_DomainZ, &ho_RegionIntersection);
  //
  //Transform the images that contain the X, Y, and Z-coordinates to a 3D object model.
  XyzToObjectModel3d(ho_X, ho_Y, ho_Z, &(*hv_ObjectModel3D));
  //
  //Loop through all channels and collect the cooresponding attribute values
  hv_AttribValues = HTuple();
  {
  HTuple end_val43 = hv_Channels;
  HTuple step_val43 = 1;
  for (hv_Index=1; hv_Index.Continue(end_val43, step_val43); hv_Index += step_val43)
  {
    AccessChannel(ho_AttribImage, &ho_Channel, hv_Index);
    GetRegionPoints(ho_RegionIntersection, &hv_Rows, &hv_Columns);
    GetGrayval(ho_Channel, hv_Rows, hv_Columns, &hv_AttribValuesTmp);
    hv_AttribValues = hv_AttribValues.TupleConcat(hv_AttribValuesTmp);
  }
  }
  //
  //Set the attributes
  SetObjectModel3dAttribMod((*hv_ObjectModel3D), hv_AttribName, "points", hv_AttribValues);
  return;
}

// Chapter: Classification / Misc
// Short Description: Auxiliary procedure for get_custom_features and get_features. 
void append_names_or_groups (HTuple hv_Mode, HTuple hv_Name, HTuple hv_Groups, HTuple hv_CurrentName, 
    HTuple hv_AccumulatedResults, HTuple *hv_ExtendedResults)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_FirstOccurrence, hv_BelongsToGroup;

  //
  //Auxiliary procedure used only by get_features and get_custom_features
  //
  (*hv_ExtendedResults) = hv_AccumulatedResults;
  if (0 != (hv_Mode==HTuple("get_names")))
  {
    hv_FirstOccurrence = HTuple((hv_AccumulatedResults.TupleLength())==0).TupleOr((hv_AccumulatedResults.TupleFind(hv_Name))==-1);
    hv_BelongsToGroup = HTuple(((hv_Name.TupleConcat(hv_Groups)).TupleFind(hv_CurrentName))!=-1).TupleOr(hv_CurrentName==HTuple("all"));
    if (0 != (hv_FirstOccurrence.TupleAnd(hv_BelongsToGroup)))
    {
      //Output in 'get_names' mode is the name of the feature
      (*hv_ExtendedResults).Clear();
      (*hv_ExtendedResults).Append(hv_AccumulatedResults);
      (*hv_ExtendedResults).Append(hv_Name);
    }
  }
  else if (0 != (hv_Mode==HTuple("get_groups")))
  {
    (*hv_ExtendedResults).Clear();
    (*hv_ExtendedResults).Append(hv_AccumulatedResults);
    (*hv_ExtendedResults).Append(hv_Groups);
  }
  return;
}

// Chapter: Tools / Geometry
// Short Description: Sort tuple pairs. 
void sort_pairs (HTuple hv_T1, HTuple hv_T2, HTuple hv_SortMode, HTuple *hv_Sorted1, 
    HTuple *hv_Sorted2)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_Indices1, hv_Indices2;

  //Sort tuple pairs.
  //
  //input parameters:
  //T1: first tuple
  //T2: second tuple
  //SortMode: if set to '1', sort by the first tuple,
  //   if set to '2', sort by the second tuple
  //
  if (0 != (HTuple(hv_SortMode==HTuple("1")).TupleOr(hv_SortMode==1)))
  {
    TupleSortIndex(hv_T1, &hv_Indices1);
    (*hv_Sorted1) = hv_T1.TupleSelect(hv_Indices1);
    (*hv_Sorted2) = hv_T2.TupleSelect(hv_Indices1);
  }
  else if (0 != (HTuple(HTuple(hv_SortMode==HTuple("column")).TupleOr(hv_SortMode==HTuple("2"))).TupleOr(hv_SortMode==2)))
  {
    TupleSortIndex(hv_T2, &hv_Indices2);
    (*hv_Sorted1) = hv_T1.TupleSelect(hv_Indices2);
    (*hv_Sorted2) = hv_T2.TupleSelect(hv_Indices2);
  }
  return;
}

// Chapter: Object / Manipulation
// Short Description: Select elements from object arrays using a mask. 
void select_mask_obj (HObject ho_Objects, HObject *ho_SelectedObjects, HTuple hv_Mask)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_Number, hv_AllNumbers, hv_Indices;

  //select_mask_obj selects one or more single elements of the object array
  //Objects and returns them in SelectedObjects.
  //The elements of Mask determine if the corresponding elements of Objects are selected.
  //If the value is greater than 0, the corresponding element is selected.
  //
  //Check number of elements
  CountObj(ho_Objects, &hv_Number);
  if (0 != (hv_Number!=(hv_Mask.TupleLength())))
  {
    throw HException("Number of elements in Objects and Mask do not match.");
  }
  //
  //Check type of mask elements
  hv_AllNumbers = (((hv_Mask.TupleIsRealElem()).TupleSum())+((hv_Mask.TupleIsIntElem()).TupleSum()))==(hv_Mask.TupleLength());
  if (0 != (HTuple(hv_AllNumbers.TupleNot()).TupleAnd(hv_Mask!=HTuple())))
  {
    throw HException("Invalid type: Elements of Mask must be integer or real numbers.");
  }
  //
  //Use select_mask for tuples to generate a list of object indices.
  hv_Indices = HTuple::TupleGenSequence(1,hv_Mask.TupleLength(),1).TupleSelectMask(hv_Mask);
  SelectObj(ho_Objects, &(*ho_SelectedObjects), hv_Indices);
  return;
}

// Chapter: Graphics / Text
// Short Description: This procedure displays 'Click 'Run' to continue' in the lower right corner of the screen. 
void disp_continue_message (HTuple hv_WindowHandle, HTuple hv_Color, HTuple hv_Box)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_GenParamName, hv_GenParamValue, hv_ContinueMessage;

  //This procedure displays 'Press Run (F5) to continue' in the
  //lower right corner of the screen.
  //It uses the procedure disp_message.
  //
  //Input parameters:
  //WindowHandle: The window, where the text shall be displayed
  //Color: defines the text color.
  //   If set to '' or 'auto', the currently set color is used.
  //Box: If set to 'true', the text is displayed in a box.
  //
  //Convert the parameter Box to generic parameters.
  hv_GenParamName = HTuple();
  hv_GenParamValue = HTuple();
  if (0 != ((hv_Box.TupleLength())>0))
  {
    if (0 != (HTuple(hv_Box[0])==HTuple("false")))
    {
      //Display no box
      hv_GenParamName = hv_GenParamName.TupleConcat("box");
      hv_GenParamValue = hv_GenParamValue.TupleConcat("false");
    }
    else if (0 != (HTuple(hv_Box[0])!=HTuple("true")))
    {
      //Set a color other than the default.
      hv_GenParamName = hv_GenParamName.TupleConcat("box_color");
      hv_GenParamValue = hv_GenParamValue.TupleConcat(HTuple(hv_Box[0]));
    }
  }
  if (0 != ((hv_Box.TupleLength())>1))
  {
    if (0 != (HTuple(hv_Box[1])==HTuple("false")))
    {
      //Display no shadow.
      hv_GenParamName = hv_GenParamName.TupleConcat("shadow");
      hv_GenParamValue = hv_GenParamValue.TupleConcat("false");
    }
    else if (0 != (HTuple(hv_Box[1])!=HTuple("true")))
    {
      //Set a shadow color other than the default.
      hv_GenParamName = hv_GenParamName.TupleConcat("shadow_color");
      hv_GenParamValue = hv_GenParamValue.TupleConcat(HTuple(hv_Box[1]));
    }
  }
  //
  if (0 != (hv_Color==HTuple("")))
  {
    //disp_text does not accept an empty string for Color.
    hv_Color = HTuple();
  }
  //
  //Display the message.
  hv_ContinueMessage = "Press Run (F5) to continue";
  DispText(hv_WindowHandle, hv_ContinueMessage, "window", "bottom", "right", hv_Color, 
      hv_GenParamName, hv_GenParamValue);
  return;
}

// Chapter: Graphics / Output
// Short Description: Display the axes of a 3d coordinate system 
void disp_3d_coord_system (HTuple hv_WindowHandle, HTuple hv_CamParam, HTuple hv_Pose, 
    HTuple hv_CoordAxesLength)
{

  // Local iconic variables
  HObject  ho_Arrows;

  // Local control variables
  HTuple  hv_CameraType, hv_IsTelecentric, hv_TransWorld2Cam;
  HTuple  hv_OrigCamX, hv_OrigCamY, hv_OrigCamZ, hv_Row0;
  HTuple  hv_Column0, hv_X, hv_Y, hv_Z, hv_RowAxX, hv_ColumnAxX;
  HTuple  hv_RowAxY, hv_ColumnAxY, hv_RowAxZ, hv_ColumnAxZ;
  HTuple  hv_Distance, hv_HeadLength, hv_Red, hv_Green, hv_Blue;

  //This procedure displays a 3D coordinate system.
  //It needs the procedure gen_arrow_contour_xld.
  //
  //Input parameters:
  //WindowHandle: The window where the coordinate system shall be displayed
  //CamParam: The camera paramters
  //Pose: The pose to be displayed
  //CoordAxesLength: The length of the coordinate axes in world coordinates
  //
  //Check, if Pose is a correct pose tuple.
  if (0 != ((hv_Pose.TupleLength())!=7))
  {
    return;
  }
  get_cam_par_data(hv_CamParam, "camera_type", &hv_CameraType);
  hv_IsTelecentric = (hv_CameraType.TupleStrstr("telecentric"))!=-1;
  if (0 != (HTuple(HTuple(hv_Pose[2])==0.0).TupleAnd(hv_IsTelecentric.TupleNot())))
  {
    //For projective cameras:
    //Poses with Z position zero cannot be projected
    //(that would lead to a division by zero error).
    return;
  }
  //Convert to pose to a transformation matrix
  PoseToHomMat3d(hv_Pose, &hv_TransWorld2Cam);
  //Project the world origin into the image
  AffineTransPoint3d(hv_TransWorld2Cam, 0, 0, 0, &hv_OrigCamX, &hv_OrigCamY, &hv_OrigCamZ);
  Project3dPoint(hv_OrigCamX, hv_OrigCamY, hv_OrigCamZ, hv_CamParam, &hv_Row0, &hv_Column0);
  //Project the coordinate axes into the image
  AffineTransPoint3d(hv_TransWorld2Cam, hv_CoordAxesLength, 0, 0, &hv_X, &hv_Y, &hv_Z);
  Project3dPoint(hv_X, hv_Y, hv_Z, hv_CamParam, &hv_RowAxX, &hv_ColumnAxX);
  AffineTransPoint3d(hv_TransWorld2Cam, 0, hv_CoordAxesLength, 0, &hv_X, &hv_Y, &hv_Z);
  Project3dPoint(hv_X, hv_Y, hv_Z, hv_CamParam, &hv_RowAxY, &hv_ColumnAxY);
  AffineTransPoint3d(hv_TransWorld2Cam, 0, 0, hv_CoordAxesLength, &hv_X, &hv_Y, &hv_Z);
  Project3dPoint(hv_X, hv_Y, hv_Z, hv_CamParam, &hv_RowAxZ, &hv_ColumnAxZ);
  //
  //Generate an XLD contour for each axis
  DistancePp((hv_Row0.TupleConcat(hv_Row0)).TupleConcat(hv_Row0), (hv_Column0.TupleConcat(hv_Column0)).TupleConcat(hv_Column0), 
      (hv_RowAxX.TupleConcat(hv_RowAxY)).TupleConcat(hv_RowAxZ), (hv_ColumnAxX.TupleConcat(hv_ColumnAxY)).TupleConcat(hv_ColumnAxZ), 
      &hv_Distance);
  hv_HeadLength = ((((hv_Distance.TupleMax())/12.0).TupleConcat(5.0)).TupleMax()).TupleInt();
  gen_arrow_contour_xld(&ho_Arrows, (hv_Row0.TupleConcat(hv_Row0)).TupleConcat(hv_Row0), 
      (hv_Column0.TupleConcat(hv_Column0)).TupleConcat(hv_Column0), (hv_RowAxX.TupleConcat(hv_RowAxY)).TupleConcat(hv_RowAxZ), 
      (hv_ColumnAxX.TupleConcat(hv_ColumnAxY)).TupleConcat(hv_ColumnAxZ), hv_HeadLength, 
      hv_HeadLength);
  //
  //Display coordinate system
  DispXld(ho_Arrows, hv_WindowHandle);
  //
  GetRgb(hv_WindowHandle, &hv_Red, &hv_Green, &hv_Blue);
  SetRgb(hv_WindowHandle, HTuple(hv_Red[0]), HTuple(hv_Green[0]), HTuple(hv_Blue[0]));
  SetTposition(hv_WindowHandle, hv_RowAxX+3, hv_ColumnAxX+3);
  WriteString(hv_WindowHandle, "X");
  SetRgb(hv_WindowHandle, HTuple(hv_Red[1%(hv_Red.TupleLength())]), HTuple(hv_Green[1%(hv_Green.TupleLength())]), 
      HTuple(hv_Blue[1%(hv_Blue.TupleLength())]));
  SetTposition(hv_WindowHandle, hv_RowAxY+3, hv_ColumnAxY+3);
  WriteString(hv_WindowHandle, "Y");
  SetRgb(hv_WindowHandle, HTuple(hv_Red[2%(hv_Red.TupleLength())]), HTuple(hv_Green[2%(hv_Green.TupleLength())]), 
      HTuple(hv_Blue[2%(hv_Blue.TupleLength())]));
  SetTposition(hv_WindowHandle, hv_RowAxZ+3, hv_ColumnAxZ+3);
  WriteString(hv_WindowHandle, "Z");
  SetRgb(hv_WindowHandle, hv_Red, hv_Green, hv_Blue);
  return;
}

// Chapter: XLD / Creation
// Short Description: Creates an arrow shaped XLD contour. 
void gen_arrow_contour_xld (HObject *ho_Arrow, HTuple hv_Row1, HTuple hv_Column1, 
    HTuple hv_Row2, HTuple hv_Column2, HTuple hv_HeadLength, HTuple hv_HeadWidth)
{

  // Local iconic variables
  HObject  ho_TempArrow;

  // Local control variables
  HTuple  hv_Length, hv_ZeroLengthIndices, hv_DR;
  HTuple  hv_DC, hv_HalfHeadWidth, hv_RowP1, hv_ColP1, hv_RowP2;
  HTuple  hv_ColP2, hv_Index;

  //This procedure generates arrow shaped XLD contours,
  //pointing from (Row1, Column1) to (Row2, Column2).
  //If starting and end point are identical, a contour consisting
  //of a single point is returned.
  //
  //input parameteres:
  //Row1, Column1: Coordinates of the arrows' starting points
  //Row2, Column2: Coordinates of the arrows' end points
  //HeadLength, HeadWidth: Size of the arrow heads in pixels
  //
  //output parameter:
  //Arrow: The resulting XLD contour
  //
  //The input tuples Row1, Column1, Row2, and Column2 have to be of
  //the same length.
  //HeadLength and HeadWidth either have to be of the same length as
  //Row1, Column1, Row2, and Column2 or have to be a single element.
  //If one of the above restrictions is violated, an error will occur.
  //
  //
  //Init
  GenEmptyObj(&(*ho_Arrow));
  //
  //Calculate the arrow length
  DistancePp(hv_Row1, hv_Column1, hv_Row2, hv_Column2, &hv_Length);
  //
  //Mark arrows with identical start and end point
  //(set Length to -1 to avoid division-by-zero exception)
  hv_ZeroLengthIndices = hv_Length.TupleFind(0);
  if (0 != (hv_ZeroLengthIndices!=-1))
  {
    hv_Length[hv_ZeroLengthIndices] = -1;
  }
  //
  //Calculate auxiliary variables.
  hv_DR = (1.0*(hv_Row2-hv_Row1))/hv_Length;
  hv_DC = (1.0*(hv_Column2-hv_Column1))/hv_Length;
  hv_HalfHeadWidth = hv_HeadWidth/2.0;
  //
  //Calculate end points of the arrow head.
  hv_RowP1 = (hv_Row1+((hv_Length-hv_HeadLength)*hv_DR))+(hv_HalfHeadWidth*hv_DC);
  hv_ColP1 = (hv_Column1+((hv_Length-hv_HeadLength)*hv_DC))-(hv_HalfHeadWidth*hv_DR);
  hv_RowP2 = (hv_Row1+((hv_Length-hv_HeadLength)*hv_DR))-(hv_HalfHeadWidth*hv_DC);
  hv_ColP2 = (hv_Column1+((hv_Length-hv_HeadLength)*hv_DC))+(hv_HalfHeadWidth*hv_DR);
  //
  //Finally create output XLD contour for each input point pair
  {
  HTuple end_val45 = (hv_Length.TupleLength())-1;
  HTuple step_val45 = 1;
  for (hv_Index=0; hv_Index.Continue(end_val45, step_val45); hv_Index += step_val45)
  {
    if (0 != (HTuple(hv_Length[hv_Index])==-1))
    {
      //Create_ single points for arrows with identical start and end point
      GenContourPolygonXld(&ho_TempArrow, HTuple(hv_Row1[hv_Index]), HTuple(hv_Column1[hv_Index]));
    }
    else
    {
      //Create arrow contour
      GenContourPolygonXld(&ho_TempArrow, ((((HTuple(hv_Row1[hv_Index]).TupleConcat(HTuple(hv_Row2[hv_Index]))).TupleConcat(HTuple(hv_RowP1[hv_Index]))).TupleConcat(HTuple(hv_Row2[hv_Index]))).TupleConcat(HTuple(hv_RowP2[hv_Index]))).TupleConcat(HTuple(hv_Row2[hv_Index])), 
          ((((HTuple(hv_Column1[hv_Index]).TupleConcat(HTuple(hv_Column2[hv_Index]))).TupleConcat(HTuple(hv_ColP1[hv_Index]))).TupleConcat(HTuple(hv_Column2[hv_Index]))).TupleConcat(HTuple(hv_ColP2[hv_Index]))).TupleConcat(HTuple(hv_Column2[hv_Index])));
    }
    ConcatObj((*ho_Arrow), ho_TempArrow, &(*ho_Arrow));
  }
  }
  return;
}

// Chapter: Filters / Arithmetic
// Short Description: Scale the gray values of an image from the interval [Min,Max] to [0,255] 
void scale_image_range (HObject ho_Image, HObject *ho_ImageScaled, HTuple hv_Min, 
    HTuple hv_Max)
{

  // Local iconic variables
  HObject  ho_ImageSelected, ho_SelectedChannel;
  HObject  ho_LowerRegion, ho_UpperRegion, ho_ImageSelectedScaled;

  // Local control variables
  HTuple  hv_LowerLimit, hv_UpperLimit, hv_Mult;
  HTuple  hv_Add, hv_NumImages, hv_ImageIndex, hv_Channels;
  HTuple  hv_ChannelIndex, hv_MinGray, hv_MaxGray, hv_Range;

  //Convenience procedure to scale the gray values of the
  //input image Image from the interval [Min,Max]
  //to the interval [0,255] (default).
  //Gray values < 0 or > 255 (after scaling) are clipped.
  //
  //If the image shall be scaled to an interval different from [0,255],
  //this can be achieved by passing tuples with 2 values [From, To]
  //as Min and Max.
  //Example:
  //scale_image_range(Image:ImageScaled:[100,50],[200,250])
  //maps the gray values of Image from the interval [100,200] to [50,250].
  //All other gray values will be clipped.
  //
  //input parameters:
  //Image: the input image
  //Min: the minimum gray value which will be mapped to 0
  //     If a tuple with two values is given, the first value will
  //     be mapped to the second value.
  //Max: The maximum gray value which will be mapped to 255
  //     If a tuple with two values is given, the first value will
  //     be mapped to the second value.
  //
  //Output parameter:
  //ImageScale: the resulting scaled image.
  //
  if (0 != ((hv_Min.TupleLength())==2))
  {
    hv_LowerLimit = ((const HTuple&)hv_Min)[1];
    hv_Min = ((const HTuple&)hv_Min)[0];
  }
  else
  {
    hv_LowerLimit = 0.0;
  }
  if (0 != ((hv_Max.TupleLength())==2))
  {
    hv_UpperLimit = ((const HTuple&)hv_Max)[1];
    hv_Max = ((const HTuple&)hv_Max)[0];
  }
  else
  {
    hv_UpperLimit = 255.0;
  }
  //
  //Calculate scaling parameters.
  hv_Mult = ((hv_UpperLimit-hv_LowerLimit).TupleReal())/(hv_Max-hv_Min);
  hv_Add = ((-hv_Mult)*hv_Min)+hv_LowerLimit;
  //
  //Scale image.
  ScaleImage(ho_Image, &ho_Image, hv_Mult, hv_Add);
  //
  //Clip gray values if necessary.
  //This must be done for each image and channel separately.
  GenEmptyObj(&(*ho_ImageScaled));
  CountObj(ho_Image, &hv_NumImages);
  {
  HTuple end_val49 = hv_NumImages;
  HTuple step_val49 = 1;
  for (hv_ImageIndex=1; hv_ImageIndex.Continue(end_val49, step_val49); hv_ImageIndex += step_val49)
  {
    SelectObj(ho_Image, &ho_ImageSelected, hv_ImageIndex);
    CountChannels(ho_ImageSelected, &hv_Channels);
    {
    HTuple end_val52 = hv_Channels;
    HTuple step_val52 = 1;
    for (hv_ChannelIndex=1; hv_ChannelIndex.Continue(end_val52, step_val52); hv_ChannelIndex += step_val52)
    {
      AccessChannel(ho_ImageSelected, &ho_SelectedChannel, hv_ChannelIndex);
      MinMaxGray(ho_SelectedChannel, ho_SelectedChannel, 0, &hv_MinGray, &hv_MaxGray, 
          &hv_Range);
      Threshold(ho_SelectedChannel, &ho_LowerRegion, (hv_MinGray.TupleConcat(hv_LowerLimit)).TupleMin(), 
          hv_LowerLimit);
      Threshold(ho_SelectedChannel, &ho_UpperRegion, hv_UpperLimit, (hv_UpperLimit.TupleConcat(hv_MaxGray)).TupleMax());
      PaintRegion(ho_LowerRegion, ho_SelectedChannel, &ho_SelectedChannel, hv_LowerLimit, 
          "fill");
      PaintRegion(ho_UpperRegion, ho_SelectedChannel, &ho_SelectedChannel, hv_UpperLimit, 
          "fill");
      if (0 != (hv_ChannelIndex==1))
      {
        CopyObj(ho_SelectedChannel, &ho_ImageSelectedScaled, 1, 1);
      }
      else
      {
        AppendChannel(ho_ImageSelectedScaled, ho_SelectedChannel, &ho_ImageSelectedScaled
            );
      }
    }
    }
    ConcatObj((*ho_ImageScaled), ho_ImageSelectedScaled, &(*ho_ImageScaled));
  }
  }
  return;
}

// Chapter: Develop
// Short Description: Switch dev_update_pc, dev_update_var and dev_update_window to 'off'. 
void dev_update_off ()
{

  //This procedure sets different update settings to 'off'.
  //This is useful to get the best performance and reduce overhead.
  //
  // dev_update_pc(...); only in hdevelop
  // dev_update_var(...); only in hdevelop
  // dev_update_window(...); only in hdevelop
  return;
}

// Chapter: Develop
// Short Description: Resizes a graphics window with a given maximum extent such that it preserves the aspect ratio of a given width and height 
void dev_resize_window_fit_size (HTuple hv_Row, HTuple hv_Column, HTuple hv_Width, 
    HTuple hv_Height, HTuple hv_WidthLimit, HTuple hv_HeightLimit)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_MinWidth, hv_MaxWidth, hv_MinHeight;
  HTuple  hv_MaxHeight, hv_ResizeFactor, hv_TempWidth, hv_TempHeight;
  HTuple  hv_WindowWidth, hv_WindowHeight;

  //This procedure adjusts the size of the current window
  //such that it fits into the limits specified by WidthLimit
  //and HeightLimit, but also maintains the correct aspect ratio
  //given by Width and Height.
  //
  //If it is impossible to match the minimum and maximum extent requirements
  //at the same time (f.e. if the image is very long but narrow),
  //the maximum value gets a higher priority.
  //
  //Parse input tuple WidthLimit
  if (0 != (HTuple((hv_WidthLimit.TupleLength())==0).TupleOr(hv_WidthLimit<0)))
  {
    hv_MinWidth = 500;
    hv_MaxWidth = 800;
  }
  else if (0 != ((hv_WidthLimit.TupleLength())==1))
  {
    hv_MinWidth = 0;
    hv_MaxWidth = hv_WidthLimit;
  }
  else
  {
    hv_MinWidth = ((const HTuple&)hv_WidthLimit)[0];
    hv_MaxWidth = ((const HTuple&)hv_WidthLimit)[1];
  }
  //Parse input tuple HeightLimit
  if (0 != (HTuple((hv_HeightLimit.TupleLength())==0).TupleOr(hv_HeightLimit<0)))
  {
    hv_MinHeight = 400;
    hv_MaxHeight = 600;
  }
  else if (0 != ((hv_HeightLimit.TupleLength())==1))
  {
    hv_MinHeight = 0;
    hv_MaxHeight = hv_HeightLimit;
  }
  else
  {
    hv_MinHeight = ((const HTuple&)hv_HeightLimit)[0];
    hv_MaxHeight = ((const HTuple&)hv_HeightLimit)[1];
  }
  //
  //Test, if window size has to be changed.
  hv_ResizeFactor = 1;
  //First, expand window to the minimum extents (if necessary).
  if (0 != (HTuple(hv_MinWidth>hv_Width).TupleOr(hv_MinHeight>hv_Height)))
  {
    hv_ResizeFactor = (((hv_MinWidth.TupleReal())/hv_Width).TupleConcat((hv_MinHeight.TupleReal())/hv_Height)).TupleMax();
  }
  hv_TempWidth = hv_Width*hv_ResizeFactor;
  hv_TempHeight = hv_Height*hv_ResizeFactor;
  //Then, shrink window to maximum extents (if necessary).
  if (0 != (HTuple(hv_MaxWidth<hv_TempWidth).TupleOr(hv_MaxHeight<hv_TempHeight)))
  {
    hv_ResizeFactor = hv_ResizeFactor*((((hv_MaxWidth.TupleReal())/hv_TempWidth).TupleConcat((hv_MaxHeight.TupleReal())/hv_TempHeight)).TupleMin());
  }
  hv_WindowWidth = hv_Width*hv_ResizeFactor;
  hv_WindowHeight = hv_Height*hv_ResizeFactor;
  //Resize window
  if (HDevWindowStack::IsOpen())
    SetWindowExtents(HDevWindowStack::GetActive(),hv_Row, hv_Column, hv_WindowWidth, 
        hv_WindowHeight);
  if (HDevWindowStack::IsOpen())
    SetPart(HDevWindowStack::GetActive(),0, 0, hv_Height-1, hv_Width-1);
  return;
}

// Chapter: Develop
// Short Description: Switch dev_update_pc, dev_update_var and dev_update_window to 'on'. 
void dev_update_on ()
{

  //This procedure sets different update settings to 'on'.
  //
  // dev_update_pc(...); only in hdevelop
  // dev_update_var(...); only in hdevelop
  // dev_update_window(...); only in hdevelop
  return;
}

// Chapter: Calibration / Hand-Eye
// Short Description: Perform a hand-eye calibration with a stationary camera. 
void calibrate_hand_eye_stationary_cam_approx (HTuple hv_RobotTouchingPointInToolCoordinates, 
    HTuple hv_RowsTouchingPointInPlane, HTuple hv_ColumnsTouchingPointInPlane, HTupleVector/*{eTupleVector,Dim=1}*/ hvec_ToolInBasePoses, 
    HTuple hv_CalibObjectData, HTuple *hv_HandEyeCalibData)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_CamParam, hv_CalPlateThickness, hv_PlaneInCamPose;
  HTuple  hv_OrderOfTransform0, hv_OrderOfRotation0, hv_ViewOfTransform0;
  HTuple  hv_Index, hv_OrderOfTransform, hv_OrderOfRotation;
  HTuple  hv_ViewOfTransform, hv_TouchingPointInToolPose;
  HTuple  hv_XBase, hv_YBase, hv_ZBase, hv_TouchingPointInBasePose;
  HTuple  hv_XPlane, hv_YPlane, hv_ZPlane, hv_HomMat3DPlaneToBase;
  HTuple  hv_PlaneInBasePose, hv_BaseInPlanePose, hv_BaseInCamPose;
  HTuple  hv_XPlaneBase, hv_YPlaneBase, hv_ZPlaneBase, hv_DiffX;
  HTuple  hv_DiffY, hv_DiffZ, hv_SqrDiff, hv_PlanePointsRMS;
  HTuple  hv_PlanePointsMaxDiff;

  //
  read_message_tuple(hv_CalibObjectData, "CamParam", &hv_CamParam);
  read_message_tuple(hv_CalibObjectData, "CalPlateThickness", &hv_CalPlateThickness);
  read_message_tuple(hv_CalibObjectData, "PlaneInCamPose", &hv_PlaneInCamPose);
  //
  //Check input
  if (0 != (HTuple(HTuple((hv_RowsTouchingPointInPlane.TupleLength())<3).TupleOr((hv_ColumnsTouchingPointInPlane.TupleLength())<3)).TupleOr(HTuple(hvec_ToolInBasePoses.Length())<3)))
  {
    throw HException("Please specify at least three image coordinates and robot poses.");
  }
  if (0 != (HTuple((hv_RowsTouchingPointInPlane.TupleLength())!=(hv_ColumnsTouchingPointInPlane.TupleLength())).TupleOr((hv_RowsTouchingPointInPlane.TupleLength())!=HTuple(hvec_ToolInBasePoses.Length()))))
  {
    throw HException("The number of image coordinates and robot poses have to be equal.");
  }
  if (0 != (HTuple(hv_CamParam[0])==HTuple("line_scan")))
  {
    throw HException("Line-scan cameras are not supported");
  }
  //
  //If points on top of the calibration plate are approached, we have to adapt the PlaneInCamPose accordingly.
  SetOriginPose(hv_PlaneInCamPose, 0, 0, -hv_CalPlateThickness, &hv_PlaneInCamPose);
  //Keep track of the pose type used by the robot.
  GetPoseType(hvec_ToolInBasePoses[0].T(), &hv_OrderOfTransform0, &hv_OrderOfRotation0, 
      &hv_ViewOfTransform0);
  {
  HTuple ExpTmpOutVar_0;
  ConvertPoseType(hvec_ToolInBasePoses[0].T(), "Rp+T", "gba", "point", &ExpTmpOutVar_0);
  hvec_ToolInBasePoses[0].T() = ExpTmpOutVar_0;
  }
  {
  HTuple end_val21 = HTuple(hvec_ToolInBasePoses.Length())-1;
  HTuple step_val21 = 1;
  for (hv_Index=1; hv_Index.Continue(end_val21, step_val21); hv_Index += step_val21)
  {
    GetPoseType(hvec_ToolInBasePoses[hv_Index].T(), &hv_OrderOfTransform, &hv_OrderOfRotation, 
        &hv_ViewOfTransform);
    if (0 != (HTuple(HTuple(hv_OrderOfTransform0!=hv_OrderOfTransform).TupleOr(hv_OrderOfRotation0!=hv_OrderOfRotation)).TupleOr(hv_ViewOfTransform0!=hv_ViewOfTransform)))
    {
      throw HException("ToolInBasePoses have different pose types.");
    }
    //Convert to default pose type.
    {
    HTuple ExpTmpOutVar_0;
    ConvertPoseType(hvec_ToolInBasePoses[hv_Index].T(), "Rp+T", "gba", "point", &ExpTmpOutVar_0);
    hvec_ToolInBasePoses[hv_Index].T() = ExpTmpOutVar_0;
    }
  }
  }
  //
  //Collect the robot translations.
  CreatePose(HTuple(hv_RobotTouchingPointInToolCoordinates[0]), HTuple(hv_RobotTouchingPointInToolCoordinates[1]), 
      HTuple(hv_RobotTouchingPointInToolCoordinates[2]), 0, 0, 0, "Rp+T", "gba", 
      "point", &hv_TouchingPointInToolPose);
  hv_XBase = HTuple();
  hv_YBase = HTuple();
  hv_ZBase = HTuple();
  {
  HTuple end_val35 = (hv_RowsTouchingPointInPlane.TupleLength())-1;
  HTuple step_val35 = 1;
  for (hv_Index=0; hv_Index.Continue(end_val35, step_val35); hv_Index += step_val35)
  {
    PoseCompose(hvec_ToolInBasePoses[hv_Index].T(), hv_TouchingPointInToolPose, &hv_TouchingPointInBasePose);
    hv_XBase = hv_XBase.TupleConcat(HTuple(hv_TouchingPointInBasePose[0]));
    hv_YBase = hv_YBase.TupleConcat(HTuple(hv_TouchingPointInBasePose[1]));
    hv_ZBase = hv_ZBase.TupleConcat(HTuple(hv_TouchingPointInBasePose[2]));
  }
  }
  //
  //Get the plane coordinates of the input image points.
  ImagePointsToWorldPlane(hv_CamParam, hv_PlaneInCamPose, hv_RowsTouchingPointInPlane, 
      hv_ColumnsTouchingPointInPlane, "m", &hv_XPlane, &hv_YPlane);
  TupleGenConst(hv_XPlane.TupleLength(), 0, &hv_ZPlane);
  VectorToHomMat3d("rigid", hv_XPlane, hv_YPlane, hv_ZPlane, hv_XBase, hv_YBase, 
      hv_ZBase, &hv_HomMat3DPlaneToBase);
  HomMat3dToPose(hv_HomMat3DPlaneToBase, &hv_PlaneInBasePose);
  //If points on top of the calibration plate are approached, we have to readapt the Plane accordingly.
  SetOriginPose(hv_PlaneInCamPose, 0, 0, hv_CalPlateThickness, &hv_PlaneInCamPose);
  SetOriginPose(hv_PlaneInBasePose, 0, 0, hv_CalPlateThickness, &hv_PlaneInBasePose);
  PoseInvert(hv_PlaneInBasePose, &hv_BaseInPlanePose);
  PoseCompose(hv_PlaneInCamPose, hv_BaseInPlanePose, &hv_BaseInCamPose);
  //
  //Get the BaseInCamPose.
  PoseInvert(hv_PlaneInBasePose, &hv_BaseInPlanePose);
  PoseCompose(hv_PlaneInCamPose, hv_BaseInPlanePose, &hv_BaseInCamPose);
  //Convert to output pose type.
  ConvertPoseType(hv_BaseInCamPose, hv_OrderOfTransform0, hv_OrderOfRotation0, hv_ViewOfTransform0, 
      &hv_BaseInCamPose);
  ConvertPoseType(hv_PlaneInBasePose, hv_OrderOfTransform0, hv_OrderOfRotation0, 
      hv_ViewOfTransform0, &hv_PlaneInBasePose);

  //Get the difference of the points in the plane as seen by the camera
  //to the points in the plane as approached by the robot.
  AffineTransPoint3d(hv_HomMat3DPlaneToBase, hv_XPlane, hv_YPlane, hv_ZPlane, &hv_XPlaneBase, 
      &hv_YPlaneBase, &hv_ZPlaneBase);
  hv_DiffX = hv_XPlaneBase-hv_XBase;
  hv_DiffY = hv_YPlaneBase-hv_YBase;
  hv_DiffZ = hv_ZPlaneBase-hv_ZBase;
  hv_SqrDiff = ((hv_DiffX*hv_DiffX)+(hv_DiffY*hv_DiffY))+(hv_DiffZ*hv_DiffZ);
  hv_PlanePointsRMS = ((hv_SqrDiff.TupleSum())/(hv_DiffX.TupleLength())).TupleSqrt();
  hv_PlanePointsMaxDiff = (hv_SqrDiff.TupleSqrt()).TupleMax();
  //
  //Create output message.
  CreateMessage(&(*hv_HandEyeCalibData));
  SetMessageTuple((*hv_HandEyeCalibData), "CamParam", hv_CamParam);
  SetMessageTuple((*hv_HandEyeCalibData), "BaseInCamPose", hv_BaseInCamPose);
  SetMessageTuple((*hv_HandEyeCalibData), "PlaneInBasePose", hv_PlaneInBasePose);
  SetMessageTuple((*hv_HandEyeCalibData), "PlaneInCamPose0", hv_PlaneInCamPose);
  SetMessageTuple((*hv_HandEyeCalibData), "PlanePointsRMS", hv_PlanePointsRMS);
  SetMessageTuple((*hv_HandEyeCalibData), "PlanePointsMaxDiff", hv_PlanePointsMaxDiff);
  return;
}

// Chapter: Calibration / Hand-Eye
// Short Description: Perform a hand-eye calibration with a stationary camera. 
void calibrate_hand_eye_stationary_cam_approx_without_calib_plate (HTuple hv_RowsTouchingPointInPlane, 
    HTuple hv_ColumnsTouchingPointInPlane, HTupleVector/*{eTupleVector,Dim=1}*/ hvec_ToolInBasePoses, 
    HTuple hv_RobotTouchingPointInToolCoordinates, HTuple hv_DistanceObjectTouchingPointToPlane, 
    HTuple hv_DistancePlaneToCamera, HTuple hv_Width, HTuple hv_Height, HTuple *hv_HandEyeCalibData)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_OrderOfTransform0, hv_OrderOfRotation0;
  HTuple  hv_ViewOfTransform0, hv_Index, hv_OrderOfTransform;
  HTuple  hv_OrderOfRotation, hv_ViewOfTransform, hv_RobotTouchingPointToToolXYZPose;
  HTuple  hv_XBase, hv_YBase, hv_ZBase, hv_TouchingPointInBasePose;
  HTuple  hv_OM3DPlanePoints, hv_OM3DPlane, hv_TouchingPointPlaneInBasePose;
  HTuple  hv_FocusOrig, hv_DiffRow, hv_DiffCol, hv_DistPixel;
  HTuple  hv_DiffX, hv_DiffY, hv_DiffZ, hv_DistWorld, hv_Quotient;
  HTuple  hv_SX, hv_SY, hv_FocusShift, hv_BestIndex, hv_ErrorBasePoseInPixel;
  HTuple  hv_NumFocus, hv_Focus, hv_CamParam0, hv_BaseInCamPose0;
  HTuple  hv_ErrorBasePoseInPixelTmp, hv_BaseInCamPose, hv_CamParam;
  HTuple  hv_TouchingPointPlaneInCamPose, hv_TouchingPointPlaneInCamPose0Rot;
  HTuple  hv_HomMat3D, hv_Qx, hv_Qy, hv_CosAngleBetweenZAxis;
  HTuple  hv_SwitchZDirection, hv_TouchingPointPlaneInCamPose1;
  HTuple  hv_CamInBasePose, hv_TouchingPointPlanePointsCamX;
  HTuple  hv_TouchingPointPlanePointsCamY, hv_TouchingPointPlanePointsCamZ;
  HTuple  hv_BaseInTouchingPointPlanePose, hv_HomMat3D1, hv_TouchingPointPlanePointsToolX;
  HTuple  hv_TouchingPointPlanePointsToolY, hv_TouchingPointPlanePointsToolZ;
  HTuple  hv_SqrDiff, hv_PlanePointsRMS, hv_PlanePointsMaxDiff;
  HTuple  hv_PlaneInBasePose, hv_PlaneInCamPose;

  //Check input.
  if (0 != (HTuple(HTuple((hv_RowsTouchingPointInPlane.TupleLength())<4).TupleOr((hv_ColumnsTouchingPointInPlane.TupleLength())<4)).TupleOr(HTuple(hvec_ToolInBasePoses.Length())<4)))
  {
    throw HException("Please specify at least four image coordinates and robot poses.");
  }
  if (0 != (HTuple((hv_RowsTouchingPointInPlane.TupleLength())!=(hv_ColumnsTouchingPointInPlane.TupleLength())).TupleOr((hv_RowsTouchingPointInPlane.TupleLength())!=HTuple(hvec_ToolInBasePoses.Length()))))
  {
    throw HException("The number of image coordinates and robot poses have to be equal.");
  }
  if (0 != (HTuple(hv_Width<=0).TupleOr(hv_Height<=0)))
  {
    throw HException("Width or Height must be greater than 0.");
  }
  if (0 != (hv_DistancePlaneToCamera<=0))
  {
    throw HException("DistancePlaneToCamera must be greater than 0.");
  }
  if (0 != (hv_DistancePlaneToCamera<=0))
  {
    throw HException("DistanceObjectTouchingPointToPlane must be greater than 0.");
  }
  //
  //Keep track of the pose type used by the robot.
  GetPoseType(hvec_ToolInBasePoses[0].T(), &hv_OrderOfTransform0, &hv_OrderOfRotation0, 
      &hv_ViewOfTransform0);
  {
  HTuple ExpTmpOutVar_0;
  ConvertPoseType(hvec_ToolInBasePoses[0].T(), "Rp+T", "gba", "point", &ExpTmpOutVar_0);
  hvec_ToolInBasePoses[0].T() = ExpTmpOutVar_0;
  }
  {
  HTuple end_val20 = HTuple(hvec_ToolInBasePoses.Length())-1;
  HTuple step_val20 = 1;
  for (hv_Index=1; hv_Index.Continue(end_val20, step_val20); hv_Index += step_val20)
  {
    GetPoseType(hvec_ToolInBasePoses[hv_Index].T(), &hv_OrderOfTransform, &hv_OrderOfRotation, 
        &hv_ViewOfTransform);
    if (0 != (HTuple(HTuple(hv_OrderOfTransform0!=hv_OrderOfTransform).TupleOr(hv_OrderOfRotation0!=hv_OrderOfRotation)).TupleOr(hv_ViewOfTransform0!=hv_ViewOfTransform)))
    {
      throw HException("ToolInBasePoses have different pose types.");
    }
    //Convert to default pose type.
    {
    HTuple ExpTmpOutVar_0;
    ConvertPoseType(hvec_ToolInBasePoses[hv_Index].T(), "Rp+T", "gba", "point", &ExpTmpOutVar_0);
    hvec_ToolInBasePoses[hv_Index].T() = ExpTmpOutVar_0;
    }
  }
  }
  //
  //Collect the robot translations.
  CreatePose(HTuple(hv_RobotTouchingPointInToolCoordinates[0]), HTuple(hv_RobotTouchingPointInToolCoordinates[1]), 
      HTuple(hv_RobotTouchingPointInToolCoordinates[2]), 0, 0, 0, "Rp+T", "gba", 
      "point", &hv_RobotTouchingPointToToolXYZPose);
  hv_XBase = HTuple();
  hv_YBase = HTuple();
  hv_ZBase = HTuple();
  {
  HTuple end_val34 = (hv_RowsTouchingPointInPlane.TupleLength())-1;
  HTuple step_val34 = 1;
  for (hv_Index=0; hv_Index.Continue(end_val34, step_val34); hv_Index += step_val34)
  {
    PoseCompose(hvec_ToolInBasePoses[hv_Index].T(), hv_RobotTouchingPointToToolXYZPose, 
        &hv_TouchingPointInBasePose);
    hv_XBase = hv_XBase.TupleConcat(HTuple(hv_TouchingPointInBasePose[0]));
    hv_YBase = hv_YBase.TupleConcat(HTuple(hv_TouchingPointInBasePose[1]));
    hv_ZBase = hv_ZBase.TupleConcat(HTuple(hv_TouchingPointInBasePose[2]));
  }
  }
  //
  // Use the specified robot translations to obtain the PlaneInBasePose.
  GenObjectModel3dFromPoints(hv_XBase, hv_YBase, hv_ZBase, &hv_OM3DPlanePoints);
  FitPrimitivesObjectModel3d(hv_OM3DPlanePoints, "primitive_type", "plane", &hv_OM3DPlane);
  GetObjectModel3dParams(hv_OM3DPlane, "primitive_pose", &hv_TouchingPointPlaneInBasePose);
  //
  //Obtain fictitious camera parameters.
  hv_FocusOrig = 0.008;
  hv_DiffRow = (hv_RowsTouchingPointInPlane.TupleSelectRange(0,(hv_RowsTouchingPointInPlane.TupleLength())-2))-(hv_RowsTouchingPointInPlane.TupleSelectRange(1,(hv_RowsTouchingPointInPlane.TupleLength())-1));
  hv_DiffCol = (hv_ColumnsTouchingPointInPlane.TupleSelectRange(0,(hv_ColumnsTouchingPointInPlane.TupleLength())-2))-(hv_ColumnsTouchingPointInPlane.TupleSelectRange(1,(hv_ColumnsTouchingPointInPlane.TupleLength())-1));
  hv_DistPixel = ((hv_DiffRow*hv_DiffRow)+(hv_DiffCol*hv_DiffCol)).TupleSqrt();
  hv_DiffX = (hv_XBase.TupleSelectRange(0,(hv_XBase.TupleLength())-2))-(hv_XBase.TupleSelectRange(1,(hv_XBase.TupleLength())-1));
  hv_DiffY = (hv_YBase.TupleSelectRange(0,(hv_YBase.TupleLength())-2))-(hv_YBase.TupleSelectRange(1,(hv_YBase.TupleLength())-1));
  hv_DiffZ = (hv_ZBase.TupleSelectRange(0,(hv_ZBase.TupleLength())-2))-(hv_ZBase.TupleSelectRange(1,(hv_ZBase.TupleLength())-1));
  hv_DistWorld = (((hv_DiffX*hv_DiffX)+(hv_DiffY*hv_DiffY))+(hv_DiffZ*hv_DiffZ)).TupleSqrt();
  hv_Quotient = (hv_DistWorld/hv_DistPixel).TupleMedian();
  //Camera parameter will be generated in the following form:
  //SX := Quotient * FocusOrig / DistancePlaneToCamera
  //SY := SX
  //gen_cam_par_area_scan_division (FocusOrig, 0, SX, SY, Width / 2.0, Height / 2.0, Width, Height, HandEyeCalibData)
  //
  //Use the specified image points and robot translations to obtain the BaseInCamPose.
  hv_FocusShift.Clear();
  hv_FocusShift[0] = 0.1;
  hv_FocusShift[1] = 0.2;
  hv_FocusShift[2] = 0.33;
  hv_FocusShift[3] = 0.5;
  hv_FocusShift[4] = 0.75;
  hv_FocusShift[5] = 1.0;
  hv_FocusShift[6] = 1.5;
  hv_FocusShift[7] = 2;
  hv_FocusShift[8] = 3;
  hv_FocusShift[9] = 3.125;
  hv_FocusShift[10] = 3.5;
  hv_FocusShift[11] = 4;
  hv_BestIndex = -1;
  //The value of focus should not have much influence when camera and plane are parallel,
  //but just in case, check different values.
  hv_ErrorBasePoseInPixel = 1e9;
  {
  HTuple end_val67 = (hv_FocusShift.TupleLength())-1;
  HTuple step_val67 = 1;
  for (hv_NumFocus=0; hv_NumFocus.Continue(end_val67, step_val67); hv_NumFocus += step_val67)
  {
    hv_Focus = hv_FocusOrig*HTuple(hv_FocusShift[hv_NumFocus]);
    hv_SX = (hv_Quotient*hv_Focus)/hv_DistancePlaneToCamera;
    hv_SY = hv_SX;
    gen_cam_par_area_scan_division(hv_Focus, 0, hv_SX, hv_SY, hv_Width/2.0, hv_Height/2.0, 
        hv_Width, hv_Height, &hv_CamParam0);
    VectorToPose(hv_XBase, hv_YBase, hv_ZBase, hv_RowsTouchingPointInPlane, hv_ColumnsTouchingPointInPlane, 
        hv_CamParam0, "iterative", "error", &hv_BaseInCamPose0, &hv_ErrorBasePoseInPixelTmp);
    if (0 != (hv_ErrorBasePoseInPixel>hv_ErrorBasePoseInPixelTmp))
    {
      hv_BaseInCamPose = hv_BaseInCamPose0;
      hv_ErrorBasePoseInPixel = hv_ErrorBasePoseInPixelTmp;
      hv_CamParam = hv_CamParam0;
    }
  }
  }
  //Get the PlaneInCamPose.
  PoseCompose(hv_BaseInCamPose, hv_TouchingPointPlaneInBasePose, &hv_TouchingPointPlaneInCamPose);
  //
  //The z-axis of the plane should point away from the camera.
  hv_TouchingPointPlaneInCamPose0Rot = hv_TouchingPointPlaneInCamPose;
  hv_TouchingPointPlaneInCamPose0Rot[HTuple::TupleGenSequence(0,2,1)] = ((HTuple(0).Append(0)).Append(0));
  PoseToHomMat3d(hv_TouchingPointPlaneInCamPose0Rot, &hv_HomMat3D);
  AffineTransPoint3d(hv_HomMat3D, 0, 0, 1, &hv_Qx, &hv_Qy, &hv_CosAngleBetweenZAxis);
  if (0 != (hv_CosAngleBetweenZAxis<0))
  {
    CreatePose(0, 0, 0, 180, 0, 0, "Rp+T", "gba", "point", &hv_SwitchZDirection);
    PoseCompose(hv_TouchingPointPlaneInCamPose, hv_SwitchZDirection, &hv_TouchingPointPlaneInCamPose1);
    hv_TouchingPointPlaneInCamPose = hv_TouchingPointPlaneInCamPose1;
    PoseInvert(hv_BaseInCamPose, &hv_CamInBasePose);
    PoseCompose(hv_CamInBasePose, hv_TouchingPointPlaneInCamPose, &hv_TouchingPointPlaneInBasePose);
  }
  //
  //Get the difference of the points in the plane as seen by the camera
  //to the points in the plane as approached by the robot.
  ImagePointsToWorldPlane(hv_CamParam, hv_TouchingPointPlaneInCamPose, hv_RowsTouchingPointInPlane, 
      hv_ColumnsTouchingPointInPlane, "m", &hv_TouchingPointPlanePointsCamX, &hv_TouchingPointPlanePointsCamY);
  TupleGenConst(hv_TouchingPointPlanePointsCamY.TupleLength(), 0.0, &hv_TouchingPointPlanePointsCamZ);
  PoseInvert(hv_TouchingPointPlaneInBasePose, &hv_BaseInTouchingPointPlanePose);
  PoseToHomMat3d(hv_BaseInTouchingPointPlanePose, &hv_HomMat3D1);
  AffineTransPoint3d(hv_HomMat3D1, hv_XBase, hv_YBase, hv_ZBase, &hv_TouchingPointPlanePointsToolX, 
      &hv_TouchingPointPlanePointsToolY, &hv_TouchingPointPlanePointsToolZ);
  hv_DiffX = hv_TouchingPointPlanePointsCamX-hv_TouchingPointPlanePointsToolX;
  hv_DiffY = hv_TouchingPointPlanePointsCamY-hv_TouchingPointPlanePointsToolY;
  hv_DiffZ = hv_TouchingPointPlanePointsCamZ-hv_TouchingPointPlanePointsToolZ;
  hv_SqrDiff = ((hv_DiffX*hv_DiffX)+(hv_DiffY*hv_DiffY))+(hv_DiffZ*hv_DiffZ);
  hv_PlanePointsRMS = ((hv_SqrDiff.TupleSum())/(hv_DiffX.TupleLength())).TupleSqrt();
  hv_PlanePointsMaxDiff = (hv_SqrDiff.TupleSqrt()).TupleMax();
  //
  SetOriginPose(hv_TouchingPointPlaneInBasePose, 0, 0, hv_DistanceObjectTouchingPointToPlane, 
      &hv_PlaneInBasePose);
  SetOriginPose(hv_TouchingPointPlaneInCamPose, 0, 0, hv_DistanceObjectTouchingPointToPlane, 
      &hv_PlaneInCamPose);
  //
  //Convert to output pose type.
  ConvertPoseType(hv_BaseInCamPose, hv_OrderOfTransform0, hv_OrderOfRotation0, hv_ViewOfTransform0, 
      &hv_BaseInCamPose);
  ConvertPoseType(hv_PlaneInBasePose, hv_OrderOfTransform0, hv_OrderOfRotation0, 
      hv_ViewOfTransform0, &hv_PlaneInBasePose);
  ConvertPoseType(hv_PlaneInCamPose, hv_OrderOfTransform0, hv_OrderOfRotation0, hv_ViewOfTransform0, 
      &hv_PlaneInCamPose);
  //
  //Create output message.
  CreateMessage(&(*hv_HandEyeCalibData));
  SetMessageTuple((*hv_HandEyeCalibData), "CamParam", hv_CamParam);
  SetMessageTuple((*hv_HandEyeCalibData), "BaseInCamPose", hv_BaseInCamPose);
  SetMessageTuple((*hv_HandEyeCalibData), "PlaneInBasePose", hv_PlaneInBasePose);
  SetMessageTuple((*hv_HandEyeCalibData), "PlaneInCamPose0", hv_PlaneInCamPose);
  SetMessageTuple((*hv_HandEyeCalibData), "PlanePointsRMS", hv_PlanePointsRMS);
  SetMessageTuple((*hv_HandEyeCalibData), "PlanePointsMaxDiff", hv_PlanePointsMaxDiff);
  return;
}

// Chapter: Calibration / Hand-Eye
// Short Description: Calibrate the X, Y, Z coordinates of a touching point of a robot. 
void calibrate_robot_touching_point (HTuple hv_DataDir, HTuple *hv_RobotTouchingPointInToolCoordinates)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_WindowHandle, hv_WindowHandleGraphics;
  HTuple  hv_Index, hv_ToolInBasePoseTouchingPoint;
  HTupleVector  hvec_ToolInBasePosesTouchingPoint(1);

  //
  //Open a new window.
  open_new_window(&hv_WindowHandle, &hv_WindowHandleGraphics);
  //Display introduction.
  dev_disp_introduction(hv_WindowHandle, hv_WindowHandleGraphics);
  // stop(...); only in hdevelop
  //
  //Read three ToolInBasesPoses which are used
  //to calibrate the RobotTouchingPointInToolCoordinates.
  for (hv_Index=1; hv_Index<=3; hv_Index+=1)
  {
    ReadPose(((hv_DataDir+"tool_in_base_pose_touching_point_0")+hv_Index)+".dat", 
        &hv_ToolInBasePoseTouchingPoint);
    dev_disp_approach_pose_touching_point_instructions(hv_WindowHandle, hv_WindowHandleGraphics, 
        hv_Index);
    // stop(...); only in hdevelop
    //Collect poses in vector.
    hvec_ToolInBasePosesTouchingPoint[hv_Index-1] = HTupleVector(hv_ToolInBasePoseTouchingPoint);
  }
  HDevWindowStack::SetActive(hv_WindowHandleGraphics);
  if (HDevWindowStack::IsOpen())
    CloseWindow(HDevWindowStack::Pop());
  //
  //Calculate the coordinates of the touching point
  //of the robot with respect to the robot's tool.
  get_robot_touching_point_in_tool_coordinates(hvec_ToolInBasePosesTouchingPoint, 
      &(*hv_RobotTouchingPointInToolCoordinates));
  //
  //Visualize results.
  visualize_calibrated_touching_point((*hv_RobotTouchingPointInToolCoordinates), 
      hvec_ToolInBasePosesTouchingPoint, hv_WindowHandle);
  return;
}

// Chapter: Calibration / Camera Parameters
// Short Description: Generate a camera parameter tuple for an area scan camera with an object-side telecentric tilt lens and with distortions modeled by the polynomial model. 
void gen_cam_par_area_scan_tilt_object_side_telecentric_polynomial (HTuple hv_Magnification, 
    HTuple hv_K1, HTuple hv_K2, HTuple hv_K3, HTuple hv_P1, HTuple hv_P2, HTuple hv_ImagePlaneDist, 
    HTuple hv_Tilt, HTuple hv_Rot, HTuple hv_Sx, HTuple hv_Sy, HTuple hv_Cx, HTuple hv_Cy, 
    HTuple hv_ImageWidth, HTuple hv_ImageHeight, HTuple *hv_CameraParam)
{

  // Local iconic variables

  //Generate a camera parameter tuple for an area scan camera with
  //an object-side telecentric tilt lens and with distortions modeled
  //by the polynomial model.
  //
  (*hv_CameraParam).Clear();
  (*hv_CameraParam)[0] = "area_scan_tilt_object_side_telecentric_polynomial";
  (*hv_CameraParam).Append(hv_Magnification);
  (*hv_CameraParam).Append(hv_K1);
  (*hv_CameraParam).Append(hv_K2);
  (*hv_CameraParam).Append(hv_K3);
  (*hv_CameraParam).Append(hv_P1);
  (*hv_CameraParam).Append(hv_P2);
  (*hv_CameraParam).Append(hv_ImagePlaneDist);
  (*hv_CameraParam).Append(hv_Tilt);
  (*hv_CameraParam).Append(hv_Rot);
  (*hv_CameraParam).Append(hv_Sx);
  (*hv_CameraParam).Append(hv_Sy);
  (*hv_CameraParam).Append(hv_Cx);
  (*hv_CameraParam).Append(hv_Cy);
  (*hv_CameraParam).Append(hv_ImageWidth);
  (*hv_CameraParam).Append(hv_ImageHeight);
  return;
}

// Chapter: Calibration / Camera Parameters
// Short Description: Generate a camera parameter tuple for an area scan camera with a tilt lens and with distortions modeled by the polynomial model. 
void gen_cam_par_area_scan_tilt_polynomial (HTuple hv_Focus, HTuple hv_K1, HTuple hv_K2, 
    HTuple hv_K3, HTuple hv_P1, HTuple hv_P2, HTuple hv_ImagePlaneDist, HTuple hv_Tilt, 
    HTuple hv_Rot, HTuple hv_Sx, HTuple hv_Sy, HTuple hv_Cx, HTuple hv_Cy, HTuple hv_ImageWidth, 
    HTuple hv_ImageHeight, HTuple *hv_CameraParam)
{

  // Local iconic variables

  //Generate a camera parameter tuple for an area scan camera with
  //a tilt lens and with distortions modeled by the polynomial model.
  //
  (*hv_CameraParam).Clear();
  (*hv_CameraParam)[0] = "area_scan_tilt_polynomial";
  (*hv_CameraParam).Append(hv_Focus);
  (*hv_CameraParam).Append(hv_K1);
  (*hv_CameraParam).Append(hv_K2);
  (*hv_CameraParam).Append(hv_K3);
  (*hv_CameraParam).Append(hv_P1);
  (*hv_CameraParam).Append(hv_P2);
  (*hv_CameraParam).Append(hv_ImagePlaneDist);
  (*hv_CameraParam).Append(hv_Tilt);
  (*hv_CameraParam).Append(hv_Rot);
  (*hv_CameraParam).Append(hv_Sx);
  (*hv_CameraParam).Append(hv_Sy);
  (*hv_CameraParam).Append(hv_Cx);
  (*hv_CameraParam).Append(hv_Cy);
  (*hv_CameraParam).Append(hv_ImageWidth);
  (*hv_CameraParam).Append(hv_ImageHeight);
  return;
}

// Chapter: Calibration / Camera Parameters
// Short Description: Generate a camera parameter tuple for an area scan camera with a bilateral telecentric tilt lens and with distortions modeled by the polynomial model. 
void gen_cam_par_area_scan_tilt_bilateral_telecentric_polynomial (HTuple hv_Magnification, 
    HTuple hv_K1, HTuple hv_K2, HTuple hv_K3, HTuple hv_P1, HTuple hv_P2, HTuple hv_Tilt, 
    HTuple hv_Rot, HTuple hv_Sx, HTuple hv_Sy, HTuple hv_Cx, HTuple hv_Cy, HTuple hv_ImageWidth, 
    HTuple hv_ImageHeight, HTuple *hv_CameraParam)
{

  // Local iconic variables

  //Generate a camera parameter tuple for an area scan camera with
  //a bilateral telecentric tilt lens and with distortions modeled
  //by the polynomial model.
  //
  (*hv_CameraParam).Clear();
  (*hv_CameraParam)[0] = "area_scan_tilt_bilateral_telecentric_polynomial";
  (*hv_CameraParam).Append(hv_Magnification);
  (*hv_CameraParam).Append(hv_K1);
  (*hv_CameraParam).Append(hv_K2);
  (*hv_CameraParam).Append(hv_K3);
  (*hv_CameraParam).Append(hv_P1);
  (*hv_CameraParam).Append(hv_P2);
  (*hv_CameraParam).Append(hv_Tilt);
  (*hv_CameraParam).Append(hv_Rot);
  (*hv_CameraParam).Append(hv_Sx);
  (*hv_CameraParam).Append(hv_Sy);
  (*hv_CameraParam).Append(hv_Cx);
  (*hv_CameraParam).Append(hv_Cy);
  (*hv_CameraParam).Append(hv_ImageWidth);
  (*hv_CameraParam).Append(hv_ImageHeight);
  return;
}

// Chapter: Calibration / Monocular
// Short Description: Collect the data to calibrate a camera with a single image. 
void collect_single_image_calibration_data (HTuple hv_ImageCaltabFileName, HTuple hv_CalPlateDescr, 
    HTuple hv_CalPlateThickness, HTuple hv_StartCamParam, HTuple *hv_CalibObjectData)
{

  // Local iconic variables
  HObject  ho_ImageCaltab;

  // Local control variables
  HTuple  hv_FinderRow, hv_FinderColumn, hv_MarksPerRow;

  //
  //Read an image of the calibration plate
  //that is placed in the measurement plane of the robot.
  ReadImage(&ho_ImageCaltab, hv_ImageCaltabFileName);
  dev_disp_calibration_data_instructions(ho_ImageCaltab);
  // stop(...); only in hdevelop
  //
  //Specify the finder pattern of the calibration plate you used.
  //The information can usually be found in the used description file.
  hv_FinderRow.Clear();
  hv_FinderRow[0] = 13;
  hv_FinderRow[1] = 6;
  hv_FinderRow[2] = 6;
  hv_FinderRow[3] = 20;
  hv_FinderRow[4] = 20;
  hv_FinderColumn.Clear();
  hv_FinderColumn[0] = 15;
  hv_FinderColumn[1] = 6;
  hv_FinderColumn[2] = 24;
  hv_FinderColumn[3] = 6;
  hv_FinderColumn[4] = 24;
  //Specify the number of marks per row.
  hv_MarksPerRow = 31;
  //
  //Create output message.
  CreateMessage(&(*hv_CalibObjectData));
  SetMessageObj(ho_ImageCaltab, (*hv_CalibObjectData), "ImageCaltab");
  SetMessageTuple((*hv_CalibObjectData), "CalPlateDescr", hv_CalPlateDescr);
  SetMessageTuple((*hv_CalibObjectData), "CalPlateThickness", hv_CalPlateThickness);
  SetMessageTuple((*hv_CalibObjectData), "StartCamParam", hv_StartCamParam);
  SetMessageTuple((*hv_CalibObjectData), "FinderRow", hv_FinderRow);
  SetMessageTuple((*hv_CalibObjectData), "FinderColumn", hv_FinderColumn);
  SetMessageTuple((*hv_CalibObjectData), "MarksPerRow", hv_MarksPerRow);
  return;
}

// Chapter: Calibration / Camera Parameters
// Short Description: Get the names of the parameters in a camera parameter tuple. 
void get_cam_par_names (HTuple hv_CameraParam, HTuple *hv_CameraType, HTuple *hv_ParamNames)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_CameraParamAreaScanDivision, hv_CameraParamAreaScanPolynomial;
  HTuple  hv_CameraParamAreaScanTelecentricDivision, hv_CameraParamAreaScanTelecentricPolynomial;
  HTuple  hv_CameraParamAreaScanTiltDivision, hv_CameraParamAreaScanTiltPolynomial;
  HTuple  hv_CameraParamAreaScanImageSideTelecentricTiltDivision;
  HTuple  hv_CameraParamAreaScanImageSideTelecentricTiltPolynomial;
  HTuple  hv_CameraParamAreaScanBilateralTelecentricTiltDivision;
  HTuple  hv_CameraParamAreaScanBilateralTelecentricTiltPolynomial;
  HTuple  hv_CameraParamAreaScanObjectSideTelecentricTiltDivision;
  HTuple  hv_CameraParamAreaScanObjectSideTelecentricTiltPolynomial;
  HTuple  hv_CameraParamLinesScan, hv_CameraParamAreaScanTiltDivisionLegacy;
  HTuple  hv_CameraParamAreaScanTiltPolynomialLegacy, hv_CameraParamAreaScanTelecentricDivisionLegacy;
  HTuple  hv_CameraParamAreaScanTelecentricPolynomialLegacy;
  HTuple  hv_CameraParamAreaScanBilateralTelecentricTiltDivisionLegacy;
  HTuple  hv_CameraParamAreaScanBilateralTelecentricTiltPolynomialLegacy;

  //get_cam_par_names returns for each element in the camera
  //parameter tuple that is passed in CameraParam the name
  //of the respective camera parameter. The parameter names
  //are returned in ParamNames. Additionally, the camera
  //type is returned in CameraType. Alternatively, instead of
  //the camera parameters, the camera type can be passed in
  //CameraParam in form of one of the following strings:
  //  - 'area_scan_division'
  //  - 'area_scan_polynomial'
  //  - 'area_scan_tilt_division'
  //  - 'area_scan_tilt_polynomial'
  //  - 'area_scan_telecentric_division'
  //  - 'area_scan_telecentric_polynomial'
  //  - 'area_scan_tilt_bilateral_telecentric_division'
  //  - 'area_scan_tilt_bilateral_telecentric_polynomial'
  //  - 'area_scan_tilt_object_side_telecentric_division'
  //  - 'area_scan_tilt_object_side_telecentric_polynomial'
  //  - 'line_scan'
  //
  hv_CameraParamAreaScanDivision.Clear();
  hv_CameraParamAreaScanDivision[0] = "focus";
  hv_CameraParamAreaScanDivision[1] = "kappa";
  hv_CameraParamAreaScanDivision[2] = "sx";
  hv_CameraParamAreaScanDivision[3] = "sy";
  hv_CameraParamAreaScanDivision[4] = "cx";
  hv_CameraParamAreaScanDivision[5] = "cy";
  hv_CameraParamAreaScanDivision[6] = "image_width";
  hv_CameraParamAreaScanDivision[7] = "image_height";
  hv_CameraParamAreaScanPolynomial.Clear();
  hv_CameraParamAreaScanPolynomial[0] = "focus";
  hv_CameraParamAreaScanPolynomial[1] = "k1";
  hv_CameraParamAreaScanPolynomial[2] = "k2";
  hv_CameraParamAreaScanPolynomial[3] = "k3";
  hv_CameraParamAreaScanPolynomial[4] = "p1";
  hv_CameraParamAreaScanPolynomial[5] = "p2";
  hv_CameraParamAreaScanPolynomial[6] = "sx";
  hv_CameraParamAreaScanPolynomial[7] = "sy";
  hv_CameraParamAreaScanPolynomial[8] = "cx";
  hv_CameraParamAreaScanPolynomial[9] = "cy";
  hv_CameraParamAreaScanPolynomial[10] = "image_width";
  hv_CameraParamAreaScanPolynomial[11] = "image_height";
  hv_CameraParamAreaScanTelecentricDivision.Clear();
  hv_CameraParamAreaScanTelecentricDivision[0] = "magnification";
  hv_CameraParamAreaScanTelecentricDivision[1] = "kappa";
  hv_CameraParamAreaScanTelecentricDivision[2] = "sx";
  hv_CameraParamAreaScanTelecentricDivision[3] = "sy";
  hv_CameraParamAreaScanTelecentricDivision[4] = "cx";
  hv_CameraParamAreaScanTelecentricDivision[5] = "cy";
  hv_CameraParamAreaScanTelecentricDivision[6] = "image_width";
  hv_CameraParamAreaScanTelecentricDivision[7] = "image_height";
  hv_CameraParamAreaScanTelecentricPolynomial.Clear();
  hv_CameraParamAreaScanTelecentricPolynomial[0] = "magnification";
  hv_CameraParamAreaScanTelecentricPolynomial[1] = "k1";
  hv_CameraParamAreaScanTelecentricPolynomial[2] = "k2";
  hv_CameraParamAreaScanTelecentricPolynomial[3] = "k3";
  hv_CameraParamAreaScanTelecentricPolynomial[4] = "p1";
  hv_CameraParamAreaScanTelecentricPolynomial[5] = "p2";
  hv_CameraParamAreaScanTelecentricPolynomial[6] = "sx";
  hv_CameraParamAreaScanTelecentricPolynomial[7] = "sy";
  hv_CameraParamAreaScanTelecentricPolynomial[8] = "cx";
  hv_CameraParamAreaScanTelecentricPolynomial[9] = "cy";
  hv_CameraParamAreaScanTelecentricPolynomial[10] = "image_width";
  hv_CameraParamAreaScanTelecentricPolynomial[11] = "image_height";
  hv_CameraParamAreaScanTiltDivision.Clear();
  hv_CameraParamAreaScanTiltDivision[0] = "focus";
  hv_CameraParamAreaScanTiltDivision[1] = "kappa";
  hv_CameraParamAreaScanTiltDivision[2] = "image_plane_dist";
  hv_CameraParamAreaScanTiltDivision[3] = "tilt";
  hv_CameraParamAreaScanTiltDivision[4] = "rot";
  hv_CameraParamAreaScanTiltDivision[5] = "sx";
  hv_CameraParamAreaScanTiltDivision[6] = "sy";
  hv_CameraParamAreaScanTiltDivision[7] = "cx";
  hv_CameraParamAreaScanTiltDivision[8] = "cy";
  hv_CameraParamAreaScanTiltDivision[9] = "image_width";
  hv_CameraParamAreaScanTiltDivision[10] = "image_height";
  hv_CameraParamAreaScanTiltPolynomial.Clear();
  hv_CameraParamAreaScanTiltPolynomial[0] = "focus";
  hv_CameraParamAreaScanTiltPolynomial[1] = "k1";
  hv_CameraParamAreaScanTiltPolynomial[2] = "k2";
  hv_CameraParamAreaScanTiltPolynomial[3] = "k3";
  hv_CameraParamAreaScanTiltPolynomial[4] = "p1";
  hv_CameraParamAreaScanTiltPolynomial[5] = "p2";
  hv_CameraParamAreaScanTiltPolynomial[6] = "image_plane_dist";
  hv_CameraParamAreaScanTiltPolynomial[7] = "tilt";
  hv_CameraParamAreaScanTiltPolynomial[8] = "rot";
  hv_CameraParamAreaScanTiltPolynomial[9] = "sx";
  hv_CameraParamAreaScanTiltPolynomial[10] = "sy";
  hv_CameraParamAreaScanTiltPolynomial[11] = "cx";
  hv_CameraParamAreaScanTiltPolynomial[12] = "cy";
  hv_CameraParamAreaScanTiltPolynomial[13] = "image_width";
  hv_CameraParamAreaScanTiltPolynomial[14] = "image_height";
  hv_CameraParamAreaScanImageSideTelecentricTiltDivision.Clear();
  hv_CameraParamAreaScanImageSideTelecentricTiltDivision[0] = "focus";
  hv_CameraParamAreaScanImageSideTelecentricTiltDivision[1] = "kappa";
  hv_CameraParamAreaScanImageSideTelecentricTiltDivision[2] = "tilt";
  hv_CameraParamAreaScanImageSideTelecentricTiltDivision[3] = "rot";
  hv_CameraParamAreaScanImageSideTelecentricTiltDivision[4] = "sx";
  hv_CameraParamAreaScanImageSideTelecentricTiltDivision[5] = "sy";
  hv_CameraParamAreaScanImageSideTelecentricTiltDivision[6] = "cx";
  hv_CameraParamAreaScanImageSideTelecentricTiltDivision[7] = "cy";
  hv_CameraParamAreaScanImageSideTelecentricTiltDivision[8] = "image_width";
  hv_CameraParamAreaScanImageSideTelecentricTiltDivision[9] = "image_height";
  hv_CameraParamAreaScanImageSideTelecentricTiltPolynomial.Clear();
  hv_CameraParamAreaScanImageSideTelecentricTiltPolynomial[0] = "focus";
  hv_CameraParamAreaScanImageSideTelecentricTiltPolynomial[1] = "k1";
  hv_CameraParamAreaScanImageSideTelecentricTiltPolynomial[2] = "k2";
  hv_CameraParamAreaScanImageSideTelecentricTiltPolynomial[3] = "k3";
  hv_CameraParamAreaScanImageSideTelecentricTiltPolynomial[4] = "p1";
  hv_CameraParamAreaScanImageSideTelecentricTiltPolynomial[5] = "p2";
  hv_CameraParamAreaScanImageSideTelecentricTiltPolynomial[6] = "tilt";
  hv_CameraParamAreaScanImageSideTelecentricTiltPolynomial[7] = "rot";
  hv_CameraParamAreaScanImageSideTelecentricTiltPolynomial[8] = "sx";
  hv_CameraParamAreaScanImageSideTelecentricTiltPolynomial[9] = "sy";
  hv_CameraParamAreaScanImageSideTelecentricTiltPolynomial[10] = "cx";
  hv_CameraParamAreaScanImageSideTelecentricTiltPolynomial[11] = "cy";
  hv_CameraParamAreaScanImageSideTelecentricTiltPolynomial[12] = "image_width";
  hv_CameraParamAreaScanImageSideTelecentricTiltPolynomial[13] = "image_height";
  hv_CameraParamAreaScanBilateralTelecentricTiltDivision.Clear();
  hv_CameraParamAreaScanBilateralTelecentricTiltDivision[0] = "magnification";
  hv_CameraParamAreaScanBilateralTelecentricTiltDivision[1] = "kappa";
  hv_CameraParamAreaScanBilateralTelecentricTiltDivision[2] = "tilt";
  hv_CameraParamAreaScanBilateralTelecentricTiltDivision[3] = "rot";
  hv_CameraParamAreaScanBilateralTelecentricTiltDivision[4] = "sx";
  hv_CameraParamAreaScanBilateralTelecentricTiltDivision[5] = "sy";
  hv_CameraParamAreaScanBilateralTelecentricTiltDivision[6] = "cx";
  hv_CameraParamAreaScanBilateralTelecentricTiltDivision[7] = "cy";
  hv_CameraParamAreaScanBilateralTelecentricTiltDivision[8] = "image_width";
  hv_CameraParamAreaScanBilateralTelecentricTiltDivision[9] = "image_height";
  hv_CameraParamAreaScanBilateralTelecentricTiltPolynomial.Clear();
  hv_CameraParamAreaScanBilateralTelecentricTiltPolynomial[0] = "magnification";
  hv_CameraParamAreaScanBilateralTelecentricTiltPolynomial[1] = "k1";
  hv_CameraParamAreaScanBilateralTelecentricTiltPolynomial[2] = "k2";
  hv_CameraParamAreaScanBilateralTelecentricTiltPolynomial[3] = "k3";
  hv_CameraParamAreaScanBilateralTelecentricTiltPolynomial[4] = "p1";
  hv_CameraParamAreaScanBilateralTelecentricTiltPolynomial[5] = "p2";
  hv_CameraParamAreaScanBilateralTelecentricTiltPolynomial[6] = "tilt";
  hv_CameraParamAreaScanBilateralTelecentricTiltPolynomial[7] = "rot";
  hv_CameraParamAreaScanBilateralTelecentricTiltPolynomial[8] = "sx";
  hv_CameraParamAreaScanBilateralTelecentricTiltPolynomial[9] = "sy";
  hv_CameraParamAreaScanBilateralTelecentricTiltPolynomial[10] = "cx";
  hv_CameraParamAreaScanBilateralTelecentricTiltPolynomial[11] = "cy";
  hv_CameraParamAreaScanBilateralTelecentricTiltPolynomial[12] = "image_width";
  hv_CameraParamAreaScanBilateralTelecentricTiltPolynomial[13] = "image_height";
  hv_CameraParamAreaScanObjectSideTelecentricTiltDivision.Clear();
  hv_CameraParamAreaScanObjectSideTelecentricTiltDivision[0] = "magnification";
  hv_CameraParamAreaScanObjectSideTelecentricTiltDivision[1] = "kappa";
  hv_CameraParamAreaScanObjectSideTelecentricTiltDivision[2] = "image_plane_dist";
  hv_CameraParamAreaScanObjectSideTelecentricTiltDivision[3] = "tilt";
  hv_CameraParamAreaScanObjectSideTelecentricTiltDivision[4] = "rot";
  hv_CameraParamAreaScanObjectSideTelecentricTiltDivision[5] = "sx";
  hv_CameraParamAreaScanObjectSideTelecentricTiltDivision[6] = "sy";
  hv_CameraParamAreaScanObjectSideTelecentricTiltDivision[7] = "cx";
  hv_CameraParamAreaScanObjectSideTelecentricTiltDivision[8] = "cy";
  hv_CameraParamAreaScanObjectSideTelecentricTiltDivision[9] = "image_width";
  hv_CameraParamAreaScanObjectSideTelecentricTiltDivision[10] = "image_height";
  hv_CameraParamAreaScanObjectSideTelecentricTiltPolynomial.Clear();
  hv_CameraParamAreaScanObjectSideTelecentricTiltPolynomial[0] = "magnification";
  hv_CameraParamAreaScanObjectSideTelecentricTiltPolynomial[1] = "k1";
  hv_CameraParamAreaScanObjectSideTelecentricTiltPolynomial[2] = "k2";
  hv_CameraParamAreaScanObjectSideTelecentricTiltPolynomial[3] = "k3";
  hv_CameraParamAreaScanObjectSideTelecentricTiltPolynomial[4] = "p1";
  hv_CameraParamAreaScanObjectSideTelecentricTiltPolynomial[5] = "p2";
  hv_CameraParamAreaScanObjectSideTelecentricTiltPolynomial[6] = "image_plane_dist";
  hv_CameraParamAreaScanObjectSideTelecentricTiltPolynomial[7] = "tilt";
  hv_CameraParamAreaScanObjectSideTelecentricTiltPolynomial[8] = "rot";
  hv_CameraParamAreaScanObjectSideTelecentricTiltPolynomial[9] = "sx";
  hv_CameraParamAreaScanObjectSideTelecentricTiltPolynomial[10] = "sy";
  hv_CameraParamAreaScanObjectSideTelecentricTiltPolynomial[11] = "cx";
  hv_CameraParamAreaScanObjectSideTelecentricTiltPolynomial[12] = "cy";
  hv_CameraParamAreaScanObjectSideTelecentricTiltPolynomial[13] = "image_width";
  hv_CameraParamAreaScanObjectSideTelecentricTiltPolynomial[14] = "image_height";
  hv_CameraParamLinesScan.Clear();
  hv_CameraParamLinesScan[0] = "focus";
  hv_CameraParamLinesScan[1] = "kappa";
  hv_CameraParamLinesScan[2] = "sx";
  hv_CameraParamLinesScan[3] = "sy";
  hv_CameraParamLinesScan[4] = "cx";
  hv_CameraParamLinesScan[5] = "cy";
  hv_CameraParamLinesScan[6] = "image_width";
  hv_CameraParamLinesScan[7] = "image_height";
  hv_CameraParamLinesScan[8] = "vx";
  hv_CameraParamLinesScan[9] = "vy";
  hv_CameraParamLinesScan[10] = "vz";
  //Legacy parameter names
  hv_CameraParamAreaScanTiltDivisionLegacy.Clear();
  hv_CameraParamAreaScanTiltDivisionLegacy[0] = "focus";
  hv_CameraParamAreaScanTiltDivisionLegacy[1] = "kappa";
  hv_CameraParamAreaScanTiltDivisionLegacy[2] = "tilt";
  hv_CameraParamAreaScanTiltDivisionLegacy[3] = "rot";
  hv_CameraParamAreaScanTiltDivisionLegacy[4] = "sx";
  hv_CameraParamAreaScanTiltDivisionLegacy[5] = "sy";
  hv_CameraParamAreaScanTiltDivisionLegacy[6] = "cx";
  hv_CameraParamAreaScanTiltDivisionLegacy[7] = "cy";
  hv_CameraParamAreaScanTiltDivisionLegacy[8] = "image_width";
  hv_CameraParamAreaScanTiltDivisionLegacy[9] = "image_height";
  hv_CameraParamAreaScanTiltPolynomialLegacy.Clear();
  hv_CameraParamAreaScanTiltPolynomialLegacy[0] = "focus";
  hv_CameraParamAreaScanTiltPolynomialLegacy[1] = "k1";
  hv_CameraParamAreaScanTiltPolynomialLegacy[2] = "k2";
  hv_CameraParamAreaScanTiltPolynomialLegacy[3] = "k3";
  hv_CameraParamAreaScanTiltPolynomialLegacy[4] = "p1";
  hv_CameraParamAreaScanTiltPolynomialLegacy[5] = "p2";
  hv_CameraParamAreaScanTiltPolynomialLegacy[6] = "tilt";
  hv_CameraParamAreaScanTiltPolynomialLegacy[7] = "rot";
  hv_CameraParamAreaScanTiltPolynomialLegacy[8] = "sx";
  hv_CameraParamAreaScanTiltPolynomialLegacy[9] = "sy";
  hv_CameraParamAreaScanTiltPolynomialLegacy[10] = "cx";
  hv_CameraParamAreaScanTiltPolynomialLegacy[11] = "cy";
  hv_CameraParamAreaScanTiltPolynomialLegacy[12] = "image_width";
  hv_CameraParamAreaScanTiltPolynomialLegacy[13] = "image_height";
  hv_CameraParamAreaScanTelecentricDivisionLegacy.Clear();
  hv_CameraParamAreaScanTelecentricDivisionLegacy[0] = "focus";
  hv_CameraParamAreaScanTelecentricDivisionLegacy[1] = "kappa";
  hv_CameraParamAreaScanTelecentricDivisionLegacy[2] = "sx";
  hv_CameraParamAreaScanTelecentricDivisionLegacy[3] = "sy";
  hv_CameraParamAreaScanTelecentricDivisionLegacy[4] = "cx";
  hv_CameraParamAreaScanTelecentricDivisionLegacy[5] = "cy";
  hv_CameraParamAreaScanTelecentricDivisionLegacy[6] = "image_width";
  hv_CameraParamAreaScanTelecentricDivisionLegacy[7] = "image_height";
  hv_CameraParamAreaScanTelecentricPolynomialLegacy.Clear();
  hv_CameraParamAreaScanTelecentricPolynomialLegacy[0] = "focus";
  hv_CameraParamAreaScanTelecentricPolynomialLegacy[1] = "k1";
  hv_CameraParamAreaScanTelecentricPolynomialLegacy[2] = "k2";
  hv_CameraParamAreaScanTelecentricPolynomialLegacy[3] = "k3";
  hv_CameraParamAreaScanTelecentricPolynomialLegacy[4] = "p1";
  hv_CameraParamAreaScanTelecentricPolynomialLegacy[5] = "p2";
  hv_CameraParamAreaScanTelecentricPolynomialLegacy[6] = "sx";
  hv_CameraParamAreaScanTelecentricPolynomialLegacy[7] = "sy";
  hv_CameraParamAreaScanTelecentricPolynomialLegacy[8] = "cx";
  hv_CameraParamAreaScanTelecentricPolynomialLegacy[9] = "cy";
  hv_CameraParamAreaScanTelecentricPolynomialLegacy[10] = "image_width";
  hv_CameraParamAreaScanTelecentricPolynomialLegacy[11] = "image_height";
  hv_CameraParamAreaScanBilateralTelecentricTiltDivisionLegacy.Clear();
  hv_CameraParamAreaScanBilateralTelecentricTiltDivisionLegacy[0] = "focus";
  hv_CameraParamAreaScanBilateralTelecentricTiltDivisionLegacy[1] = "kappa";
  hv_CameraParamAreaScanBilateralTelecentricTiltDivisionLegacy[2] = "tilt";
  hv_CameraParamAreaScanBilateralTelecentricTiltDivisionLegacy[3] = "rot";
  hv_CameraParamAreaScanBilateralTelecentricTiltDivisionLegacy[4] = "sx";
  hv_CameraParamAreaScanBilateralTelecentricTiltDivisionLegacy[5] = "sy";
  hv_CameraParamAreaScanBilateralTelecentricTiltDivisionLegacy[6] = "cx";
  hv_CameraParamAreaScanBilateralTelecentricTiltDivisionLegacy[7] = "cy";
  hv_CameraParamAreaScanBilateralTelecentricTiltDivisionLegacy[8] = "image_width";
  hv_CameraParamAreaScanBilateralTelecentricTiltDivisionLegacy[9] = "image_height";
  hv_CameraParamAreaScanBilateralTelecentricTiltPolynomialLegacy.Clear();
  hv_CameraParamAreaScanBilateralTelecentricTiltPolynomialLegacy[0] = "focus";
  hv_CameraParamAreaScanBilateralTelecentricTiltPolynomialLegacy[1] = "k1";
  hv_CameraParamAreaScanBilateralTelecentricTiltPolynomialLegacy[2] = "k2";
  hv_CameraParamAreaScanBilateralTelecentricTiltPolynomialLegacy[3] = "k3";
  hv_CameraParamAreaScanBilateralTelecentricTiltPolynomialLegacy[4] = "p1";
  hv_CameraParamAreaScanBilateralTelecentricTiltPolynomialLegacy[5] = "p2";
  hv_CameraParamAreaScanBilateralTelecentricTiltPolynomialLegacy[6] = "tilt";
  hv_CameraParamAreaScanBilateralTelecentricTiltPolynomialLegacy[7] = "rot";
  hv_CameraParamAreaScanBilateralTelecentricTiltPolynomialLegacy[8] = "sx";
  hv_CameraParamAreaScanBilateralTelecentricTiltPolynomialLegacy[9] = "sy";
  hv_CameraParamAreaScanBilateralTelecentricTiltPolynomialLegacy[10] = "cx";
  hv_CameraParamAreaScanBilateralTelecentricTiltPolynomialLegacy[11] = "cy";
  hv_CameraParamAreaScanBilateralTelecentricTiltPolynomialLegacy[12] = "image_width";
  hv_CameraParamAreaScanBilateralTelecentricTiltPolynomialLegacy[13] = "image_height";
  //
  //If the camera type is passed in CameraParam
  if (0 != (HTuple((hv_CameraParam.TupleLength())==1).TupleAnd(HTuple(hv_CameraParam[0]).TupleIsString())))
  {
    (*hv_CameraType) = ((const HTuple&)hv_CameraParam)[0];
    if (0 != ((*hv_CameraType)==HTuple("area_scan_division")))
    {
      (*hv_ParamNames).Clear();
      (*hv_ParamNames)[0] = "camera_type";
      (*hv_ParamNames).Append(hv_CameraParamAreaScanDivision);
    }
    else if (0 != ((*hv_CameraType)==HTuple("area_scan_polynomial")))
    {
      (*hv_ParamNames).Clear();
      (*hv_ParamNames)[0] = "camera_type";
      (*hv_ParamNames).Append(hv_CameraParamAreaScanPolynomial);
    }
    else if (0 != ((*hv_CameraType)==HTuple("area_scan_telecentric_division")))
    {
      (*hv_ParamNames).Clear();
      (*hv_ParamNames)[0] = "camera_type";
      (*hv_ParamNames).Append(hv_CameraParamAreaScanTelecentricDivision);
    }
    else if (0 != ((*hv_CameraType)==HTuple("area_scan_telecentric_polynomial")))
    {
      (*hv_ParamNames).Clear();
      (*hv_ParamNames)[0] = "camera_type";
      (*hv_ParamNames).Append(hv_CameraParamAreaScanTelecentricPolynomial);
    }
    else if (0 != ((*hv_CameraType)==HTuple("area_scan_tilt_division")))
    {
      (*hv_ParamNames).Clear();
      (*hv_ParamNames)[0] = "camera_type";
      (*hv_ParamNames).Append(hv_CameraParamAreaScanTiltDivision);
    }
    else if (0 != ((*hv_CameraType)==HTuple("area_scan_tilt_polynomial")))
    {
      (*hv_ParamNames).Clear();
      (*hv_ParamNames)[0] = "camera_type";
      (*hv_ParamNames).Append(hv_CameraParamAreaScanTiltPolynomial);
    }
    else if (0 != ((*hv_CameraType)==HTuple("area_scan_tilt_image_side_telecentric_division")))
    {
      (*hv_ParamNames).Clear();
      (*hv_ParamNames)[0] = "camera_type";
      (*hv_ParamNames).Append(hv_CameraParamAreaScanImageSideTelecentricTiltDivision);
    }
    else if (0 != ((*hv_CameraType)==HTuple("area_scan_tilt_image_side_telecentric_polynomial")))
    {
      (*hv_ParamNames).Clear();
      (*hv_ParamNames)[0] = "camera_type";
      (*hv_ParamNames).Append(hv_CameraParamAreaScanImageSideTelecentricTiltPolynomial);
    }
    else if (0 != ((*hv_CameraType)==HTuple("area_scan_tilt_bilateral_telecentric_division")))
    {
      (*hv_ParamNames).Clear();
      (*hv_ParamNames)[0] = "camera_type";
      (*hv_ParamNames).Append(hv_CameraParamAreaScanBilateralTelecentricTiltDivision);
    }
    else if (0 != ((*hv_CameraType)==HTuple("area_scan_tilt_bilateral_telecentric_polynomial")))
    {
      (*hv_ParamNames).Clear();
      (*hv_ParamNames)[0] = "camera_type";
      (*hv_ParamNames).Append(hv_CameraParamAreaScanBilateralTelecentricTiltPolynomial);
    }
    else if (0 != ((*hv_CameraType)==HTuple("area_scan_tilt_object_side_telecentric_division")))
    {
      (*hv_ParamNames).Clear();
      (*hv_ParamNames)[0] = "camera_type";
      (*hv_ParamNames).Append(hv_CameraParamAreaScanObjectSideTelecentricTiltDivision);
    }
    else if (0 != ((*hv_CameraType)==HTuple("area_scan_tilt_object_side_telecentric_polynomial")))
    {
      (*hv_ParamNames).Clear();
      (*hv_ParamNames)[0] = "camera_type";
      (*hv_ParamNames).Append(hv_CameraParamAreaScanObjectSideTelecentricTiltPolynomial);
    }
    else if (0 != ((*hv_CameraType)==HTuple("line_scan")))
    {
      (*hv_ParamNames).Clear();
      (*hv_ParamNames)[0] = "camera_type";
      (*hv_ParamNames).Append(hv_CameraParamLinesScan);
    }
    else
    {
      throw HException(("Unknown camera type '"+(*hv_CameraType))+"' passed in CameraParam.");
    }
    return;
  }
  //
  //If the camera parameters are passed in CameraParam
  if (0 != ((HTuple(hv_CameraParam[0]).TupleIsString()).TupleNot()))
  {
    //Format of camera parameters for HALCON 12 and earlier
    switch ((hv_CameraParam.TupleLength()).I())
    {
      //
      //Area Scan
    case 8:
      //CameraType: 'area_scan_division' or 'area_scan_telecentric_division'
      if (0 != (HTuple(hv_CameraParam[0])!=0.0))
      {
        (*hv_ParamNames) = hv_CameraParamAreaScanDivision;
        (*hv_CameraType) = "area_scan_division";
      }
      else
      {
        (*hv_ParamNames) = hv_CameraParamAreaScanTelecentricDivisionLegacy;
        (*hv_CameraType) = "area_scan_telecentric_division";
      }
      break;
    case 10:
      //CameraType: 'area_scan_tilt_division' or 'area_scan_telecentric_tilt_division'
      if (0 != (HTuple(hv_CameraParam[0])!=0.0))
      {
        (*hv_ParamNames) = hv_CameraParamAreaScanTiltDivisionLegacy;
        (*hv_CameraType) = "area_scan_tilt_division";
      }
      else
      {
        (*hv_ParamNames) = hv_CameraParamAreaScanBilateralTelecentricTiltDivisionLegacy;
        (*hv_CameraType) = "area_scan_tilt_bilateral_telecentric_division";
      }
      break;
    case 12:
      //CameraType: 'area_scan_polynomial' or 'area_scan_telecentric_polynomial'
      if (0 != (HTuple(hv_CameraParam[0])!=0.0))
      {
        (*hv_ParamNames) = hv_CameraParamAreaScanPolynomial;
        (*hv_CameraType) = "area_scan_polynomial";
      }
      else
      {
        (*hv_ParamNames) = hv_CameraParamAreaScanTelecentricPolynomialLegacy;
        (*hv_CameraType) = "area_scan_telecentric_polynomial";
      }
      break;
    case 14:
      //CameraType: 'area_scan_tilt_polynomial' or 'area_scan_telecentric_tilt_polynomial'
      if (0 != (HTuple(hv_CameraParam[0])!=0.0))
      {
        (*hv_ParamNames) = hv_CameraParamAreaScanTiltPolynomialLegacy;
        (*hv_CameraType) = "area_scan_tilt_polynomial";
      }
      else
      {
        (*hv_ParamNames) = hv_CameraParamAreaScanBilateralTelecentricTiltPolynomialLegacy;
        (*hv_CameraType) = "area_scan_tilt_bilateral_telecentric_polynomial";
      }
      break;
      //
      //Line Scan
    case 11:
      //CameraType: 'line_scan'
      (*hv_ParamNames) = hv_CameraParamLinesScan;
      (*hv_CameraType) = "line_scan";
      break;
    default:
      throw HException("Wrong number of values in CameraParam.");
    }
  }
  else
  {
    //Format of camera parameters since HALCON 13
    (*hv_CameraType) = ((const HTuple&)hv_CameraParam)[0];
    if (0 != ((*hv_CameraType)==HTuple("area_scan_division")))
    {
      if (0 != ((hv_CameraParam.TupleLength())!=9))
      {
        throw HException("Wrong number of values in CameraParam.");
      }
      (*hv_ParamNames).Clear();
      (*hv_ParamNames)[0] = "camera_type";
      (*hv_ParamNames).Append(hv_CameraParamAreaScanDivision);
    }
    else if (0 != ((*hv_CameraType)==HTuple("area_scan_polynomial")))
    {
      if (0 != ((hv_CameraParam.TupleLength())!=13))
      {
        throw HException("Wrong number of values in CameraParam.");
      }
      (*hv_ParamNames).Clear();
      (*hv_ParamNames)[0] = "camera_type";
      (*hv_ParamNames).Append(hv_CameraParamAreaScanPolynomial);
    }
    else if (0 != ((*hv_CameraType)==HTuple("area_scan_telecentric_division")))
    {
      if (0 != ((hv_CameraParam.TupleLength())!=9))
      {
        throw HException("Wrong number of values in CameraParam.");
      }
      (*hv_ParamNames).Clear();
      (*hv_ParamNames)[0] = "camera_type";
      (*hv_ParamNames).Append(hv_CameraParamAreaScanTelecentricDivision);
    }
    else if (0 != ((*hv_CameraType)==HTuple("area_scan_telecentric_polynomial")))
    {
      if (0 != ((hv_CameraParam.TupleLength())!=13))
      {
        throw HException("Wrong number of values in CameraParam.");
      }
      (*hv_ParamNames).Clear();
      (*hv_ParamNames)[0] = "camera_type";
      (*hv_ParamNames).Append(hv_CameraParamAreaScanTelecentricPolynomial);
    }
    else if (0 != ((*hv_CameraType)==HTuple("area_scan_tilt_division")))
    {
      if (0 != ((hv_CameraParam.TupleLength())!=12))
      {
        throw HException("Wrong number of values in CameraParam.");
      }
      (*hv_ParamNames).Clear();
      (*hv_ParamNames)[0] = "camera_type";
      (*hv_ParamNames).Append(hv_CameraParamAreaScanTiltDivision);
    }
    else if (0 != ((*hv_CameraType)==HTuple("area_scan_tilt_polynomial")))
    {
      if (0 != ((hv_CameraParam.TupleLength())!=16))
      {
        throw HException("Wrong number of values in CameraParam.");
      }
      (*hv_ParamNames).Clear();
      (*hv_ParamNames)[0] = "camera_type";
      (*hv_ParamNames).Append(hv_CameraParamAreaScanTiltPolynomial);
    }
    else if (0 != ((*hv_CameraType)==HTuple("area_scan_tilt_image_side_telecentric_division")))
    {
      if (0 != ((hv_CameraParam.TupleLength())!=11))
      {
        throw HException("Wrong number of values in CameraParam.");
      }
      (*hv_ParamNames).Clear();
      (*hv_ParamNames)[0] = "camera_type";
      (*hv_ParamNames).Append(hv_CameraParamAreaScanImageSideTelecentricTiltDivision);
    }
    else if (0 != ((*hv_CameraType)==HTuple("area_scan_tilt_image_side_telecentric_polynomial")))
    {
      if (0 != ((hv_CameraParam.TupleLength())!=15))
      {
        throw HException("Wrong number of values in CameraParam.");
      }
      (*hv_ParamNames).Clear();
      (*hv_ParamNames)[0] = "camera_type";
      (*hv_ParamNames).Append(hv_CameraParamAreaScanImageSideTelecentricTiltPolynomial);
    }
    else if (0 != ((*hv_CameraType)==HTuple("area_scan_tilt_bilateral_telecentric_division")))
    {
      if (0 != ((hv_CameraParam.TupleLength())!=11))
      {
        throw HException("Wrong number of values in CameraParam.");
      }
      (*hv_ParamNames).Clear();
      (*hv_ParamNames)[0] = "camera_type";
      (*hv_ParamNames).Append(hv_CameraParamAreaScanBilateralTelecentricTiltDivision);
    }
    else if (0 != ((*hv_CameraType)==HTuple("area_scan_tilt_bilateral_telecentric_polynomial")))
    {
      if (0 != ((hv_CameraParam.TupleLength())!=15))
      {
        throw HException("Wrong number of values in CameraParam.");
      }
      (*hv_ParamNames).Clear();
      (*hv_ParamNames)[0] = "camera_type";
      (*hv_ParamNames).Append(hv_CameraParamAreaScanBilateralTelecentricTiltPolynomial);
    }
    else if (0 != ((*hv_CameraType)==HTuple("area_scan_tilt_object_side_telecentric_division")))
    {
      if (0 != ((hv_CameraParam.TupleLength())!=12))
      {
        throw HException("Wrong number of values in CameraParam.");
      }
      (*hv_ParamNames).Clear();
      (*hv_ParamNames)[0] = "camera_type";
      (*hv_ParamNames).Append(hv_CameraParamAreaScanObjectSideTelecentricTiltDivision);
    }
    else if (0 != ((*hv_CameraType)==HTuple("area_scan_tilt_object_side_telecentric_polynomial")))
    {
      if (0 != ((hv_CameraParam.TupleLength())!=16))
      {
        throw HException("Wrong number of values in CameraParam.");
      }
      (*hv_ParamNames).Clear();
      (*hv_ParamNames)[0] = "camera_type";
      (*hv_ParamNames).Append(hv_CameraParamAreaScanObjectSideTelecentricTiltPolynomial);
    }
    else if (0 != ((*hv_CameraType)==HTuple("line_scan")))
    {
      if (0 != ((hv_CameraParam.TupleLength())!=12))
      {
        throw HException("Wrong number of values in CameraParam.");
      }
      (*hv_ParamNames).Clear();
      (*hv_ParamNames)[0] = "camera_type";
      (*hv_ParamNames).Append(hv_CameraParamLinesScan);
    }
    else
    {
      throw HException("Unknown camera type in CameraParam.");
    }
  }
  return;
}

// Chapter: Calibration / Monocular
// Short Description: Calibrate a camera with a single image. 
void calibrate_camera_and_plane_single_image (HTuple hv_CalibObjectData)
{

  // Local iconic variables
  HObject  ho_ImageCaltab;

  // Local control variables
  HTuple  hv_CalPlateDescr, hv_CalPlateThickness;
  HTuple  hv_StartCamParam, hv_CalibDataID, hv_ErrorCamCalibInPixel;
  HTuple  hv_CamParam, hv_PlaneInCamPose0, hv_PlaneInCamPose;

  read_message_obj(&ho_ImageCaltab, hv_CalibObjectData, "ImageCaltab");
  read_message_tuple(hv_CalibObjectData, "CalPlateDescr", &hv_CalPlateDescr);
  read_message_tuple(hv_CalibObjectData, "CalPlateThickness", &hv_CalPlateThickness);
  read_message_tuple(hv_CalibObjectData, "StartCamParam", &hv_StartCamParam);
  //
  //Check input
  if (0 != (HTuple(hv_StartCamParam[0])==HTuple("line_scan")))
  {
    throw HException("Line-scan cameras are not supported");
  }
  //
  //Create a HALCON calibration data model.
  CreateCalibData("calibration_object", 1, 1, &hv_CalibDataID);
  //Set the needed calibration information.
  SetCalibDataCamParam(hv_CalibDataID, 0, HTuple(), hv_StartCamParam);
  SetCalibDataCalibObject(hv_CalibDataID, 0, hv_CalPlateDescr);
  //Find the calibration plate.
  FindCalibObject(ho_ImageCaltab, hv_CalibDataID, 0, 0, 0, HTuple(), HTuple());
  //Calibrating from only one view requires some parameter to be excluded
  //from the optimization.
  SetCalibData(hv_CalibDataID, "camera", 0, "excluded_settings", "focus");
  //Calibrate the camera.
  CalibrateCameras(hv_CalibDataID, &hv_ErrorCamCalibInPixel);
  //Get the calibration results.
  GetCalibData(hv_CalibDataID, "camera", 0, "params", &hv_CamParam);
  GetCalibData(hv_CalibDataID, "calib_obj_pose", (HTuple(0).Append(0)), "pose", &hv_PlaneInCamPose0);
  SetOriginPose(hv_PlaneInCamPose0, 0, 0, hv_CalPlateThickness, &hv_PlaneInCamPose);
  //Convert pose to standard pose type.
  ConvertPoseType(hv_PlaneInCamPose, "Rp+T", "gba", "point", &hv_PlaneInCamPose);
  //
  //Add data to output message.
  SetMessageTuple(hv_CalibObjectData, "ErrorCamCalibInPixel", hv_ErrorCamCalibInPixel);
  SetMessageTuple(hv_CalibObjectData, "CamParam", hv_CamParam);
  SetMessageTuple(hv_CalibObjectData, "PlaneInCamPose", hv_PlaneInCamPose);
  //Clean up.
  ClearCalibData(hv_CalibDataID);
  return;
}

// Chapter: Calibration / Camera Parameters
// Short Description: Generate a camera parameter tuple for an area scan camera with a telecentric lens and with distortions modeled by the polynomial model. 
void gen_cam_par_area_scan_telecentric_polynomial (HTuple hv_Magnification, HTuple hv_K1, 
    HTuple hv_K2, HTuple hv_K3, HTuple hv_P1, HTuple hv_P2, HTuple hv_Sx, HTuple hv_Sy, 
    HTuple hv_Cx, HTuple hv_Cy, HTuple hv_ImageWidth, HTuple hv_ImageHeight, HTuple *hv_CameraParam)
{

  // Local iconic variables

  //Generate a camera parameter tuple for an area scan camera
  //with a telecentric lens and with distortions modeled by the
  //polynomial model.
  //
  (*hv_CameraParam).Clear();
  (*hv_CameraParam)[0] = "area_scan_telecentric_polynomial";
  (*hv_CameraParam).Append(hv_Magnification);
  (*hv_CameraParam).Append(hv_K1);
  (*hv_CameraParam).Append(hv_K2);
  (*hv_CameraParam).Append(hv_K3);
  (*hv_CameraParam).Append(hv_P1);
  (*hv_CameraParam).Append(hv_P2);
  (*hv_CameraParam).Append(hv_Sx);
  (*hv_CameraParam).Append(hv_Sy);
  (*hv_CameraParam).Append(hv_Cx);
  (*hv_CameraParam).Append(hv_Cy);
  (*hv_CameraParam).Append(hv_ImageWidth);
  (*hv_CameraParam).Append(hv_ImageHeight);
  return;
}

// Chapter: Calibration / Camera Parameters
// Short Description: Generate a camera parameter tuple for an area scan camera with a bilateral telecentric tilt lens and with distortions modeled by the division model. 
void gen_cam_par_area_scan_tilt_bilateral_telecentric_division (HTuple hv_Magnification, 
    HTuple hv_Kappa, HTuple hv_Tilt, HTuple hv_Rot, HTuple hv_Sx, HTuple hv_Sy, HTuple hv_Cx, 
    HTuple hv_Cy, HTuple hv_ImageWidth, HTuple hv_ImageHeight, HTuple *hv_CameraParam)
{

  // Local iconic variables

  //Generate a camera parameter tuple for an area scan camera with
  //a bilateral telecentric tilt lens and with distortions modeled
  //by the division model.
  //
  (*hv_CameraParam).Clear();
  (*hv_CameraParam)[0] = "area_scan_tilt_bilateral_telecentric_division";
  (*hv_CameraParam).Append(hv_Magnification);
  (*hv_CameraParam).Append(hv_Kappa);
  (*hv_CameraParam).Append(hv_Tilt);
  (*hv_CameraParam).Append(hv_Rot);
  (*hv_CameraParam).Append(hv_Sx);
  (*hv_CameraParam).Append(hv_Sy);
  (*hv_CameraParam).Append(hv_Cx);
  (*hv_CameraParam).Append(hv_Cy);
  (*hv_CameraParam).Append(hv_ImageWidth);
  (*hv_CameraParam).Append(hv_ImageHeight);
  return;
}

// Chapter: Calibration / Camera Parameters
// Short Description: Generate a camera parameter tuple for an area scan camera with an object-side telecentric tilt lens and with distortions modeled by the division model. 
void gen_cam_par_area_scan_tilt_object_side_telecentric_division (HTuple hv_Magnification, 
    HTuple hv_Kappa, HTuple hv_ImagePlaneDist, HTuple hv_Tilt, HTuple hv_Rot, HTuple hv_Sx, 
    HTuple hv_Sy, HTuple hv_Cx, HTuple hv_Cy, HTuple hv_ImageWidth, HTuple hv_ImageHeight, 
    HTuple *hv_CameraParam)
{

  // Local iconic variables

  //Generate a camera parameter tuple for an area scan camera with
  //an object-side telecentric tilt lens and with distortions modeled
  //by the division model.
  //
  (*hv_CameraParam).Clear();
  (*hv_CameraParam)[0] = "area_scan_tilt_object_side_telecentric_division";
  (*hv_CameraParam).Append(hv_Magnification);
  (*hv_CameraParam).Append(hv_Kappa);
  (*hv_CameraParam).Append(hv_ImagePlaneDist);
  (*hv_CameraParam).Append(hv_Tilt);
  (*hv_CameraParam).Append(hv_Rot);
  (*hv_CameraParam).Append(hv_Sx);
  (*hv_CameraParam).Append(hv_Sy);
  (*hv_CameraParam).Append(hv_Cx);
  (*hv_CameraParam).Append(hv_Cy);
  (*hv_CameraParam).Append(hv_ImageWidth);
  (*hv_CameraParam).Append(hv_ImageHeight);
  return;
}

// Chapter: Calibration / Camera Parameters
// Short Description: Get the value of a specified camera parameter from the camera parameter tuple. 
void get_cam_par_data (HTuple hv_CameraParam, HTuple hv_ParamName, HTuple *hv_ParamValue)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_CameraType, hv_CameraParamNames, hv_Index;
  HTuple  hv_ParamNameInd, hv_I;

  //get_cam_par_data returns in ParamValue the value of the
  //parameter that is given in ParamName from the tuple of
  //camera parameters that is given in CameraParam.
  //
  //Get the parameter names that correspond to the
  //elements in the input camera parameter tuple.
  get_cam_par_names(hv_CameraParam, &hv_CameraType, &hv_CameraParamNames);
  //
  //Find the index of the requested camera data and return
  //the corresponding value.
  (*hv_ParamValue) = HTuple();
  {
  HTuple end_val11 = (hv_ParamName.TupleLength())-1;
  HTuple step_val11 = 1;
  for (hv_Index=0; hv_Index.Continue(end_val11, step_val11); hv_Index += step_val11)
  {
    hv_ParamNameInd = HTuple(hv_ParamName[hv_Index]);
    if (0 != (hv_ParamNameInd==HTuple("camera_type")))
    {
      (*hv_ParamValue) = (*hv_ParamValue).TupleConcat(hv_CameraType);
      continue;
    }
    hv_I = hv_CameraParamNames.TupleFind(hv_ParamNameInd);
    if (0 != (hv_I!=-1))
    {
      (*hv_ParamValue) = (*hv_ParamValue).TupleConcat(HTuple(hv_CameraParam[hv_I]));
    }
    else
    {
      throw HException("Unknown camera parameter "+hv_ParamNameInd);
    }
  }
  }
  return;
}

// Chapter: Calibration / Camera Parameters
// Short Description: Generate a camera parameter tuple for an area scan camera with a tilt lens and with distortions modeled by the division model. 
void gen_cam_par_area_scan_tilt_division (HTuple hv_Focus, HTuple hv_Kappa, HTuple hv_ImagePlaneDist, 
    HTuple hv_Tilt, HTuple hv_Rot, HTuple hv_Sx, HTuple hv_Sy, HTuple hv_Cx, HTuple hv_Cy, 
    HTuple hv_ImageWidth, HTuple hv_ImageHeight, HTuple *hv_CameraParam)
{

  // Local iconic variables

  //Generate a camera parameter tuple for an area scan camera with
  //a tilt lens and with distortions modeled by the division model.
  //
  (*hv_CameraParam).Clear();
  (*hv_CameraParam)[0] = "area_scan_tilt_division";
  (*hv_CameraParam).Append(hv_Focus);
  (*hv_CameraParam).Append(hv_Kappa);
  (*hv_CameraParam).Append(hv_ImagePlaneDist);
  (*hv_CameraParam).Append(hv_Tilt);
  (*hv_CameraParam).Append(hv_Rot);
  (*hv_CameraParam).Append(hv_Sx);
  (*hv_CameraParam).Append(hv_Sy);
  (*hv_CameraParam).Append(hv_Cx);
  (*hv_CameraParam).Append(hv_Cy);
  (*hv_CameraParam).Append(hv_ImageWidth);
  (*hv_CameraParam).Append(hv_ImageHeight);
  return;
}

// Chapter: Calibration / Camera Parameters
// Short Description: Generate a camera parameter tuple for an area scan camera with an image-side telecentric tilt lens and with distortions modeled by the division model. 
void gen_cam_par_area_scan_tilt_image_side_telecentric_division (HTuple hv_Focus, 
    HTuple hv_Kappa, HTuple hv_Tilt, HTuple hv_Rot, HTuple hv_Sx, HTuple hv_Sy, HTuple hv_Cx, 
    HTuple hv_Cy, HTuple hv_ImageWidth, HTuple hv_ImageHeight, HTuple *hv_CameraParam)
{

  // Local iconic variables

  //Generate a camera parameter tuple for an area scan camera with
  //an image-side telecentric tilt lens and with distortions modeled
  //by the division model.
  //
  (*hv_CameraParam).Clear();
  (*hv_CameraParam)[0] = "area_scan_tilt_image_side_telecentric_division";
  (*hv_CameraParam).Append(hv_Focus);
  (*hv_CameraParam).Append(hv_Kappa);
  (*hv_CameraParam).Append(hv_Tilt);
  (*hv_CameraParam).Append(hv_Rot);
  (*hv_CameraParam).Append(hv_Sx);
  (*hv_CameraParam).Append(hv_Sy);
  (*hv_CameraParam).Append(hv_Cx);
  (*hv_CameraParam).Append(hv_Cy);
  (*hv_CameraParam).Append(hv_ImageWidth);
  (*hv_CameraParam).Append(hv_ImageHeight);
  return;
}

// Chapter: Calibration / Camera Parameters
// Short Description: Set the value of a specified camera parameter in the camera parameter tuple. 
void set_cam_par_data (HTuple hv_CameraParamIn, HTuple hv_ParamName, HTuple hv_ParamValue, 
    HTuple *hv_CameraParamOut)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_Index, hv_ParamNameInd, hv_CameraParamNames;
  HTuple  hv_I, hv_CameraType, hv_IsTelecentric;

  //set_cam_par_data sets the value of the parameter that
  //is given in ParamName in the tuple of camera parameters
  //given in CameraParamIn. The modified camera parameters
  //are returned in CameraParamOut.
  //
  //Check for consistent length of input parameters
  if (0 != ((hv_ParamName.TupleLength())!=(hv_ParamValue.TupleLength())))
  {
    throw HException("Different number of values in ParamName and ParamValue");
  }
  //First, get the parameter names that correspond to the
  //elements in the input camera parameter tuple.
  get_cam_par_names(hv_CameraParamIn, &hv_CameraType, &hv_CameraParamNames);
  //
  //Find the index of the requested camera data and return
  //the corresponding value.
  (*hv_CameraParamOut) = hv_CameraParamIn;
  {
  HTuple end_val16 = (hv_ParamName.TupleLength())-1;
  HTuple step_val16 = 1;
  for (hv_Index=0; hv_Index.Continue(end_val16, step_val16); hv_Index += step_val16)
  {
    hv_ParamNameInd = HTuple(hv_ParamName[hv_Index]);
    hv_I = hv_CameraParamNames.TupleFind(hv_ParamNameInd);
    if (0 != (hv_I!=-1))
    {
      (*hv_CameraParamOut)[hv_I] = HTuple(hv_ParamValue[hv_Index]);
    }
    else
    {
      throw HException("Wrong ParamName "+hv_ParamNameInd);
    }
    //Check the consistency of focus and telecentricity
    if (0 != (hv_ParamNameInd==HTuple("focus")))
    {
      hv_IsTelecentric = HTuple((hv_CameraType.TupleStrstr("telecentric"))!=-1).TupleAnd((hv_CameraType.TupleStrstr("image_side_telecentric"))==-1);
      if (0 != hv_IsTelecentric)
      {
        throw HException(HTuple("Focus for telecentric lenses is always 0, and hence, cannot be changed."));
      }
      if (0 != (HTuple(hv_IsTelecentric.TupleNot()).TupleAnd(HTuple(hv_ParamValue[hv_Index])==0.0)))
      {
        throw HException("Focus for non-telecentric lenses must not be 0.");
      }
    }
  }
  }
  return;
}

// Chapter: Calibration / Camera Parameters
// Short Description: Generate a camera parameter tuple for a line scan camera. 
void gen_cam_par_line_scan (HTuple hv_Focus, HTuple hv_Kappa, HTuple hv_Sx, HTuple hv_Sy, 
    HTuple hv_Cx, HTuple hv_Cy, HTuple hv_ImageWidth, HTuple hv_ImageHeight, HTuple hv_Vx, 
    HTuple hv_Vy, HTuple hv_Vz, HTuple *hv_CameraParam)
{

  // Local iconic variables

  //Generate a camera parameter tuple for a line scan camera.
  //
  (*hv_CameraParam).Clear();
  (*hv_CameraParam)[0] = "line_scan";
  (*hv_CameraParam).Append(hv_Focus);
  (*hv_CameraParam).Append(hv_Kappa);
  (*hv_CameraParam).Append(hv_Sx);
  (*hv_CameraParam).Append(hv_Sy);
  (*hv_CameraParam).Append(hv_Cx);
  (*hv_CameraParam).Append(hv_Cy);
  (*hv_CameraParam).Append(hv_ImageWidth);
  (*hv_CameraParam).Append(hv_ImageHeight);
  (*hv_CameraParam).Append(hv_Vx);
  (*hv_CameraParam).Append(hv_Vy);
  (*hv_CameraParam).Append(hv_Vz);
  return;
}

// Chapter: Transformations / Poses
// Short Description: Calculate the poses to grasp an object. 
void calculate_tool_in_base_robot_path_poses (HTupleVector/*{eTupleVector,Dim=1}*/ hvec_ToolInModelRobotPathPoses, 
    HTuple hv_ModelInBasePose, HTuple hv_Poses, HTupleVector/*{eTupleVector,Dim=1}*/ *hvec_ToolInBaseRobotPathPoses)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_OrderOfTransform, hv_OrderOfRotation;
  HTuple  hv_ViewOfTransform, hv_Index1, hv_ToolInBaseRobotPathPose;

  //
  read_message_tuple(hv_Poses, "OrderOfTransform", &hv_OrderOfTransform);
  read_message_tuple(hv_Poses, "OrderOfRotation", &hv_OrderOfRotation);
  read_message_tuple(hv_Poses, "ViewOfTransform", &hv_ViewOfTransform);
  //
  {
  HTuple end_val5 = HTuple(hvec_ToolInModelRobotPathPoses.Length())-1;
  HTuple step_val5 = 1;
  for (hv_Index1=0; hv_Index1.Continue(end_val5, step_val5); hv_Index1 += step_val5)
  {
    PoseCompose(hv_ModelInBasePose, hvec_ToolInModelRobotPathPoses[hv_Index1].T(), 
        &hv_ToolInBaseRobotPathPose);
    ConvertPoseType(hv_ToolInBaseRobotPathPose, hv_OrderOfTransform, hv_OrderOfRotation, 
        hv_ViewOfTransform, &hv_ToolInBaseRobotPathPose);
    (*hvec_ToolInBaseRobotPathPoses)[hv_Index1] = HTupleVector(hv_ToolInBaseRobotPathPose);
  }
  }
  return;
}

// Chapter: Calibration / Camera Parameters
// Short Description: Generate a camera parameter tuple for an area scan camera with an image-side telecentric tilt lens and with distortions modeled by the polynomial model. 
void gen_cam_par_area_scan_tilt_image_side_telecentric_polynomial (HTuple hv_Focus, 
    HTuple hv_K1, HTuple hv_K2, HTuple hv_K3, HTuple hv_P1, HTuple hv_P2, HTuple hv_Tilt, 
    HTuple hv_Rot, HTuple hv_Sx, HTuple hv_Sy, HTuple hv_Cx, HTuple hv_Cy, HTuple hv_ImageWidth, 
    HTuple hv_ImageHeight, HTuple *hv_CameraParam)
{

  // Local iconic variables

  //Generate a camera parameter tuple for an area scan camera with
  //an image-side telecentric tilt lens and with distortions modeled
  //by the polynomial model.
  //
  (*hv_CameraParam).Clear();
  (*hv_CameraParam)[0] = "area_scan_tilt_image_side_telecentric_polynomial";
  (*hv_CameraParam).Append(hv_Focus);
  (*hv_CameraParam).Append(hv_K1);
  (*hv_CameraParam).Append(hv_K2);
  (*hv_CameraParam).Append(hv_K3);
  (*hv_CameraParam).Append(hv_P1);
  (*hv_CameraParam).Append(hv_P2);
  (*hv_CameraParam).Append(hv_Tilt);
  (*hv_CameraParam).Append(hv_Rot);
  (*hv_CameraParam).Append(hv_Sx);
  (*hv_CameraParam).Append(hv_Sy);
  (*hv_CameraParam).Append(hv_Cx);
  (*hv_CameraParam).Append(hv_Cy);
  (*hv_CameraParam).Append(hv_ImageWidth);
  (*hv_CameraParam).Append(hv_ImageHeight);
  return;
}

// Chapter: 3D Object Model / Features
void get_bounding_box_points_from_min_max (HTuple hv_BoundingBox, HTuple *hv_PX, 
    HTuple *hv_PY, HTuple *hv_PZ)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_Index;
  HTupleVector  hvec_Points(1);

  hvec_Points = (HTupleVector(1).Insert(0,HTupleVector(HTuple())));
  hvec_Points[0] = HTupleVector((HTuple(hv_BoundingBox[0]).TupleConcat(HTuple(hv_BoundingBox[1]))).TupleConcat(HTuple(hv_BoundingBox[2])));
  hvec_Points[1] = HTupleVector((HTuple(hv_BoundingBox[3]).TupleConcat(HTuple(hv_BoundingBox[1]))).TupleConcat(HTuple(hv_BoundingBox[2])));
  hvec_Points[2] = HTupleVector((HTuple(hv_BoundingBox[3]).TupleConcat(HTuple(hv_BoundingBox[4]))).TupleConcat(HTuple(hv_BoundingBox[2])));
  hvec_Points[3] = HTupleVector((HTuple(hv_BoundingBox[0]).TupleConcat(HTuple(hv_BoundingBox[4]))).TupleConcat(HTuple(hv_BoundingBox[2])));
  hvec_Points[4] = HTupleVector((HTuple(hv_BoundingBox[0]).TupleConcat(HTuple(hv_BoundingBox[1]))).TupleConcat(HTuple(hv_BoundingBox[5])));
  hvec_Points[5] = HTupleVector((HTuple(hv_BoundingBox[3]).TupleConcat(HTuple(hv_BoundingBox[1]))).TupleConcat(HTuple(hv_BoundingBox[5])));
  hvec_Points[6] = HTupleVector((HTuple(hv_BoundingBox[3]).TupleConcat(HTuple(hv_BoundingBox[4]))).TupleConcat(HTuple(hv_BoundingBox[5])));
  hvec_Points[7] = HTupleVector((HTuple(hv_BoundingBox[0]).TupleConcat(HTuple(hv_BoundingBox[4]))).TupleConcat(HTuple(hv_BoundingBox[5])));
  (*hv_PX) = HTuple();
  (*hv_PY) = HTuple();
  (*hv_PZ) = HTuple();
  for (hv_Index=0; hv_Index<=7; hv_Index+=1)
  {
    (*hv_PX) = (*hv_PX).TupleConcat(HTuple(hvec_Points[hv_Index].T()[0]));
    (*hv_PY) = (*hv_PY).TupleConcat(HTuple(hvec_Points[hv_Index].T()[1]));
    (*hv_PZ) = (*hv_PZ).TupleConcat(HTuple(hvec_Points[hv_Index].T()[2]));
  }
  return;
}

// Chapter: 3D Object Model / Transformations
void get_extent_by_axis (HTuple hv_OM3D, HTuple hv_XExtent, HTuple hv_YExtent, HTuple hv_ZExtent, 
    HTuple *hv_XExtentOut, HTuple *hv_YExtentOut, HTuple *hv_ZExtentOut)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_BB, hv_Index;

  (*hv_XExtentOut) = hv_XExtent;
  (*hv_YExtentOut) = hv_YExtent;
  (*hv_ZExtentOut) = hv_ZExtent;
  GetObjectModel3dParams(hv_OM3D, "bounding_box1", &hv_BB);
  {
  HTuple end_val4 = ((hv_BB.TupleLength())/6)-1;
  HTuple step_val4 = 1;
  for (hv_Index=0; hv_Index.Continue(end_val4, step_val4); hv_Index += step_val4)
  {
    (*hv_XExtentOut) = ((*hv_XExtentOut).TupleConcat(HTuple(hv_BB[hv_Index*6]))).TupleConcat(HTuple(hv_BB[(hv_Index*6)+3]));
    (*hv_YExtentOut) = ((*hv_YExtentOut).TupleConcat(HTuple(hv_BB[(hv_Index*6)+1]))).TupleConcat(HTuple(hv_BB[(hv_Index*6)+4]));
    (*hv_ZExtentOut) = ((*hv_ZExtentOut).TupleConcat(HTuple(hv_BB[(hv_Index*6)+2]))).TupleConcat(HTuple(hv_BB[(hv_Index*6)+5]));
  }
  }
  return;
}

// Chapter: Calibration / Hand-Eye
// Short Description: Get the coordinates of the central mark of the closest finder pattern. 
void get_nearest_finder_pattern_coordinates (HObject ho_CalibPlateImage, HTuple hv_RowNearFinderPattern, 
    HTuple hv_ColumNearFinderPattern, HTuple hv_CalibObjectData, HTuple *hv_RowFinderPattern, 
    HTuple *hv_ColumnFinderPattern)
{

  // Local iconic variables
  HObject  ho_Contours, ho_Region, ho_RegionUnion;

  // Local control variables
  HTuple  hv_CamParam, hv_CalPlateDescr, hv_MarksPerRow;
  HTuple  hv_FinderRow, hv_FinderColumn, hv_CalibDataID, hv_Exception;
  HTuple  hv_Row, hv_Column, hv_Index1, hv_Pose, hv_Area1;
  HTuple  hv_Row2, hv_Column2, hv_RowTmp, hv_ColTmp, hv_Diff;
  HTuple  hv_IndexFinal, hv_RowToApproach1, hv_ColToApproach1;
  HTuple  hv_XCal, hv_YCal, hv_ZCal, hv_XFP, hv_YFP, hv_HomMat3D;
  HTuple  hv_ZFP, hv_X1, hv_Y1, hv_Z1;

  //
  read_message_tuple(hv_CalibObjectData, "CamParam", &hv_CamParam);
  read_message_tuple(hv_CalibObjectData, "CalPlateDescr", &hv_CalPlateDescr);
  read_message_tuple(hv_CalibObjectData, "MarksPerRow", &hv_MarksPerRow);
  read_message_tuple(hv_CalibObjectData, "FinderRow", &hv_FinderRow);
  read_message_tuple(hv_CalibObjectData, "FinderColumn", &hv_FinderColumn);
  //
  //Check input.
  //
  //Check image coordinates.
  if (0 != (HTuple((hv_RowNearFinderPattern.TupleLength())>1).TupleOr((hv_ColumNearFinderPattern.TupleLength())>1)))
  {
    throw HException("Please specify only one image coordinate.");
  }
  //Check number of marks per row.
  if (0 != (hv_MarksPerRow<3))
  {
    throw HException("At least three marks per row are necessary for a valid finder pattern.");
  }
  //Find calibration plate.
  CreateCalibData("calibration_object", 1, 1, &hv_CalibDataID);
  SetCalibDataCamParam(hv_CalibDataID, 0, HTuple(), hv_CamParam);
  SetCalibDataCalibObject(hv_CalibDataID, 0, hv_CalPlateDescr);
  try
  {
    FindCalibObject(ho_CalibPlateImage, hv_CalibDataID, 0, 0, 0, HTuple(), HTuple());
  }
  // catch (Exception) 
  catch (HException &HDevExpDefaultException)
  {
    HDevExpDefaultException.ToHTuple(&hv_Exception);
    throw HException(HTuple("Calibration plate could not be find, please make sure that at least one finder pattern is visible."));
  }
  GetCalibDataObservPoints(hv_CalibDataID, 0, 0, 0, &hv_Row, &hv_Column, &hv_Index1, 
      &hv_Pose);
  GetCalibDataObservContours(&ho_Contours, hv_CalibDataID, "caltab", 0, 0, 0);
  //Get the finder pattern used to find the calibration plate.
  GenRegionContourXld(ho_Contours, &ho_Region, "filled");
  Union1(ho_Region, &ho_RegionUnion);
  AreaCenter(ho_RegionUnion, &hv_Area1, &hv_Row2, &hv_Column2);
  hv_RowTmp = (hv_Row-hv_Row2).TupleAbs();
  hv_ColTmp = (hv_Column-hv_Column2).TupleAbs();
  hv_Diff = ((hv_RowTmp*hv_RowTmp)+(hv_ColTmp*hv_ColTmp)).TupleSqrt();
  TupleFind(hv_Diff, hv_Diff.TupleMin(), &hv_IndexFinal);
  hv_RowToApproach1 = HTuple(hv_Row[hv_IndexFinal]);
  hv_ColToApproach1 = HTuple(hv_Column[hv_IndexFinal]);
  ClearCalibData(hv_CalibDataID);
  //Get remaining finder pattern.
  //
  //Get finder pattern in world coordinates.
  CaltabPoints(hv_CalPlateDescr, &hv_XCal, &hv_YCal, &hv_ZCal);
  hv_XFP = HTuple(hv_XCal[(hv_FinderRow*hv_MarksPerRow)+hv_FinderColumn]);
  hv_YFP = HTuple(hv_YCal[(hv_FinderRow*hv_MarksPerRow)+hv_FinderColumn]);
  //Get finder pattern in camera coordinates.
  PoseToHomMat3d(hv_Pose, &hv_HomMat3D);
  TupleGenConst(hv_XFP.TupleLength(), 0.0, &hv_ZFP);
  AffineTransPoint3d(hv_HomMat3D, hv_XFP, hv_YFP, hv_ZFP, &hv_X1, &hv_Y1, &hv_Z1);
  //Project into the image.
  Project3dPoint(hv_X1, hv_Y1, hv_Z1, hv_CamParam, &hv_Row, &hv_Column);
  //
  //Get the image coordinates that are the closest ones to the passed ones.
  hv_RowTmp = (hv_Row-hv_RowNearFinderPattern).TupleAbs();
  hv_ColTmp = (hv_Column-hv_ColumNearFinderPattern).TupleAbs();
  hv_Diff = ((hv_RowTmp*hv_RowTmp)+(hv_ColTmp*hv_ColTmp)).TupleSqrt();
  TupleFind(hv_Diff, hv_Diff.TupleMin(), &hv_IndexFinal);
  //Return the image coordinates.
  (*hv_RowFinderPattern) = HTuple(hv_Row[hv_IndexFinal]);
  (*hv_ColumnFinderPattern) = HTuple(hv_Column[hv_IndexFinal]);
  return;
}

// Chapter: Graphics / Text
void dev_disp_calibration_data_instructions2 (HObject ho_Image)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_Text;

  if (HDevWindowStack::IsOpen())
    DispObj(ho_Image, HDevWindowStack::GetActive());
  hv_Text = HTuple("If you did NOT use a standard HALCON calibration plate, ");
  hv_Text[1] = HTuple("but used create_caltab to create your own calibration plate,");
  hv_Text[2] = HTuple("please adapt the parameters FinderRow, FinderColumn, and MarksPerRow");
  hv_Text[3] = "in the code.";
  if (HDevWindowStack::IsOpen())
    DispText(HDevWindowStack::GetActive(),hv_Text, "window", "top", "left", "black", 
        HTuple(), HTuple());
  if (HDevWindowStack::IsOpen())
    DispText(HDevWindowStack::GetActive(),"Press Run (F5) to continue", "window", 
        "bottom", "right", "black", HTuple(), HTuple());
  return;
}

// Chapter: Matrix / Arithmetic
void get_rotation_axis (HTuple hv_MatRot, HTuple hv_MatRot0, HTuple *hv_RotationAxis, 
    HTuple *hv_DiffToIdentity)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_MatrixMultID, hv_Identity, hv_MatrixSubID;
  HTuple  hv_Values, hv_MatrixUID, hv_MatrixSID, hv_MatrixVID;
  HTuple  hv_SingularValues, hv_AbsSingularValues, hv_Indices;

  //
  //Get (R_i)^(-1)R_0
  MultMatrix(hv_MatRot, hv_MatRot0, "ATB", &hv_MatrixMultID);
  //Get some measure for how far the matrix is from the identity.
  CreateMatrix(3, 3, "identity", &hv_Identity);
  SubMatrix(hv_MatrixMultID, hv_Identity, &hv_MatrixSubID);
  GetFullMatrix(hv_MatrixSubID, &hv_Values);
  (*hv_DiffToIdentity) = (hv_Values*hv_Values).TupleSum();
  //Get its rotation axis.
  SvdMatrix(hv_MatrixSubID, "full", "both", &hv_MatrixUID, &hv_MatrixSID, &hv_MatrixVID);
  GetValueMatrix(hv_MatrixSID, ((HTuple(0).Append(1)).Append(2)), ((HTuple(0).Append(1)).Append(2)), 
      &hv_SingularValues);
  hv_AbsSingularValues = hv_SingularValues.TupleAbs();
  TupleSortIndex(hv_AbsSingularValues, &hv_Indices);
  GetValueMatrix(hv_MatrixVID, ((HTuple(0).Append(1)).Append(2)), (HTuple(hv_Indices[0]).TupleConcat(HTuple(hv_Indices[0]))).TupleConcat(HTuple(hv_Indices[0])), 
      &(*hv_RotationAxis));
  //Clear matrices.
  ClearMatrix(hv_MatrixMultID);
  ClearMatrix(hv_MatrixUID);
  ClearMatrix(hv_MatrixSID);
  ClearMatrix(hv_MatrixVID);
  ClearMatrix(hv_MatrixSubID);
  ClearMatrix(hv_Identity);
  return;
}

// Chapter: 3D Object Model / Creation
// Short Description: Generate 3D object models for the camera, the plane, the robot's base and the robot's tool in a stationary camera setup. 
void gen_current_setup_stationary_cam_object_model_3d (HTuple hv_ArrowThickness, 
    HTuple hv_ArrowLength, HTuple hv_CameraSize, HTuple hv_HandEyeCalibData, HTuple *hv_OM3DCamera, 
    HTuple *hv_OM3DPlane, HTuple *hv_OM3DBase, HTuple *hv_OM3DToolOrigin)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_CamParam, hv_PlaneInCamPose0, hv_BaseInCamPose;
  HTuple  hv_CX, hv_CY, hv_OptAxisPlaneX, hv_OptAxisPlaneY;
  HTuple  hv_HomMat3D, hv_OptAxisCamX, hv_OptAxisCamY, hv_OptAxisCamZ;
  HTuple  hv_ConeLength, hv_IdentityPose, hv_CameraSetupModelID;
  HTuple  hv_OM3DCameraOrigin, hv_OM3DConeOrig, hv_CamInBasePose;
  HTuple  hv_FactorBorder, hv_PlaneInBasePose;

  //This procedure generates the 3D object models of the camera and its
  //cone, the plane, the robot's base and the robot's tool at its
  //initial position.
  //
  read_message_tuple(hv_HandEyeCalibData, "CamParam", &hv_CamParam);
  read_message_tuple(hv_HandEyeCalibData, "PlaneInCamPose0", &hv_PlaneInCamPose0);
  read_message_tuple(hv_HandEyeCalibData, "BaseInCamPose", &hv_BaseInCamPose);
  //
  //Visualize base and tool in the origin.
  gen_robot_tool_and_base_object_model_3d(hv_ArrowThickness, hv_ArrowLength, &(*hv_OM3DToolOrigin), 
      &(*hv_OM3DBase));
  //Visualize camera.
  get_cam_par_data(hv_CamParam, "cx", &hv_CX);
  get_cam_par_data(hv_CamParam, "cy", &hv_CY);
  ImagePointsToWorldPlane(hv_CamParam, hv_PlaneInCamPose0, hv_CY, hv_CX, "m", &hv_OptAxisPlaneX, 
      &hv_OptAxisPlaneY);
  PoseToHomMat3d(hv_PlaneInCamPose0, &hv_HomMat3D);
  AffineTransPoint3d(hv_HomMat3D, hv_OptAxisPlaneX, hv_OptAxisPlaneY, 0, &hv_OptAxisCamX, 
      &hv_OptAxisCamY, &hv_OptAxisCamZ);
  hv_ConeLength = hv_OptAxisCamZ*1.1;
  //If the optical axis does not intersect the plane, we still want to visualize the camera.
  if (0 != (hv_ConeLength<=0.0))
  {
    hv_ConeLength = hv_CameraSize;
  }
  CreatePose(0, 0, 0, 0, 0, 0, "Rp+T", "gba", "point", &hv_IdentityPose);
  CreateCameraSetupModel(1, &hv_CameraSetupModelID);
  SetCameraSetupCamParam(hv_CameraSetupModelID, 0, HTuple(), hv_CamParam, hv_IdentityPose);
  gen_camera_setup_object_model_3d(hv_CameraSetupModelID, hv_CameraSize, hv_ConeLength, 
      &hv_OM3DCameraOrigin, &hv_OM3DConeOrig);
  ClearCameraSetupModel(hv_CameraSetupModelID);
  hv_OM3DCameraOrigin = hv_OM3DCameraOrigin.TupleConcat(hv_OM3DConeOrig);
  PoseInvert(hv_BaseInCamPose, &hv_CamInBasePose);
  RigidTransObjectModel3d(hv_OM3DCameraOrigin, hv_CamInBasePose, &(*hv_OM3DCamera));
  ClearObjectModel3d(hv_OM3DCameraOrigin);
  //
  //Create 3D object model of plane.
  hv_FactorBorder = 1.5;
  PoseCompose(hv_CamInBasePose, hv_PlaneInCamPose0, &hv_PlaneInBasePose);
  gen_ground_plane_object_model_3d((*hv_OM3DToolOrigin), (*hv_OM3DCamera), (*hv_OM3DBase), 
      hv_FactorBorder, hv_PlaneInBasePose, &(*hv_OM3DPlane));
  return;

}

// Chapter: Transformations / Misc
// Short Description: Obtain the pose of the matched model in the base coordinate system in a stationary camera setup. 
void obtain_3d_pose_of_match_stationary_cam (HTuple hv_Row, HTuple hv_Column, HTuple hv_Angle, 
    HTuple hv_HandEyeCalibData, HTuple hv_Poses, HTuple hv_RectificationData, HTuple *hv_ModelInBasePose)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_CamParam, hv_BaseInCamPose, hv_PlaneInModelPose;
  HTuple  hv_MatchingPlaneInCamPose, hv_RectifyImage, hv_ScaleRectification;
  HTuple  hv_OrderOfTransform, hv_OrderOfRotation, hv_ViewOfTransform;
  HTuple  hv_HomMat2DObject, hv_RowObject, hv_ColObject, hv_PXM;
  HTuple  hv_PYM, hv_HomMat3DObject, hv_ModelToMatchInPlanePose;
  HTuple  hv_ModelInPlanePose, hv_ModelInCamPose, hv_ModelToMatchInPlanePartRectPose;
  HTuple  hv_ModelInPlanePartRectPose, hv_CamInBasePose;

  //This procedure obtains the 3D pose from the model to the base of
  //the robot.
  read_message_tuple(hv_HandEyeCalibData, "CamParam", &hv_CamParam);
  read_message_tuple(hv_HandEyeCalibData, "BaseInCamPose", &hv_BaseInCamPose);
  read_message_tuple(hv_Poses, "PlaneInModelPose", &hv_PlaneInModelPose);
  read_message_tuple(hv_Poses, "MatchingPlaneInCamPose", &hv_MatchingPlaneInCamPose);
  read_message_tuple(hv_RectificationData, "RectifyImage", &hv_RectifyImage);
  if (0 != (hv_RectifyImage==HTuple("true")))
  {
    read_message_tuple(hv_RectificationData, "ScaleRectification", &hv_ScaleRectification);
  }
  //
  //Keep track of the pose type used by the robot.
  GetPoseType(hv_PlaneInModelPose, &hv_OrderOfTransform, &hv_OrderOfRotation, &hv_ViewOfTransform);
  //Convert to default pose type.
  ConvertPoseType(hv_MatchingPlaneInCamPose, "Rp+T", "gba", "point", &hv_MatchingPlaneInCamPose);
  ConvertPoseType(hv_PlaneInModelPose, "Rp+T", "gba", "point", &hv_PlaneInModelPose);
  if (0 != (HTuple(HTuple((hv_Row.TupleLength())==1).TupleAnd((hv_Column.TupleLength())==1)).TupleAnd((hv_Angle.TupleLength())==1)))
  {
    VectorAngleToRigid(0, 0, 0, hv_Row, hv_Column, hv_Angle, &hv_HomMat2DObject);
    //col = x, row = y
    if (0 != (hv_RectifyImage==HTuple("false")))
    {
      AffineTransPixel(hv_HomMat2DObject, 0, 0, &hv_RowObject, &hv_ColObject);
      ImagePointsToWorldPlane(hv_CamParam, hv_MatchingPlaneInCamPose, hv_RowObject, 
          hv_ColObject, "m", &hv_PXM, &hv_PYM);
      hv_HomMat3DObject.Clear();
      hv_HomMat3DObject.Append(HTuple(hv_HomMat2DObject[4]));
      hv_HomMat3DObject.Append(HTuple(hv_HomMat2DObject[3]));
      hv_HomMat3DObject.Append(0);
      hv_HomMat3DObject.Append(hv_PXM);
      hv_HomMat3DObject.Append(HTuple(hv_HomMat2DObject[1]));
      hv_HomMat3DObject.Append(HTuple(hv_HomMat2DObject[0]));
      hv_HomMat3DObject.Append(0);
      hv_HomMat3DObject.Append(hv_PYM);
      hv_HomMat3DObject.Append(0);
      hv_HomMat3DObject.Append(0);
      hv_HomMat3DObject.Append(1);
      hv_HomMat3DObject.Append(0);
      HomMat3dToPose(hv_HomMat3DObject, &hv_ModelToMatchInPlanePose);
      PoseCompose(hv_ModelToMatchInPlanePose, hv_PlaneInModelPose, &hv_ModelInPlanePose);
      PoseCompose(hv_MatchingPlaneInCamPose, hv_ModelInPlanePose, &hv_ModelInCamPose);
    }
    else if (0 != (hv_RectifyImage==HTuple("true")))
    {
      hv_HomMat3DObject.Clear();
      hv_HomMat3DObject.Append(HTuple(hv_HomMat2DObject[4]));
      hv_HomMat3DObject.Append(HTuple(hv_HomMat2DObject[3]));
      hv_HomMat3DObject.Append(0);
      hv_HomMat3DObject.Append(HTuple(hv_HomMat2DObject[5])*hv_ScaleRectification);
      hv_HomMat3DObject.Append(HTuple(hv_HomMat2DObject[1]));
      hv_HomMat3DObject.Append(HTuple(hv_HomMat2DObject[0]));
      hv_HomMat3DObject.Append(0);
      hv_HomMat3DObject.Append(HTuple(hv_HomMat2DObject[2])*hv_ScaleRectification);
      hv_HomMat3DObject.Append(0);
      hv_HomMat3DObject.Append(0);
      hv_HomMat3DObject.Append(1);
      hv_HomMat3DObject.Append(0);
      HomMat3dToPose(hv_HomMat3DObject, &hv_ModelToMatchInPlanePartRectPose);
      PoseCompose(hv_ModelToMatchInPlanePartRectPose, hv_PlaneInModelPose, &hv_ModelInPlanePartRectPose);
      PoseCompose(hv_MatchingPlaneInCamPose, hv_ModelInPlanePartRectPose, &hv_ModelInCamPose);
    }
    else
    {
      throw HException("Please set the parameter RectifyImage correctly");
    }
    PoseInvert(hv_BaseInCamPose, &hv_CamInBasePose);
    PoseCompose(hv_CamInBasePose, hv_ModelInCamPose, &(*hv_ModelInBasePose));
    //
    ConvertPoseType((*hv_ModelInBasePose), hv_OrderOfTransform, hv_OrderOfRotation, 
        hv_ViewOfTransform, &(*hv_ModelInBasePose));
  }
  else
  {
    throw HException("Exactly one match should be given as input");
  }
  return;
}

// Chapter: Graphics / Window
// Short Description: Open a new window next to an existing one. 
void open_new_window (HTuple *hv_WindowHandle, HTuple *hv_WindowHandleGraphics)
{

  // Local control variables
  HTuple  hv_Row, hv_Column, hv_Width, hv_Height;

  WaitSeconds(0.1);
  if (HDevWindowStack::IsOpen())
    (*hv_WindowHandle) = HDevWindowStack::GetActive();
  GetWindowExtents((*hv_WindowHandle), &hv_Row, &hv_Column, &hv_Width, &hv_Height);
  dev_open_window_fit_size(0, hv_Width+8, hv_Width, hv_Height, 600, -1, &(*hv_WindowHandleGraphics));
  set_display_font((*hv_WindowHandleGraphics), 14, "mono", "true", "false");
  SetPartStyle((*hv_WindowHandleGraphics), 2);
  return;
}

// Chapter: Graphics / Text
void dev_disp_calibration_data_instructions (HObject ho_Image)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_Text;

  if (HDevWindowStack::IsOpen())
    DispObj(ho_Image, HDevWindowStack::GetActive());
  hv_Text = HTuple("In the code, please");
  hv_Text[1] = HTuple("- read an image of a calibration plate in the measurement plane,");
  hv_Text[2] = HTuple("- specify the location of the calibration plate description file,");
  hv_Text[3] = "- specify the thickness of the calibration plate (in meters) and";
  hv_Text[4] = "- specify initial camera parameters.";
  hv_Text[5] = "";
  hv_Text[6] = HTuple(" (If you did NOT use a standard HALCON calibration plate, ");
  hv_Text[7] = HTuple("  but used create_caltab to create your own calibration plate,");
  hv_Text[8] = HTuple("  you also need to adapt the parameters FinderRow, FinderColumn,");
  hv_Text[9] = "  and MarksPerRow accordingly.)";
  //
  if (HDevWindowStack::IsOpen())
    DispText(HDevWindowStack::GetActive(),hv_Text, "window", "top", "left", "black", 
        HTuple(), HTuple());
  if (HDevWindowStack::IsOpen())
    DispText(HDevWindowStack::GetActive(),"Press Run (F5) to continue", "window", 
        "bottom", "right", "black", HTuple(), HTuple());
  return;
}

// Chapter: 3D Object Model / Creation
// Short Description: Generate 3D object models for the camera and the robot's tool. 
void gen_camera_and_tool_moving_cam_object_model_3d (HTuple hv_ToolInCamPose, HTuple hv_ToolInBasePose, 
    HTuple hv_CameraSize, HTuple hv_ConeLength, HTuple hv_OM3DToolOrig, HTuple hv_CamParam, 
    HTuple *hv_OM3DCamera, HTuple *hv_OM3DTool)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_IdentityPose, hv_CameraSetupModelID;
  HTuple  hv_OM3DCameraOrigin, hv_OM3DConeOrig, hv_CamInToolPose;
  HTuple  hv_CamInBasePose;

  //This procedure helps visualize the camera and its cone, as well
  //as the robot's tool in their current positions.
  //
  //Visualize Tool.
  RigidTransObjectModel3d(hv_OM3DToolOrig, hv_ToolInBasePose, &(*hv_OM3DTool));
  //
  //Visualize Camera.
  CreatePose(0, 0, 0, 0, 0, 0, "Rp+T", "gba", "point", &hv_IdentityPose);
  CreateCameraSetupModel(1, &hv_CameraSetupModelID);
  SetCameraSetupCamParam(hv_CameraSetupModelID, 0, HTuple(), hv_CamParam, hv_IdentityPose);
  gen_camera_setup_object_model_3d(hv_CameraSetupModelID, hv_CameraSize, hv_ConeLength, 
      &hv_OM3DCameraOrigin, &hv_OM3DConeOrig);
  ClearCameraSetupModel(hv_CameraSetupModelID);
  hv_OM3DCameraOrigin = hv_OM3DCameraOrigin.TupleConcat(hv_OM3DConeOrig);
  //
  PoseInvert(hv_ToolInCamPose, &hv_CamInToolPose);
  PoseCompose(hv_ToolInBasePose, hv_CamInToolPose, &hv_CamInBasePose);
  RigidTransObjectModel3d(hv_OM3DCameraOrigin, hv_CamInBasePose, &(*hv_OM3DCamera));
  ClearObjectModel3d(hv_OM3DCameraOrigin);
  return;
}

// Chapter: 3D Object Model / Creation
// Short Description: Generate the 3D object model of the plane. 
void gen_ground_plane_object_model_3d (HTuple hv_OM3DTool, HTuple hv_OM3DCamera, 
    HTuple hv_OM3DBase, HTuple hv_FactorBorder, HTuple hv_PlaneInBasePose, HTuple *hv_OM3DPlane)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_XBase, hv_YBase, hv_ZBase, hv_MinXt;
  HTuple  hv_MinYt, hv_MinZt, hv_MaxXt, hv_MaxYt, hv_MaxZt;
  HTuple  hv_Min, hv_Max, hv_MinT, hv_MaxT, hv_BoundingBox;
  HTuple  hv_PXBB, hv_PYBB, hv_PZBB, hv_BaseInPlanePose, hv_HomMat3D;
  HTuple  hv_PX, hv_PY, hv_PZ, hv_Qx, hv_Qx1, hv_Qy, hv_Qy1;
  HTuple  hv_XPlane, hv_YPlane, hv_ZPlane, hv_HomMat3D1, hv_Qx2;
  HTuple  hv_Qy2, hv_Qz, hv_Faces;

  //This procedure generates the 3D object model of
  //the plane on which objects are matched and grasped.
  //
  hv_XBase = HTuple();
  hv_YBase = HTuple();
  hv_ZBase = HTuple();
  //Extent of tool in base coordinates.
  get_extent_by_axis(hv_OM3DTool, hv_XBase, hv_YBase, hv_ZBase, &hv_XBase, &hv_YBase, 
      &hv_ZBase);
  //Extent of camera in base coordinates.
  get_extent_by_axis(hv_OM3DCamera, hv_XBase, hv_YBase, hv_ZBase, &hv_XBase, &hv_YBase, 
      &hv_ZBase);
  //Extent of base in base coordinates.
  get_extent_by_axis(hv_OM3DBase, hv_XBase, hv_YBase, hv_ZBase, &hv_XBase, &hv_YBase, 
      &hv_ZBase);
  //
  //Joint bounding box.
  hv_MinXt = hv_XBase.TupleMin();
  hv_MinYt = hv_YBase.TupleMin();
  hv_MinZt = hv_ZBase.TupleMin();
  hv_MaxXt = hv_XBase.TupleMax();
  hv_MaxYt = hv_YBase.TupleMax();
  hv_MaxZt = hv_ZBase.TupleMax();
  hv_Min.Clear();
  hv_Min.Append(hv_MinXt);
  hv_Min.Append(hv_MinYt);
  hv_Min.Append(hv_MinZt);
  hv_Max.Clear();
  hv_Max.Append(hv_MaxXt);
  hv_Max.Append(hv_MaxYt);
  hv_Max.Append(hv_MaxZt);
  //
  //Joint bounding box extended by a factor of FactorBorder.
  hv_MinT = ((hv_Max*(1.0-hv_FactorBorder))/2.0)+((hv_Min*(1.0+hv_FactorBorder))/2.0);
  hv_MaxT = ((hv_Max*(1.0+hv_FactorBorder))/2.0)+((hv_Min*(1.0-hv_FactorBorder))/2.0);
  hv_BoundingBox.Clear();
  hv_BoundingBox.Append(hv_MinT);
  hv_BoundingBox.Append(hv_MaxT);
  //
  //Get the eight corner points of the bounding box from the min/max representation.
  get_bounding_box_points_from_min_max(hv_BoundingBox, &hv_PXBB, &hv_PYBB, &hv_PZBB);

  //Transform to plane coordinates (z is direction of the normal of the plane).
  PoseInvert(hv_PlaneInBasePose, &hv_BaseInPlanePose);
  PoseToHomMat3d(hv_BaseInPlanePose, &hv_HomMat3D);
  AffineTransPoint3d(hv_HomMat3D, hv_PXBB, hv_PYBB, hv_PZBB, &hv_PX, &hv_PY, &hv_PZ);
  //
  //Get outline of projection onto the plane.
  hv_Qx = hv_PX.TupleMin();
  hv_Qx1 = hv_PX.TupleMax();
  hv_Qy = hv_PY.TupleMin();
  hv_Qy1 = hv_PY.TupleMax();
  hv_XPlane.Clear();
  hv_XPlane.Append(hv_Qx);
  hv_XPlane.Append(hv_Qx);
  hv_XPlane.Append(hv_Qx1);
  hv_XPlane.Append(hv_Qx1);
  hv_YPlane.Clear();
  hv_YPlane.Append(hv_Qy);
  hv_YPlane.Append(hv_Qy1);
  hv_YPlane.Append(hv_Qy1);
  hv_YPlane.Append(hv_Qy);
  TupleGenConst(4, 0, &hv_ZPlane);
  //
  //Transform back to base coordinates.
  PoseToHomMat3d(hv_PlaneInBasePose, &hv_HomMat3D1);
  AffineTransPoint3d(hv_HomMat3D1, hv_XPlane, hv_YPlane, hv_ZPlane, &hv_Qx2, &hv_Qy2, 
      &hv_Qz);
  //
  //Generate the visualization.
  GenObjectModel3dFromPoints(hv_Qx2, hv_Qy2, hv_Qz, &(*hv_OM3DPlane));
  hv_Faces = HTuple();
  hv_Faces = hv_Faces.TupleConcat(((((HTuple(4).Append(0)).Append(1)).Append(2)).Append(3)));
  SetObjectModel3dAttribMod((*hv_OM3DPlane), "polygons", HTuple(), hv_Faces);
  //
  return;
}

// Chapter: Graphics / Text
void dev_disp_approach_pose_touching_point_instructions (HTuple hv_WindowHandle, 
    HTuple hv_WindowHandleGraphics, HTuple hv_Index)
{

  // Local iconic variables
  HObject  ho_Image, ho_Rectangle;

  // Local control variables
  HTuple  hv_Text, hv_Color, hv_HighlighColumn;

  //
  HDevWindowStack::SetActive(hv_WindowHandle);
  if (HDevWindowStack::IsOpen())
    ClearWindow(HDevWindowStack::GetActive());
  hv_Text = "Calibrate touching point";
  hv_Text[1] = "";
  hv_Text[2] = "General workflow";
  hv_Text[3] = "----------------";
  hv_Text[4] = HTuple("Approach a fixed point in the plane with your gripper, and read the");
  hv_Text[5] = "pose as ToolInBasePoseTouchingPoint.";
  hv_Text[6] = HTuple("Then, approach the same point at least twice again, rotating the tool");
  hv_Text[7] = "around at least two axis and reading the corresponding ";
  hv_Text[8] = "ToolInBasePoseTouchingPoint.";
  hv_Text[9] = "";
  hv_Text[10] = ("Read ToolInBasePoseTouchingPoint "+hv_Index)+HTuple("/3, then press F5.");
  if (HDevWindowStack::IsOpen())
    DispText(HDevWindowStack::GetActive(),hv_Text, "window", "top", "left", "white", 
        "box", "false");
  if (HDevWindowStack::IsOpen())
    DispText(HDevWindowStack::GetActive(),"Press Run (F5) to continue", "window", 
        "bottom", "right", "black", HTuple(), HTuple());
  hv_Color = HTuple(3,"gray");
  hv_Color[hv_Index-1] = "#fbba00";
  if (HDevWindowStack::IsOpen())
    DispText(HDevWindowStack::GetActive(),"   1   ", "window", 255, 12, "black", 
        (HTuple("box_color").Append("shadow")), HTuple(hv_Color[0]).TupleConcat("false"));
  if (HDevWindowStack::IsOpen())
    DispText(HDevWindowStack::GetActive(),"   2   ", "window", 255, 112, "black", 
        (HTuple("box_color").Append("shadow")), HTuple(hv_Color[1]).TupleConcat("false"));
  if (HDevWindowStack::IsOpen())
    DispText(HDevWindowStack::GetActive(),"   3   ", "window", 255, 212, "black", 
        (HTuple("box_color").Append("shadow")), HTuple(hv_Color[2]).TupleConcat("false"));
  //
  HDevWindowStack::SetActive(hv_WindowHandleGraphics);
  if (HDevWindowStack::IsOpen())
    ClearWindow(HDevWindowStack::GetActive());
  ReadImage(&ho_Image, "3d_machine_vision/handeye/instruction_images/tool_in_base_pose_touching_point");
  if (HDevWindowStack::IsOpen())
    DispObj(ho_Image, HDevWindowStack::GetActive());
  hv_HighlighColumn = 255+(hv_Index*200);
  GenRectangle1(&ho_Rectangle, 320, hv_HighlighColumn-100, 630, hv_HighlighColumn+100);
  if (HDevWindowStack::IsOpen())
    SetLineWidth(HDevWindowStack::GetActive(),4);
  if (HDevWindowStack::IsOpen())
    SetDraw(HDevWindowStack::GetActive(),"margin");
  if (HDevWindowStack::IsOpen())
    SetColor(HDevWindowStack::GetActive(),"#fbba00");
  if (HDevWindowStack::IsOpen())
    DispObj(ho_Rectangle, HDevWindowStack::GetActive());
  if (HDevWindowStack::IsOpen())
    DispText(HDevWindowStack::GetActive(),"Read this pose", "image", 6350, hv_HighlighColumn-105, 
        "black", "box_color", "#fbba00");
  return;
}

// Chapter: 3D Object Model / Creation
// Short Description: Generate base and tool 3D models of the robot. 
void gen_robot_tool_and_base_object_model_3d (HTuple hv_ArrowThickness, HTuple hv_ArrowLength, 
    HTuple *hv_OM3DToolOrigin, HTuple *hv_OM3DBase)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_IdentityPose, hv_TransXPose, hv_OM3DToolXOrigin;
  HTuple  hv_TransYPose, hv_OM3DToolYOrigin, hv_TransZPose;
  HTuple  hv_OM3DToolZOrigin, hv_FactorVisBase, hv_OM3DBasePlate;
  HTuple  hv_OM3DBaseX, hv_OM3DBaseY, hv_OM3DBaseZ;

  //This procedure creates 3D models that represent the tool and the base
  //of the robot.
  //
  if (0 != (hv_ArrowThickness<=0))
  {
    throw HException("ArrowThickness should be > 0");
  }
  if (0 != (hv_ArrowLength<=0))
  {
    throw HException("ArrowLength should be > 0");
  }
  CreatePose(0, 0, 0, 0, 0, 0, "Rp+T", "gba", "point", &hv_IdentityPose);
  //
  //3D model for the tool.
  CreatePose(hv_ArrowLength, 0, 0, 0, 0, 0, "Rp+T", "gba", "point", &hv_TransXPose);
  gen_arrow_object_model_3d(hv_ArrowThickness, hv_IdentityPose, hv_TransXPose, &hv_OM3DToolXOrigin);
  CreatePose(0, hv_ArrowLength, 0, 0, 0, 0, "Rp+T", "gba", "point", &hv_TransYPose);
  gen_arrow_object_model_3d(hv_ArrowThickness, hv_IdentityPose, hv_TransYPose, &hv_OM3DToolYOrigin);
  CreatePose(0, 0, hv_ArrowLength, 0, 0, 0, "Rp+T", "gba", "point", &hv_TransZPose);
  gen_arrow_object_model_3d(hv_ArrowThickness, hv_IdentityPose, hv_TransZPose, &hv_OM3DToolZOrigin);
  (*hv_OM3DToolOrigin).Clear();
  (*hv_OM3DToolOrigin).Append(hv_OM3DToolXOrigin);
  (*hv_OM3DToolOrigin).Append(hv_OM3DToolYOrigin);
  (*hv_OM3DToolOrigin).Append(hv_OM3DToolZOrigin);
  //
  //3D model for the base.
  hv_FactorVisBase = hv_ArrowThickness*10;
  GenBoxObjectModel3d(hv_IdentityPose, hv_FactorVisBase*1.5, hv_FactorVisBase*1.5, 
      hv_FactorVisBase/12, &hv_OM3DBasePlate);
  CreatePose(hv_ArrowLength, 0, 0, 0, 0, 0, "Rp+T", "gba", "point", &hv_TransXPose);
  gen_arrow_object_model_3d(hv_ArrowThickness, hv_IdentityPose, hv_TransXPose, &hv_OM3DBaseX);
  CreatePose(0, hv_ArrowLength, 0, 0, 0, 0, "Rp+T", "gba", "point", &hv_TransYPose);
  gen_arrow_object_model_3d(hv_ArrowThickness, hv_IdentityPose, hv_TransYPose, &hv_OM3DBaseY);
  CreatePose(0, 0, hv_ArrowLength, 0, 0, 0, "Rp+T", "gba", "point", &hv_TransZPose);
  gen_arrow_object_model_3d(hv_ArrowThickness, hv_IdentityPose, hv_TransZPose, &hv_OM3DBaseZ);
  (*hv_OM3DBase).Clear();
  (*hv_OM3DBase).Append(hv_OM3DBaseX);
  (*hv_OM3DBase).Append(hv_OM3DBaseY);
  (*hv_OM3DBase).Append(hv_OM3DBaseZ);
  (*hv_OM3DBase).Append(hv_OM3DBasePlate);
  return;
}

// Chapter: Transformations / Misc
// Short Description: Calculate the touching point in tool coordinates. 
void get_robot_touching_point_in_tool_coordinates (HTupleVector/*{eTupleVector,Dim=1}*/ hvec_ToolInBasePosesTouchingPoint, 
    HTuple *hv_RobotTouchingPointInToolCoordinates)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_LHS, hv_RHS, hv_HomMat3D0, hv_Mat0;
  HTuple  hv_MatRot0, hv_MatTrans0, hv_Index, hv_HomMat3D;
  HTuple  hv_Mat, hv_MatRot, hv_MatTrans, hv_MatrixResultID;
  HTuple  hv_DetailedErrors, hv_MinDiffToIdentity, hv_MinCosAngle;
  HTuple  hv_Index1, hv_CosAngle, hv_MaxAngleBetweenRotationAxes;
  HTuple  hv_MatrixUID, hv_MatrixSID, hv_MatrixVID, hv_SingularValues;
  HTuple  hv_MinSingularValue;
  HTupleVector  hvec_RotationAxisRelativ(1), hvec_DiffToIdentity(1);

  //To estimate the touching point with respect to the tool coordinate system, we have to
  //arrange three equations in the following form:
  //Rp + T = q,
  //where R is a is the rotation matrix that rotates a point from the tool to the base coordinate
  //system and T is a translation that translates a point from the tool to the base coordinate.
  //q is the touching point with respect to the base coordinate system
  //and p the unknown touching point with respect to the tool coordinate system.
  //
  //Approaching the same point three times while rotating the tool leads to three rotation matrices
  //R0, R1 and R2 and three translations T0, T1 and T2.
  //Solving this equation for the unknown touching point yields therefore:
  //R0*p + T0 = q, R1*p + T1 = q and R2*p + T2 = q.
  //After building two equations in the form (R1-R0)*p = T0-T1 and (R2-R0)*p = T0-T2,
  //the DLT (direct linear transformation) can be used to efficiently solve for the unknown
  //touching point p.


  //Check input.
  if (0 != (HTuple(hvec_ToolInBasePosesTouchingPoint.Length())<3))
  {
    throw HException("Please specify at least three robot poses.");
  }

  //Initialize equation.
  CreateMatrix((HTuple(hvec_ToolInBasePosesTouchingPoint.Length())-1)*3, 3, 0, &hv_LHS);
  CreateMatrix((HTuple(hvec_ToolInBasePosesTouchingPoint.Length())-1)*3, 1, 0, &hv_RHS);
  hvec_RotationAxisRelativ = (HTupleVector(1).Insert(0,HTupleVector(HTuple())));
  hvec_DiffToIdentity = (HTupleVector(1).Insert(0,HTupleVector(HTuple())));
  //Decompose first pose.
  PoseToHomMat3d(hvec_ToolInBasePosesTouchingPoint[0].T(), &hv_HomMat3D0);
  CreateMatrix(3, 4, hv_HomMat3D0, &hv_Mat0);
  GetSubMatrix(hv_Mat0, 0, 0, 3, 3, &hv_MatRot0);
  GetSubMatrix(hv_Mat0, 0, 3, 3, 1, &hv_MatTrans0);
  //
  {
  HTuple end_val33 = HTuple(hvec_ToolInBasePosesTouchingPoint.Length())-1;
  HTuple step_val33 = 1;
  for (hv_Index=1; hv_Index.Continue(end_val33, step_val33); hv_Index += step_val33)
  {
    //Decompose current pose.
    PoseToHomMat3d(hvec_ToolInBasePosesTouchingPoint[hv_Index].T(), &hv_HomMat3D);
    CreateMatrix(3, 4, hv_HomMat3D, &hv_Mat);
    GetSubMatrix(hv_Mat, 0, 0, 3, 3, &hv_MatRot);
    GetSubMatrix(hv_Mat, 0, 3, 3, 1, &hv_MatTrans);
    //Get rotation axis relativ to first pose.
    {
    HTuple ExpTmpOutVar_0;HTuple ExpTmpOutVar_1;
    get_rotation_axis(hv_MatRot, hv_MatRot0, &ExpTmpOutVar_0, &ExpTmpOutVar_1);
    hvec_RotationAxisRelativ[hv_Index].T() = ExpTmpOutVar_0;
    hvec_DiffToIdentity[hv_Index].T() = ExpTmpOutVar_1;
    }
    //Fill equation.
    SubMatrixMod(hv_MatRot, hv_MatRot0);
    SetSubMatrix(hv_LHS, hv_MatRot, (hv_Index-1)*3, 0);
    SubMatrixMod(hv_MatTrans, hv_MatTrans0);
    ScaleMatrixMod(hv_MatTrans, -1.0);
    SetSubMatrix(hv_RHS, hv_MatTrans, (hv_Index-1)*3, 0);
    //Clear.
    ClearMatrix(hv_Mat);
    ClearMatrix(hv_MatRot);
    ClearMatrix(hv_MatTrans);
  }
  }
  //Solve.
  SolveMatrix(hv_LHS, "general", 0, hv_RHS, &hv_MatrixResultID);
  GetFullMatrix(hv_MatrixResultID, &(*hv_RobotTouchingPointInToolCoordinates));
  //Detailed errors.
  hv_DetailedErrors = 0;
  if (0 != hv_DetailedErrors)
  {
    //Check that the tool was tilted enough compared to the first pose.
    hv_MinDiffToIdentity = 1e8;
    {
    HTuple end_val60 = HTuple(hvec_ToolInBasePosesTouchingPoint.Length())-1;
    HTuple step_val60 = 1;
    for (hv_Index=1; hv_Index.Continue(end_val60, step_val60); hv_Index += step_val60)
    {
      if (0 != (hvec_DiffToIdentity[hv_Index].T()<hv_MinDiffToIdentity))
      {
        hv_MinDiffToIdentity = hvec_DiffToIdentity[hv_Index].T();
      }
    }
    }
    //Check that different rotation axis were used when tilted away from first pose.
    hv_MinCosAngle = 1.5;
    {
    HTuple end_val67 = HTuple(hvec_ToolInBasePosesTouchingPoint.Length())-2;
    HTuple step_val67 = 1;
    for (hv_Index=1; hv_Index.Continue(end_val67, step_val67); hv_Index += step_val67)
    {
      {
      HTuple end_val68 = HTuple(hvec_ToolInBasePosesTouchingPoint.Length())-1;
      HTuple step_val68 = 1;
      for (hv_Index1=hv_Index+1; hv_Index1.Continue(end_val68, step_val68); hv_Index1 += step_val68)
      {
        hv_CosAngle = ((hvec_RotationAxisRelativ[hv_Index].T()*hvec_RotationAxisRelativ[hv_Index1].T()).TupleSum()).TupleAbs();
        if (0 != (hv_CosAngle<hv_MinCosAngle))
        {
          hv_MinCosAngle = hv_CosAngle;
        }
      }
      }
    }
    }
    hv_MaxAngleBetweenRotationAxes = (hv_MinCosAngle.TupleAcos()).TupleDeg();
  }
  SvdMatrix(hv_LHS, "full", "both", &hv_MatrixUID, &hv_MatrixSID, &hv_MatrixVID);
  GetValueMatrix(hv_MatrixSID, ((HTuple(0).Append(1)).Append(2)), ((HTuple(0).Append(1)).Append(2)), 
      &hv_SingularValues);
  hv_MinSingularValue = (hv_SingularValues.TupleAbs()).TupleMin();
  if (0 != (hv_MinSingularValue<0.15))
  {
    //Consider the rotations of the tool from its first position to each following position.
    //Please rotate the tool enough away from the first position.
    //Furthermore, please use at least two significantly different rotation axis when rotating the tool
    //from its first position (preferably orthogonal directions?).
    //The maximum angle between the corresponding rotation axis is MaxAngleBetweenRotationAxes.
    //
    throw HException("The estimated touching point might not be reliable. Try to use at least two different rotation axis and/or increase the rotations around these axis.");
  }
  //
  //Clear.
  ClearMatrix(hv_MatrixUID);
  ClearMatrix(hv_MatrixSID);
  ClearMatrix(hv_MatrixVID);
  ClearMatrix(hv_Mat0);
  ClearMatrix(hv_MatRot0);
  ClearMatrix(hv_MatTrans0);
  ClearMatrix(hv_LHS);
  ClearMatrix(hv_RHS);
  return;
}

// Chapter: Transformations / Misc
// Short Description: Obtain the pose of the matched model in the base coordinate system. 
void obtain_3d_pose_of_match_moving_cam (HTuple hv_Row, HTuple hv_Column, HTuple hv_Angle, 
    HTuple hv_ToolInBasePose, HTuple hv_HandEyeCalibData, HTuple hv_Poses, HTuple hv_RectificationData, 
    HTuple *hv_ModelInBasePose)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_CamParam, hv_ToolInCamPose, hv_PlaneInModelPose;
  HTuple  hv_RectifyImage, hv_ScaleRectification, hv_MatchingPlaneRectifiedPartInCamPose;
  HTuple  hv_OrderOfTransform, hv_OrderOfRotation, hv_ViewOfTransform;
  HTuple  hv_HomMat2DObject, hv_RowObject, hv_ColObject, hv_PXM;
  HTuple  hv_PYM, hv_HomMat3DObject, hv_ModelToMatchInPlanePose;
  HTuple  hv_ModelInPlanePose, hv_ModelInCamPose, hv_ModelToMatchInPlanePartRectPose;
  HTuple  hv_ModelInMatchingPlaneRectifiedPartPose, hv_BaseInToolPose;
  HTuple  hv_BaseInCamPose, hv_CamInBasePose;

  //This procedure obtains the 3D pose from the model to the base of
  //the robot.
  read_message_tuple(hv_HandEyeCalibData, "CamParam", &hv_CamParam);
  read_message_tuple(hv_HandEyeCalibData, "ToolInCamPose", &hv_ToolInCamPose);
  read_message_tuple(hv_Poses, "PlaneInModelPose", &hv_PlaneInModelPose);
  read_message_tuple(hv_RectificationData, "RectifyImage", &hv_RectifyImage);
  if (0 != (hv_RectifyImage!=HTuple("no_rectification")))
  {
    read_message_tuple(hv_RectificationData, "ScaleRectification", &hv_ScaleRectification);
  }
  read_message_tuple(hv_RectificationData, "MatchingPlaneRectifiedPartInCamPose", 
      &hv_MatchingPlaneRectifiedPartInCamPose);
  //
  //Keep track of the pose type used by the robot.
  GetPoseType(hv_ToolInBasePose, &hv_OrderOfTransform, &hv_OrderOfRotation, &hv_ViewOfTransform);
  //Convert to default pose type.
  ConvertPoseType(hv_MatchingPlaneRectifiedPartInCamPose, "Rp+T", "gba", "point", 
      &hv_MatchingPlaneRectifiedPartInCamPose);
  ConvertPoseType(hv_PlaneInModelPose, "Rp+T", "gba", "point", &hv_PlaneInModelPose);
  ConvertPoseType(hv_ToolInBasePose, "Rp+T", "gba", "point", &hv_ToolInBasePose);
  ConvertPoseType(hv_ToolInCamPose, "Rp+T", "gba", "point", &hv_ToolInCamPose);
  if (0 != ((hv_Row.TupleLength())==1))
  {
    VectorAngleToRigid(0, 0, 0, hv_Row, hv_Column, hv_Angle, &hv_HomMat2DObject);
    //Col = x, Row = y.
    if (0 != (hv_RectifyImage==HTuple("no_rectification")))
    {
      AffineTransPixel(hv_HomMat2DObject, 0, 0, &hv_RowObject, &hv_ColObject);
      ImagePointsToWorldPlane(hv_CamParam, hv_MatchingPlaneRectifiedPartInCamPose, 
          hv_RowObject, hv_ColObject, "m", &hv_PXM, &hv_PYM);
      hv_HomMat3DObject.Clear();
      hv_HomMat3DObject.Append(HTuple(hv_HomMat2DObject[4]));
      hv_HomMat3DObject.Append(HTuple(hv_HomMat2DObject[3]));
      hv_HomMat3DObject.Append(0);
      hv_HomMat3DObject.Append(hv_PXM);
      hv_HomMat3DObject.Append(HTuple(hv_HomMat2DObject[1]));
      hv_HomMat3DObject.Append(HTuple(hv_HomMat2DObject[0]));
      hv_HomMat3DObject.Append(0);
      hv_HomMat3DObject.Append(hv_PYM);
      hv_HomMat3DObject.Append(0);
      hv_HomMat3DObject.Append(0);
      hv_HomMat3DObject.Append(1);
      hv_HomMat3DObject.Append(0);
      HomMat3dToPose(hv_HomMat3DObject, &hv_ModelToMatchInPlanePose);
      PoseCompose(hv_ModelToMatchInPlanePose, hv_PlaneInModelPose, &hv_ModelInPlanePose);
      PoseCompose(hv_MatchingPlaneRectifiedPartInCamPose, hv_ModelInPlanePose, &hv_ModelInCamPose);
    }
    else if (0 != (HTuple(hv_RectifyImage==HTuple("only_rectify")).TupleOr(hv_RectifyImage==HTuple("align_and_rectify"))))
    {
      hv_HomMat3DObject.Clear();
      hv_HomMat3DObject.Append(HTuple(hv_HomMat2DObject[4]));
      hv_HomMat3DObject.Append(HTuple(hv_HomMat2DObject[3]));
      hv_HomMat3DObject.Append(0);
      hv_HomMat3DObject.Append(HTuple(hv_HomMat2DObject[5])*hv_ScaleRectification);
      hv_HomMat3DObject.Append(HTuple(hv_HomMat2DObject[1]));
      hv_HomMat3DObject.Append(HTuple(hv_HomMat2DObject[0]));
      hv_HomMat3DObject.Append(0);
      hv_HomMat3DObject.Append(HTuple(hv_HomMat2DObject[2])*hv_ScaleRectification);
      hv_HomMat3DObject.Append(0);
      hv_HomMat3DObject.Append(0);
      hv_HomMat3DObject.Append(1);
      hv_HomMat3DObject.Append(0);
      HomMat3dToPose(hv_HomMat3DObject, &hv_ModelToMatchInPlanePartRectPose);
      PoseCompose(hv_ModelToMatchInPlanePartRectPose, hv_PlaneInModelPose, &hv_ModelInMatchingPlaneRectifiedPartPose);
      PoseCompose(hv_MatchingPlaneRectifiedPartInCamPose, hv_ModelInMatchingPlaneRectifiedPartPose, 
          &hv_ModelInCamPose);
    }
    else
    {
      throw HException("Please set the parameter RectifyImage correctly");
    }
    PoseInvert(hv_ToolInBasePose, &hv_BaseInToolPose);
    PoseCompose(hv_ToolInCamPose, hv_BaseInToolPose, &hv_BaseInCamPose);
    PoseInvert(hv_BaseInCamPose, &hv_CamInBasePose);
    PoseCompose(hv_CamInBasePose, hv_ModelInCamPose, &(*hv_ModelInBasePose));
    //
    ConvertPoseType((*hv_ModelInBasePose), hv_OrderOfTransform, hv_OrderOfRotation, 
        hv_ViewOfTransform, &(*hv_ModelInBasePose));
  }
  else
  {
    throw HException("Exactly one match should be given as input");
  }
  return;
}

// Chapter: 3D Object Model / Creation
// Short Description: Generate 3D object models for the camera, robot's tool and plane. 
void gen_current_setup_moving_cam_object_model_3d (HTuple hv_CameraSize, HTuple hv_ToolInBasePose, 
    HTuple hv_HandEyeCalibData, HTuple hv_OM3DToolOrigin, HTuple hv_OM3DBase, HTuple *hv_OM3DCamera, 
    HTuple *hv_OM3DTool, HTuple *hv_OM3DPlane)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_ToolInCamPose, hv_CamParam, hv_PlaneInBasePose0;
  HTuple  hv_BaseInToolPose, hv_PlaneInToolPose, hv_PlaneInCamPose;
  HTuple  hv_CX, hv_CY, hv_OptAxisPlaneX, hv_OptAxisPlaneY;
  HTuple  hv_HomMat3D, hv_OptAxisCamX, hv_OptAxisCamY, hv_OptAxisCamZ;
  HTuple  hv_ConeLength, hv_FactorBorder;

  //This procedure visualizes the camera, tool, and plane in their
  //current positions.
  //
  read_message_tuple(hv_HandEyeCalibData, "ToolInCamPose", &hv_ToolInCamPose);
  read_message_tuple(hv_HandEyeCalibData, "CamParam", &hv_CamParam);
  read_message_tuple(hv_HandEyeCalibData, "PlaneInBasePose0", &hv_PlaneInBasePose0);
  //
  if (0 != (hv_CameraSize<=0))
  {
    throw HException("CameraSize should be > 0");
  }
  //
  //Visualize current camera and tool position.
  //
  //Get the intersection of the optical axis of the camera and the plane
  PoseInvert(hv_ToolInBasePose, &hv_BaseInToolPose);
  PoseCompose(hv_BaseInToolPose, hv_PlaneInBasePose0, &hv_PlaneInToolPose);
  PoseCompose(hv_ToolInCamPose, hv_PlaneInToolPose, &hv_PlaneInCamPose);
  get_cam_par_data(hv_CamParam, "cx", &hv_CX);
  get_cam_par_data(hv_CamParam, "cy", &hv_CY);
  ImagePointsToWorldPlane(hv_CamParam, hv_PlaneInCamPose, hv_CY, hv_CX, "m", &hv_OptAxisPlaneX, 
      &hv_OptAxisPlaneY);
  //Transform to camera coordinates
  PoseToHomMat3d(hv_PlaneInCamPose, &hv_HomMat3D);
  AffineTransPoint3d(hv_HomMat3D, hv_OptAxisPlaneX, hv_OptAxisPlaneY, 0, &hv_OptAxisCamX, 
      &hv_OptAxisCamY, &hv_OptAxisCamZ);
  hv_ConeLength = hv_OptAxisCamZ*1.1;
  //If the optical axis does not intersect the plane, we still want to visualize the camera.
  if (0 != (hv_ConeLength<=0.0))
  {
    hv_ConeLength = hv_CameraSize;
  }
  gen_camera_and_tool_moving_cam_object_model_3d(hv_ToolInCamPose, hv_ToolInBasePose, 
      hv_CameraSize, hv_ConeLength, hv_OM3DToolOrigin, hv_CamParam, &(*hv_OM3DCamera), 
      &(*hv_OM3DTool));
  //
  //Create 3D object model of plane.
  hv_FactorBorder = 1.5;
  gen_ground_plane_object_model_3d((*hv_OM3DTool), (*hv_OM3DCamera), hv_OM3DBase, 
      hv_FactorBorder, hv_PlaneInBasePose0, &(*hv_OM3DPlane));
  return;
}

// Chapter: Graphics / Text
// Short Description: Display the introduction for the procedure calibrate_robot_touching_point. 
void dev_disp_introduction (HTuple hv_WindowHandle, HTuple hv_WindowHandleGraphics)
{

  // Local iconic variables
  HObject  ho_InstructionImage;

  // Local control variables
  HTuple  hv_Text, hv_Row, hv_Column, hv_Width;
  HTuple  hv_Height;

  //
  HDevWindowStack::SetActive(hv_WindowHandle);
  if (HDevWindowStack::IsOpen())
    ClearWindow(HDevWindowStack::GetActive());
  hv_Text = HTuple("With this procedure, we calibrate the coordinates of the touching point");
  hv_Text[1] = "of a robot with respect to the robot's tool.";
  hv_Text[2] = "";
  hv_Text[3] = "The touching point is a point that has to be fixed with respect to";
  hv_Text[4] = HTuple("the tool coordinate system, but does not have to be located on the");
  hv_Text[5] = HTuple("surface of the gripper. It can, for example, lie halfway between");
  hv_Text[6] = "two fingers of a gripper.";
  hv_Text[7] = "";
  hv_Text[8] = "The touching point should be chosen such that it can approach ";
  hv_Text[9] = "a point in the plane easily and accurately.";
  hv_Text[10] = "";
  hv_Text[11] = "The coordinates of this point (RobotTouchingPointInToolCoordinates)";
  hv_Text[12] = HTuple("are necessary, for example, to perform a hand-eye calibration of a robot");
  hv_Text[13] = "with a stationary camera.";
  hv_Text[14] = "";
  hv_Text[15] = "This procedure is used in the example";
  hv_Text[16] = "calibrate_hand_eye_stationary_cam_approx.hdev.";
  if (HDevWindowStack::IsOpen())
    DispText(HDevWindowStack::GetActive(),hv_Text, "window", "top", "left", "white", 
        "box", "false");
  if (HDevWindowStack::IsOpen())
    DispText(HDevWindowStack::GetActive(),"Press Run (F5) to continue", "window", 
        "bottom", "right", "black", HTuple(), HTuple());
  //
  HDevWindowStack::SetActive(hv_WindowHandleGraphics);
  ReadImage(&ho_InstructionImage, "3d_machine_vision/handeye/instruction_images/robot_touching_point_in_tool_coordinates");
  GetWindowExtents(hv_WindowHandle, &hv_Row, &hv_Column, &hv_Width, &hv_Height);
  dev_resize_window_fit_image(ho_InstructionImage, 0, hv_Width+10, 600, -1);
  if (HDevWindowStack::IsOpen())
    DispObj(ho_InstructionImage, HDevWindowStack::GetActive());
  return;

}

// Chapter: 3D Object Model / Creation
// Short Description: Generate a 3D object of the matched model, in the case of rectification. 
void gen_matching_object_model_3d (HTuple hv_ModelID, HTuple hv_ObjectHeight, HTuple hv_Poses, 
    HTuple hv_HandEyeCalibData, HTuple hv_RectificationData, HTuple *hv_OM3DModel)
{

  // Local iconic variables
  HObject  ho_ModelContours, ho_ObjectSelected;

  // Local control variables
  HTuple  hv_CamParam, hv_MatchingPlaneInCamPose;
  HTuple  hv_RectifyImage, hv_ScaleRectification, hv_Number;
  HTuple  hv_ModelRows, hv_ModelCols, hv_Index, hv_Row1, hv_Col1;
  HTuple  hv_PX, hv_PY, hv_PXPlane, hv_PYPlane, hv_PXPlaneOrig;
  HTuple  hv_PYPlaneOrig, hv_PZ1, hv_PZ2, hv_PlanePartRectToModelPose;
  HTuple  hv_HomMat3D, hv_Qx, hv_Qy, hv_Qz;

  //This procedure generates a 3D model from a shape model for
  //visualization for a known (rectified) matching plane.
  //
  //The 3D model consists of the model-contours transformed to
  //their real world size. The origin of the 3D model coordinate system
  //lies in the origin of the input shape model with the z-axis
  //pointing towards the camera. The model contours are displayed
  //twice, at z = 0 and z = ObjectHeight.
  //
  read_message_tuple(hv_HandEyeCalibData, "CamParam", &hv_CamParam);
  read_message_tuple(hv_Poses, "MatchingPlaneInCamPose", &hv_MatchingPlaneInCamPose);
  read_message_tuple(hv_RectificationData, "RectifyImage", &hv_RectifyImage);
  if (0 != (HTuple(HTuple(hv_RectifyImage==HTuple("true")).TupleOr(hv_RectifyImage==HTuple("only_rectify"))).TupleOr(hv_RectifyImage==HTuple("align_and_rectify"))))
  {
    read_message_tuple(hv_RectificationData, "ScaleRectification", &hv_ScaleRectification);
  }
  //
  //Get shape model contours.
  GetShapeModelContours(&ho_ModelContours, hv_ModelID, 1);
  CountObj(ho_ModelContours, &hv_Number);
  hv_ModelRows = HTuple();
  hv_ModelCols = HTuple();
  {
  HTuple end_val21 = hv_Number;
  HTuple step_val21 = 1;
  for (hv_Index=1; hv_Index.Continue(end_val21, step_val21); hv_Index += step_val21)
  {
    SelectObj(ho_ModelContours, &ho_ObjectSelected, hv_Index);
    GetContourXld(ho_ObjectSelected, &hv_Row1, &hv_Col1);
    hv_ModelRows = hv_ModelRows.TupleConcat(hv_Row1);
    hv_ModelCols = hv_ModelCols.TupleConcat(hv_Col1);
  }
  }
  //Obtain real world size (col = x, row = y), centered around the shape model origin (0,0).
  if (0 != (HTuple(HTuple(hv_RectifyImage==HTuple("true")).TupleOr(hv_RectifyImage==HTuple("only_rectify"))).TupleOr(hv_RectifyImage==HTuple("align_and_rectify"))))
  {
    hv_PX = hv_ModelCols*hv_ScaleRectification;
    hv_PY = hv_ModelRows*hv_ScaleRectification;
  }
  else
  {
    ImagePointsToWorldPlane(hv_CamParam, hv_MatchingPlaneInCamPose, hv_ModelRows, 
        hv_ModelCols, "m", &hv_PXPlane, &hv_PYPlane);
    ImagePointsToWorldPlane(hv_CamParam, hv_MatchingPlaneInCamPose, 0, 0, "m", &hv_PXPlaneOrig, 
        &hv_PYPlaneOrig);
    hv_PX = hv_PXPlane-hv_PXPlaneOrig;
    hv_PY = hv_PYPlane-hv_PYPlaneOrig;
  }
  //Display the contours twice, once in the plane, once above.
  TupleGenConst(hv_PY.TupleLength(), 0, &hv_PZ1);
  TupleGenConst(hv_PY.TupleLength(), hv_ObjectHeight, &hv_PZ2);
  //Transform from plane to model coordinate system. The plane
  //coordinate system has previously been adapted such that its
  //z-axis points away from the camera.
  CreatePose(0, 0, hv_ObjectHeight, 180, 0, 0, "Rp+T", "gba", "point", &hv_PlanePartRectToModelPose);
  PoseToHomMat3d(hv_PlanePartRectToModelPose, &hv_HomMat3D);
  AffineTransPoint3d(hv_HomMat3D, hv_PX.TupleConcat(hv_PX), hv_PY.TupleConcat(hv_PY), 
      hv_PZ1.TupleConcat(hv_PZ2), &hv_Qx, &hv_Qy, &hv_Qz);
  GenObjectModel3dFromPoints(hv_Qx, hv_Qy, hv_Qz, &(*hv_OM3DModel));
  return;
}

// Chapter: 3D Object Model / Creation
void gen_tool_to_touching_point_object_model_3d (HTupleVector/*{eTupleVector,Dim=1}*/ hvec_ToolInBasePosesTouchingPoint, 
    HTuple hv_RobotTouchingPointInToolCoordinates, HTuple *hv_OM3DToolTouchingPoint)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_OM3DToolOrigin, hv_OM3DToolTouchingPointTmp;
  HTuple  hv_Index, hv_OM3DRigidTrans, hv_OM3DBase;

  //
  gen_robot_tool_and_base_object_model_3d(0.0025, 0.05, &hv_OM3DToolOrigin, &hv_OM3DBase);
  GenObjectModel3dFromPoints(HTuple(0).TupleConcat(HTuple(hv_RobotTouchingPointInToolCoordinates[0])), 
      HTuple(0).TupleConcat(HTuple(hv_RobotTouchingPointInToolCoordinates[1])), HTuple(0).TupleConcat(HTuple(hv_RobotTouchingPointInToolCoordinates[2])), 
      &(*hv_OM3DToolTouchingPoint));
  SetObjectModel3dAttribMod((*hv_OM3DToolTouchingPoint), "lines", HTuple(), ((HTuple(2).Append(0)).Append(1)));
  hv_OM3DToolTouchingPointTmp.Clear();
  hv_OM3DToolTouchingPointTmp.Append(hv_OM3DToolOrigin);
  hv_OM3DToolTouchingPointTmp.Append((*hv_OM3DToolTouchingPoint));
  //
  (*hv_OM3DToolTouchingPoint) = HTuple();
  {
  HTuple end_val7 = HTuple(hvec_ToolInBasePosesTouchingPoint.Length())-1;
  HTuple step_val7 = 1;
  for (hv_Index=0; hv_Index.Continue(end_val7, step_val7); hv_Index += step_val7)
  {
    RigidTransObjectModel3d(hv_OM3DToolTouchingPointTmp, hvec_ToolInBasePosesTouchingPoint[hv_Index].T(), 
        &hv_OM3DRigidTrans);
    (*hv_OM3DToolTouchingPoint) = (*hv_OM3DToolTouchingPoint).TupleConcat(hv_OM3DRigidTrans);
  }
  }
  return;
}

// Chapter: Classification / Misc
// Short Description: Returns the length of the feature vector for each feature name. 
void get_feature_lengths (HTuple hv_FeatureNames, HTuple *hv_Lengths)
{

  // Local iconic variables
  HObject  ho_Region, ho_Image;

  //
  //Calculate the lengths of the feature vectors of
  //the features in FeatureNames.
  //
  gen_dummy_objects(&ho_Region, &ho_Image);
  get_features(ho_Region, ho_Image, hv_FeatureNames, "get_lengths", &(*hv_Lengths));
  return;
}

// Chapter: Classification / Misc
// Short Description: List all available feature group names. 
void query_feature_group_names (HTuple *hv_GroupNames)
{

  // Local iconic variables
  HObject  ho_Region, ho_Image;

  //
  //Return all available feature groups
  //
  gen_dummy_objects(&ho_Region, &ho_Image);
  get_features(ho_Region, ho_Image, "", "get_groups", &(*hv_GroupNames));
  (*hv_GroupNames) = ((*hv_GroupNames).TupleSort()).TupleUniq();
  (*hv_GroupNames) = (*hv_GroupNames).TupleConcat("all");
  return;
}

// Chapter: Calibration / Camera Parameters
// Short Description: Generate a camera parameter tuple for an area scan camera with distortions modeled by the polynomial model. 
void gen_cam_par_area_scan_polynomial (HTuple hv_Focus, HTuple hv_K1, HTuple hv_K2, 
    HTuple hv_K3, HTuple hv_P1, HTuple hv_P2, HTuple hv_Sx, HTuple hv_Sy, HTuple hv_Cx, 
    HTuple hv_Cy, HTuple hv_ImageWidth, HTuple hv_ImageHeight, HTuple *hv_CameraParam)
{

  // Local iconic variables

  //Generate a camera parameter tuple for an area scan camera
  //with distortions modeled by the polynomial model.
  //
  (*hv_CameraParam).Clear();
  (*hv_CameraParam)[0] = "area_scan_polynomial";
  (*hv_CameraParam).Append(hv_Focus);
  (*hv_CameraParam).Append(hv_K1);
  (*hv_CameraParam).Append(hv_K2);
  (*hv_CameraParam).Append(hv_K3);
  (*hv_CameraParam).Append(hv_P1);
  (*hv_CameraParam).Append(hv_P2);
  (*hv_CameraParam).Append(hv_Sx);
  (*hv_CameraParam).Append(hv_Sy);
  (*hv_CameraParam).Append(hv_Cx);
  (*hv_CameraParam).Append(hv_Cy);
  (*hv_CameraParam).Append(hv_ImageWidth);
  (*hv_CameraParam).Append(hv_ImageHeight);
  return;
}

// Chapter: Classification / Misc
// Short Description: Test procedure for custom features. 
void test_features (HTuple hv_FeatureNames)
{

  // Local iconic variables
  HObject  ho_Image, ho_Region, ho_TestRegion, ho_TestRegionSelected;
  HObject  ho_ObjectSelected;

  // Local control variables
  HTuple  hv_TestSuccessful, hv_TestString, hv_Test;
  HTuple  hv_NumRegions, hv_AllFeatures, hv_Index, hv_CurName;
  HTuple  hv_Lengths, hv_CurLength, hv_Features, hv_SumLengths;
  HTuple  hv_Total, hv_I, hv_Features2, hv_J, hv_Features1;
  HTuple  hv_CorrectOrder;

  //
  //Test procedure for custom features
  //
  //This procedure can be used to test, if custom features
  //implemented in get_custom_features comply with the
  //specifications of the calculate_feature_set library.
  //
  //In particular, the feature vector Feature, that is
  //calculated with calculate_feature must fulfil
  //following conditions:
  //
  //- For a single input region the result of
  //  get_feature_length has to be equal to the length
  //  of the featue vector: |Feature| == Length
  //
  //- For an empty input region array, the feature
  //  vector has to be empty:
  //  Feature == []
  //
  //- For input region arrays with multiple regions, the
  //  following condition must be met:
  //  |Feature| == NumRegions * Length
  //
  //- Additionally, the feature vector has to be sorted
  //  according to the 'feature_column' order of
  //  add_sample_class_train_data.
  //
  hv_TestSuccessful = 0;
  ReadImage(&ho_Image, "patras");
  Threshold(ho_Image, &ho_Region, 128, 255);
  get_feature_lengths(hv_FeatureNames, &hv_Lengths);
  //
  hv_TestString[0] = "Empty region array test (no region)";
  hv_TestString[1] = "Empty region test";
  hv_TestString[2] = "Single region test";
  for (hv_Test=0; hv_Test<=2; hv_Test+=1)
  {
    switch (hv_Test.I())
    {
    case 0:
      SelectShape(ho_Region, &ho_TestRegion, "area", "and", 0, 0);
      break;
    case 1:
      GenEmptyRegion(&ho_TestRegion);
      break;
    case 2:
      CopyObj(ho_Region, &ho_TestRegion, 1, 1);
      break;
    default:
      ;
    }
    CountObj(ho_TestRegion, &hv_NumRegions);
    hv_AllFeatures = HTuple();
    {
    HTuple end_val50 = (hv_FeatureNames.TupleLength())-1;
    HTuple step_val50 = 1;
    for (hv_Index=0; hv_Index.Continue(end_val50, step_val50); hv_Index += step_val50)
    {
      hv_CurName = HTuple(hv_FeatureNames[hv_Index]);
      hv_CurLength = HTuple(hv_Lengths[hv_Index]);
      calculate_features(ho_TestRegion, ho_Image, hv_CurName, &hv_Features);
      if (0 != ((hv_NumRegions*hv_CurLength)!=(hv_Features.TupleLength())))
      {
        throw HException(((HTuple(hv_TestString[hv_Test])+" failed for feature '")+hv_CurName)+"'");
      }
      hv_AllFeatures = hv_AllFeatures.TupleConcat(hv_Features);
    }
    }
    hv_SumLengths = hv_Lengths.TupleSum();
    hv_Total = hv_SumLengths*hv_NumRegions;
    if (0 != (hv_Total!=(hv_AllFeatures.TupleLength())))
    {
      throw HException((("Test "+hv_Test)+" failed").TupleConcat(HTuple(hv_TestString[hv_Test])));
    }
  }
  //
  //Test multiple input regions
  Connection(ho_Region, &ho_TestRegion);
  SelectObj(ho_TestRegion, &ho_TestRegionSelected, HTuple::TupleGenSequence(1,3,1));
  {
  HTuple end_val69 = (hv_FeatureNames.TupleLength())-1;
  HTuple step_val69 = 1;
  for (hv_I=0; hv_I.Continue(end_val69, step_val69); hv_I += step_val69)
  {
    hv_CurName = HTuple(hv_FeatureNames[hv_I]);
    calculate_features(ho_TestRegionSelected, ho_Image, hv_CurName, &hv_Features1);
    hv_Features2 = HTuple();
    CountObj(ho_TestRegionSelected, &hv_NumRegions);
    {
    HTuple end_val74 = hv_NumRegions;
    HTuple step_val74 = 1;
    for (hv_J=1; hv_J.Continue(end_val74, step_val74); hv_J += step_val74)
    {
      SelectObj(ho_TestRegionSelected, &ho_ObjectSelected, hv_J);
      calculate_features(ho_ObjectSelected, ho_Image, hv_CurName, &hv_Features);
      hv_Features2 = hv_Features2.TupleConcat(hv_Features);
    }
    }
    hv_CorrectOrder = hv_Features1==hv_Features2;
    if (0 != (hv_CorrectOrder.TupleNot()))
    {
      throw HException(("Multiple region test failed for feature '"+hv_CurName)+"'");
    }
  }
  }
  hv_TestSuccessful = 1;
  return;
}

// Chapter: Classification / Misc
// Short Description: Returns a table of feature names sorted by groups. 
void query_feature_names_by_group (HTuple hv_GroupNames, HTuple *hv_FeatureNames, 
    HTuple *hv_Groups)
{

  // Local iconic variables
  HObject  ho_Region, ho_Image;

  // Local control variables
  HTuple  hv_I, hv_Names;

  //
  //Return a table (consisting of two tuples)
  //of all features and the groups they belong to.
  //
  (*hv_FeatureNames) = HTuple();
  (*hv_Groups) = HTuple();
  gen_dummy_objects(&ho_Region, &ho_Image);
  {
  HTuple end_val7 = (hv_GroupNames.TupleLength())-1;
  HTuple step_val7 = 1;
  for (hv_I=0; hv_I.Continue(end_val7, step_val7); hv_I += step_val7)
  {
    get_features(ho_Region, ho_Image, HTuple(hv_GroupNames[hv_I]), "get_names", &hv_Names);
    (*hv_FeatureNames) = (*hv_FeatureNames).TupleConcat(hv_Names);
    (*hv_Groups) = (*hv_Groups).TupleConcat(HTuple(hv_Names.TupleLength(),HTuple(hv_GroupNames[hv_I])));
  }
  }
  return;
}

// Chapter: Classification / Misc
// Short Description: Calculate color intensity features. 
void calc_feature_color_intensity (HObject ho_Region, HObject ho_Image, HTuple hv_ColorSpace, 
    HTuple hv_Mode, HTuple *hv_Feature)
{

  // Local iconic variables
  HObject  ho_R, ho_G, ho_B, ho_I1, ho_I2, ho_I3;

  // Local control variables
  HTuple  hv_Channels, hv_Mean1, hv_Deviation1;
  HTuple  hv_Mean2, hv_Deviation2, hv_Mean3, hv_Deviation3;
  HTuple  hv_Tmp1, hv_Tmp2, hv_Tmp3, hv_NumRegions, hv_Index;

  //
  //Calculate color features
  //
  //Transform an RGB image into the given ColorSpace
  //and calculate the mean gray value and the deviation
  //for all three channels.
  //
  CountChannels(ho_Image, &hv_Channels);
  if (0 != (hv_Channels!=3))
  {
    throw HException(((("Error when calculating feature "+hv_ColorSpace)+"_")+hv_Mode).TupleConcat("Please use a 3-channel RGB image or remove color feature from the list."));
  }
  Decompose3(ho_Image, &ho_R, &ho_G, &ho_B);
  if (0 != (hv_ColorSpace==HTuple("rgb")))
  {
    Intensity(ho_Region, ho_R, &hv_Mean1, &hv_Deviation1);
    Intensity(ho_Region, ho_G, &hv_Mean2, &hv_Deviation2);
    Intensity(ho_Region, ho_B, &hv_Mean3, &hv_Deviation3);
  }
  else
  {
    TransFromRgb(ho_R, ho_G, ho_B, &ho_I1, &ho_I2, &ho_I3, hv_ColorSpace);
    Intensity(ho_Region, ho_I1, &hv_Mean1, &hv_Deviation1);
    Intensity(ho_Region, ho_I2, &hv_Mean2, &hv_Deviation2);
    Intensity(ho_Region, ho_I3, &hv_Mean3, &hv_Deviation3);
  }
  if (0 != (hv_Mode==HTuple("mean")))
  {
    hv_Tmp1 = hv_Mean1;
    hv_Tmp2 = hv_Mean2;
    hv_Tmp3 = hv_Mean3;
  }
  else if (0 != (hv_Mode==HTuple("deviation")))
  {
    hv_Tmp1 = hv_Deviation1;
    hv_Tmp2 = hv_Deviation2;
    hv_Tmp3 = hv_Deviation3;
  }
  CountObj(ho_Region, &hv_NumRegions);
  if (0 != (hv_NumRegions>0))
  {
    hv_Index = HTuple::TupleGenSequence(0,(3*hv_NumRegions)-1,3);
    (*hv_Feature)[hv_Index] = hv_Tmp1;
    (*hv_Feature)[1+hv_Index] = hv_Tmp2;
    (*hv_Feature)[2+hv_Index] = hv_Tmp3;
  }
  else
  {
    (*hv_Feature) = HTuple();
  }
  return;
}

// Chapter: Classification / Misc
// Short Description: Returns a list of feature names that belong to the feature groups given in GroupNames. 
void get_feature_names (HTuple hv_GroupNames, HTuple *hv_Names)
{

  // Local iconic variables
  HObject  ho_Region, ho_Image;

  //
  //Return all features that belong to
  //at least one of the groups in GroupNames
  //
  gen_dummy_objects(&ho_Region, &ho_Image);
  get_features(ho_Region, ho_Image, hv_GroupNames, "get_names", &(*hv_Names));
  return;
}

// Chapter: Calibration / Camera Parameters
// Short Description: Generate a camera parameter tuple for an area scan camera with distortions modeled by the division model. 
void gen_cam_par_area_scan_division (HTuple hv_Focus, HTuple hv_Kappa, HTuple hv_Sx, 
    HTuple hv_Sy, HTuple hv_Cx, HTuple hv_Cy, HTuple hv_ImageWidth, HTuple hv_ImageHeight, 
    HTuple *hv_CameraParam)
{

  // Local iconic variables

  //Generate a camera parameter tuple for an area scan camera
  //with distortions modeled by the division model.
  //
  (*hv_CameraParam).Clear();
  (*hv_CameraParam)[0] = "area_scan_division";
  (*hv_CameraParam).Append(hv_Focus);
  (*hv_CameraParam).Append(hv_Kappa);
  (*hv_CameraParam).Append(hv_Sx);
  (*hv_CameraParam).Append(hv_Sy);
  (*hv_CameraParam).Append(hv_Cx);
  (*hv_CameraParam).Append(hv_Cy);
  (*hv_CameraParam).Append(hv_ImageWidth);
  (*hv_CameraParam).Append(hv_ImageHeight);
  return;
}

// Chapter: Classification / Misc
// Short Description: This procedure contains all relevant information about the supported features. 
void get_features (HObject ho_Region, HObject ho_Image, HTuple hv_Namelist, HTuple hv_Mode, 
    HTuple *hv_Output)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_EmptyRegionResult, hv_AccumulatedResults;
  HTuple  hv_CustomResults, hv_NumRegions, hv_ImageWidth;
  HTuple  hv_ImageHeight, hv_I, hv_CurrentName, hv_Name, hv_Groups;
  HTuple  hv_Feature, hv_ExpDefaultCtrlDummyVar, hv_ExtendedResults;
  HTuple  hv_Row1, hv_Column1, hv_Row2, hv_Column2, hv_Ra;
  HTuple  hv_Rb, hv_Phi, hv_Distance, hv_Sigma, hv_Roundness;
  HTuple  hv_Sides, hv_NumConnected, hv_NumHoles, hv_Diameter;
  HTuple  hv_Row, hv_Column, hv_Anisometry, hv_Bulkiness;
  HTuple  hv_StructureFactor, hv_Length1, hv_Length2, hv_ContLength;
  HTuple  hv_AreaHoles, hv_Area, hv_Min, hv_Max, hv_Range;
  HTuple  hv_Mean, hv_Deviation, hv_Entropy, hv_Anisotropy;
  HTuple  hv_Size, hv_NumBins, hv_NameRegExp, hv_Names, hv_NumPyramids;
  HTuple  hv_Energy, hv_Correlation, hv_Homogeneity, hv_Contrast;
  HTuple  hv_Index, hv_Width, hv_Height, hv_Projection, hv_Start;
  HTuple  hv_Histo, hv_BinSize;

  //*********************************************************
  //Feature procedure
  //Contains the names, properties and calculation of
  //all supproted features.
  //It consists of similar blocks for each feature.
  //
  //If you like to add your own features, please use
  //the external procedure get_custom_features.hdvp
  //in the HALCON procedures/templates directory.
  //*********************************************************
  //
  //Insert location of your custom procedure here
  //
  GetSystem("empty_region_result", &hv_EmptyRegionResult);
  SetSystem("empty_region_result", "true");
  hv_AccumulatedResults = HTuple();
  hv_CustomResults = HTuple();
  CountObj(ho_Region, &hv_NumRegions);
  GetImageSize(ho_Image, &hv_ImageWidth, &hv_ImageHeight);
  //
  {
  HTuple end_val20 = (hv_Namelist.TupleLength())-1;
  HTuple step_val20 = 1;
  for (hv_I=0; hv_I.Continue(end_val20, step_val20); hv_I += step_val20)
  {
    hv_CurrentName = HTuple(hv_Namelist[hv_I]);
    //
    get_custom_features(ho_Region, ho_Image, hv_CurrentName, hv_Mode, &hv_CustomResults);
    hv_AccumulatedResults = hv_AccumulatedResults.TupleConcat(hv_CustomResults);
    //
    //
    //************************************
    //HALCON REGION FEATURES
    //************************************
    //
    //************************************
    //BASIC
    //************************************
    //** area ***
    hv_Name = "area";
    hv_Groups.Clear();
    hv_Groups[0] = "region";
    hv_Groups[1] = "rot_invar";
    //****************
    if (0 != (hv_Name==hv_CurrentName))
    {
      //** Calculate feature ***
      AreaCenter(ho_Region, &hv_Feature, &hv_ExpDefaultCtrlDummyVar, &hv_ExpDefaultCtrlDummyVar);
      //*************************
      append_length_or_values(hv_Mode, hv_Feature, hv_AccumulatedResults, &hv_ExtendedResults);
      hv_AccumulatedResults = hv_ExtendedResults;
    }
    append_names_or_groups(hv_Mode, hv_Name, hv_Groups, hv_CurrentName, hv_AccumulatedResults, 
        &hv_ExtendedResults);
    hv_AccumulatedResults = hv_ExtendedResults;
    //************************************
    //
    //************************************
    //** width ***
    hv_Name = "width";
    hv_Groups = "region";
    //*************
    if (0 != (hv_Name==hv_CurrentName))
    {
      //** Calculate feature ***
      SmallestRectangle1(ho_Region, &hv_Row1, &hv_Column1, &hv_Row2, &hv_Column2);
      hv_Feature = (hv_Column2-hv_Column1)+1;
      //*************************
      append_length_or_values(hv_Mode, hv_Feature, hv_AccumulatedResults, &hv_ExtendedResults);
      hv_AccumulatedResults = hv_ExtendedResults;
    }
    append_names_or_groups(hv_Mode, hv_Name, hv_Groups, hv_CurrentName, hv_AccumulatedResults, 
        &hv_ExtendedResults);
    hv_AccumulatedResults = hv_ExtendedResults;
    //************************************
    //
    //************************************
    //** height ***
    hv_Name = "height";
    hv_Groups = "region";
    //*************
    if (0 != (hv_Name==hv_CurrentName))
    {
      //** Calculate feature ***
      SmallestRectangle1(ho_Region, &hv_Row1, &hv_Column1, &hv_Row2, &hv_Column2);
      hv_Feature = (hv_Row2-hv_Row1)+1;
      //*************************
      append_length_or_values(hv_Mode, hv_Feature, hv_AccumulatedResults, &hv_ExtendedResults);
      hv_AccumulatedResults = hv_ExtendedResults;
    }
    append_names_or_groups(hv_Mode, hv_Name, hv_Groups, hv_CurrentName, hv_AccumulatedResults, 
        &hv_ExtendedResults);
    hv_AccumulatedResults = hv_ExtendedResults;
    //************************************
    //
    //************************************
    //** ra ***
    hv_Name = "ra";
    hv_Groups.Clear();
    hv_Groups[0] = "region";
    hv_Groups[1] = "rot_invar";
    //*************
    if (0 != (hv_Name==hv_CurrentName))
    {
      //** Calculate feature ***
      EllipticAxis(ho_Region, &hv_Ra, &hv_Rb, &hv_Phi);
      hv_Feature = hv_Ra;
      //*************************
      append_length_or_values(hv_Mode, hv_Feature, hv_AccumulatedResults, &hv_ExtendedResults);
      hv_AccumulatedResults = hv_ExtendedResults;
    }
    append_names_or_groups(hv_Mode, hv_Name, hv_Groups, hv_CurrentName, hv_AccumulatedResults, 
        &hv_ExtendedResults);
    hv_AccumulatedResults = hv_ExtendedResults;
    //************************************
    //
    //************************************
    //** rb ***
    hv_Name = "rb";
    hv_Groups.Clear();
    hv_Groups[0] = "region";
    hv_Groups[1] = "rot_invar";
    //*************
    if (0 != (hv_Name==hv_CurrentName))
    {
      //** Calculate feature ***
      EllipticAxis(ho_Region, &hv_Ra, &hv_Rb, &hv_Phi);
      hv_Feature = hv_Rb;
      //*************************
      append_length_or_values(hv_Mode, hv_Feature, hv_AccumulatedResults, &hv_ExtendedResults);
      hv_AccumulatedResults = hv_ExtendedResults;
    }
    append_names_or_groups(hv_Mode, hv_Name, hv_Groups, hv_CurrentName, hv_AccumulatedResults, 
        &hv_ExtendedResults);
    hv_AccumulatedResults = hv_ExtendedResults;
    //************************************
    //
    //************************************
    //** phi ***
    hv_Name = "phi";
    hv_Groups.Clear();
    hv_Groups[0] = "region";
    hv_Groups[1] = "scale_invar";
    //*************
    if (0 != (hv_Name==hv_CurrentName))
    {
      //** Calculate feature ***
      EllipticAxis(ho_Region, &hv_Ra, &hv_Rb, &hv_Phi);
      hv_Feature = hv_Phi;
      //*************************
      append_length_or_values(hv_Mode, hv_Feature, hv_AccumulatedResults, &hv_ExtendedResults);
      hv_AccumulatedResults = hv_ExtendedResults;
    }
    append_names_or_groups(hv_Mode, hv_Name, hv_Groups, hv_CurrentName, hv_AccumulatedResults, 
        &hv_ExtendedResults);
    hv_AccumulatedResults = hv_ExtendedResults;
    //************************************
    //
    //************************************
    //** roundness ***
    hv_Name = "roundness";
    hv_Groups.Clear();
    hv_Groups[0] = "region";
    hv_Groups[1] = "rot_invar";
    hv_Groups[2] = "scale_invar";
    //*************
    if (0 != (hv_Name==hv_CurrentName))
    {
      //** Calculate feature ***
      Roundness(ho_Region, &hv_Distance, &hv_Sigma, &hv_Roundness, &hv_Sides);
      hv_Feature = hv_Roundness;
      //*************************
      append_length_or_values(hv_Mode, hv_Feature, hv_AccumulatedResults, &hv_ExtendedResults);
      hv_AccumulatedResults = hv_ExtendedResults;
    }
    append_names_or_groups(hv_Mode, hv_Name, hv_Groups, hv_CurrentName, hv_AccumulatedResults, 
        &hv_ExtendedResults);
    hv_AccumulatedResults = hv_ExtendedResults;
    //************************************
    //
    //************************************
    //** num_sides ***
    hv_Name = "num_sides";
    hv_Groups.Clear();
    hv_Groups[0] = "region";
    hv_Groups[1] = "rot_invar";
    hv_Groups[2] = "scale_invar";
    //*************
    if (0 != (hv_Name==hv_CurrentName))
    {
      //** Calculate feature ***
      Roundness(ho_Region, &hv_Distance, &hv_Sigma, &hv_Roundness, &hv_Sides);
      hv_Feature = hv_Sides;
      //*************************
      append_length_or_values(hv_Mode, hv_Feature, hv_AccumulatedResults, &hv_ExtendedResults);
      hv_AccumulatedResults = hv_ExtendedResults;
    }
    append_names_or_groups(hv_Mode, hv_Name, hv_Groups, hv_CurrentName, hv_AccumulatedResults, 
        &hv_ExtendedResults);
    hv_AccumulatedResults = hv_ExtendedResults;
    //************************************
    //
    //************************************
    //** num_connected ***
    hv_Name = "num_connected";
    hv_Groups.Clear();
    hv_Groups[0] = "region";
    hv_Groups[1] = "rot_invar";
    hv_Groups[2] = "scale_invar";
    //*************
    if (0 != (hv_Name==hv_CurrentName))
    {
      //** Calculate feature ***
      ConnectAndHoles(ho_Region, &hv_NumConnected, &hv_NumHoles);
      hv_Feature = hv_NumConnected;
      //*************************
      append_length_or_values(hv_Mode, hv_Feature, hv_AccumulatedResults, &hv_ExtendedResults);
      hv_AccumulatedResults = hv_ExtendedResults;
    }
    append_names_or_groups(hv_Mode, hv_Name, hv_Groups, hv_CurrentName, hv_AccumulatedResults, 
        &hv_ExtendedResults);
    hv_AccumulatedResults = hv_ExtendedResults;
    //************************************
    //
    //************************************
    //** num_holes ***
    hv_Name = "num_holes";
    hv_Groups.Clear();
    hv_Groups[0] = "region";
    hv_Groups[1] = "rot_invar";
    hv_Groups[2] = "scale_invar";
    //*************
    if (0 != (hv_Name==hv_CurrentName))
    {
      //** Calculate feature ***
      ConnectAndHoles(ho_Region, &hv_NumConnected, &hv_NumHoles);
      hv_Feature = hv_NumHoles;
      //*************************
      append_length_or_values(hv_Mode, hv_Feature, hv_AccumulatedResults, &hv_ExtendedResults);
      hv_AccumulatedResults = hv_ExtendedResults;
    }
    append_names_or_groups(hv_Mode, hv_Name, hv_Groups, hv_CurrentName, hv_AccumulatedResults, 
        &hv_ExtendedResults);
    hv_AccumulatedResults = hv_ExtendedResults;
    //************************************
    //
    //************************************
    //** area_holes ***
    hv_Name = "area_holes";
    hv_Groups.Clear();
    hv_Groups[0] = "region";
    hv_Groups[1] = "rot_invar";
    //*************
    if (0 != (hv_Name==hv_CurrentName))
    {
      //** Calculate feature ***
      AreaHoles(ho_Region, &hv_Feature);
      //*************************
      append_length_or_values(hv_Mode, hv_Feature, hv_AccumulatedResults, &hv_ExtendedResults);
      hv_AccumulatedResults = hv_ExtendedResults;
    }
    append_names_or_groups(hv_Mode, hv_Name, hv_Groups, hv_CurrentName, hv_AccumulatedResults, 
        &hv_ExtendedResults);
    hv_AccumulatedResults = hv_ExtendedResults;
    //************************************
    //
    //************************************
    //** max_diameter ***
    hv_Name = "max_diameter";
    hv_Groups.Clear();
    hv_Groups[0] = "region";
    hv_Groups[1] = "rot_invar";
    //*************
    if (0 != (hv_Name==hv_CurrentName))
    {
      //** Calculate feature ***
      DiameterRegion(ho_Region, &hv_Row1, &hv_Column1, &hv_Row2, &hv_Column2, &hv_Diameter);
      hv_Feature = hv_Diameter;
      //*************************
      append_length_or_values(hv_Mode, hv_Feature, hv_AccumulatedResults, &hv_ExtendedResults);
      hv_AccumulatedResults = hv_ExtendedResults;
    }
    append_names_or_groups(hv_Mode, hv_Name, hv_Groups, hv_CurrentName, hv_AccumulatedResults, 
        &hv_ExtendedResults);
    hv_AccumulatedResults = hv_ExtendedResults;
    //************************************
    //
    //************************************
    //** orientation ***
    hv_Name = "orientation";
    hv_Groups.Clear();
    hv_Groups[0] = "region";
    hv_Groups[1] = "scale_invar";
    //*************
    if (0 != (hv_Name==hv_CurrentName))
    {
      //** Calculate feature ***
      OrientationRegion(ho_Region, &hv_Feature);
      //*************************
      append_length_or_values(hv_Mode, hv_Feature, hv_AccumulatedResults, &hv_ExtendedResults);
      hv_AccumulatedResults = hv_ExtendedResults;
    }
    append_names_or_groups(hv_Mode, hv_Name, hv_Groups, hv_CurrentName, hv_AccumulatedResults, 
        &hv_ExtendedResults);
    hv_AccumulatedResults = hv_ExtendedResults;
    //************************************
    //
    //************************************
    //SHAPE
    //************************************
    //
    //************************************
    //** outer_radius ***
    hv_Name = "outer_radius";
    hv_Groups.Clear();
    hv_Groups[0] = "region";
    hv_Groups[1] = "rot_invar";
    //*************
    if (0 != (hv_Name==hv_CurrentName))
    {
      //** Calculate feature ***
      SmallestCircle(ho_Region, &hv_Row, &hv_Column, &hv_Feature);
      //*************************
      append_length_or_values(hv_Mode, hv_Feature, hv_AccumulatedResults, &hv_ExtendedResults);
      hv_AccumulatedResults = hv_ExtendedResults;
    }
    append_names_or_groups(hv_Mode, hv_Name, hv_Groups, hv_CurrentName, hv_AccumulatedResults, 
        &hv_ExtendedResults);
    hv_AccumulatedResults = hv_ExtendedResults;
    //************************************
    //
    //************************************
    //** inner_radius ***
    hv_Name = "inner_radius";
    hv_Groups.Clear();
    hv_Groups[0] = "region";
    hv_Groups[1] = "rot_invar";
    //*************
    if (0 != (hv_Name==hv_CurrentName))
    {
      //** Calculate feature ***
      InnerCircle(ho_Region, &hv_Row, &hv_Column, &hv_Feature);
      //*************************
      append_length_or_values(hv_Mode, hv_Feature, hv_AccumulatedResults, &hv_ExtendedResults);
      hv_AccumulatedResults = hv_ExtendedResults;
    }
    append_names_or_groups(hv_Mode, hv_Name, hv_Groups, hv_CurrentName, hv_AccumulatedResults, 
        &hv_ExtendedResults);
    hv_AccumulatedResults = hv_ExtendedResults;
    //************************************
    //
    //************************************
    //** inner_width ***
    hv_Name = "inner_width";
    hv_Groups = "region";
    //*************
    if (0 != (hv_Name==hv_CurrentName))
    {
      //** Calculate feature ***
      InnerRectangle1(ho_Region, &hv_Row1, &hv_Column1, &hv_Row2, &hv_Column2);
      hv_Feature = (hv_Column2-hv_Column1)+1;
      //*************************
      append_length_or_values(hv_Mode, hv_Feature, hv_AccumulatedResults, &hv_ExtendedResults);
      hv_AccumulatedResults = hv_ExtendedResults;
    }
    append_names_or_groups(hv_Mode, hv_Name, hv_Groups, hv_CurrentName, hv_AccumulatedResults, 
        &hv_ExtendedResults);
    hv_AccumulatedResults = hv_ExtendedResults;
    //************************************
    //
    //************************************
    //** inner_height ***
    hv_Name = "inner_height";
    hv_Groups = "region";
    //*************
    if (0 != (hv_Name==hv_CurrentName))
    {
      //** Calculate feature ***
      InnerRectangle1(ho_Region, &hv_Row1, &hv_Column1, &hv_Row2, &hv_Column2);
      hv_Feature = (hv_Row2-hv_Row1)+1;
      //*************************
      append_length_or_values(hv_Mode, hv_Feature, hv_AccumulatedResults, &hv_ExtendedResults);
      hv_AccumulatedResults = hv_ExtendedResults;
    }
    append_names_or_groups(hv_Mode, hv_Name, hv_Groups, hv_CurrentName, hv_AccumulatedResults, 
        &hv_ExtendedResults);
    hv_AccumulatedResults = hv_ExtendedResults;
    //
    //************************************
    //
    //************************************
    //** circularity ***
    hv_Name = "circularity";
    hv_Groups.Clear();
    hv_Groups[0] = "region";
    hv_Groups[1] = "rot_invar";
    hv_Groups[2] = "scale_invar";
    //*************
    if (0 != (hv_Name==hv_CurrentName))
    {
      //** Calculate feature ***
      Circularity(ho_Region, &hv_Feature);
      //*************************
      append_length_or_values(hv_Mode, hv_Feature, hv_AccumulatedResults, &hv_ExtendedResults);
      hv_AccumulatedResults = hv_ExtendedResults;
    }
    append_names_or_groups(hv_Mode, hv_Name, hv_Groups, hv_CurrentName, hv_AccumulatedResults, 
        &hv_ExtendedResults);
    hv_AccumulatedResults = hv_ExtendedResults;
    //
    //************************************
    //
    //************************************
    //** compactness ***
    hv_Name = "compactness";
    hv_Groups.Clear();
    hv_Groups[0] = "region";
    hv_Groups[1] = "rot_invar";
    hv_Groups[2] = "scale_invar";
    //*************
    if (0 != (hv_Name==hv_CurrentName))
    {
      //** Calculate feature ***
      Compactness(ho_Region, &hv_Feature);
      //*************************
      append_length_or_values(hv_Mode, hv_Feature, hv_AccumulatedResults, &hv_ExtendedResults);
      hv_AccumulatedResults = hv_ExtendedResults;
    }
    append_names_or_groups(hv_Mode, hv_Name, hv_Groups, hv_CurrentName, hv_AccumulatedResults, 
        &hv_ExtendedResults);
    hv_AccumulatedResults = hv_ExtendedResults;
    //
    //************************************
    //
    //************************************
    //** convexity ***
    hv_Name = "convexity";
    hv_Groups.Clear();
    hv_Groups[0] = "region";
    hv_Groups[1] = "rot_invar";
    hv_Groups[2] = "scale_invar";
    //*************
    if (0 != (hv_Name==hv_CurrentName))
    {
      //** Calculate feature ***
      Convexity(ho_Region, &hv_Feature);
      //*************************
      append_length_or_values(hv_Mode, hv_Feature, hv_AccumulatedResults, &hv_ExtendedResults);
      hv_AccumulatedResults = hv_ExtendedResults;
    }
    append_names_or_groups(hv_Mode, hv_Name, hv_Groups, hv_CurrentName, hv_AccumulatedResults, 
        &hv_ExtendedResults);
    hv_AccumulatedResults = hv_ExtendedResults;
    //
    //************************************
    //
    //************************************
    //** rectangularity ***
    hv_Name = "rectangularity";
    hv_Groups.Clear();
    hv_Groups[0] = "region";
    hv_Groups[1] = "rot_invar";
    hv_Groups[2] = "scale_invar";
    //*************
    if (0 != (hv_Name==hv_CurrentName))
    {
      //** Calculate feature ***
      Rectangularity(ho_Region, &hv_Feature);
      //*************************
      append_length_or_values(hv_Mode, hv_Feature, hv_AccumulatedResults, &hv_ExtendedResults);
      hv_AccumulatedResults = hv_ExtendedResults;
    }
    append_names_or_groups(hv_Mode, hv_Name, hv_Groups, hv_CurrentName, hv_AccumulatedResults, 
        &hv_ExtendedResults);
    hv_AccumulatedResults = hv_ExtendedResults;
    //
    //************************************
    //
    //************************************
    //** anisometry ***
    hv_Name = "anisometry";
    hv_Groups.Clear();
    hv_Groups[0] = "region";
    hv_Groups[1] = "rot_invar";
    hv_Groups[2] = "scale_invar";
    //*************
    if (0 != (hv_Name==hv_CurrentName))
    {
      //** Calculate feature ***
      Eccentricity(ho_Region, &hv_Anisometry, &hv_Bulkiness, &hv_StructureFactor);
      hv_Feature = hv_Anisometry;
      //*************************
      append_length_or_values(hv_Mode, hv_Feature, hv_AccumulatedResults, &hv_ExtendedResults);
      hv_AccumulatedResults = hv_ExtendedResults;
    }
    append_names_or_groups(hv_Mode, hv_Name, hv_Groups, hv_CurrentName, hv_AccumulatedResults, 
        &hv_ExtendedResults);
    hv_AccumulatedResults = hv_ExtendedResults;
    //
    //************************************
    //
    //************************************
    //** bulkiness ***
    hv_Name = "bulkiness";
    hv_Groups.Clear();
    hv_Groups[0] = "region";
    hv_Groups[1] = "rot_invar";
    hv_Groups[2] = "scale_invar";
    //*************
    if (0 != (hv_Name==hv_CurrentName))
    {
      //** Calculate feature ***
      Eccentricity(ho_Region, &hv_Anisometry, &hv_Bulkiness, &hv_StructureFactor);
      hv_Feature = hv_Bulkiness;
      //*************************
      append_length_or_values(hv_Mode, hv_Feature, hv_AccumulatedResults, &hv_ExtendedResults);
      hv_AccumulatedResults = hv_ExtendedResults;
    }
    append_names_or_groups(hv_Mode, hv_Name, hv_Groups, hv_CurrentName, hv_AccumulatedResults, 
        &hv_ExtendedResults);
    hv_AccumulatedResults = hv_ExtendedResults;
    //
    //************************************
    //
    //************************************
    //** struct_factor ***
    hv_Name = "struct_factor";
    hv_Groups.Clear();
    hv_Groups[0] = "region";
    hv_Groups[1] = "rot_invar";
    hv_Groups[2] = "scale_invar";
    //*************
    if (0 != (hv_Name==hv_CurrentName))
    {
      //** Calculate feature ***
      Eccentricity(ho_Region, &hv_Anisometry, &hv_Bulkiness, &hv_StructureFactor);
      hv_Feature = hv_StructureFactor;
      //*************************
      append_length_or_values(hv_Mode, hv_Feature, hv_AccumulatedResults, &hv_ExtendedResults);
      hv_AccumulatedResults = hv_ExtendedResults;
    }
    append_names_or_groups(hv_Mode, hv_Name, hv_Groups, hv_CurrentName, hv_AccumulatedResults, 
        &hv_ExtendedResults);
    hv_AccumulatedResults = hv_ExtendedResults;
    //
    //************************************
    //
    //************************************
    //** dist_mean ***
    hv_Name = "dist_mean";
    hv_Groups.Clear();
    hv_Groups[0] = "region";
    hv_Groups[1] = "rot_invar";
    //*************
    if (0 != (hv_Name==hv_CurrentName))
    {
      //** Calculate feature ***
      Roundness(ho_Region, &hv_Distance, &hv_Sigma, &hv_Roundness, &hv_Sides);
      hv_Feature = hv_Distance;
      //*************************
      append_length_or_values(hv_Mode, hv_Feature, hv_AccumulatedResults, &hv_ExtendedResults);
      hv_AccumulatedResults = hv_ExtendedResults;
    }
    append_names_or_groups(hv_Mode, hv_Name, hv_Groups, hv_CurrentName, hv_AccumulatedResults, 
        &hv_ExtendedResults);
    hv_AccumulatedResults = hv_ExtendedResults;
    //
    //************************************
    //
    //************************************
    //** dist_deviation ***
    hv_Name = "dist_deviation";
    hv_Groups.Clear();
    hv_Groups[0] = "region";
    hv_Groups[1] = "rot_invar";
    //*************
    if (0 != (hv_Name==hv_CurrentName))
    {
      //** Calculate feature ***
      Roundness(ho_Region, &hv_Distance, &hv_Sigma, &hv_Roundness, &hv_Sides);
      hv_Feature = hv_Sigma;
      //*************************
      append_length_or_values(hv_Mode, hv_Feature, hv_AccumulatedResults, &hv_ExtendedResults);
      hv_AccumulatedResults = hv_ExtendedResults;
    }
    append_names_or_groups(hv_Mode, hv_Name, hv_Groups, hv_CurrentName, hv_AccumulatedResults, 
        &hv_ExtendedResults);
    hv_AccumulatedResults = hv_ExtendedResults;
    //
    //************************************
    //
    //************************************
    //** euler_number ***
    hv_Name = "euler_number";
    hv_Groups.Clear();
    hv_Groups[0] = "region";
    hv_Groups[1] = "rot_invar";
    hv_Groups[2] = "scale_invar";
    //*************
    if (0 != (hv_Name==hv_CurrentName))
    {
      //** Calculate feature ***
      EulerNumber(ho_Region, &hv_Feature);
      //*************************
      append_length_or_values(hv_Mode, hv_Feature, hv_AccumulatedResults, &hv_ExtendedResults);
      hv_AccumulatedResults = hv_ExtendedResults;
    }
    append_names_or_groups(hv_Mode, hv_Name, hv_Groups, hv_CurrentName, hv_AccumulatedResults, 
        &hv_ExtendedResults);
    hv_AccumulatedResults = hv_ExtendedResults;
    //
    //************************************
    //
    //************************************
    //** rect2_phi ***
    hv_Name = "rect2_phi";
    hv_Groups.Clear();
    hv_Groups[0] = "region";
    hv_Groups[1] = "scale_invar";
    //*************
    if (0 != (hv_Name==hv_CurrentName))
    {
      //** Calculate feature ***
      SmallestRectangle2(ho_Region, &hv_Row, &hv_Column, &hv_Phi, &hv_Length1, &hv_Length2);
      hv_Feature = hv_Phi;
      //*************************
      append_length_or_values(hv_Mode, hv_Feature, hv_AccumulatedResults, &hv_ExtendedResults);
      hv_AccumulatedResults = hv_ExtendedResults;
    }
    append_names_or_groups(hv_Mode, hv_Name, hv_Groups, hv_CurrentName, hv_AccumulatedResults, 
        &hv_ExtendedResults);
    hv_AccumulatedResults = hv_ExtendedResults;
    //
    //************************************
    //
    //************************************
    //** rect2_len1 ***
    hv_Name = "rect2_len1";
    hv_Groups.Clear();
    hv_Groups[0] = "region";
    hv_Groups[1] = "rot_invar";
    //*************
    if (0 != (hv_Name==hv_CurrentName))
    {
      //** Calculate feature ***
      SmallestRectangle2(ho_Region, &hv_Row, &hv_Column, &hv_Phi, &hv_Length1, &hv_Length2);
      hv_Feature = hv_Length1;
      //*************************
      append_length_or_values(hv_Mode, hv_Feature, hv_AccumulatedResults, &hv_ExtendedResults);
      hv_AccumulatedResults = hv_ExtendedResults;
    }
    append_names_or_groups(hv_Mode, hv_Name, hv_Groups, hv_CurrentName, hv_AccumulatedResults, 
        &hv_ExtendedResults);
    hv_AccumulatedResults = hv_ExtendedResults;
    //
    //************************************
    //
    //************************************
    //** rect2_len2 ***
    hv_Name = "rect2_len2";
    hv_Groups.Clear();
    hv_Groups[0] = "region";
    hv_Groups[1] = "rot_invar";
    //*************
    if (0 != (hv_Name==hv_CurrentName))
    {
      //** Calculate feature ***
      SmallestRectangle2(ho_Region, &hv_Row, &hv_Column, &hv_Phi, &hv_Length1, &hv_Length2);
      hv_Feature = hv_Length2;
      //*************************
      append_length_or_values(hv_Mode, hv_Feature, hv_AccumulatedResults, &hv_ExtendedResults);
      hv_AccumulatedResults = hv_ExtendedResults;
    }
    append_names_or_groups(hv_Mode, hv_Name, hv_Groups, hv_CurrentName, hv_AccumulatedResults, 
        &hv_ExtendedResults);
    hv_AccumulatedResults = hv_ExtendedResults;
    //
    //************************************
    //
    //************************************
    //** contlength ***
    hv_Name = "contlength";
    hv_Groups.Clear();
    hv_Groups[0] = "region";
    hv_Groups[1] = "rot_invar";
    //*************
    if (0 != (hv_Name==hv_CurrentName))
    {
      //** Calculate feature ***
      Contlength(ho_Region, &hv_ContLength);
      hv_Feature = hv_ContLength;
      //*************************
      append_length_or_values(hv_Mode, hv_Feature, hv_AccumulatedResults, &hv_ExtendedResults);
      hv_AccumulatedResults = hv_ExtendedResults;
    }
    append_names_or_groups(hv_Mode, hv_Name, hv_Groups, hv_CurrentName, hv_AccumulatedResults, 
        &hv_ExtendedResults);
    hv_AccumulatedResults = hv_ExtendedResults;
    //
    //************************************
    //REGION FEATURES
    //************************************
    //MISC
    //************************************
    //** porosity ***
    hv_Name = "porosity";
    hv_Groups.Clear();
    hv_Groups[0] = "region";
    hv_Groups[1] = "rot_invar";
    hv_Groups[2] = "scale_invar";
    //*************
    if (0 != (hv_Name==hv_CurrentName))
    {
      //** Calculate feature ***
      AreaHoles(ho_Region, &hv_AreaHoles);
      AreaCenter(ho_Region, &hv_Area, &hv_Row, &hv_Column);
      if (0 != (hv_Area==0))
      {
        hv_Feature = 0.0;
      }
      else
      {
        hv_Feature = (hv_AreaHoles.TupleReal())/(hv_Area+hv_AreaHoles);
      }
      //*************************
      append_length_or_values(hv_Mode, hv_Feature, hv_AccumulatedResults, &hv_ExtendedResults);
      hv_AccumulatedResults = hv_ExtendedResults;
    }
    append_names_or_groups(hv_Mode, hv_Name, hv_Groups, hv_CurrentName, hv_AccumulatedResults, 
        &hv_ExtendedResults);
    hv_AccumulatedResults = hv_ExtendedResults;
    //
    //************************************
    //HALCON GRAY VALUE FEATURES
    //************************************
    //BASIC
    //************************************
    //
    //** gray_area ***
    hv_Name = "gray_area";
    hv_Groups.Clear();
    hv_Groups[0] = "gray";
    hv_Groups[1] = "rot_invar";
    //****************
    if (0 != (hv_Name==hv_CurrentName))
    {
      //** Calculate feature ***
      AreaCenterGray(ho_Region, ho_Image, &hv_Area, &hv_Row, &hv_Column);
      hv_Feature = hv_Area;
      //*************************
      append_length_or_values(hv_Mode, hv_Feature, hv_AccumulatedResults, &hv_ExtendedResults);
      hv_AccumulatedResults = hv_ExtendedResults;
    }
    append_names_or_groups(hv_Mode, hv_Name, hv_Groups, hv_CurrentName, hv_AccumulatedResults, 
        &hv_ExtendedResults);
    hv_AccumulatedResults = hv_ExtendedResults;
    //************************************
    //
    //************************************
    //** gray_ra ***
    hv_Name = "gray_ra";
    hv_Groups.Clear();
    hv_Groups[0] = "gray";
    hv_Groups[1] = "rot_invar";
    //****************
    if (0 != (hv_Name==hv_CurrentName))
    {
      //** Calculate feature ***
      EllipticAxisGray(ho_Region, ho_Image, &hv_Ra, &hv_Rb, &hv_Phi);
      hv_Feature = hv_Ra;
      //*************************
      append_length_or_values(hv_Mode, hv_Feature, hv_AccumulatedResults, &hv_ExtendedResults);
      hv_AccumulatedResults = hv_ExtendedResults;
    }
    append_names_or_groups(hv_Mode, hv_Name, hv_Groups, hv_CurrentName, hv_AccumulatedResults, 
        &hv_ExtendedResults);
    hv_AccumulatedResults = hv_ExtendedResults;
    //************************************
    //
    //************************************
    //** gray_rb ***
    hv_Name = "gray_rb";
    hv_Groups.Clear();
    hv_Groups[0] = "gray";
    hv_Groups[1] = "rot_invar";
    //****************
    if (0 != (hv_Name==hv_CurrentName))
    {
      //** Calculate feature ***
      EllipticAxisGray(ho_Region, ho_Image, &hv_Ra, &hv_Rb, &hv_Phi);
      hv_Feature = hv_Rb;
      //*************************
      append_length_or_values(hv_Mode, hv_Feature, hv_AccumulatedResults, &hv_ExtendedResults);
      hv_AccumulatedResults = hv_ExtendedResults;
    }
    append_names_or_groups(hv_Mode, hv_Name, hv_Groups, hv_CurrentName, hv_AccumulatedResults, 
        &hv_ExtendedResults);
    hv_AccumulatedResults = hv_ExtendedResults;
    //************************************
    //
    //************************************
    //** gray_phi ***
    hv_Name = "gray_phi";
    hv_Groups.Clear();
    hv_Groups[0] = "gray";
    hv_Groups[1] = "scale_invar";
    //****************
    if (0 != (hv_Name==hv_CurrentName))
    {
      //** Calculate feature ***
      EllipticAxisGray(ho_Region, ho_Image, &hv_Ra, &hv_Rb, &hv_Phi);
      hv_Feature = hv_Phi;
      //*************************
      append_length_or_values(hv_Mode, hv_Feature, hv_AccumulatedResults, &hv_ExtendedResults);
      hv_AccumulatedResults = hv_ExtendedResults;
    }
    append_names_or_groups(hv_Mode, hv_Name, hv_Groups, hv_CurrentName, hv_AccumulatedResults, 
        &hv_ExtendedResults);
    hv_AccumulatedResults = hv_ExtendedResults;
    //************************************
    //
    //************************************
    //** gray_min ***
    hv_Name = "gray_min";
    hv_Groups.Clear();
    hv_Groups[0] = "gray";
    hv_Groups[1] = "rot_invar";
    hv_Groups[2] = "scale_invar";
    //****************
    if (0 != (hv_Name==hv_CurrentName))
    {
      //** Calculate feature ***
      MinMaxGray(ho_Region, ho_Image, 0, &hv_Min, &hv_Max, &hv_Range);
      hv_Feature = hv_Min;
      //*************************
      append_length_or_values(hv_Mode, hv_Feature, hv_AccumulatedResults, &hv_ExtendedResults);
      hv_AccumulatedResults = hv_ExtendedResults;
    }
    append_names_or_groups(hv_Mode, hv_Name, hv_Groups, hv_CurrentName, hv_AccumulatedResults, 
        &hv_ExtendedResults);
    hv_AccumulatedResults = hv_ExtendedResults;
    //************************************
    //
    //************************************
    //** gray_max ***
    hv_Name = "gray_max";
    hv_Groups.Clear();
    hv_Groups[0] = "gray";
    hv_Groups[1] = "rot_invar";
    hv_Groups[2] = "scale_invar";
    //****************
    if (0 != (hv_Name==hv_CurrentName))
    {
      //** Calculate feature ***
      MinMaxGray(ho_Region, ho_Image, 0, &hv_Min, &hv_Max, &hv_Range);
      hv_Feature = hv_Max;
      //*************************
      append_length_or_values(hv_Mode, hv_Feature, hv_AccumulatedResults, &hv_ExtendedResults);
      hv_AccumulatedResults = hv_ExtendedResults;
    }
    append_names_or_groups(hv_Mode, hv_Name, hv_Groups, hv_CurrentName, hv_AccumulatedResults, 
        &hv_ExtendedResults);
    hv_AccumulatedResults = hv_ExtendedResults;
    //************************************
    //
    //************************************
    //** gray_range ***
    hv_Name = "gray_range";
    hv_Groups.Clear();
    hv_Groups[0] = "gray";
    hv_Groups[1] = "rot_invar";
    hv_Groups[2] = "scale_invar";
    //****************
    if (0 != (hv_Name==hv_CurrentName))
    {
      //** Calculate feature ***
      MinMaxGray(ho_Region, ho_Image, 0, &hv_Min, &hv_Max, &hv_Range);
      hv_Feature = hv_Range;
      //*************************
      append_length_or_values(hv_Mode, hv_Feature, hv_AccumulatedResults, &hv_ExtendedResults);
      hv_AccumulatedResults = hv_ExtendedResults;
    }
    append_names_or_groups(hv_Mode, hv_Name, hv_Groups, hv_CurrentName, hv_AccumulatedResults, 
        &hv_ExtendedResults);
    hv_AccumulatedResults = hv_ExtendedResults;
    //************************************
    //
    //************************************
    //TEXTURE
    //************************************
    //
    //************************************
    //** gray_mean ***
    hv_Name = "gray_mean";
    hv_Groups.Clear();
    hv_Groups[0] = "gray";
    hv_Groups[1] = "texture";
    hv_Groups[2] = "rot_invar";
    hv_Groups[3] = "scale_invar";
    //****************
    if (0 != (hv_Name==hv_CurrentName))
    {
      //** Calculate feature ***
      Intensity(ho_Region, ho_Image, &hv_Mean, &hv_Deviation);
      hv_Feature = hv_Mean;
      //*************************
      append_length_or_values(hv_Mode, hv_Feature, hv_AccumulatedResults, &hv_ExtendedResults);
      hv_AccumulatedResults = hv_ExtendedResults;
    }
    append_names_or_groups(hv_Mode, hv_Name, hv_Groups, hv_CurrentName, hv_AccumulatedResults, 
        &hv_ExtendedResults);
    hv_AccumulatedResults = hv_ExtendedResults;
    //************************************
    //
    //************************************
    //** gray_deviation ***
    hv_Name = "gray_deviation";
    hv_Groups.Clear();
    hv_Groups[0] = "gray";
    hv_Groups[1] = "texture";
    hv_Groups[2] = "rot_invar";
    hv_Groups[3] = "scale_invar";
    //****************
    if (0 != (hv_Name==hv_CurrentName))
    {
      //** Calculate feature ***
      Intensity(ho_Region, ho_Image, &hv_Mean, &hv_Deviation);
      hv_Feature = hv_Deviation;
      //*************************
      append_length_or_values(hv_Mode, hv_Feature, hv_AccumulatedResults, &hv_ExtendedResults);
      hv_AccumulatedResults = hv_ExtendedResults;
    }
    append_names_or_groups(hv_Mode, hv_Name, hv_Groups, hv_CurrentName, hv_AccumulatedResults, 
        &hv_ExtendedResults);
    hv_AccumulatedResults = hv_ExtendedResults;
    //************************************
    //
    //************************************
    //** gray_plane_deviation ***
    hv_Name = "gray_plane_deviation";
    hv_Groups.Clear();
    hv_Groups[0] = "gray";
    hv_Groups[1] = "texture";
    hv_Groups[2] = "rot_invar";
    hv_Groups[3] = "scale_invar";
    //****************
    if (0 != (hv_Name==hv_CurrentName))
    {
      //** Calculate feature ***
      PlaneDeviation(ho_Region, ho_Image, &hv_Feature);
      //*************************
      append_length_or_values(hv_Mode, hv_Feature, hv_AccumulatedResults, &hv_ExtendedResults);
      hv_AccumulatedResults = hv_ExtendedResults;
    }
    append_names_or_groups(hv_Mode, hv_Name, hv_Groups, hv_CurrentName, hv_AccumulatedResults, 
        &hv_ExtendedResults);
    hv_AccumulatedResults = hv_ExtendedResults;
    //************************************
    //
    //************************************
    //** gray_anisotropy ***
    hv_Name = "gray_anisotropy";
    hv_Groups.Clear();
    hv_Groups[0] = "gray";
    hv_Groups[1] = "texture";
    hv_Groups[2] = "rot_invar";
    hv_Groups[3] = "scale_invar";
    //****************
    if (0 != (hv_Name==hv_CurrentName))
    {
      //** Calculate feature ***
      EntropyGray(ho_Region, ho_Image, &hv_Entropy, &hv_Anisotropy);
      hv_Feature = hv_Anisotropy;
      //*************************
      append_length_or_values(hv_Mode, hv_Feature, hv_AccumulatedResults, &hv_ExtendedResults);
      hv_AccumulatedResults = hv_ExtendedResults;
    }
    append_names_or_groups(hv_Mode, hv_Name, hv_Groups, hv_CurrentName, hv_AccumulatedResults, 
        &hv_ExtendedResults);
    hv_AccumulatedResults = hv_ExtendedResults;
    //************************************
    //
    //************************************
    //** gray_entropy ***
    hv_Name = "gray_entropy";
    hv_Groups.Clear();
    hv_Groups[0] = "gray";
    hv_Groups[1] = "texture";
    hv_Groups[2] = "rot_invar";
    hv_Groups[3] = "scale_invar";
    //****************
    if (0 != (hv_Name==hv_CurrentName))
    {
      //** Calculate feature ***
      EntropyGray(ho_Region, ho_Image, &hv_Entropy, &hv_Anisotropy);
      hv_Feature = hv_Entropy;
      //*************************
      append_length_or_values(hv_Mode, hv_Feature, hv_AccumulatedResults, &hv_ExtendedResults);
      hv_AccumulatedResults = hv_ExtendedResults;
    }
    append_names_or_groups(hv_Mode, hv_Name, hv_Groups, hv_CurrentName, hv_AccumulatedResults, 
        &hv_ExtendedResults);
    hv_AccumulatedResults = hv_ExtendedResults;
    //************************************
    //
    //************************************
    //** gray_hor_proj ***
    hv_Name = "gray_hor_proj";
    hv_Groups.Clear();
    hv_Groups[0] = "gray";
    hv_Groups[1] = "texture";
    hv_Groups[2] = "scale_invar";
    //****************
    if (0 != (hv_Name==hv_CurrentName))
    {
      //** Calculate feature ***
      hv_Size = 20;
      calc_feature_gray_proj(ho_Region, ho_Image, "hor", hv_Size, &hv_Feature);
      //*************************
      append_length_or_values(hv_Mode, hv_Feature, hv_AccumulatedResults, &hv_ExtendedResults);
      hv_AccumulatedResults = hv_ExtendedResults;
    }
    append_names_or_groups(hv_Mode, hv_Name, hv_Groups, hv_CurrentName, hv_AccumulatedResults, 
        &hv_ExtendedResults);
    hv_AccumulatedResults = hv_ExtendedResults;
    //************************************
    //
    //************************************
    //** gray_vert_proj ***
    hv_Name = "gray_vert_proj";
    hv_Groups.Clear();
    hv_Groups[0] = "gray";
    hv_Groups[1] = "texture";
    hv_Groups[2] = "scale_invar";
    //****************
    if (0 != (hv_Name==hv_CurrentName))
    {
      //** Calculate feature ***
      hv_Size = 20;
      calc_feature_gray_proj(ho_Region, ho_Image, "vert", hv_Size, &hv_Feature);
      //*************************
      append_length_or_values(hv_Mode, hv_Feature, hv_AccumulatedResults, &hv_ExtendedResults);
      hv_AccumulatedResults = hv_ExtendedResults;
    }
    append_names_or_groups(hv_Mode, hv_Name, hv_Groups, hv_CurrentName, hv_AccumulatedResults, 
        &hv_ExtendedResults);
    hv_AccumulatedResults = hv_ExtendedResults;
    //************************************
    //
    //************************************
    //** gray_hor_proj_histo ***
    hv_Name = "gray_hor_proj_histo";
    hv_Groups.Clear();
    hv_Groups[0] = "gray";
    hv_Groups[1] = "texture";
    hv_Groups[2] = "scale_invar";
    //****************
    if (0 != (hv_Name==hv_CurrentName))
    {
      //** Calculate feature ***
      hv_Size = 20;
      calc_feature_gray_proj(ho_Region, ho_Image, "hor_histo", hv_Size, &hv_Feature);
      //*************************
      append_length_or_values(hv_Mode, hv_Feature, hv_AccumulatedResults, &hv_ExtendedResults);
      hv_AccumulatedResults = hv_ExtendedResults;
    }
    append_names_or_groups(hv_Mode, hv_Name, hv_Groups, hv_CurrentName, hv_AccumulatedResults, 
        &hv_ExtendedResults);
    hv_AccumulatedResults = hv_ExtendedResults;
    //************************************
    //
    //************************************
    //** gray_vert_proj_histo ***
    hv_Name = "gray_vert_proj_histo";
    hv_Groups.Clear();
    hv_Groups[0] = "gray";
    hv_Groups[1] = "texture";
    hv_Groups[2] = "scale_invar";
    //****************
    if (0 != (hv_Name==hv_CurrentName))
    {
      //** Calculate feature ***
      hv_Size = 20;
      calc_feature_gray_proj(ho_Region, ho_Image, "vert_histo", hv_Size, &hv_Feature);
      //*************************
      append_length_or_values(hv_Mode, hv_Feature, hv_AccumulatedResults, &hv_ExtendedResults);
      hv_AccumulatedResults = hv_ExtendedResults;
    }
    append_names_or_groups(hv_Mode, hv_Name, hv_Groups, hv_CurrentName, hv_AccumulatedResults, 
        &hv_ExtendedResults);
    hv_AccumulatedResults = hv_ExtendedResults;
    //************************************
    //
    //************************************
    //** grad_dir_histo ***
    hv_Name = "grad_dir_histo";
    hv_Groups.Clear();
    hv_Groups[0] = "gray";
    hv_Groups[1] = "texture";
    //****************
    if (0 != (hv_Name==hv_CurrentName))
    {
      //** Calculate feature ***
      hv_NumBins = 20;
      calc_feature_grad_dir_histo(ho_Region, ho_Image, hv_NumBins, &hv_Feature);
      //*************************
      append_length_or_values(hv_Mode, hv_Feature, hv_AccumulatedResults, &hv_ExtendedResults);
      hv_AccumulatedResults = hv_ExtendedResults;
    }
    append_names_or_groups(hv_Mode, hv_Name, hv_Groups, hv_CurrentName, hv_AccumulatedResults, 
        &hv_ExtendedResults);
    hv_AccumulatedResults = hv_ExtendedResults;
    //************************************
    //
    //************************************
    //** edge_density ***
    hv_Name = "edge_density";
    hv_Groups.Clear();
    hv_Groups[0] = "gray";
    hv_Groups[1] = "texture";
    hv_Groups[2] = "rot_invar";
    hv_Groups[3] = "scale_invar";
    //****************
    if (0 != (hv_Name==hv_CurrentName))
    {
      //** Calculate feature ***
      calc_feature_edge_density(ho_Region, ho_Image, &hv_Feature);
      //*************************
      append_length_or_values(hv_Mode, hv_Feature, hv_AccumulatedResults, &hv_ExtendedResults);
      hv_AccumulatedResults = hv_ExtendedResults;
    }
    append_names_or_groups(hv_Mode, hv_Name, hv_Groups, hv_CurrentName, hv_AccumulatedResults, 
        &hv_ExtendedResults);
    hv_AccumulatedResults = hv_ExtendedResults;
    //
    //************************************
    //
    //************************************
    //** edge_density_histogram ***
    hv_Name = "edge_density_histogram";
    hv_Groups.Clear();
    hv_Groups[0] = "gray";
    hv_Groups[1] = "texture";
    hv_Groups[2] = "rot_invar";
    hv_Groups[3] = "scale_invar";
    //****************
    if (0 != (hv_Name==hv_CurrentName))
    {
      //** Calculate feature ***
      hv_NumBins = 4;
      calc_feature_edge_density_histogram(ho_Region, ho_Image, hv_NumBins, &hv_Feature);
      //*************************
      append_length_or_values(hv_Mode, hv_Feature, hv_AccumulatedResults, &hv_ExtendedResults);
      hv_AccumulatedResults = hv_ExtendedResults;
    }
    append_names_or_groups(hv_Mode, hv_Name, hv_Groups, hv_CurrentName, hv_AccumulatedResults, 
        &hv_ExtendedResults);
    hv_AccumulatedResults = hv_ExtendedResults;
    //
    //************************************
    //
    //************************************
    //** edge_density_pyramid ***
    hv_NameRegExp = "edge_density_pyramid_([234])";
    hv_Names = HTuple("edge_density_pyramid_")+HTuple::TupleGenSequence(2,4,1);
    hv_Groups.Clear();
    hv_Groups[0] = "gray";
    hv_Groups[1] = "texture";
    hv_Groups[2] = "rot_invar";
    hv_Groups[3] = "scale_invar";
    //****************
    if (0 != (hv_CurrentName.TupleRegexpTest(hv_NameRegExp)))
    {
      //** Calculate feature ***
      hv_NumPyramids = (hv_CurrentName.TupleRegexpMatch(hv_NameRegExp)).TupleNumber();
      calc_feature_pyramid(ho_Region, ho_Image, "edge_density", hv_NumPyramids, &hv_Feature);
      //*************************
      append_length_or_values(hv_Mode, hv_Feature, hv_AccumulatedResults, &hv_ExtendedResults);
      hv_AccumulatedResults = hv_ExtendedResults;
    }
    append_names_or_groups_pyramid(hv_Mode, hv_Groups, hv_CurrentName, hv_Names, 
        hv_NameRegExp, hv_AccumulatedResults, &hv_ExtendedResults);
    hv_AccumulatedResults = hv_ExtendedResults;
    //
    //************************************
    //
    //************************************
    //** edge_density_histogram_pyramid ***
    hv_NameRegExp = "edge_density_histogram_pyramid_([234])";
    hv_Names = HTuple("edge_density_histogram_pyramid_")+HTuple::TupleGenSequence(2,4,1);
    hv_Groups.Clear();
    hv_Groups[0] = "gray";
    hv_Groups[1] = "texture";
    hv_Groups[2] = "rot_invar";
    hv_Groups[3] = "scale_invar";
    //****************
    if (0 != (hv_CurrentName.TupleRegexpTest(hv_NameRegExp)))
    {
      //** Calculate feature ***
      hv_NumPyramids = (hv_CurrentName.TupleRegexpMatch(hv_NameRegExp)).TupleNumber();
      calc_feature_pyramid(ho_Region, ho_Image, "edge_density_histogram", hv_NumPyramids, 
          &hv_Feature);
      //*************************
      append_length_or_values(hv_Mode, hv_Feature, hv_AccumulatedResults, &hv_ExtendedResults);
      hv_AccumulatedResults = hv_ExtendedResults;
    }
    append_names_or_groups_pyramid(hv_Mode, hv_Groups, hv_CurrentName, hv_Names, 
        hv_NameRegExp, hv_AccumulatedResults, &hv_ExtendedResults);
    hv_AccumulatedResults = hv_ExtendedResults;
    //
    //************************************
    //
    //************************************
    //** cooc ***
    hv_Name = "cooc";
    hv_Groups.Clear();
    hv_Groups[0] = "gray";
    hv_Groups[1] = "texture";
    //****************
    if (0 != (hv_Name==hv_CurrentName))
    {
      //** Calculate feature ***
      hv_Feature = HTuple();
      CoocFeatureImage(ho_Region, ho_Image, 6, 0, &hv_Energy, &hv_Correlation, &hv_Homogeneity, 
          &hv_Contrast);
      if (0 != (hv_NumRegions>0))
      {
        hv_Index = HTuple::TupleGenSequence(0,(4*hv_NumRegions)-1,4);
        hv_Feature[hv_Index] = hv_Energy;
        hv_Feature[1+hv_Index] = hv_Correlation;
        hv_Feature[2+hv_Index] = hv_Homogeneity;
        hv_Feature[3+hv_Index] = hv_Contrast;
      }
      //*************************
      append_length_or_values(hv_Mode, hv_Feature, hv_AccumulatedResults, &hv_ExtendedResults);
      hv_AccumulatedResults = hv_ExtendedResults;
    }
    append_names_or_groups(hv_Mode, hv_Name, hv_Groups, hv_CurrentName, hv_AccumulatedResults, 
        &hv_ExtendedResults);
    hv_AccumulatedResults = hv_ExtendedResults;
    //************************************
    //
    //************************************
    //** cooc_pyramid ***
    hv_NameRegExp = "cooc_pyramid_([234])";
    hv_Names = HTuple("cooc_pyramid_")+HTuple::TupleGenSequence(2,4,1);
    hv_Groups.Clear();
    hv_Groups[0] = "gray";
    hv_Groups[1] = "texture";
    //****************
    if (0 != (hv_CurrentName.TupleRegexpTest(hv_NameRegExp)))
    {
      //** Calculate feature ***
      hv_NumPyramids = (hv_CurrentName.TupleRegexpMatch(hv_NameRegExp)).TupleNumber();
      calc_feature_pyramid(ho_Region, ho_Image, "cooc", hv_NumPyramids, &hv_Feature);
      //*************************
      append_length_or_values(hv_Mode, hv_Feature, hv_AccumulatedResults, &hv_ExtendedResults);
      hv_AccumulatedResults = hv_ExtendedResults;
    }
    append_names_or_groups_pyramid(hv_Mode, hv_Groups, hv_CurrentName, hv_Names, 
        hv_NameRegExp, hv_AccumulatedResults, &hv_ExtendedResults);
    hv_AccumulatedResults = hv_ExtendedResults;
    //
    //************************************
    //
    //************************************
    //POLAR TRANSFORM FEATURES
    //************************************
    //
    //************************************
    //** polar_gray_proj ***
    hv_Name = "polar_gray_proj";
    hv_Groups.Clear();
    hv_Groups[0] = "gray";
    hv_Groups[1] = "rot_invar";
    hv_Groups[2] = "scale_invar";
    //*************
    if (0 != (hv_Name==hv_CurrentName))
    {
      //** Calculate feature ***
      hv_Width = 100;
      hv_Height = 40;
      calc_feature_polar_gray_proj(ho_Region, ho_Image, "hor_gray", hv_Width, hv_Height, 
          &hv_Feature);
      //*************************
      append_length_or_values(hv_Mode, hv_Feature, hv_AccumulatedResults, &hv_ExtendedResults);
      hv_AccumulatedResults = hv_ExtendedResults;
    }
    append_names_or_groups(hv_Mode, hv_Name, hv_Groups, hv_CurrentName, hv_AccumulatedResults, 
        &hv_ExtendedResults);
    hv_AccumulatedResults = hv_ExtendedResults;
    //************************************
    //
    //************************************
    //** polar_grad_proj ***
    hv_Name = "polar_grad_proj";
    hv_Groups.Clear();
    hv_Groups[0] = "gray";
    hv_Groups[1] = "rot_invar";
    hv_Groups[2] = "scale_invar";
    //*************
    if (0 != (hv_Name==hv_CurrentName))
    {
      //** Calculate feature ***
      hv_Width = 100;
      hv_Height = 40;
      calc_feature_polar_gray_proj(ho_Region, ho_Image, "hor_sobel_amp", hv_Width, 
          hv_Height, &hv_Feature);
      //*************************
      append_length_or_values(hv_Mode, hv_Feature, hv_AccumulatedResults, &hv_ExtendedResults);
      hv_AccumulatedResults = hv_ExtendedResults;
    }
    append_names_or_groups(hv_Mode, hv_Name, hv_Groups, hv_CurrentName, hv_AccumulatedResults, 
        &hv_ExtendedResults);
    hv_AccumulatedResults = hv_ExtendedResults;
    //************************************
    //
    //************************************
    //** polar_grad_x_proj ***
    hv_Name = "polar_grad_x_proj";
    hv_Groups.Clear();
    hv_Groups[0] = "gray";
    hv_Groups[1] = "rot_invar";
    hv_Groups[2] = "scale_invar";
    //*************
    if (0 != (hv_Name==hv_CurrentName))
    {
      //** Calculate feature ***
      hv_Width = 100;
      hv_Height = 40;
      calc_feature_polar_gray_proj(ho_Region, ho_Image, "hor_sobel_x", hv_Width, 
          hv_Height, &hv_Feature);
      //*************************
      append_length_or_values(hv_Mode, hv_Feature, hv_AccumulatedResults, &hv_ExtendedResults);
      hv_AccumulatedResults = hv_ExtendedResults;
    }
    append_names_or_groups(hv_Mode, hv_Name, hv_Groups, hv_CurrentName, hv_AccumulatedResults, 
        &hv_ExtendedResults);
    hv_AccumulatedResults = hv_ExtendedResults;
    //************************************
    //
    //************************************
    //** polar_grad_y_proj ***
    hv_Name = "polar_grad_y_proj";
    hv_Groups.Clear();
    hv_Groups[0] = "gray";
    hv_Groups[1] = "rot_invar";
    hv_Groups[2] = "scale_invar";
    //*************
    if (0 != (hv_Name==hv_CurrentName))
    {
      //** Calculate feature ***
      hv_Width = 100;
      hv_Height = 40;
      calc_feature_polar_gray_proj(ho_Region, ho_Image, "hor_sobel_y", hv_Width, 
          hv_Height, &hv_Feature);
      //*************************
      append_length_or_values(hv_Mode, hv_Feature, hv_AccumulatedResults, &hv_ExtendedResults);
      hv_AccumulatedResults = hv_ExtendedResults;
    }
    append_names_or_groups(hv_Mode, hv_Name, hv_Groups, hv_CurrentName, hv_AccumulatedResults, 
        &hv_ExtendedResults);
    hv_AccumulatedResults = hv_ExtendedResults;
    //************************************
    //
    //************************************
    //** polar_gray_proj_histo ***
    hv_Name = "polar_gray_proj_histo";
    hv_Groups.Clear();
    hv_Groups[0] = "gray";
    hv_Groups[1] = "rot_invar";
    hv_Groups[2] = "scale_invar";
    //*************
    if (0 != (hv_Name==hv_CurrentName))
    {
      //** Calculate feature ***
      hv_Width = 100;
      hv_Height = 40;
      calc_feature_polar_gray_proj(ho_Region, ho_Image, "vert_gray", hv_Width, hv_Height, 
          &hv_Projection);
      hv_NumBins = 20;
      hv_Feature = HTuple();
      {
      HTuple end_val1093 = hv_NumRegions;
      HTuple step_val1093 = 1;
      for (hv_Index=1; hv_Index.Continue(end_val1093, step_val1093); hv_Index += step_val1093)
      {
        hv_Start = (hv_Index-1)*hv_Width;
        TupleHistoRange(hv_Projection.TupleSelectRange(hv_Start,(hv_Start+hv_Width)-1), 
            0, 255, hv_NumBins, &hv_Histo, &hv_BinSize);
        hv_Feature = hv_Feature.TupleConcat(hv_Histo);
      }
      }
      //*************************
      append_length_or_values(hv_Mode, hv_Feature, hv_AccumulatedResults, &hv_ExtendedResults);
      hv_AccumulatedResults = hv_ExtendedResults;
    }
    append_names_or_groups(hv_Mode, hv_Name, hv_Groups, hv_CurrentName, hv_AccumulatedResults, 
        &hv_ExtendedResults);
    hv_AccumulatedResults = hv_ExtendedResults;
    //************************************
    //
    //************************************
    //COLOR FEATURES
    //************************************
    //
    //************************************
    //** cielab_mean ***
    hv_Name = "cielab_mean";
    hv_Groups = "color";
    //*************
    if (0 != (hv_Name==hv_CurrentName))
    {
      //** Calculate feature ***
      calc_feature_color_intensity(ho_Region, ho_Image, "cielab", "mean", &hv_Feature);
      //*************************
      append_length_or_values(hv_Mode, hv_Feature, hv_AccumulatedResults, &hv_ExtendedResults);
      hv_AccumulatedResults = hv_ExtendedResults;
    }
    append_names_or_groups(hv_Mode, hv_Name, hv_Groups, hv_CurrentName, hv_AccumulatedResults, 
        &hv_ExtendedResults);
    hv_AccumulatedResults = hv_ExtendedResults;
    //************************************
    //
    //************************************
    //** cielab_dev ***
    hv_Name = "cielab_dev";
    hv_Groups = "color";
    //*************
    if (0 != (hv_Name==hv_CurrentName))
    {
      //** Calculate feature ***
      calc_feature_color_intensity(ho_Region, ho_Image, "cielab", "deviation", &hv_Feature);
      //*************************
      append_length_or_values(hv_Mode, hv_Feature, hv_AccumulatedResults, &hv_ExtendedResults);
      hv_AccumulatedResults = hv_ExtendedResults;
    }
    append_names_or_groups(hv_Mode, hv_Name, hv_Groups, hv_CurrentName, hv_AccumulatedResults, 
        &hv_ExtendedResults);
    hv_AccumulatedResults = hv_ExtendedResults;
    //************************************
    //
    //************************************
    //** hls_mean ***
    hv_Name = "hls_mean";
    hv_Groups = "color";
    //*************
    if (0 != (hv_Name==hv_CurrentName))
    {
      //** Calculate feature ***
      calc_feature_color_intensity(ho_Region, ho_Image, "hls", "mean", &hv_Feature);
      //*************************
      append_length_or_values(hv_Mode, hv_Feature, hv_AccumulatedResults, &hv_ExtendedResults);
      hv_AccumulatedResults = hv_ExtendedResults;
    }
    append_names_or_groups(hv_Mode, hv_Name, hv_Groups, hv_CurrentName, hv_AccumulatedResults, 
        &hv_ExtendedResults);
    hv_AccumulatedResults = hv_ExtendedResults;
    //************************************
    //
    //************************************
    //** hls_dev ***
    hv_Name = "hls_dev";
    hv_Groups = "color";
    //*************
    if (0 != (hv_Name==hv_CurrentName))
    {
      //** Calculate feature ***
      calc_feature_color_intensity(ho_Region, ho_Image, "hls", "deviation", &hv_Feature);
      //*************************
      append_length_or_values(hv_Mode, hv_Feature, hv_AccumulatedResults, &hv_ExtendedResults);
      hv_AccumulatedResults = hv_ExtendedResults;
    }
    append_names_or_groups(hv_Mode, hv_Name, hv_Groups, hv_CurrentName, hv_AccumulatedResults, 
        &hv_ExtendedResults);
    hv_AccumulatedResults = hv_ExtendedResults;
    //************************************
    //
    //************************************
    //** rgb_mean ***
    hv_Name = "rgb_mean";
    hv_Groups = "color";
    //*************
    if (0 != (hv_Name==hv_CurrentName))
    {
      //** Calculate feature ***
      calc_feature_color_intensity(ho_Region, ho_Image, "rgb", "mean", &hv_Feature);
      //*************************
      append_length_or_values(hv_Mode, hv_Feature, hv_AccumulatedResults, &hv_ExtendedResults);
      hv_AccumulatedResults = hv_ExtendedResults;
    }
    append_names_or_groups(hv_Mode, hv_Name, hv_Groups, hv_CurrentName, hv_AccumulatedResults, 
        &hv_ExtendedResults);
    hv_AccumulatedResults = hv_ExtendedResults;
    //************************************
    //
    //************************************
    //** rgb_dev ***
    hv_Name = "rgb_dev";
    hv_Groups = "color";
    //*************
    if (0 != (hv_Name==hv_CurrentName))
    {
      //** Calculate feature ***
      calc_feature_color_intensity(ho_Region, ho_Image, "rgb", "deviation", &hv_Feature);
      //*************************
      append_length_or_values(hv_Mode, hv_Feature, hv_AccumulatedResults, &hv_ExtendedResults);
      hv_AccumulatedResults = hv_ExtendedResults;
    }
    append_names_or_groups(hv_Mode, hv_Name, hv_Groups, hv_CurrentName, hv_AccumulatedResults, 
        &hv_ExtendedResults);
    hv_AccumulatedResults = hv_ExtendedResults;
  }
  }
  (*hv_Output) = hv_AccumulatedResults;
  SetSystem("empty_region_result", hv_EmptyRegionResult);
  return;
}

// Chapter: Calibration / Camera Parameters
// Short Description: Generate a camera parameter tuple for an area scan camera with a telecentric lens and with distortions modeled by the division model. 
void gen_cam_par_area_scan_telecentric_division (HTuple hv_Magnification, HTuple hv_Kappa, 
    HTuple hv_Sx, HTuple hv_Sy, HTuple hv_Cx, HTuple hv_Cy, HTuple hv_ImageWidth, 
    HTuple hv_ImageHeight, HTuple *hv_CameraParam)
{

  // Local iconic variables

  //Generate a camera parameter tuple for an area scan camera
  //with a telecentric lens and with distortions modeled by the
  //division model.
  //
  (*hv_CameraParam).Clear();
  (*hv_CameraParam)[0] = "area_scan_telecentric_division";
  (*hv_CameraParam).Append(hv_Magnification);
  (*hv_CameraParam).Append(hv_Kappa);
  (*hv_CameraParam).Append(hv_Sx);
  (*hv_CameraParam).Append(hv_Sy);
  (*hv_CameraParam).Append(hv_Cx);
  (*hv_CameraParam).Append(hv_Cy);
  (*hv_CameraParam).Append(hv_ImageWidth);
  (*hv_CameraParam).Append(hv_ImageHeight);
  return;
}

// Chapter: Classification / Misc
// Short Description: Auxiliary procedure for get_features. 
void append_names_or_groups_pyramid (HTuple hv_Mode, HTuple hv_Groups, HTuple hv_CurrentName, 
    HTuple hv_Names, HTuple hv_NameRegExp, HTuple hv_AccumulatedResults, HTuple *hv_ExtendedResults)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_BelongsToGroup, hv_TmpNames, hv_J;
  HTuple  hv_FirstOccurrence;

  //
  //Auxiliary procedure used only by get_features and get_custom_features
  //
  (*hv_ExtendedResults) = hv_AccumulatedResults;
  if (0 != (hv_Mode==HTuple("get_names")))
  {
    hv_BelongsToGroup = HTuple((hv_Groups.TupleFind(hv_CurrentName))!=-1).TupleOr(hv_CurrentName==HTuple("all"));
    if (0 != (hv_CurrentName.TupleRegexpTest(hv_NameRegExp)))
    {
      hv_Names = hv_CurrentName;
    }
    else if (0 != (hv_BelongsToGroup.TupleNot()))
    {
      hv_Names = HTuple();
    }
    hv_TmpNames = HTuple();
    {
    HTuple end_val12 = (hv_Names.TupleLength())-1;
    HTuple step_val12 = 1;
    for (hv_J=0; hv_J.Continue(end_val12, step_val12); hv_J += step_val12)
    {
      hv_FirstOccurrence = HTuple((hv_AccumulatedResults.TupleLength())==0).TupleOr((hv_AccumulatedResults.TupleFind(HTuple(hv_Names[hv_J])))==-1);
      if (0 != hv_FirstOccurrence)
      {
        //Output in 'get_names' mode is the name of the feature
        hv_TmpNames = hv_TmpNames.TupleConcat(HTuple(hv_Names[hv_J]));
      }
    }
    }
    (*hv_ExtendedResults).Clear();
    (*hv_ExtendedResults).Append(hv_AccumulatedResults);
    (*hv_ExtendedResults).Append(hv_TmpNames);
  }
  else if (0 != (hv_Mode==HTuple("get_groups")))
  {
    (*hv_ExtendedResults).Clear();
    (*hv_ExtendedResults).Append(hv_AccumulatedResults);
    (*hv_ExtendedResults).Append(hv_Groups);
  }
  return;
}

// Chapter: Classification / Misc
// Short Description: Calculate a feature on different image pyramid levels. 
void calc_feature_pyramid (HObject ho_Region, HObject ho_Image, HTuple hv_FeatureName, 
    HTuple hv_NumLevels, HTuple *hv_Feature)
{

  // Local iconic variables
  HObject  ho_ImageZoom, ho_RegionZoom;

  // Local control variables
  HTuple  hv_Zoom, hv_NumRegions, hv_I, hv_Features;
  HTuple  hv_FeatureLength, hv_Step, hv_Indices, hv_J, hv_Start;
  HTuple  hv_End;

  //
  //Calculate a feature for different pyramid levels
  //
  hv_Zoom = 0.5;
  (*hv_Feature) = HTuple();
  CountObj(ho_Region, &hv_NumRegions);
  if (0 != (hv_NumRegions>0))
  {
    {
    HTuple end_val7 = hv_NumLevels;
    HTuple step_val7 = 1;
    for (hv_I=1; hv_I.Continue(end_val7, step_val7); hv_I += step_val7)
    {
      if (0 != (hv_I>1))
      {
        ZoomImageFactor(ho_ImageZoom, &ho_ImageZoom, hv_Zoom, hv_Zoom, "constant");
        ZoomRegion(ho_RegionZoom, &ho_RegionZoom, hv_Zoom, hv_Zoom);
        calculate_features(ho_RegionZoom, ho_ImageZoom, hv_FeatureName, &hv_Features);
      }
      else
      {
        CopyObj(ho_Image, &ho_ImageZoom, 1, 1);
        CopyObj(ho_Region, &ho_RegionZoom, 1, hv_NumRegions);
        calculate_features(ho_RegionZoom, ho_ImageZoom, hv_FeatureName, &hv_Features);
        hv_FeatureLength = (hv_Features.TupleLength())/hv_NumRegions;
        hv_Step = hv_NumLevels*hv_FeatureLength;
      }
      hv_Indices = HTuple();
      {
      HTuple end_val20 = hv_NumRegions-1;
      HTuple step_val20 = 1;
      for (hv_J=0; hv_J.Continue(end_val20, step_val20); hv_J += step_val20)
      {
        hv_Start = (hv_J*hv_Step)+((hv_I-1)*hv_FeatureLength);
        hv_End = (hv_Start+hv_FeatureLength)-1;
        hv_Indices = hv_Indices.TupleConcat(HTuple::TupleGenSequence(hv_Start,hv_End,1));
      }
      }
      (*hv_Feature)[hv_Indices] = hv_Features;
    }
    }
  }
  return;
}

// Chapter: Classification / Misc
// Short Description: Calculate gray-value projections and their histograms. 
void calc_feature_gray_proj (HObject ho_Region, HObject ho_Image, HTuple hv_Mode, 
    HTuple hv_Size, HTuple *hv_Feature)
{

  // Local iconic variables
  HObject  ho_RegionTmp, ho_RegionMoved, ho_ImageTmp;

  // Local control variables
  HTuple  hv_NumRegions, hv_Index, hv_RowsTmp, hv_ColumnsTmp;
  HTuple  hv_HorProjectionFilledUp, hv_VertProjectionFilledUp;
  HTuple  hv_Row1, hv_Column1, hv_Row2, hv_Column2, hv_ScaleHeight;
  HTuple  hv_ScaleWidth, hv_HorProjection, hv_VertProjection;
  HTuple  hv_HorProjectionFilledUpFront, hv_VertProjectionFilledUpFront;
  HTuple  hv_Histo, hv_BinSize;

  //
  //Calculate gray-value projections and their histograms
  //
  CountObj(ho_Region, &hv_NumRegions);
  (*hv_Feature) = HTuple();
  //
  {
  HTuple end_val6 = hv_NumRegions;
  HTuple step_val6 = 1;
  for (hv_Index=1; hv_Index.Continue(end_val6, step_val6); hv_Index += step_val6)
  {
    SelectObj(ho_Region, &ho_RegionTmp, hv_Index);
    //Test empty region
    GetRegionPoints(ho_RegionTmp, &hv_RowsTmp, &hv_ColumnsTmp);
    if (0 != ((hv_RowsTmp.TupleLength())==0))
    {
      hv_HorProjectionFilledUp = HTuple(hv_Size,-1.0);
      hv_VertProjectionFilledUp = HTuple(hv_Size,-1.0);
    }
    else
    {
      //Zoom image and region to Size x Size pixels
      SmallestRectangle1(ho_RegionTmp, &hv_Row1, &hv_Column1, &hv_Row2, &hv_Column2);
      MoveRegion(ho_RegionTmp, &ho_RegionMoved, -hv_Row1, -hv_Column1);
      CropRectangle1(ho_Image, &ho_ImageTmp, hv_Row1, hv_Column1, hv_Row2, hv_Column2);
      hv_ScaleHeight = (hv_Size.TupleReal())/((hv_Row2-hv_Row1)+1);
      hv_ScaleWidth = (hv_Size.TupleReal())/((hv_Column2-hv_Column1)+1);
      ZoomImageFactor(ho_ImageTmp, &ho_ImageTmp, hv_ScaleWidth, hv_ScaleHeight, "constant");
      ZoomRegion(ho_RegionMoved, &ho_RegionTmp, hv_ScaleWidth, hv_ScaleHeight);
      //Calculate gray value projection
      GrayProjections(ho_RegionTmp, ho_ImageTmp, "simple", &hv_HorProjection, &hv_VertProjection);
      //Fill up projection in case the zoomed region is smaller than
      //Size x Size pixels due to interpolation effects
      SmallestRectangle1(ho_RegionTmp, &hv_Row1, &hv_Column1, &hv_Row2, &hv_Column2);
      hv_HorProjectionFilledUpFront.Clear();
      hv_HorProjectionFilledUpFront.Append(HTuple(HTuple(0).TupleMax2(hv_Row1),-1.0));
      hv_HorProjectionFilledUpFront.Append(hv_HorProjection);
      hv_HorProjectionFilledUp.Clear();
      hv_HorProjectionFilledUp.Append(hv_HorProjectionFilledUpFront);
      hv_HorProjectionFilledUp.Append(HTuple(hv_Size-(hv_HorProjectionFilledUpFront.TupleLength()),-1.0));
      hv_VertProjectionFilledUpFront.Clear();
      hv_VertProjectionFilledUpFront.Append(HTuple(HTuple(0).TupleMax2(hv_Column1),-1.0));
      hv_VertProjectionFilledUpFront.Append(hv_VertProjection);
      hv_VertProjectionFilledUp.Clear();
      hv_VertProjectionFilledUp.Append(hv_VertProjectionFilledUpFront);
      hv_VertProjectionFilledUp.Append(HTuple(hv_Size-(hv_VertProjectionFilledUpFront.TupleLength()),-1.0));
    }
    if (0 != (hv_Mode==HTuple("hor")))
    {
      (*hv_Feature) = (*hv_Feature).TupleConcat(hv_HorProjectionFilledUp);
    }
    else if (0 != (hv_Mode==HTuple("vert")))
    {
      (*hv_Feature) = (*hv_Feature).TupleConcat(hv_VertProjectionFilledUp);
    }
    else if (0 != (hv_Mode==HTuple("hor_histo")))
    {
      TupleHistoRange(hv_HorProjectionFilledUp, 0, 255, hv_Size, &hv_Histo, &hv_BinSize);
      (*hv_Feature) = (*hv_Feature).TupleConcat(hv_Histo);
    }
    else if (0 != (hv_Mode==HTuple("vert_histo")))
    {
      TupleHistoRange(hv_VertProjectionFilledUp, 0, 255, hv_Size, &hv_Histo, &hv_BinSize);
      (*hv_Feature) = (*hv_Feature).TupleConcat(hv_Histo);
    }
  }
  }
  return;
}

// Chapter: Classification / Misc
// Short Description: Calculate one or more features of a given image and/or region. 
void calculate_features (HObject ho_Region, HObject ho_Image, HTuple hv_FeatureNames, 
    HTuple *hv_Features)
{

  //
  //Calculate features given in FeatureNames
  //for the input regions in Region
  //(if needed supported by the underlying
  //gray-value or color image Image).
  //
  get_features(ho_Region, ho_Image, hv_FeatureNames, "calculate", &(*hv_Features));
  return;
}

// Chapter: Classification / Misc
// Short Description: Calculate edge density histogram feature. 
void calc_feature_edge_density_histogram (HObject ho_Region, HObject ho_Image, HTuple hv_NumBins, 
    HTuple *hv_Feature)
{

  // Local iconic variables
  HObject  ho_Channel1, ho_EdgeAmplitude, ho_RegionSelected;

  // Local control variables
  HTuple  hv_ImageWidth, hv_ImageHeight, hv_NumRegions;
  HTuple  hv_J, hv_Area, hv_Row, hv_Column, hv_Histo, hv_BinSize;

  //
  //Calculate the edge density histogram, i.e.
  //the ratio of the edge amplitude histogram to the area of the region.
  //
  (*hv_Feature) = HTuple();
  GetImageSize(ho_Image, &hv_ImageWidth, &hv_ImageHeight);
  CountObj(ho_Region, &hv_NumRegions);
  if (0 != (HTuple(hv_ImageWidth>1).TupleAnd(hv_ImageHeight>1)))
  {
    AccessChannel(ho_Image, &ho_Channel1, 1);
    SobelAmp(ho_Channel1, &ho_EdgeAmplitude, "sum_abs", 3);
    {
    HTuple end_val10 = hv_NumRegions;
    HTuple step_val10 = 1;
    for (hv_J=1; hv_J.Continue(end_val10, step_val10); hv_J += step_val10)
    {
      SelectObj(ho_Region, &ho_RegionSelected, hv_J);
      AreaCenter(ho_RegionSelected, &hv_Area, &hv_Row, &hv_Column);
      if (0 != (hv_Area>0))
      {
        GrayHistoRange(ho_RegionSelected, ho_EdgeAmplitude, 0, 255, hv_NumBins, &hv_Histo, 
            &hv_BinSize);
        (*hv_Feature) = (*hv_Feature).TupleConcat((hv_Histo.TupleReal())/(hv_Histo.TupleSum()));
      }
      else
      {
        (*hv_Feature) = ((*hv_Feature).TupleConcat(1.0)).TupleConcat(HTuple(hv_NumBins-1,0.0));
      }
    }
    }
  }
  else
  {
    (*hv_Feature) = HTuple(hv_NumRegions*hv_NumBins,0.0);
  }
  return;
}

// Chapter: Classification / Misc
// Short Description: Calculate the gradient direction histogram. 
void calc_feature_grad_dir_histo (HObject ho_Region, HObject ho_Image, HTuple hv_NumBins, 
    HTuple *hv_Feature)
{

  // Local iconic variables
  HObject  ho_Channel1, ho_RegionSelected, ho_ImageReduced;
  HObject  ho_EdgeAmplitude, ho_EdgeDirection;

  // Local control variables
  HTuple  hv_NumRegions, hv_Index, hv_Histo, hv_BinSize;
  HTuple  hv_Sum;

  //
  //Calculate gradient direction histogram
  //
  AccessChannel(ho_Image, &ho_Channel1, 1);
  CountObj(ho_Region, &hv_NumRegions);
  (*hv_Feature) = HTuple();
  {
  HTuple end_val6 = hv_NumRegions;
  HTuple step_val6 = 1;
  for (hv_Index=1; hv_Index.Continue(end_val6, step_val6); hv_Index += step_val6)
  {
    SelectObj(ho_Region, &ho_RegionSelected, hv_Index);
    ReduceDomain(ho_Channel1, ho_RegionSelected, &ho_ImageReduced);
    SobelDir(ho_ImageReduced, &ho_EdgeAmplitude, &ho_EdgeDirection, "sum_abs_binomial", 
        3);
    GrayHistoRange(ho_RegionSelected, ho_EdgeDirection, 0, 179, hv_NumBins, &hv_Histo, 
        &hv_BinSize);
    hv_Sum = hv_Histo.TupleSum();
    if (0 != (hv_Sum!=0))
    {
      (*hv_Feature) = (*hv_Feature).TupleConcat((hv_Histo.TupleReal())/hv_Sum);
    }
    else
    {
      (*hv_Feature) = (*hv_Feature).TupleConcat(hv_Histo);
    }
  }
  }
  return;
}

// Chapter: Classification / Misc
// Short Description: Generate a dummy image and region that are, e.g., used to determine the lengths of the feature vectors in get_feature_lengths. 
void gen_dummy_objects (HObject *ho_Region, HObject *ho_Image)
{

  //
  //Create dummy objects for the feature calculation
  //(may be used to determine the lengths of the
  //vectors etc.).
  //
  GenImageConst(&(*ho_Image), "byte", 3, 3);
  Compose3((*ho_Image), (*ho_Image), (*ho_Image), &(*ho_Image));
  GetDomain((*ho_Image), &(*ho_Region));
  return;
}

// Chapter: Classification / Misc
// Short Description: Calculate edge density. 
void calc_feature_edge_density (HObject ho_Region, HObject ho_Image, HTuple *hv_Feature)
{

  // Local iconic variables
  HObject  ho_RegionUnion, ho_ImageReduced, ho_EdgeAmplitude;

  // Local control variables
  HTuple  hv_Area, hv_Row, hv_Column, hv_Width;
  HTuple  hv_Height, hv_AreaGray, hv_ZeroIndex;

  //
  //Calculate the edge density, i.e.
  //the ratio of the edge amplitudes to the area of the region.
  //
  Union1(ho_Region, &ho_RegionUnion);
  ReduceDomain(ho_Image, ho_RegionUnion, &ho_ImageReduced);
  AreaCenter(ho_Region, &hv_Area, &hv_Row, &hv_Column);
  GetImageSize(ho_ImageReduced, &hv_Width, &hv_Height);
  if (0 != (HTuple(hv_Width>1).TupleAnd(hv_Height>1)))
  {
    SobelAmp(ho_ImageReduced, &ho_EdgeAmplitude, "sum_abs", 3);
    AreaCenterGray(ho_Region, ho_EdgeAmplitude, &hv_AreaGray, &hv_Row, &hv_Column);
    hv_ZeroIndex = hv_Area.TupleFind(0);
    if (0 != (hv_ZeroIndex!=-1))
    {
      hv_Area[hv_ZeroIndex] = 1;
      hv_AreaGray[hv_ZeroIndex] = 0;
    }
    (*hv_Feature) = hv_AreaGray/hv_Area;
  }
  else
  {
    (*hv_Feature) = HTuple(hv_Area.TupleLength(),0.0);
  }
  return;
}

// Chapter: Classification / Misc
// Short Description: Calculate gray-value projections of polar-transformed image regions. 
void calc_feature_polar_gray_proj (HObject ho_Region, HObject ho_Image, HTuple hv_Mode, 
    HTuple hv_Width, HTuple hv_Height, HTuple *hv_Features)
{

  // Local iconic variables
  HObject  ho_RegionSelected, ho_PolarTransImage;
  HObject  ho_EdgeAmplitude, ho_ImageAbs;

  // Local control variables
  HTuple  hv_NumRegions, hv_Index, hv_Row, hv_Column;
  HTuple  hv_Radius, hv_HorProjection, hv_VertProjection;

  //
  //Calculate gray-value projections of
  //polar-transformed image regions.
  //
  CountObj(ho_Region, &hv_NumRegions);
  (*hv_Features) = HTuple();
  {
  HTuple end_val6 = hv_NumRegions;
  HTuple step_val6 = 1;
  for (hv_Index=1; hv_Index.Continue(end_val6, step_val6); hv_Index += step_val6)
  {
    SelectObj(ho_Region, &ho_RegionSelected, hv_Index);
    SmallestCircle(ho_RegionSelected, &hv_Row, &hv_Column, &hv_Radius);
    PolarTransImageExt(ho_Image, &ho_PolarTransImage, hv_Row, hv_Column, 0, HTuple(360).TupleRad(), 
        0, (hv_Radius.TupleConcat(1)).TupleMax(), hv_Width, hv_Height, "bilinear");
    //
    if (0 != (hv_Mode==HTuple("hor_gray")))
    {
      GrayProjections(ho_PolarTransImage, ho_PolarTransImage, "simple", &hv_HorProjection, 
          &hv_VertProjection);
      (*hv_Features) = (*hv_Features).TupleConcat(hv_HorProjection);
    }
    else if (0 != (hv_Mode==HTuple("vert_gray")))
    {
      GrayProjections(ho_PolarTransImage, ho_PolarTransImage, "simple", &hv_HorProjection, 
          &hv_VertProjection);
      (*hv_Features) = (*hv_Features).TupleConcat(hv_VertProjection);
    }
    else if (0 != (hv_Mode==HTuple("hor_sobel_amp")))
    {
      SobelAmp(ho_PolarTransImage, &ho_EdgeAmplitude, "sum_abs", 3);
      AbsImage(ho_EdgeAmplitude, &ho_ImageAbs);
      GrayProjections(ho_ImageAbs, ho_ImageAbs, "simple", &hv_HorProjection, &hv_VertProjection);
      (*hv_Features) = (*hv_Features).TupleConcat(hv_HorProjection);
    }
    else if (0 != (hv_Mode==HTuple("vert_sobel_amp")))
    {
      SobelAmp(ho_PolarTransImage, &ho_EdgeAmplitude, "sum_abs", 3);
      AbsImage(ho_EdgeAmplitude, &ho_ImageAbs);
      GrayProjections(ho_ImageAbs, ho_ImageAbs, "simple", &hv_HorProjection, &hv_VertProjection);
      (*hv_Features) = (*hv_Features).TupleConcat(hv_VertProjection);
    }
    else if (0 != (hv_Mode==HTuple("hor_sobel_x")))
    {
      SobelAmp(ho_PolarTransImage, &ho_EdgeAmplitude, "x_binomial", 3);
      AbsImage(ho_EdgeAmplitude, &ho_ImageAbs);
      GrayProjections(ho_ImageAbs, ho_ImageAbs, "simple", &hv_HorProjection, &hv_VertProjection);
      (*hv_Features) = (*hv_Features).TupleConcat(hv_HorProjection);
    }
    else if (0 != (hv_Mode==HTuple("vert_sobel_x")))
    {
      SobelAmp(ho_PolarTransImage, &ho_EdgeAmplitude, "x_binomial", 3);
      AbsImage(ho_EdgeAmplitude, &ho_ImageAbs);
      GrayProjections(ho_ImageAbs, ho_ImageAbs, "simple", &hv_HorProjection, &hv_VertProjection);
      (*hv_Features) = (*hv_Features).TupleConcat(hv_VertProjection);
    }
    else if (0 != (hv_Mode==HTuple("hor_sobel_y")))
    {
      SobelAmp(ho_PolarTransImage, &ho_EdgeAmplitude, "y_binomial", 3);
      AbsImage(ho_EdgeAmplitude, &ho_ImageAbs);
      GrayProjections(ho_ImageAbs, ho_ImageAbs, "simple", &hv_HorProjection, &hv_VertProjection);
      (*hv_Features) = (*hv_Features).TupleConcat(hv_HorProjection);
    }
    else if (0 != (hv_Mode==HTuple("vert_sobel_y")))
    {
      SobelAmp(ho_PolarTransImage, &ho_EdgeAmplitude, "y_binomial", 3);
      AbsImage(ho_EdgeAmplitude, &ho_ImageAbs);
      GrayProjections(ho_ImageAbs, ho_ImageAbs, "simple", &hv_HorProjection, &hv_VertProjection);
      (*hv_Features) = (*hv_Features).TupleConcat(hv_VertProjection);
    }
    else
    {
      throw HException(("Unknown Mode: "+hv_Mode)+" in calc_feature_polar_proj");
    }
  }
  }
  return;
}

// Chapter: 3D Object Model / Creation
// Short Description: Generate a symbolic 3D object model of a camera. 
void gen_camera_object_model_3d (HTuple hv_CameraSetupModel, HTuple hv_CamIndex, 
    HTuple hv_CameraSize, HTuple *hv_OM3DCam)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_LensePose, hv_CylinderLength, hv_ObjectModel3DLense;
  HTuple  hv_ObjectModel3DInit, hv_CamParams, hv_Type, hv_Tilt;
  HTuple  hv_Rot, hv_HomMat3DIdentity, hv_HomMat3DRotate;
  HTuple  hv_SensorToLenseRotation, hv_ObjectModel3DInitTilted;
  HTuple  hv_BoundingBox, hv_PX, hv_PY, hv_QZ, hv_PoseBack;
  HTuple  hv_ObjectModel3DInitTiltedBack, hv_CamPose, hv_OM3DSensor;
  HTuple  hv_OM3DLense;

  //
  //Generate a cylinder (lens) and move it behind the origin in direction z.
  CreatePose(0.0, 0.0, 0.0, 0, 0, 0, "Rp+T", "gba", "point", &hv_LensePose);
  hv_CylinderLength = hv_CameraSize/4.0;
  GenCylinderObjectModel3d(hv_LensePose, hv_CameraSize/2.0, (-hv_CylinderLength)/2.0, 
      0.0, &hv_ObjectModel3DLense);
  //
  //Generate a box (sensor housing) and tilt it, if necessary.
  GenBoxObjectModel3d(hv_LensePose, 1.0*hv_CameraSize, 1.0*hv_CameraSize, 1.0*hv_CameraSize, 
      &hv_ObjectModel3DInit);
  GetCameraSetupParam(hv_CameraSetupModel, hv_CamIndex, "params", &hv_CamParams);
  GetCameraSetupParam(hv_CameraSetupModel, hv_CamIndex, "type", &hv_Type);
  //
  //Distinguish cases with/without tilt.
  if (0 != (hv_Type.TupleRegexpTest("tilt")))
  {
    get_cam_par_data(hv_CamParams, "tilt", &hv_Tilt);
    get_cam_par_data(hv_CamParams, "rot", &hv_Rot);
  }
  else
  {
    hv_Tilt = 0;
    hv_Rot = 0;
  }
  HomMat3dIdentity(&hv_HomMat3DIdentity);
  HomMat3dRotate(hv_HomMat3DIdentity, hv_Tilt.TupleRad(), (((hv_Rot.TupleRad()).TupleCos()).TupleConcat((hv_Rot.TupleRad()).TupleSin())).TupleConcat(0), 
      0, 0, 0, &hv_HomMat3DRotate);
  HomMat3dToPose(hv_HomMat3DRotate, &hv_SensorToLenseRotation);
  RigidTransObjectModel3d(hv_ObjectModel3DInit, hv_SensorToLenseRotation, &hv_ObjectModel3DInitTilted);
  //
  //Move the sensor to a convenient position behind the lens.
  GetObjectModel3dParams(hv_ObjectModel3DInitTilted, "bounding_box1", &hv_BoundingBox);
  AffineTransPoint3d(hv_HomMat3DRotate, 0.0, 0.0, 0.5*hv_CameraSize, &hv_PX, &hv_PY, 
      &hv_QZ);
  CreatePose(-hv_PX, -hv_PY, (-HTuple(hv_BoundingBox[5]))-(hv_CylinderLength/2.0), 
      0, 0, 0, "Rp+T", "gba", "point", &hv_PoseBack);
  RigidTransObjectModel3d(hv_ObjectModel3DInitTilted, hv_PoseBack, &hv_ObjectModel3DInitTiltedBack);
  //
  //Move to the position of the camera in world coordinates.
  GetCameraSetupParam(hv_CameraSetupModel, hv_CamIndex, "pose", &hv_CamPose);
  RigidTransObjectModel3d(hv_ObjectModel3DInitTiltedBack, hv_CamPose, &hv_OM3DSensor);
  RigidTransObjectModel3d(hv_ObjectModel3DLense, hv_CamPose, &hv_OM3DLense);
  (*hv_OM3DCam).Clear();
  (*hv_OM3DCam).Append(hv_OM3DSensor);
  (*hv_OM3DCam).Append(hv_OM3DLense);
  //
  //Clean up.
  ClearObjectModel3d(hv_ObjectModel3DInit);
  ClearObjectModel3d(hv_ObjectModel3DInitTilted);
  ClearObjectModel3d(hv_ObjectModel3DInitTiltedBack);
  ClearObjectModel3d(hv_ObjectModel3DLense);
  return;
}

// Chapter: Graphics / Output
// Short Description: Displays a continue button. 
void disp_continue_button (HTuple hv_WindowHandle)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_ContinueMessage, hv_Exception, hv_Row;
  HTuple  hv_Column, hv_Width, hv_Height, hv_Ascent, hv_Descent;
  HTuple  hv_TextWidth, hv_TextHeight;

  //This procedure displays a 'Continue' text button
  //in the lower right corner of the screen.
  //It uses the procedure disp_message.
  //
  //Input parameters:
  //WindowHandle: The window, where the text shall be displayed
  //
  //Use the continue message set in the global variable gTerminationButtonLabel.
  //If this variable is not defined, set a standard text instead.
  //global tuple gTerminationButtonLabel
  try
  {
    hv_ContinueMessage = ExpGetGlobalVar_gTerminationButtonLabel();
  }
  // catch (Exception) 
  catch (HException &HDevExpDefaultException)
  {
    HDevExpDefaultException.ToHTuple(&hv_Exception);
    hv_ContinueMessage = "Continue";
  }
  //Display the continue button
  GetWindowExtents(hv_WindowHandle, &hv_Row, &hv_Column, &hv_Width, &hv_Height);
  GetStringExtents(hv_WindowHandle, (" "+hv_ContinueMessage)+" ", &hv_Ascent, &hv_Descent, 
      &hv_TextWidth, &hv_TextHeight);
  disp_text_button(hv_WindowHandle, hv_ContinueMessage, "window", (hv_Height-hv_TextHeight)-22, 
      (hv_Width-hv_TextWidth)-12, "black", "#f28f26");
  return;
}

// Chapter: Graphics / Output
// Short Description: This procedure calls disp_object_model_3d and a fallback solution if there is no OpenGL Available. 
void disp_object_model_3d_safe (HTuple hv_WindowHandle, HTuple hv_ObjectModel3D, 
    HTuple hv_CamParam, HTuple hv_Pose, HTuple hv_GenParamName, HTuple hv_GenParamValue)
{

  // Local iconic variables
  HObject  ho_ModelContours;

  // Local control variables
  HTuple  hv_Exception, hv_Center, hv_CPLength;
  HTuple  hv_RowNotUsed, hv_ColumnNotUsed, hv_Width, hv_Height;
  HTuple  hv_CamParamValue, hv_CamWidth, hv_CamHeight, hv_Scale;
  HTuple  hv_NumModels, hv_PoseEstimated, hv_Poses, hv_HomMat3Ds;
  HTuple  hv_Sequence, hv_Indices;

  try
  {
    DispObjectModel3d(hv_WindowHandle, hv_ObjectModel3D, hv_CamParam, hv_Pose, hv_GenParamName, 
        hv_GenParamValue);
  }
  // catch (Exception) 
  catch (HException &HDevExpDefaultException)
  {
    HDevExpDefaultException.ToHTuple(&hv_Exception);
    //Read and check the parameter PoseIn for each object
    get_object_models_center(hv_ObjectModel3D, &hv_Center);
    hv_CPLength = hv_CamParam.TupleLength();
    GetWindowExtents(hv_WindowHandle, &hv_RowNotUsed, &hv_ColumnNotUsed, &hv_Width, 
        &hv_Height);
    if (0 != (hv_CPLength==0))
    {
      gen_cam_par_area_scan_division(0.06, 0, 8.5e-6, 8.5e-6, hv_Width/2, hv_Height/2, 
          hv_Width, hv_Height, &hv_CamParam);
    }
    else
    {
      get_cam_par_data(hv_CamParam, (((((HTuple("sx").Append("sy")).Append("cx")).Append("cy")).Append("image_width")).Append("image_height")), 
          &hv_CamParamValue);
      hv_CamWidth = HTuple(hv_CamParamValue[4]).TupleReal();
      hv_CamHeight = HTuple(hv_CamParamValue[5]).TupleReal();
      hv_Scale = ((hv_Width/hv_CamWidth).TupleConcat(hv_Height/hv_CamHeight)).TupleMin();
      set_cam_par_data(hv_CamParam, "sx", HTuple(hv_CamParamValue[0])/hv_Scale, &hv_CamParam);
      set_cam_par_data(hv_CamParam, "sy", HTuple(hv_CamParamValue[1])/hv_Scale, &hv_CamParam);
      set_cam_par_data(hv_CamParam, "cx", HTuple(hv_CamParamValue[2])*hv_Scale, &hv_CamParam);
      set_cam_par_data(hv_CamParam, "cy", HTuple(hv_CamParamValue[3])*hv_Scale, &hv_CamParam);
      set_cam_par_data(hv_CamParam, "image_width", (HTuple(hv_CamParamValue[4])*hv_Scale).TupleInt(), 
          &hv_CamParam);
      set_cam_par_data(hv_CamParam, "image_height", (HTuple(hv_CamParamValue[5])*hv_Scale).TupleInt(), 
          &hv_CamParam);
    }
    hv_NumModels = hv_ObjectModel3D.TupleLength();
    if (0 != ((hv_Pose.TupleLength())==0))
    {
      //If no pose was specified by the caller, automatically calculate
      //a pose that is appropriate for the visualization.
      //Set the initial model reference pose. The orientation is parallel
      //to the object coordinate system, the position is at the center
      //of gravity of all models.
      CreatePose(-HTuple(hv_Center[0]), -HTuple(hv_Center[1]), -HTuple(hv_Center[2]), 
          0, 0, 0, "Rp+T", "gba", "point", &hv_Pose);
      determine_optimum_pose_distance(hv_ObjectModel3D, hv_CamParam, 0.9, hv_Pose, 
          &hv_PoseEstimated);
      hv_Poses = HTuple();
      hv_HomMat3Ds = HTuple();
      hv_Sequence = HTuple::TupleGenSequence(0,(hv_NumModels*7)-1,1);
      hv_Poses = HTuple(hv_PoseEstimated[hv_Sequence%7]);
    }
    else if (0 != ((hv_Pose.TupleLength())==7))
    {
      hv_Poses = HTuple();
      hv_HomMat3Ds = HTuple();
      hv_Sequence = HTuple::TupleGenSequence(0,(hv_NumModels*7)-1,1);
      hv_Poses = HTuple(hv_Pose[hv_Sequence%7]);
    }
    else
    {
      if (0 != ((hv_Pose.TupleLength())!=((hv_ObjectModel3D.TupleLength())*7)))
      {
        //Error: Wrong number of values of input control parameter 'PoseIn'
        // stop(...); only in hdevelop
      }
      else
      {
        hv_Poses = hv_Pose;
      }
    }
    TupleFind(hv_GenParamName, "disp_background", &hv_Indices);
    if (0 != (hv_Indices>0))
    {
      if (0 != (HTuple(hv_GenParamValue[hv_Indices])==HTuple("true")))
      {
        //display background do not clear background
      }
      else
      {
        HDevWindowStack::SetActive(hv_WindowHandle);
        if (HDevWindowStack::IsOpen())
          ClearWindow(HDevWindowStack::GetActive());
      }
    }
    else
    {
      //No indication of  'disp_background' clear window
      HDevWindowStack::SetActive(hv_WindowHandle);
      if (HDevWindowStack::IsOpen())
        ClearWindow(HDevWindowStack::GetActive());
    }
    disp_object_model_no_opengl(&ho_ModelContours, hv_ObjectModel3D, hv_GenParamName, 
        hv_GenParamValue, hv_WindowHandle, hv_CamParam, hv_Poses);
  }
  return;
}

// Chapter: Calibration / Hand-Eye
// Short Description: Prepares the model to match and grasp in a stationary camera setup. 
void prepare_poses_and_rectification_data_stationary_cam (HTuple hv_ObjectHeight, 
    HTuple hv_RectifyImage, HTuple hv_HandEyeCalibData, HTuple *hv_Poses, HTuple *hv_RectificationData)
{

  // Local iconic variables
  HObject  ho_RegionGrid, ho_ContCircle, ho_ContCircleWorldPlane;
  HObject  ho_ImageArea, ho_RegionBorder, ho_RectificationMap;

  // Local control variables
  HTuple  hv_CamParam, hv_PlaneInCamPose0, hv_OrderOfTransform;
  HTuple  hv_OrderOfRotation, hv_ViewOfTransform, hv_PlaneInCamPose0Rot;
  HTuple  hv_HomMat3D, hv_Qx, hv_Qy, hv_CosAngleBetweenZAxis;
  HTuple  hv_SwitchZDirection, hv_PlaneInCamPose, hv_MatchingPlaneInPlanePose;
  HTuple  hv_MatchingPlaneInCamPose, hv_ScaleRectification;
  HTuple  hv_Width, hv_Height, hv_Rows, hv_Columns, hv_Row;
  HTuple  hv_Column, hv_Phi, hv_Radius1, hv_Radius2, hv_StartPhi;
  HTuple  hv_EndPhi, hv_PointOrder, hv_ClipRegion, hv_BorderRows;
  HTuple  hv_BorderColumns, hv_BorderX, hv_BorderY, hv_PoseOffset;
  HTuple  hv_WidthRect, hv_HeightRect, hv_ModelInPlanePose;
  HTuple  hv_PlaneInModelPose;

  //Prepare the needed poses to match and grasp, and compute the rectification
  //map in case rectification is set by the user.
  //
  read_message_tuple(hv_HandEyeCalibData, "CamParam", &hv_CamParam);
  read_message_tuple(hv_HandEyeCalibData, "PlaneInCamPose0", &hv_PlaneInCamPose0);
  //
  //Check input
  if (0 != (hv_ObjectHeight<0.0))
  {
    throw HException("The parameter ObjectHeight cannot be negative");
  }
  if (0 != (HTuple(hv_CamParam[0])==HTuple("line_scan")))
  {
    throw HException("Line-scan cameras are not supported");
  }
  //Keep track of the pose type used by the robot.
  GetPoseType(hv_PlaneInCamPose0, &hv_OrderOfTransform, &hv_OrderOfRotation, &hv_ViewOfTransform);
  //Convert to default pose type.
  ConvertPoseType(hv_PlaneInCamPose0, "Rp+T", "gba", "point", &hv_PlaneInCamPose0);
  //The z-axis of the plane should point away from the camera.
  hv_PlaneInCamPose0Rot = hv_PlaneInCamPose0;
  hv_PlaneInCamPose0Rot[HTuple::TupleGenSequence(0,2,1)] = ((HTuple(0).Append(0)).Append(0));
  PoseToHomMat3d(hv_PlaneInCamPose0Rot, &hv_HomMat3D);
  AffineTransPoint3d(hv_HomMat3D, 0, 0, 1, &hv_Qx, &hv_Qy, &hv_CosAngleBetweenZAxis);
  if (0 != (hv_CosAngleBetweenZAxis<0))
  {
    CreatePose(0, 0, 0, 180, 0, 0, "Rp+T", "gba", "point", &hv_SwitchZDirection);
    PoseCompose(hv_PlaneInCamPose0, hv_SwitchZDirection, &hv_PlaneInCamPose0);
  }
  //Align with the current image.
  hv_PlaneInCamPose = hv_PlaneInCamPose0;
  hv_PlaneInCamPose[5] = 0.0;
  //
  //Create the plane for matching.
  CreatePose(0, 0, -hv_ObjectHeight, 0, 0, 0, "Rp+T", "gba", "point", &hv_MatchingPlaneInPlanePose);
  PoseCompose(hv_PlaneInCamPose, hv_MatchingPlaneInPlanePose, &hv_MatchingPlaneInCamPose);
  //
  if (0 != (hv_RectifyImage==HTuple("false")))
  {
    hv_ScaleRectification = HTuple();
  }
  else if (0 != (hv_RectifyImage==HTuple("true")))
  {
    //Determine the scale such that the mapped image has at least the same
    //resolution as the current image.
    get_cam_par_data(hv_CamParam, "image_width", &hv_Width);
    get_cam_par_data(hv_CamParam, "image_height", &hv_Height);
    GenGridRegion(&ho_RegionGrid, 20, 20, "points", hv_Width, hv_Height);
    GetRegionPoints(ho_RegionGrid, &hv_Rows, &hv_Columns);
    GenCircleContourXld(&ho_ContCircle, hv_Rows, hv_Columns, HTuple(hv_Rows.TupleLength(),1.0), 
        0, 6.28318, "positive", 0.1);
    ContourToWorldPlaneXld(ho_ContCircle, &ho_ContCircleWorldPlane, hv_CamParam, 
        hv_MatchingPlaneInCamPose, "m");
    FitEllipseContourXld(ho_ContCircleWorldPlane, "fitzgibbon", -1, 0, 0, 200, 3, 
        2, &hv_Row, &hv_Column, &hv_Phi, &hv_Radius1, &hv_Radius2, &hv_StartPhi, 
        &hv_EndPhi, &hv_PointOrder);
    hv_ScaleRectification = hv_Radius2.TupleMin();
    //
    //Rectify the current image and create the shape model.
    //
    //The image dimensions should cover the entire original field of view
    //in the current rectification.
    //Look at border of the current image in the world plane.
    GetSystem("clip_region", &hv_ClipRegion);
    SetSystem("clip_region", "false");
    GenRectangle1(&ho_ImageArea, 0, 0, hv_Height-1, hv_Width-1);
    Boundary(ho_ImageArea, &ho_RegionBorder, "outer");
    SetSystem("clip_region", hv_ClipRegion);
    GetRegionPoints(ho_RegionBorder, &hv_BorderRows, &hv_BorderColumns);
    ImagePointsToWorldPlane(hv_CamParam, hv_MatchingPlaneInCamPose, hv_BorderRows, 
        hv_BorderColumns, "m", &hv_BorderX, &hv_BorderY);
    //Adapt parameters.
    CreatePose(hv_BorderX.TupleMin(), hv_BorderY.TupleMin(), 0, 0, 0, 0, "Rp+T", 
        "gba", "point", &hv_PoseOffset);
    PoseCompose(hv_MatchingPlaneInCamPose, hv_PoseOffset, &hv_MatchingPlaneInCamPose);
    hv_WidthRect = ((((hv_BorderX.TupleMax())-(hv_BorderX.TupleMin()))/hv_ScaleRectification)+0.5).TupleInt();
    hv_HeightRect = ((((hv_BorderY.TupleMax())-(hv_BorderY.TupleMin()))/hv_ScaleRectification)+0.5).TupleInt();
    //
    //Create a map for repeated use.
    GenImageToWorldPlaneMap(&ho_RectificationMap, hv_CamParam, hv_MatchingPlaneInCamPose, 
        hv_Width, hv_Height, hv_WidthRect, hv_HeightRect, hv_ScaleRectification, 
        "bilinear");
  }
  else
  {
    throw HException("Please set the parameter RectifyImage correctly");
  }
  //Convert to output pose type.
  ConvertPoseType(hv_PlaneInCamPose, hv_OrderOfTransform, hv_OrderOfRotation, hv_ViewOfTransform, 
      &hv_PlaneInCamPose);
  ConvertPoseType(hv_MatchingPlaneInCamPose, hv_OrderOfTransform, hv_OrderOfRotation, 
      hv_ViewOfTransform, &hv_MatchingPlaneInCamPose);
  //
  CreatePose(0, 0, hv_ObjectHeight, 180, 0, 0, "Rp+T", "gba", "point", &hv_ModelInPlanePose);
  //Remember the transformation.
  PoseInvert(hv_ModelInPlanePose, &hv_PlaneInModelPose);
  //
  //Create message for Poses.
  CreateMessage(&(*hv_Poses));
  SetMessageTuple((*hv_Poses), "PlaneInModelPose", hv_PlaneInModelPose);
  SetMessageTuple((*hv_Poses), "MatchingPlaneInCamPose", hv_MatchingPlaneInCamPose);
  SetMessageTuple((*hv_Poses), "PlaneInCamPose", hv_PlaneInCamPose);
  //
  //Create message for rectification data.
  CreateMessage(&(*hv_RectificationData));
  SetMessageTuple((*hv_RectificationData), "RectifyImage", hv_RectifyImage);
  if (0 != (hv_RectifyImage==HTuple("true")))
  {
    SetMessageTuple((*hv_RectificationData), "ScaleRectification", hv_ScaleRectification);
    SetMessageObj(ho_RectificationMap, (*hv_RectificationData), "RectificationMap");
  }
  return;
}

// Chapter: Graphics / Output
// Short Description: Can replace disp_object_model_3d if there is no OpenGL available. 
void disp_object_model_no_opengl (HObject *ho_ModelContours, HTuple hv_ObjectModel3DID, 
    HTuple hv_GenParamName, HTuple hv_GenParamValue, HTuple hv_WindowHandleBuffer, 
    HTuple hv_CamParam, HTuple hv_PosesOut)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_Idx, hv_CustomParamName, hv_CustomParamValue;
  HTuple  hv_Font, hv_IndicesDispBackGround, hv_Indices, hv_ImageWidth;
  HTuple  hv_HasPolygons, hv_HasTri, hv_HasPoints, hv_HasLines;
  HTuple  hv_NumPoints, hv_IsPrimitive, hv_Center, hv_Diameter;
  HTuple  hv_OpenGlHiddenSurface, hv_CenterX, hv_CenterY;
  HTuple  hv_CenterZ, hv_PosObjectsZ, hv_I, hv_Pose, hv_HomMat3DObj;
  HTuple  hv_PosObjCenterX, hv_PosObjCenterY, hv_PosObjCenterZ;
  HTuple  hv_PosObjectsX, hv_PosObjectsY, hv_Color, hv_Indices1;
  HTuple  hv_Indices2, hv_J, hv_Indices3, hv_HomMat3D, hv_SampledObjectModel3D;
  HTuple  hv_X, hv_Y, hv_Z, hv_HomMat3D1, hv_Qx, hv_Qy, hv_Qz;
  HTuple  hv_Row, hv_Column, hv_ObjectModel3DConvexHull, hv_Exception;

  //This procedure allows to use project_object_model_3d to simulate a disp_object_model_3d
  //call for small objects. Large objects are sampled down to display.
  hv_Idx = hv_GenParamName.TupleFind("point_size");
  if (0 != (HTuple(hv_Idx.TupleLength()).TupleAnd(hv_Idx!=-1)))
  {
    hv_CustomParamName = "point_size";
    hv_CustomParamValue = HTuple(hv_GenParamValue[hv_Idx]);
    if (0 != (hv_CustomParamValue==1))
    {
      hv_CustomParamValue = 0;
    }
  }
  else
  {
    hv_CustomParamName = HTuple();
    hv_CustomParamValue = HTuple();
  }
  GetFont(hv_WindowHandleBuffer, &hv_Font);
  TupleFind(hv_GenParamName, "disp_background", &hv_IndicesDispBackGround);
  if (0 != (hv_IndicesDispBackGround!=-1))
  {
    TupleFind(HTuple(hv_GenParamName[hv_IndicesDispBackGround]), "false", &hv_Indices);
    if (0 != (hv_Indices!=-1))
    {
      ClearWindow(hv_WindowHandleBuffer);
    }
  }
  set_display_font(hv_WindowHandleBuffer, 11, "mono", "false", "false");
  get_cam_par_data(hv_CamParam, "image_width", &hv_ImageWidth);
  disp_message(hv_WindowHandleBuffer, "OpenGL missing!", "image", 5, hv_ImageWidth-130, 
      "red", "false");
  SetFont(hv_WindowHandleBuffer, hv_Font);
  GetObjectModel3dParams(hv_ObjectModel3DID, "has_polygons", &hv_HasPolygons);
  GetObjectModel3dParams(hv_ObjectModel3DID, "has_triangles", &hv_HasTri);
  GetObjectModel3dParams(hv_ObjectModel3DID, "has_points", &hv_HasPoints);
  GetObjectModel3dParams(hv_ObjectModel3DID, "has_lines", &hv_HasLines);
  GetObjectModel3dParams(hv_ObjectModel3DID, "num_points", &hv_NumPoints);
  GetObjectModel3dParams(hv_ObjectModel3DID, "has_primitive_data", &hv_IsPrimitive);
  GetObjectModel3dParams(hv_ObjectModel3DID, "center", &hv_Center);
  GetObjectModel3dParams(hv_ObjectModel3DID, "diameter", &hv_Diameter);
  GetSystem("opengl_hidden_surface_removal_enable", &hv_OpenGlHiddenSurface);
  SetSystem("opengl_hidden_surface_removal_enable", "false");
  //Sort the objects by inverse z
  hv_CenterX = ((const HTuple&)hv_Center)[HTuple::TupleGenSequence(0,(hv_Center.TupleLength())-1,3)];
  hv_CenterY = ((const HTuple&)hv_Center)[HTuple::TupleGenSequence(0,(hv_Center.TupleLength())-1,3)+1];
  hv_CenterZ = ((const HTuple&)hv_Center)[HTuple::TupleGenSequence(0,(hv_Center.TupleLength())-1,3)+2];
  hv_PosObjectsZ = HTuple();
  if (0 != ((hv_PosesOut.TupleLength())>7))
  {
    {
    HTuple end_val41 = (hv_ObjectModel3DID.TupleLength())-1;
    HTuple step_val41 = 1;
    for (hv_I=0; hv_I.Continue(end_val41, step_val41); hv_I += step_val41)
    {
      hv_Pose = hv_PosesOut.TupleSelectRange(hv_I*7,(hv_I*7)+6);
      PoseToHomMat3d(hv_Pose, &hv_HomMat3DObj);
      AffineTransPoint3d(hv_HomMat3DObj, HTuple(hv_CenterX[hv_I]), HTuple(hv_CenterY[hv_I]), 
          HTuple(hv_CenterZ[hv_I]), &hv_PosObjCenterX, &hv_PosObjCenterY, &hv_PosObjCenterZ);
      hv_PosObjectsZ = hv_PosObjectsZ.TupleConcat(hv_PosObjCenterZ);
    }
    }
  }
  else
  {
    hv_Pose = hv_PosesOut.TupleSelectRange(0,6);
    PoseToHomMat3d(hv_Pose, &hv_HomMat3DObj);
    AffineTransPoint3d(hv_HomMat3DObj, hv_CenterX, hv_CenterY, hv_CenterZ, &hv_PosObjectsX, 
        &hv_PosObjectsY, &hv_PosObjectsZ);
  }
  hv_Idx = (hv_PosObjectsZ.TupleSortIndex()).TupleInverse();
  hv_Color = "white";
  SetColor(hv_WindowHandleBuffer, hv_Color);
  if (0 != ((hv_GenParamName.TupleLength())>0))
  {
    TupleFind(hv_GenParamName, "colored", &hv_Indices1);
    TupleFind(hv_GenParamName, "color", &hv_Indices2);
    if (0 != (HTuple(hv_Indices1[0])!=-1))
    {
      if (0 != (HTuple(hv_GenParamValue[HTuple(hv_Indices1[0])])==3))
      {
        hv_Color.Clear();
        hv_Color[0] = "red";
        hv_Color[1] = "green";
        hv_Color[2] = "blue";
      }
      else if (0 != (HTuple(hv_GenParamValue[HTuple(hv_Indices1[0])])==6))
      {
        hv_Color.Clear();
        hv_Color[0] = "red";
        hv_Color[1] = "green";
        hv_Color[2] = "blue";
        hv_Color[3] = "cyan";
        hv_Color[4] = "magenta";
        hv_Color[5] = "yellow";
      }
      else if (0 != (HTuple(hv_GenParamValue[HTuple(hv_Indices1[0])])==12))
      {
        hv_Color.Clear();
        hv_Color[0] = "red";
        hv_Color[1] = "green";
        hv_Color[2] = "blue";
        hv_Color[3] = "cyan";
        hv_Color[4] = "magenta";
        hv_Color[5] = "yellow";
        hv_Color[6] = "coral";
        hv_Color[7] = "slate blue";
        hv_Color[8] = "spring green";
        hv_Color[9] = "orange red";
        hv_Color[10] = "pink";
        hv_Color[11] = "gold";
      }
    }
    else if (0 != (HTuple(hv_Indices2[0])!=-1))
    {
      hv_Color = HTuple(hv_GenParamValue[HTuple(hv_Indices2[0])]);
    }
  }
  {
  HTuple end_val70 = (hv_ObjectModel3DID.TupleLength())-1;
  HTuple step_val70 = 1;
  for (hv_J=0; hv_J.Continue(end_val70, step_val70); hv_J += step_val70)
  {
    hv_I = HTuple(hv_Idx[hv_J]);
    if (0 != (HTuple(HTuple(HTuple(HTuple(hv_HasPolygons[hv_I])==HTuple("true")).TupleOr(HTuple(hv_HasTri[hv_I])==HTuple("true"))).TupleOr(HTuple(hv_HasPoints[hv_I])==HTuple("true"))).TupleOr(HTuple(hv_HasLines[hv_I])==HTuple("true"))))
    {
      if (0 != ((hv_GenParamName.TupleLength())>0))
      {
        TupleFind(hv_GenParamName, "color_"+hv_I, &hv_Indices3);
        if (0 != (HTuple(hv_Indices3[0])!=-1))
        {
          SetColor(hv_WindowHandleBuffer, HTuple(hv_GenParamValue[HTuple(hv_Indices3[0])]));
        }
        else
        {
          SetColor(hv_WindowHandleBuffer, HTuple(hv_Color[hv_I%(hv_Color.TupleLength())]));
        }
      }
      if (0 != ((hv_PosesOut.TupleLength())>=((hv_I*7)+6)))
      {
        hv_Pose = hv_PosesOut.TupleSelectRange(hv_I*7,(hv_I*7)+6);
      }
      else
      {
        hv_Pose = hv_PosesOut.TupleSelectRange(0,6);
      }
      if (0 != (HTuple(hv_NumPoints[hv_I])<10000))
      {
        ProjectObjectModel3d(&(*ho_ModelContours), HTuple(hv_ObjectModel3DID[hv_I]), 
            hv_CamParam, hv_Pose, hv_CustomParamName, hv_CustomParamValue);
        DispObj((*ho_ModelContours), hv_WindowHandleBuffer);
      }
      else
      {
        PoseToHomMat3d(hv_Pose, &hv_HomMat3D);
        SampleObjectModel3d(HTuple(hv_ObjectModel3DID[hv_I]), "fast", 0.01*HTuple(hv_Diameter[hv_I]), 
            HTuple(), HTuple(), &hv_SampledObjectModel3D);
        ProjectObjectModel3d(&(*ho_ModelContours), hv_SampledObjectModel3D, hv_CamParam, 
            hv_Pose, "point_size", 1);
        GetObjectModel3dParams(hv_SampledObjectModel3D, "point_coord_x", &hv_X);
        GetObjectModel3dParams(hv_SampledObjectModel3D, "point_coord_y", &hv_Y);
        GetObjectModel3dParams(hv_SampledObjectModel3D, "point_coord_z", &hv_Z);
        PoseToHomMat3d(hv_Pose, &hv_HomMat3D1);
        AffineTransPoint3d(hv_HomMat3D1, hv_X, hv_Y, hv_Z, &hv_Qx, &hv_Qy, &hv_Qz);
        Project3dPoint(hv_Qx, hv_Qy, hv_Qz, hv_CamParam, &hv_Row, &hv_Column);
        DispObj((*ho_ModelContours), hv_WindowHandleBuffer);
        ClearObjectModel3d(hv_SampledObjectModel3D);
      }
    }
    else
    {
      if (0 != ((hv_GenParamName.TupleLength())>0))
      {
        TupleFind(hv_GenParamName, "color_"+hv_I, &hv_Indices3);
        if (0 != (HTuple(hv_Indices3[0])!=-1))
        {
          SetColor(hv_WindowHandleBuffer, HTuple(hv_GenParamValue[HTuple(hv_Indices3[0])]));
        }
        else
        {
          SetColor(hv_WindowHandleBuffer, HTuple(hv_Color[hv_I%(hv_Color.TupleLength())]));
        }
      }
      if (0 != ((hv_PosesOut.TupleLength())>=((hv_I*7)+6)))
      {
        hv_Pose = hv_PosesOut.TupleSelectRange(hv_I*7,(hv_I*7)+6);
      }
      else
      {
        hv_Pose = hv_PosesOut.TupleSelectRange(0,6);
      }
      if (0 != (HTuple(hv_IsPrimitive[hv_I])==HTuple("true")))
      {
        try
        {
          ConvexHullObjectModel3d(HTuple(hv_ObjectModel3DID[hv_I]), &hv_ObjectModel3DConvexHull);
          if (0 != (HTuple(hv_NumPoints[hv_I])<10000))
          {
            ProjectObjectModel3d(&(*ho_ModelContours), hv_ObjectModel3DConvexHull, 
                hv_CamParam, hv_Pose, hv_CustomParamName, hv_CustomParamValue);
            DispObj((*ho_ModelContours), hv_WindowHandleBuffer);
          }
          else
          {
            PoseToHomMat3d(hv_Pose, &hv_HomMat3D);
            SampleObjectModel3d(hv_ObjectModel3DConvexHull, "fast", 0.01*HTuple(hv_Diameter[hv_I]), 
                HTuple(), HTuple(), &hv_SampledObjectModel3D);
            ProjectObjectModel3d(&(*ho_ModelContours), hv_SampledObjectModel3D, hv_CamParam, 
                hv_Pose, "point_size", 1);
            DispObj((*ho_ModelContours), hv_WindowHandleBuffer);
            ClearObjectModel3d(hv_SampledObjectModel3D);
          }
          ClearObjectModel3d(hv_ObjectModel3DConvexHull);
        }
        // catch (Exception) 
        catch (HException &HDevExpDefaultException)
        {
          HDevExpDefaultException.ToHTuple(&hv_Exception);
        }
      }
    }
  }
  }
  SetSystem("opengl_hidden_surface_removal_enable", hv_OpenGlHiddenSurface);
  return;
}

// Chapter: System / Multithreading
void read_message_tuple (HTuple hv_MessageHandle, HTuple hv_Key, HTuple *hv_TupleData)
{

  // Local control variables
  HTuple  hv_Exception;

  try
  {
    GetMessageTuple(hv_MessageHandle, hv_Key, &(*hv_TupleData));
  }
  // catch (Exception) 
  catch (HException &HDevExpDefaultException)
  {
    HDevExpDefaultException.ToHTuple(&hv_Exception);
    throw HException((("The key "+hv_Key)+" is missing from the message ")+hv_MessageHandle);
  }
  return;
}

// Chapter: System / Multithreading
void read_message_obj (HObject *ho_ObjectData, HTuple hv_MessageHandle, HTuple hv_Key)
{

  // Local control variables
  HTuple  hv_Exception;

  try
  {
    GetMessageObj(&(*ho_ObjectData), hv_MessageHandle, hv_Key);
  }
  // catch (Exception) 
  catch (HException &HDevExpDefaultException)
  {
    HDevExpDefaultException.ToHTuple(&hv_Exception);
    throw HException((("The key "+hv_Key)+" is missing from the message ")+hv_MessageHandle);
  }
  return;
}

// Chapter: Calibration / Hand-Eye
// Short Description: Prepare the input image for matching and compute the needed pose. 
void rectify_image_and_compute_matching_plane_moving_cam (HObject ho_Image, HObject *ho_ImageRectified, 
    HTuple hv_ToolInBasePose, HTuple hv_HandEyeCalibData, HTuple hv_Poses, HTuple hv_RectificationData)
{

  // Local iconic variables
  HObject  ho_ImageArea, ho_RegionBorder;

  // Local control variables
  HTuple  hv_RectifyImage, hv_OrderOfTransform;
  HTuple  hv_OrderOfRotation, hv_ViewOfTransform, hv_ToolInCamPose;
  HTuple  hv_MatchingPlaneInBasePose, hv_BaseInToolPose, hv_BaseInCamPose;
  HTuple  hv_MatchingPlaneInCamPose, hv_MatchingPlaneRectifiedPartInCamPose;
  HTuple  hv_CamParam, hv_Width, hv_Height, hv_ClipRegion;
  HTuple  hv_BorderRows, hv_BorderColumns, hv_BorderX, hv_BorderY;
  HTuple  hv_MatchingPlaneRectifiedPartInMatchingPlanePose;
  HTuple  hv_ScaleRectification, hv_WidthRect, hv_HeightRect;

  //This procedure finds the pose of the matching part on the plane
  //in the camera coordinate system. Rectification is applied if it
  //is set by the user.
  //
  read_message_tuple(hv_HandEyeCalibData, "CamParam", &hv_CamParam);
  read_message_tuple(hv_HandEyeCalibData, "ToolInCamPose", &hv_ToolInCamPose);
  read_message_tuple(hv_RectificationData, "RectifyImage", &hv_RectifyImage);
  if (0 != (HTuple(hv_RectifyImage==HTuple("only_rectify")).TupleOr(hv_RectifyImage==HTuple("align_and_rectify"))))
  {
    read_message_tuple(hv_RectificationData, "ScaleRectification", &hv_ScaleRectification);
  }
  read_message_tuple(hv_Poses, "MatchingPlaneInBasePose", &hv_MatchingPlaneInBasePose);
  //
  //Keep track of the pose type used by the robot.
  GetPoseType(hv_ToolInBasePose, &hv_OrderOfTransform, &hv_OrderOfRotation, &hv_ViewOfTransform);
  //Convert to default pose type.
  ConvertPoseType(hv_ToolInBasePose, "Rp+T", "gba", "point", &hv_ToolInBasePose);
  ConvertPoseType(hv_ToolInCamPose, "Rp+T", "gba", "point", &hv_ToolInCamPose);
  ConvertPoseType(hv_MatchingPlaneInBasePose, "Rp+T", "gba", "point", &hv_MatchingPlaneInBasePose);
  //
  PoseInvert(hv_ToolInBasePose, &hv_BaseInToolPose);
  PoseCompose(hv_ToolInCamPose, hv_BaseInToolPose, &hv_BaseInCamPose);
  PoseCompose(hv_BaseInCamPose, hv_MatchingPlaneInBasePose, &hv_MatchingPlaneInCamPose);
  //
  if (0 != (hv_RectifyImage==HTuple("no_rectification")))
  {
    hv_MatchingPlaneRectifiedPartInCamPose = hv_MatchingPlaneInCamPose;
    CopyObj(ho_Image, &(*ho_ImageRectified), 1, 1);
  }
  else if (0 != (HTuple(hv_RectifyImage==HTuple("only_rectify")).TupleOr(hv_RectifyImage==HTuple("align_and_rectify"))))
  {
    if (0 != (hv_RectifyImage==HTuple("only_rectify")))
    {
      hv_MatchingPlaneInCamPose[5] = 0.0;
    }
    //The image dimensions should cover the entire original
    //field of view in the current rectification. Look at the
    //border of the current image in the world plane.
    get_cam_par_data(hv_CamParam, "image_width", &hv_Width);
    get_cam_par_data(hv_CamParam, "image_height", &hv_Height);
    GetSystem("clip_region", &hv_ClipRegion);
    SetSystem("clip_region", "false");
    GenRectangle1(&ho_ImageArea, 0, 0, hv_Height-1, hv_Width-1);
    Boundary(ho_ImageArea, &ho_RegionBorder, "outer");
    SetSystem("clip_region", hv_ClipRegion);
    GetRegionPoints(ho_RegionBorder, &hv_BorderRows, &hv_BorderColumns);
    ImagePointsToWorldPlane(hv_CamParam, hv_MatchingPlaneInCamPose, hv_BorderRows, 
        hv_BorderColumns, "m", &hv_BorderX, &hv_BorderY);
    //Adapt parameters.
    CreatePose(hv_BorderX.TupleMin(), hv_BorderY.TupleMin(), 0, 0, 0, 0, "Rp+T", 
        "gba", "point", &hv_MatchingPlaneRectifiedPartInMatchingPlanePose);
    PoseCompose(hv_MatchingPlaneInCamPose, hv_MatchingPlaneRectifiedPartInMatchingPlanePose, 
        &hv_MatchingPlaneRectifiedPartInCamPose);
    hv_WidthRect = ((((hv_BorderX.TupleMax())-(hv_BorderX.TupleMin()))/hv_ScaleRectification)+0.5).TupleInt();
    hv_HeightRect = ((((hv_BorderY.TupleMax())-(hv_BorderY.TupleMin()))/hv_ScaleRectification)+0.5).TupleInt();
    //
    ImageToWorldPlane(ho_Image, &(*ho_ImageRectified), hv_CamParam, hv_MatchingPlaneRectifiedPartInCamPose, 
        hv_WidthRect, hv_HeightRect, hv_ScaleRectification, "bilinear");
  }
  else
  {
    throw HException("Please set the parameter RectifyImage correctly");
  }
  ConvertPoseType(hv_MatchingPlaneRectifiedPartInCamPose, hv_OrderOfTransform, hv_OrderOfRotation, 
      hv_ViewOfTransform, &hv_MatchingPlaneRectifiedPartInCamPose);
  SetMessageTuple(hv_RectificationData, "MatchingPlaneRectifiedPartInCamPose", hv_MatchingPlaneRectifiedPartInCamPose);
  return;
}

// Chapter: Graphics / 3D Scene
// Short Description: Visualize the poses that were used to calculate the touching point, and the result. 
void visualize_calibrated_touching_point (HTuple hv_RobotTouchingPointInToolCoordinates, 
    HTupleVector/*{eTupleVector,Dim=1}*/ hvec_ToolInBasePosesTouchingPoint, HTuple hv_WindowHandle)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_OM3DToolTouchingPoint, hv_Instructions;
  HTuple  hv_PoseIn, hv_GenParamName, hv_GenParamValue, hv_Title;
  HTuple  hv_NumOM3D, hv_Label, hv_PoseOut;

  //
  //Create 3D object models.
  gen_tool_to_touching_point_object_model_3d(hvec_ToolInBasePosesTouchingPoint, hv_RobotTouchingPointInToolCoordinates, 
      &hv_OM3DToolTouchingPoint);
  //
  //Prepare parameters for visualize_object_model_3d.
  //Instructions.
  hv_Instructions[0] = "Rotate: Left button";
  hv_Instructions[1] = "Zoom:   Shift + left button";
  hv_Instructions[2] = "Move:   Ctrl  + left button";
  //3D visualization pose.
  CreatePose(0.326, 0.016, 3.137, 83.33, 341.96, 99.32, "Rp+T", "gba", "point", &hv_PoseIn);
  //
  hv_GenParamName.Clear();
  hv_GenParamName[0] = "color_0";
  hv_GenParamName[1] = "color_1";
  hv_GenParamName[2] = "color_2";
  hv_GenParamName[3] = "color_3";
  hv_GenParamName[4] = "color_4";
  hv_GenParamName[5] = "color_5";
  hv_GenParamName[6] = "color_6";
  hv_GenParamName[7] = "color_7";
  hv_GenParamName[8] = "color_8";
  hv_GenParamName[9] = "color_9";
  hv_GenParamName[10] = "color_10";
  hv_GenParamName[11] = "color_11";
  hv_GenParamValue.Clear();
  hv_GenParamValue[0] = "red";
  hv_GenParamValue[1] = "green";
  hv_GenParamValue[2] = "blue";
  hv_GenParamValue[3] = "magenta";
  hv_GenParamValue[4] = "red";
  hv_GenParamValue[5] = "green";
  hv_GenParamValue[6] = "blue";
  hv_GenParamValue[7] = "magenta";
  hv_GenParamValue[8] = "red";
  hv_GenParamValue[9] = "green";
  hv_GenParamValue[10] = "blue";
  hv_GenParamValue[11] = "magenta";
  //
  hv_Title = "Visualization of the read poses. The magenta lines connect the";
  hv_Title[1] = "tool coordinate system with the touching point. They intersect";
  hv_Title[2] = "in the approached point in the plane. Calculated touching point";
  hv_Title[3] = "coordinates with respect to the robot's tool: ";
  hv_Title[4] = ((((("X: "+((HTuple(hv_RobotTouchingPointInToolCoordinates[0])*1000).TupleString(".2f")))+HTuple(" mm, Y: "))+((HTuple(hv_RobotTouchingPointInToolCoordinates[1])*1000).TupleString(".2f")))+HTuple(" mm, Z: "))+((HTuple(hv_RobotTouchingPointInToolCoordinates[2])*1000).TupleString(".2f")))+" mm";
  //Labels for the visualized 3D object models.
  hv_NumOM3D = hv_OM3DToolTouchingPoint.TupleLength();
  TupleGenConst(hv_NumOM3D, "", &hv_Label);
  hv_Label[2] = "ToolInBasePosesTouchingPoint 1";
  hv_Label[6] = "ToolInBasePosesTouchingPoint 2";
  hv_Label[10] = "ToolInBasePosesTouchingPoint 3";
  //
  visualize_object_model_3d(hv_WindowHandle, hv_OM3DToolTouchingPoint, HTuple(), 
      hv_PoseIn, hv_GenParamName, hv_GenParamValue, hv_Title, hv_Label, hv_Instructions, 
      &hv_PoseOut);
  //
  //Clean up.
  ClearObjectModel3d(hv_OM3DToolTouchingPoint);
  return;
}

// Chapter: 3D Reconstruction / Multi-View Stereo
// Short Description: Estimate a bounding box for 3D reconstruction based on a stereo setup. 
void estimate_bounding_box_3d_reconstruction (HTuple hv_StereoModelID, HTuple hv_ObjectHeight, 
    HTuple *hv_BoundingBox)
{

  // Local iconic variables
  HObject  ho_PlaneConeIntersections, ho_ContourFrom;
  HObject  ho_ContourTo, ho_RectangleFrom, ho_RectangleTo;
  HObject  ho_ContoursIntersection, ho_PlaneConeIntersectionUnion;
  HObject  ho_ObjectSelected;

  // Local control variables
  HTuple  hv_CameraSetupModelID, hv_ReferenceCamera;
  HTuple  hv_From, hv_To, hv_NumCameras, hv_ObjectModel3DCone;
  HTuple  hv_DistanceCameras, hv_CameraIndex, hv_CamPose;
  HTuple  hv_DistanceCamera, hv_ConeLength, hv_Type, hv_ObjectModel3D;
  HTuple  hv_Index1, hv_ObjectModel3DIntersectionFrom, hv_ObjectModel3DIntersectionTo;
  HTuple  hv_XFrom, hv_YFrom, hv_XTo, hv_YTo, hv_Row, hv_Column;
  HTuple  hv_Phi, hv_Length1, hv_Length2, hv_Number, hv_Index2;
  HTuple  hv_RowContour, hv_ColumnContour;

  //The goal of this procedure is to estimate bounding box parameters
  //for 3D reconstruction. This is done by intersecting the
  //cones of sight of the cameras with a plane defined by the pose
  //of the reference calibration plate.
  //
  if (0 != (hv_ObjectHeight==0))
  {
    throw HException("Object height must not be zero.");
  }
  //Check whether the coordinate system has been moved by setting a pose
  //with the parameter 'coord_transf_pose' in set_camera_setup_param.
  //If this is not the case, the origin is still in one of the cameras.
  //However, this procedures needs the origin to be in a calibration plate.
  GetStereoModelParam(hv_StereoModelID, "camera_setup_model", &hv_CameraSetupModelID);
  GetCameraSetupParam(hv_CameraSetupModelID, "general", "reference_camera", &hv_ReferenceCamera);
  if (0 != (hv_ReferenceCamera!=-1))
  {
    throw HException("Please set the 'coord_transf_pose' to the pose of an calibration plate that lies horizontally in the image using the get_calib_data and set_camera_setup_param.");
  }
  //Check whether the image pairs have been set.
  GetStereoModelImagePairs(hv_StereoModelID, &hv_From, &hv_To);
  if (0 != (HTuple((hv_From.TupleLength())==0).TupleOr((hv_To.TupleLength())==0)))
  {
    throw HException("Please define the image pairs first with 'get_stereo_model_image_pairs.'");
  }
  //
  //First, we generate 3D object models that represent the cones of sight of the cameras,
  //like in the procedure gen_camera_setup_object_model_3d.
  GetCameraSetupParam(hv_CameraSetupModelID, "general", "num_cameras", &hv_NumCameras);
  hv_ObjectModel3DCone = HTuple();
  hv_DistanceCameras = HTuple();
  {
  HTuple end_val28 = hv_NumCameras-1;
  HTuple step_val28 = 1;
  for (hv_CameraIndex=0; hv_CameraIndex.Continue(end_val28, step_val28); hv_CameraIndex += step_val28)
  {
    GetCameraSetupParam(hv_CameraSetupModelID, hv_CameraIndex, "pose", &hv_CamPose);
    hv_DistanceCamera = (((HTuple(hv_CamPose[0])*HTuple(hv_CamPose[0]))+(HTuple(hv_CamPose[1])*HTuple(hv_CamPose[1])))+(HTuple(hv_CamPose[2])*HTuple(hv_CamPose[2]))).TupleSqrt();
    hv_DistanceCameras = hv_DistanceCameras.TupleConcat(hv_DistanceCamera);
    hv_ConeLength = hv_DistanceCamera*2.0;
    //Distinguish cases with/without projection center.
    GetCameraSetupParam(hv_CameraSetupModelID, hv_CameraIndex, "type", &hv_Type);
    if (0 != (hv_Type.TupleRegexpTest("telecentric")))
    {
      gen_cone_telecentric_object_model_3d(hv_CameraSetupModelID, hv_CameraIndex, 
          hv_ConeLength, &hv_ObjectModel3D);
    }
    else
    {
      gen_cone_perspective_object_model_3d(hv_CameraSetupModelID, hv_CameraIndex, 
          hv_ConeLength, &hv_ObjectModel3D);
    }
    hv_ObjectModel3DCone = hv_ObjectModel3DCone.TupleConcat(hv_ObjectModel3D);
  }
  }
  //
  //Then, we intersect these cones of sight with a plane that lies horizontally
  //in the origin of the stereo setup. We do this simultaneously for the
  //previously defined image pairs.
  GenEmptyObj(&ho_PlaneConeIntersections);
  {
  HTuple end_val47 = (hv_From.TupleLength())-1;
  HTuple step_val47 = 1;
  for (hv_Index1=0; hv_Index1.Continue(end_val47, step_val47); hv_Index1 += step_val47)
  {
    IntersectPlaneObjectModel3d(HTuple(hv_ObjectModel3DCone[HTuple(hv_From[hv_Index1])]), 
        ((((((HTuple(0).Append(0)).Append(0)).Append(0)).Append(0)).Append(0)).Append(0)), 
        &hv_ObjectModel3DIntersectionFrom);
    IntersectPlaneObjectModel3d(HTuple(hv_ObjectModel3DCone[HTuple(hv_To[hv_Index1])]), 
        ((((((HTuple(0).Append(0)).Append(0)).Append(0)).Append(0)).Append(0)).Append(0)), 
        &hv_ObjectModel3DIntersectionTo);
    //
    //Get the coordinates of the 3D object models that represent the intersection.
    GetObjectModel3dParams(hv_ObjectModel3DIntersectionFrom, "point_coord_x", &hv_XFrom);
    GetObjectModel3dParams(hv_ObjectModel3DIntersectionFrom, "point_coord_y", &hv_YFrom);
    GetObjectModel3dParams(hv_ObjectModel3DIntersectionTo, "point_coord_x", &hv_XTo);
    GetObjectModel3dParams(hv_ObjectModel3DIntersectionTo, "point_coord_y", &hv_YTo);
    //
    //The, we want to intersect the intersections of the image pair. We do this in 2D using XLDs.
    //Generate the XLD of the 'From' intersection.
    GenContourPolygonXld(&ho_ContourFrom, hv_XFrom, hv_YFrom);
    //Generate the XLD of the 'To' intersection.
    GenContourPolygonXld(&ho_ContourTo, hv_XTo, hv_YTo);
    //
    //The order of the coordinates from get_object_model_3d_params might not be ideal.
    //Thus, we compute the smallest rectangle around the created XLD.
    SmallestRectangle2Xld(ho_ContourFrom, &hv_Row, &hv_Column, &hv_Phi, &hv_Length1, 
        &hv_Length2);
    GenRectangle2ContourXld(&ho_RectangleFrom, hv_Row, hv_Column, hv_Phi, hv_Length1, 
        hv_Length2);
    SmallestRectangle2Xld(ho_ContourTo, &hv_Row, &hv_Column, &hv_Phi, &hv_Length1, 
        &hv_Length2);
    GenRectangle2ContourXld(&ho_RectangleTo, hv_Row, hv_Column, hv_Phi, hv_Length1, 
        hv_Length2);
    //
    //Intersect and concatenate the intersections
    IntersectionClosedContoursXld(ho_RectangleFrom, ho_RectangleTo, &ho_ContoursIntersection
        );
    ConcatObj(ho_PlaneConeIntersections, ho_ContoursIntersection, &ho_PlaneConeIntersections
        );
    ClearObjectModel3d(hv_ObjectModel3DIntersectionFrom);
    ClearObjectModel3d(hv_ObjectModel3DIntersectionTo);
  }
  }
  //
  //Union all intersections of all image pairs.
  GenEmptyObj(&ho_PlaneConeIntersectionUnion);
  CountObj(ho_PlaneConeIntersections, &hv_Number);
  {
  HTuple end_val80 = hv_Number;
  HTuple step_val80 = 1;
  for (hv_Index2=1; hv_Index2.Continue(end_val80, step_val80); hv_Index2 += step_val80)
  {
    SelectObj(ho_PlaneConeIntersections, &ho_ObjectSelected, hv_Index2);
    Union2ClosedContoursXld(ho_ObjectSelected, ho_PlaneConeIntersectionUnion, &ho_PlaneConeIntersectionUnion
        );
  }
  }
  //
  //Get the coordinates of the resulting XLD, which represents the area
  //in 2D where the reconstruction is possible.
  GetContourXld(ho_PlaneConeIntersectionUnion, &hv_RowContour, &hv_ColumnContour);
  //
  //Based on this contour, we can easily access the parameters of the bounding box.
  if (0 != (hv_ObjectHeight>0))
  {
    (*hv_BoundingBox).Clear();
    (*hv_BoundingBox).Append(hv_RowContour.TupleMin());
    (*hv_BoundingBox).Append(hv_ColumnContour.TupleMin());
    (*hv_BoundingBox).Append(-hv_ObjectHeight);
    (*hv_BoundingBox).Append(hv_RowContour.TupleMax());
    (*hv_BoundingBox).Append(hv_ColumnContour.TupleMax());
    (*hv_BoundingBox).Append(0);
  }
  else
  {
    (*hv_BoundingBox).Clear();
    (*hv_BoundingBox).Append(hv_RowContour.TupleMin());
    (*hv_BoundingBox).Append(hv_ColumnContour.TupleMin());
    (*hv_BoundingBox).Append(0);
    (*hv_BoundingBox).Append(hv_RowContour.TupleMax());
    (*hv_BoundingBox).Append(hv_ColumnContour.TupleMax());
    (*hv_BoundingBox).Append(-hv_ObjectHeight);
  }
  //
  //Clean up.
  ClearCameraSetupModel(hv_CameraSetupModelID);
  ClearObjectModel3d(hv_ObjectModel3DCone);
  return;
}

// Chapter: 3D Object Model / Creation
// Short Description: Generate a 3D object model representing the view cone of a telecentric camera. 
void gen_cone_telecentric_object_model_3d (HTuple hv_CameraSetupModelID, HTuple hv_CameraIndex, 
    HTuple hv_ConeLength, HTuple *hv_ObjectModel3D)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_CamPose, hv_HomMat3D, hv_CamParam;
  HTuple  hv_PX, hv_PY, hv_PZ, hv_QX, hv_QY, hv_QZ, hv_Qx;
  HTuple  hv_Qy, hv_Qz, hv_QZT, hv_Index, hv_Faces;
  HTupleVector  hvec_Points(1);

  GetCameraSetupParam(hv_CameraSetupModelID, hv_CameraIndex, "pose", &hv_CamPose);
  PoseToHomMat3d(hv_CamPose, &hv_HomMat3D);
  GetCameraSetupParam(hv_CameraSetupModelID, hv_CameraIndex, "params", &hv_CamParam);
  //
  //Get the lines of sight of the four corner points of the image.
  //Scale them to the given length and transform into world coordinates.
  hvec_Points = (HTupleVector(1).Insert(0,HTupleVector(HTuple())));
  //First corner.
  GetLineOfSight(0, 0, hv_CamParam, &hv_PX, &hv_PY, &hv_PZ, &hv_QX, &hv_QY, &hv_QZ);
  AffineTransPoint3d(hv_HomMat3D, hv_PX, hv_PY, hv_PZ, &hv_Qx, &hv_Qy, &hv_Qz);
  hvec_Points[0] = HTupleVector((hv_Qx.TupleConcat(hv_Qy)).TupleConcat(hv_Qz));
  hv_QZT = hv_ConeLength;
  AffineTransPoint3d(hv_HomMat3D, hv_QX, hv_QY, hv_QZT, &hv_Qx, &hv_Qy, &hv_Qz);
  hvec_Points[1] = HTupleVector((hv_Qx.TupleConcat(hv_Qy)).TupleConcat(hv_Qz));
  //Second corner.
  GetLineOfSight(HTuple(hv_CamParam[(hv_CamParam.TupleLength())-1])-1, 0, hv_CamParam, 
      &hv_PX, &hv_PY, &hv_PZ, &hv_QX, &hv_QY, &hv_QZ);
  AffineTransPoint3d(hv_HomMat3D, hv_PX, hv_PY, hv_PZ, &hv_Qx, &hv_Qy, &hv_Qz);
  hvec_Points[2] = HTupleVector((hv_Qx.TupleConcat(hv_Qy)).TupleConcat(hv_Qz));
  hv_QZT = hv_ConeLength;
  AffineTransPoint3d(hv_HomMat3D, hv_QX, hv_QY, hv_QZT, &hv_Qx, &hv_Qy, &hv_Qz);
  hvec_Points[3] = HTupleVector((hv_Qx.TupleConcat(hv_Qy)).TupleConcat(hv_Qz));
  //Third corner.
  GetLineOfSight(HTuple(hv_CamParam[(hv_CamParam.TupleLength())-1])-1, HTuple(hv_CamParam[(hv_CamParam.TupleLength())-2])-1, 
      hv_CamParam, &hv_PX, &hv_PY, &hv_PZ, &hv_QX, &hv_QY, &hv_QZ);
  AffineTransPoint3d(hv_HomMat3D, hv_PX, hv_PY, hv_PZ, &hv_Qx, &hv_Qy, &hv_Qz);
  hvec_Points[4] = HTupleVector((hv_Qx.TupleConcat(hv_Qy)).TupleConcat(hv_Qz));
  hv_QZT = hv_ConeLength;
  AffineTransPoint3d(hv_HomMat3D, hv_QX, hv_QY, hv_QZT, &hv_Qx, &hv_Qy, &hv_Qz);
  hvec_Points[5] = HTupleVector((hv_Qx.TupleConcat(hv_Qy)).TupleConcat(hv_Qz));
  //Fourth corner.
  GetLineOfSight(0, HTuple(hv_CamParam[(hv_CamParam.TupleLength())-2])-1, hv_CamParam, 
      &hv_PX, &hv_PY, &hv_PZ, &hv_QX, &hv_QY, &hv_QZ);
  AffineTransPoint3d(hv_HomMat3D, hv_PX, hv_PY, hv_PZ, &hv_Qx, &hv_Qy, &hv_Qz);
  hvec_Points[6] = HTupleVector((hv_Qx.TupleConcat(hv_Qy)).TupleConcat(hv_Qz));
  hv_QZT = hv_ConeLength;
  AffineTransPoint3d(hv_HomMat3D, hv_QX, hv_QY, hv_QZT, &hv_Qx, &hv_Qy, &hv_Qz);
  hvec_Points[7] = HTupleVector((hv_Qx.TupleConcat(hv_Qy)).TupleConcat(hv_Qz));
  //
  //Sort the points by coordinate direction.
  hv_PX = HTuple();
  hv_PY = HTuple();
  hv_PZ = HTuple();
  for (hv_Index=0; hv_Index<=7; hv_Index+=1)
  {
    hv_PX = hv_PX.TupleConcat(HTuple(hvec_Points[hv_Index].T()[0]));
    hv_PY = hv_PY.TupleConcat(HTuple(hvec_Points[hv_Index].T()[1]));
    hv_PZ = hv_PZ.TupleConcat(HTuple(hvec_Points[hv_Index].T()[2]));
  }
  GenObjectModel3dFromPoints(hv_PX, hv_PY, hv_PZ, &(*hv_ObjectModel3D));
  //
  //Set the sides of the cone.
  hv_Faces = HTuple();
  hv_Faces = hv_Faces.TupleConcat(((((HTuple(4).Append(0)).Append(1)).Append(3)).Append(2)));
  hv_Faces = hv_Faces.TupleConcat(((((HTuple(4).Append(2)).Append(3)).Append(5)).Append(4)));
  hv_Faces = hv_Faces.TupleConcat(((((HTuple(4).Append(4)).Append(5)).Append(7)).Append(6)));
  hv_Faces = hv_Faces.TupleConcat(((((HTuple(4).Append(6)).Append(7)).Append(1)).Append(0)));
  SetObjectModel3dAttribMod((*hv_ObjectModel3D), "polygons", HTuple(), hv_Faces);
  return;
}

// Chapter: Graphics / Parameters
void color_string_to_rgb (HTuple hv_Color, HTuple *hv_RGB)
{

  // Local iconic variables
  HObject  ho_Rectangle, ho_Image;

  // Local control variables
  HTuple  hv_WindowHandleBuffer, hv_Exception;

  OpenWindow(0, 0, 1, 1, 0, "buffer", "", &hv_WindowHandleBuffer);
  SetPart(hv_WindowHandleBuffer, 0, 0, -1, -1);
  GenRectangle1(&ho_Rectangle, 0, 0, 0, 0);
  try
  {
    SetColor(hv_WindowHandleBuffer, hv_Color);
  }
  // catch (Exception) 
  catch (HException &HDevExpDefaultException)
  {
    HDevExpDefaultException.ToHTuple(&hv_Exception);
    hv_Exception = "Wrong value of control parameter Color (must be a valid color string)";
    throw HException(hv_Exception);
  }
  DispObj(ho_Rectangle, hv_WindowHandleBuffer);
  DumpWindowImage(&ho_Image, hv_WindowHandleBuffer);
  CloseWindow(hv_WindowHandleBuffer);
  GetGrayval(ho_Image, 0, 0, &(*hv_RGB));
  (*hv_RGB) += ((HTuple(0).Append(0)).Append(0));
  return;
}

// Chapter: 3D Object Model / Creation
// Short Description: Generate a 3D object model representing the view cone of a perspective camera. 
void gen_cone_perspective_object_model_3d (HTuple hv_CameraSetupModelID, HTuple hv_CameraIndex, 
    HTuple hv_ConeLength, HTuple *hv_ObjectModel3D)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_CamPose, hv_HomMat3D, hv_CamParam;
  HTuple  hv_PX, hv_PY, hv_PZ, hv_QX, hv_QY, hv_QZ, hv_QXT;
  HTuple  hv_QYT, hv_QZT, hv_Qx, hv_Qy, hv_Qz, hv_Index, hv_Faces;
  HTupleVector  hvec_Points(1);

  GetCameraSetupParam(hv_CameraSetupModelID, hv_CameraIndex, "pose", &hv_CamPose);
  PoseToHomMat3d(hv_CamPose, &hv_HomMat3D);
  GetCameraSetupParam(hv_CameraSetupModelID, hv_CameraIndex, "params", &hv_CamParam);
  //
  //Get the lines of sight of the four corner points of the image.
  //Scale them to the given length and transform into world coordinates.
  hvec_Points = (HTupleVector(1).Insert(0,HTupleVector(HTuple())));
  //First corner.
  GetLineOfSight(0, 0, hv_CamParam, &hv_PX, &hv_PY, &hv_PZ, &hv_QX, &hv_QY, &hv_QZ);
  hv_QXT = (hv_QX/hv_QZ)*hv_ConeLength;
  hv_QYT = (hv_QY/hv_QZ)*hv_ConeLength;
  hv_QZT = hv_ConeLength;
  AffineTransPoint3d(hv_HomMat3D, hv_QXT, hv_QYT, hv_QZT, &hv_Qx, &hv_Qy, &hv_Qz);
  hvec_Points[0] = HTupleVector((hv_Qx.TupleConcat(hv_Qy)).TupleConcat(hv_Qz));
  //Second corner.
  GetLineOfSight(HTuple(hv_CamParam[(hv_CamParam.TupleLength())-1])-1, 0, hv_CamParam, 
      &hv_PX, &hv_PY, &hv_PZ, &hv_QX, &hv_QY, &hv_QZ);
  hv_QXT = (hv_QX/hv_QZ)*hv_ConeLength;
  hv_QYT = (hv_QY/hv_QZ)*hv_ConeLength;
  hv_QZT = hv_ConeLength;
  AffineTransPoint3d(hv_HomMat3D, hv_QXT, hv_QYT, hv_QZT, &hv_Qx, &hv_Qy, &hv_Qz);
  hvec_Points[1] = HTupleVector((hv_Qx.TupleConcat(hv_Qy)).TupleConcat(hv_Qz));
  //Third corner.
  GetLineOfSight(HTuple(hv_CamParam[(hv_CamParam.TupleLength())-1])-1, HTuple(hv_CamParam[(hv_CamParam.TupleLength())-2])-1, 
      hv_CamParam, &hv_PX, &hv_PY, &hv_PZ, &hv_QX, &hv_QY, &hv_QZ);
  hv_QXT = (hv_QX/hv_QZ)*hv_ConeLength;
  hv_QYT = (hv_QY/hv_QZ)*hv_ConeLength;
  hv_QZT = hv_ConeLength;
  AffineTransPoint3d(hv_HomMat3D, hv_QXT, hv_QYT, hv_QZT, &hv_Qx, &hv_Qy, &hv_Qz);
  hvec_Points[2] = HTupleVector((hv_Qx.TupleConcat(hv_Qy)).TupleConcat(hv_Qz));
  //Fourth corner.
  GetLineOfSight(0, HTuple(hv_CamParam[(hv_CamParam.TupleLength())-2])-1, hv_CamParam, 
      &hv_PX, &hv_PY, &hv_PZ, &hv_QX, &hv_QY, &hv_QZ);
  hv_QXT = (hv_QX/hv_QZ)*hv_ConeLength;
  hv_QYT = (hv_QY/hv_QZ)*hv_ConeLength;
  hv_QZT = hv_ConeLength;
  AffineTransPoint3d(hv_HomMat3D, hv_QXT, hv_QYT, hv_QZT, &hv_Qx, &hv_Qy, &hv_Qz);
  hvec_Points[3] = HTupleVector((hv_Qx.TupleConcat(hv_Qy)).TupleConcat(hv_Qz));
  //
  //Get camera center.
  AffineTransPoint3d(hv_HomMat3D, 0, 0, 0, &hv_Qx, &hv_Qy, &hv_Qz);
  hvec_Points[4] = HTupleVector((hv_Qx.TupleConcat(hv_Qy)).TupleConcat(hv_Qz));
  //
  //Sort the points by coordinate direction.
  hv_PX = HTuple();
  hv_PY = HTuple();
  hv_PZ = HTuple();
  for (hv_Index=0; hv_Index<=4; hv_Index+=1)
  {
    hv_PX = hv_PX.TupleConcat(HTuple(hvec_Points[hv_Index].T()[0]));
    hv_PY = hv_PY.TupleConcat(HTuple(hvec_Points[hv_Index].T()[1]));
    hv_PZ = hv_PZ.TupleConcat(HTuple(hvec_Points[hv_Index].T()[2]));
  }
  GenObjectModel3dFromPoints(hv_PX, hv_PY, hv_PZ, &(*hv_ObjectModel3D));
  //
  //Set the sides of the cone.
  hv_Faces = HTuple();
  hv_Faces = hv_Faces.TupleConcat(((HTuple(4).Append(0)).Append(1)));
  hv_Faces = hv_Faces.TupleConcat(((HTuple(4).Append(1)).Append(2)));
  hv_Faces = hv_Faces.TupleConcat(((HTuple(4).Append(2)).Append(3)));
  hv_Faces = hv_Faces.TupleConcat(((HTuple(4).Append(3)).Append(0)));
  SetObjectModel3dAttribMod((*hv_ObjectModel3D), "triangles", HTuple(), hv_Faces);
  return;
}

// Chapter: Graphics / Output
// Short Description: Reflect the pose change that was introduced by the user by moving the mouse 
void analyze_graph_event (HObject ho_BackgroundImage, HTuple hv_MouseMapping, HTuple hv_Button, 
    HTuple hv_Row, HTuple hv_Column, HTuple hv_WindowHandle, HTuple hv_WindowHandleBuffer, 
    HTuple hv_VirtualTrackball, HTuple hv_TrackballSize, HTuple hv_SelectedObjectIn, 
    HTuple hv_Scene3D, HTuple hv_AlphaOrig, HTuple hv_ObjectModel3DID, HTuple hv_CamParam, 
    HTuple hv_Labels, HTuple hv_Title, HTuple hv_Information, HTuple hv_GenParamName, 
    HTuple hv_GenParamValue, HTuple hv_PosesIn, HTuple hv_ButtonHoldIn, HTuple hv_TBCenter, 
    HTuple hv_TBSize, HTuple hv_WindowCenteredRotationlIn, HTuple hv_MaxNumModels, 
    HTuple *hv_PosesOut, HTuple *hv_SelectedObjectOut, HTuple *hv_ButtonHoldOut, 
    HTuple *hv_WindowCenteredRotationOut)
{

  // Local iconic variables
  HObject  ho_ImageDump;

  // Local control variables
  HTuple  ExpTmpLocalVar_gIsSinglePose, hv_VisualizeTB;
  HTuple  hv_InvLog2, hv_Seconds, hv_ModelIndex, hv_Exception1;
  HTuple  hv_HomMat3DIdentity, hv_NumModels, hv_Width, hv_Height;
  HTuple  hv_MinImageSize, hv_TrackballRadiusPixel, hv_TrackballCenterRow;
  HTuple  hv_TrackballCenterCol, hv_NumChannels, hv_ColorImage;
  HTuple  hv_BAnd, hv_SensFactor, hv_IsButtonTrans, hv_IsButtonRot;
  HTuple  hv_IsButtonDist, hv_MRow1, hv_MCol1, hv_ButtonLoop;
  HTuple  hv_MRow2, hv_MCol2, hv_PX, hv_PY, hv_PZ, hv_QX1;
  HTuple  hv_QY1, hv_QZ1, hv_QX2, hv_QY2, hv_QZ2, hv_Len;
  HTuple  hv_Dist, hv_Translate, hv_Index, hv_PoseIn, hv_HomMat3DIn;
  HTuple  hv_HomMat3DOut, hv_PoseOut, hv_Indices, hv_Sequence;
  HTuple  hv_Mod, hv_SequenceReal, hv_Sequence2Int, hv_Selected;
  HTuple  hv_InvSelected, hv_Exception, hv_DRow, hv_TranslateZ;
  HTuple  hv_MX1, hv_MY1, hv_MX2, hv_MY2, hv_RelQuaternion;
  HTuple  hv_HomMat3DRotRel, hv_HomMat3DInTmp1, hv_HomMat3DInTmp;
  HTuple  hv_PosesOut2;

  //This procedure reflects
  //- the pose change that was introduced by the user by
  //  moving the mouse
  //- the selection of a single object
  //
  //global tuple gIsSinglePose
  //
  (*hv_ButtonHoldOut) = hv_ButtonHoldIn;
  (*hv_PosesOut) = hv_PosesIn;
  (*hv_SelectedObjectOut) = hv_SelectedObjectIn;
  (*hv_WindowCenteredRotationOut) = hv_WindowCenteredRotationlIn;
  hv_VisualizeTB = ((*hv_SelectedObjectOut).TupleMax())!=0;
  hv_InvLog2 = 1.0/(HTuple(2).TupleLog());
  //
  if (0 != (hv_Button==HTuple(hv_MouseMapping[6])))
  {
    if (0 != (*hv_ButtonHoldOut))
    {
      return;
    }
    //Ctrl (16) + Alt (32) + left mouse button (1) => Toggle rotation center position
    //If WindowCenteredRotation is not 1, set it to 1, otherwise, set it to 2
    CountSeconds(&hv_Seconds);
    if (0 != ((*hv_WindowCenteredRotationOut)==1))
    {
      (*hv_WindowCenteredRotationOut) = 2;
    }
    else
    {
      (*hv_WindowCenteredRotationOut) = 1;
    }
    (*hv_ButtonHoldOut) = 1;
    return;
  }
  if (0 != (HTuple(hv_Button==HTuple(hv_MouseMapping[5])).TupleAnd((hv_ObjectModel3DID.TupleLength())<=hv_MaxNumModels)))
  {
    if (0 != (*hv_ButtonHoldOut))
    {
      return;
    }
    //Ctrl (16) + left mouse button (1) => Select an object
    try
    {
      SetScene3dParam(hv_Scene3D, "object_index_persistence", "true");
      DisplayScene3d(hv_WindowHandleBuffer, hv_Scene3D, 0);
      GetDisplayScene3dInfo(hv_WindowHandleBuffer, hv_Scene3D, hv_Row, hv_Column, 
          "object_index", &hv_ModelIndex);
      SetScene3dParam(hv_Scene3D, "object_index_persistence", "false");
    }
    // catch (Exception1) 
    catch (HException &HDevExpDefaultException)
    {
      HDevExpDefaultException.ToHTuple(&hv_Exception1);
      //* NO OpenGL, no selection possible
      return;
    }
    if (0 != (hv_ModelIndex==-1))
    {
      //Background click:
      if (0 != (((*hv_SelectedObjectOut).TupleSum())==((*hv_SelectedObjectOut).TupleLength())))
      {
        //If all objects are already selected, deselect all
        (*hv_SelectedObjectOut) = HTuple(hv_ObjectModel3DID.TupleLength(),0);
      }
      else
      {
        //Otherwise select all
        (*hv_SelectedObjectOut) = HTuple(hv_ObjectModel3DID.TupleLength(),1);
      }
    }
    else
    {
      //Object click:
      (*hv_SelectedObjectOut)[hv_ModelIndex] = HTuple((*hv_SelectedObjectOut)[hv_ModelIndex]).TupleNot();
    }
    (*hv_ButtonHoldOut) = 1;
  }
  else
  {
    //Change the pose
    HomMat3dIdentity(&hv_HomMat3DIdentity);
    hv_NumModels = hv_ObjectModel3DID.TupleLength();
    get_cam_par_data(hv_CamParam, "image_width", &hv_Width);
    get_cam_par_data(hv_CamParam, "image_height", &hv_Height);
    hv_MinImageSize = (hv_Width.TupleConcat(hv_Height)).TupleMin();
    hv_TrackballRadiusPixel = (hv_TrackballSize*hv_MinImageSize)/2.0;
    //Set trackball fixed in the center of the window
    hv_TrackballCenterRow = hv_Height/2;
    hv_TrackballCenterCol = hv_Width/2;
    if (0 != ((hv_ObjectModel3DID.TupleLength())<hv_MaxNumModels))
    {
      if (0 != ((*hv_WindowCenteredRotationOut)==1))
      {
        get_trackball_center_fixed(hv_SelectedObjectIn, hv_TrackballCenterRow, hv_TrackballCenterCol, 
            hv_TrackballRadiusPixel, hv_Scene3D, hv_ObjectModel3DID, hv_PosesIn, 
            hv_WindowHandleBuffer, hv_CamParam, hv_GenParamName, hv_GenParamValue, 
            &hv_TBCenter, &hv_TBSize);
      }
      else
      {
        get_trackball_center(hv_SelectedObjectIn, hv_TrackballRadiusPixel, hv_ObjectModel3DID, 
            hv_PosesIn, &hv_TBCenter, &hv_TBSize);
      }
    }
    if (0 != (HTuple(((*hv_SelectedObjectOut).TupleMin())==0).TupleAnd(((*hv_SelectedObjectOut).TupleMax())==1)))
    {
      //At this point, multiple objects do not necessary have the same
      //pose any more. Consequently, we have to return a tuple of poses
      //as output of visualize_object_model_3d
      ExpTmpLocalVar_gIsSinglePose = 0;
      ExpSetGlobalVar_gIsSinglePose(ExpTmpLocalVar_gIsSinglePose);
    }
    CountChannels(ho_BackgroundImage, &hv_NumChannels);
    hv_ColorImage = hv_NumChannels==3;
    //Alt (32) => lower sensitivity
    TupleRsh(hv_Button, 5, &hv_BAnd);
    if (0 != (hv_BAnd%2))
    {
      hv_SensFactor = 0.1;
    }
    else
    {
      hv_SensFactor = 1.0;
    }
    hv_IsButtonTrans = HTuple(HTuple(hv_MouseMapping[0])==hv_Button).TupleOr((32+HTuple(hv_MouseMapping[0]))==hv_Button);
    hv_IsButtonRot = HTuple(HTuple(hv_MouseMapping[1])==hv_Button).TupleOr((32+HTuple(hv_MouseMapping[1]))==hv_Button);
    hv_IsButtonDist = HTuple(HTuple(HTuple(HTuple(HTuple(HTuple(hv_MouseMapping[2])==hv_Button).TupleOr((32+HTuple(hv_MouseMapping[2]))==hv_Button)).TupleOr(HTuple(hv_MouseMapping[3])==hv_Button)).TupleOr((32+HTuple(hv_MouseMapping[3]))==hv_Button)).TupleOr(HTuple(hv_MouseMapping[4])==hv_Button)).TupleOr((32+HTuple(hv_MouseMapping[4]))==hv_Button);
    if (0 != hv_IsButtonTrans)
    {
      //Translate in XY-direction
      hv_MRow1 = hv_Row;
      hv_MCol1 = hv_Column;
      while (0 != hv_IsButtonTrans)
      {
        try
        {
          GetMpositionSubPix(hv_WindowHandle, &hv_Row, &hv_Column, &hv_ButtonLoop);
          hv_IsButtonTrans = hv_ButtonLoop==hv_Button;
          hv_MRow2 = hv_MRow1+((hv_Row-hv_MRow1)*hv_SensFactor);
          hv_MCol2 = hv_MCol1+((hv_Column-hv_MCol1)*hv_SensFactor);
          GetLineOfSight(hv_MRow1, hv_MCol1, hv_CamParam, &hv_PX, &hv_PY, &hv_PZ, 
              &hv_QX1, &hv_QY1, &hv_QZ1);
          GetLineOfSight(hv_MRow2, hv_MCol2, hv_CamParam, &hv_PX, &hv_PY, &hv_PZ, 
              &hv_QX2, &hv_QY2, &hv_QZ2);
          hv_Len = (((hv_QX1*hv_QX1)+(hv_QY1*hv_QY1))+(hv_QZ1*hv_QZ1)).TupleSqrt();
          hv_Dist = (((HTuple(hv_TBCenter[0])*HTuple(hv_TBCenter[0]))+(HTuple(hv_TBCenter[1])*HTuple(hv_TBCenter[1])))+(HTuple(hv_TBCenter[2])*HTuple(hv_TBCenter[2]))).TupleSqrt();
          hv_Translate = ((((hv_QX2-hv_QX1).TupleConcat(hv_QY2-hv_QY1)).TupleConcat(hv_QZ2-hv_QZ1))*hv_Dist)/hv_Len;
          (*hv_PosesOut) = HTuple();
          if (0 != (hv_NumModels<=hv_MaxNumModels))
          {
            {
            HTuple end_val110 = hv_NumModels-1;
            HTuple step_val110 = 1;
            for (hv_Index=0; hv_Index.Continue(end_val110, step_val110); hv_Index += step_val110)
            {
              hv_PoseIn = hv_PosesIn.TupleSelectRange(hv_Index*7,(hv_Index*7)+6);
              if (0 != (HTuple((*hv_SelectedObjectOut)[hv_Index])))
              {
                PoseToHomMat3d(hv_PoseIn, &hv_HomMat3DIn);
                HomMat3dTranslate(hv_HomMat3DIn, HTuple(hv_Translate[0]), HTuple(hv_Translate[1]), 
                    HTuple(hv_Translate[2]), &hv_HomMat3DOut);
                HomMat3dToPose(hv_HomMat3DOut, &hv_PoseOut);
                SetScene3dInstancePose(hv_Scene3D, hv_Index, hv_PoseOut);
              }
              else
              {
                hv_PoseOut = hv_PoseIn;
              }
              (*hv_PosesOut) = (*hv_PosesOut).TupleConcat(hv_PoseOut);
            }
            }
          }
          else
          {
            TupleFind((*hv_SelectedObjectOut), 1, &hv_Indices);
            hv_PoseIn = hv_PosesIn.TupleSelectRange(HTuple(hv_Indices[0])*7,(HTuple(hv_Indices[0])*7)+6);
            PoseToHomMat3d(hv_PoseIn, &hv_HomMat3DIn);
            HomMat3dTranslate(hv_HomMat3DIn, HTuple(hv_Translate[0]), HTuple(hv_Translate[1]), 
                HTuple(hv_Translate[2]), &hv_HomMat3DOut);
            HomMat3dToPose(hv_HomMat3DOut, &hv_PoseOut);
            hv_Sequence = HTuple::TupleGenSequence(0,(hv_NumModels*7)-1,1);
            TupleMod(hv_Sequence, 7, &hv_Mod);
            hv_SequenceReal = HTuple::TupleGenSequence(0,hv_NumModels-(1.0/7.0),1.0/7.0);
            hv_Sequence2Int = hv_SequenceReal.TupleInt();
            TupleSelect((*hv_SelectedObjectOut), hv_Sequence2Int, &hv_Selected);
            hv_InvSelected = 1-hv_Selected;
            TupleSelect(hv_PoseOut, hv_Mod, &(*hv_PosesOut));
            (*hv_PosesOut) = ((*hv_PosesOut)*hv_Selected)+(hv_PosesIn*hv_InvSelected);
            SetScene3dInstancePose(hv_Scene3D, HTuple::TupleGenSequence(0,hv_NumModels-1,1), 
                (*hv_PosesOut));
          }
          dump_image_output(ho_BackgroundImage, hv_WindowHandleBuffer, hv_Scene3D, 
              hv_AlphaOrig, hv_ObjectModel3DID, hv_GenParamName, hv_GenParamValue, 
              hv_CamParam, (*hv_PosesOut), hv_ColorImage, hv_Title, hv_Information, 
              hv_Labels, hv_VisualizeTB, "true", hv_TrackballCenterRow, hv_TrackballCenterCol, 
              hv_TBSize, (*hv_SelectedObjectOut), (*hv_WindowCenteredRotationOut)==1, 
              hv_TBCenter);
          DumpWindowImage(&ho_ImageDump, hv_WindowHandleBuffer);
          HDevWindowStack::SetActive(hv_WindowHandle);
          if (HDevWindowStack::IsOpen())
            DispObj(ho_ImageDump, HDevWindowStack::GetActive());
          //
          hv_MRow1 = hv_Row;
          hv_MCol1 = hv_Column;
          hv_PosesIn = (*hv_PosesOut);
        }
        // catch (Exception) 
        catch (HException &HDevExpDefaultException)
        {
          HDevExpDefaultException.ToHTuple(&hv_Exception);
          //Keep waiting
        }
      }
    }
    else if (0 != hv_IsButtonDist)
    {
      //Change the Z distance
      hv_MRow1 = hv_Row;
      while (0 != hv_IsButtonDist)
      {
        try
        {
          GetMpositionSubPix(hv_WindowHandle, &hv_Row, &hv_Column, &hv_ButtonLoop);
          hv_IsButtonDist = hv_ButtonLoop==hv_Button;
          hv_MRow2 = hv_Row;
          hv_DRow = hv_MRow2-hv_MRow1;
          hv_Dist = (((HTuple(hv_TBCenter[0])*HTuple(hv_TBCenter[0]))+(HTuple(hv_TBCenter[1])*HTuple(hv_TBCenter[1])))+(HTuple(hv_TBCenter[2])*HTuple(hv_TBCenter[2]))).TupleSqrt();
          hv_TranslateZ = (((-hv_Dist)*hv_DRow)*0.003)*hv_SensFactor;
          hv_TBCenter[2] = HTuple(hv_TBCenter[2])+hv_TranslateZ;
          (*hv_PosesOut) = HTuple();
          if (0 != (hv_NumModels<=hv_MaxNumModels))
          {
            {
            HTuple end_val164 = hv_NumModels-1;
            HTuple step_val164 = 1;
            for (hv_Index=0; hv_Index.Continue(end_val164, step_val164); hv_Index += step_val164)
            {
              hv_PoseIn = hv_PosesIn.TupleSelectRange(hv_Index*7,(hv_Index*7)+6);
              if (0 != (HTuple((*hv_SelectedObjectOut)[hv_Index])))
              {
                //Transform the whole scene or selected object only
                PoseToHomMat3d(hv_PoseIn, &hv_HomMat3DIn);
                HomMat3dTranslate(hv_HomMat3DIn, 0, 0, hv_TranslateZ, &hv_HomMat3DOut);
                HomMat3dToPose(hv_HomMat3DOut, &hv_PoseOut);
                SetScene3dInstancePose(hv_Scene3D, hv_Index, hv_PoseOut);
              }
              else
              {
                hv_PoseOut = hv_PoseIn;
              }
              (*hv_PosesOut) = (*hv_PosesOut).TupleConcat(hv_PoseOut);
            }
            }
          }
          else
          {
            TupleFind((*hv_SelectedObjectOut), 1, &hv_Indices);
            hv_PoseIn = hv_PosesIn.TupleSelectRange(HTuple(hv_Indices[0])*7,(HTuple(hv_Indices[0])*7)+6);
            PoseToHomMat3d(hv_PoseIn, &hv_HomMat3DIn);
            HomMat3dTranslate(hv_HomMat3DIn, 0, 0, hv_TranslateZ, &hv_HomMat3DOut);
            HomMat3dToPose(hv_HomMat3DOut, &hv_PoseOut);
            hv_Sequence = HTuple::TupleGenSequence(0,(hv_NumModels*7)-1,1);
            TupleMod(hv_Sequence, 7, &hv_Mod);
            hv_SequenceReal = HTuple::TupleGenSequence(0,hv_NumModels-(1.0/7.0),1.0/7.0);
            hv_Sequence2Int = hv_SequenceReal.TupleInt();
            TupleSelect((*hv_SelectedObjectOut), hv_Sequence2Int, &hv_Selected);
            hv_InvSelected = 1-hv_Selected;
            TupleSelect(hv_PoseOut, hv_Mod, &(*hv_PosesOut));
            (*hv_PosesOut) = ((*hv_PosesOut)*hv_Selected)+(hv_PosesIn*hv_InvSelected);
            SetScene3dInstancePose(hv_Scene3D, HTuple::TupleGenSequence(0,hv_NumModels-1,1), 
                (*hv_PosesOut));
          }
          dump_image_output(ho_BackgroundImage, hv_WindowHandleBuffer, hv_Scene3D, 
              hv_AlphaOrig, hv_ObjectModel3DID, hv_GenParamName, hv_GenParamValue, 
              hv_CamParam, (*hv_PosesOut), hv_ColorImage, hv_Title, hv_Information, 
              hv_Labels, hv_VisualizeTB, "true", hv_TrackballCenterRow, hv_TrackballCenterCol, 
              hv_TBSize, (*hv_SelectedObjectOut), (*hv_WindowCenteredRotationOut), 
              hv_TBCenter);
          DumpWindowImage(&ho_ImageDump, hv_WindowHandleBuffer);
          HDevWindowStack::SetActive(hv_WindowHandle);
          if (HDevWindowStack::IsOpen())
            DispObj(ho_ImageDump, HDevWindowStack::GetActive());
          //
          hv_MRow1 = hv_Row;
          hv_PosesIn = (*hv_PosesOut);
        }
        // catch (Exception) 
        catch (HException &HDevExpDefaultException)
        {
          HDevExpDefaultException.ToHTuple(&hv_Exception);
          //Keep waiting
        }
      }
    }
    else if (0 != hv_IsButtonRot)
    {
      //Rotate the object
      hv_MRow1 = hv_Row;
      hv_MCol1 = hv_Column;
      while (0 != hv_IsButtonRot)
      {
        try
        {
          GetMpositionSubPix(hv_WindowHandle, &hv_Row, &hv_Column, &hv_ButtonLoop);
          hv_IsButtonRot = hv_ButtonLoop==hv_Button;
          hv_MRow2 = hv_Row;
          hv_MCol2 = hv_Column;
          //Transform the pixel coordinates to relative image coordinates
          hv_MX1 = (hv_TrackballCenterCol-hv_MCol1)/(0.5*hv_MinImageSize);
          hv_MY1 = (hv_TrackballCenterRow-hv_MRow1)/(0.5*hv_MinImageSize);
          hv_MX2 = (hv_TrackballCenterCol-hv_MCol2)/(0.5*hv_MinImageSize);
          hv_MY2 = (hv_TrackballCenterRow-hv_MRow2)/(0.5*hv_MinImageSize);
          //Compute the quaternion rotation that corresponds to the mouse
          //movement
          trackball(hv_MX1, hv_MY1, hv_MX2, hv_MY2, hv_VirtualTrackball, hv_TrackballSize, 
              hv_SensFactor, &hv_RelQuaternion);
          //Transform the quaternion to a rotation matrix
          QuatToHomMat3d(hv_RelQuaternion, &hv_HomMat3DRotRel);
          (*hv_PosesOut) = HTuple();
          if (0 != (hv_NumModels<=hv_MaxNumModels))
          {
            {
            HTuple end_val226 = hv_NumModels-1;
            HTuple step_val226 = 1;
            for (hv_Index=0; hv_Index.Continue(end_val226, step_val226); hv_Index += step_val226)
            {
              hv_PoseIn = hv_PosesIn.TupleSelectRange(hv_Index*7,(hv_Index*7)+6);
              if (0 != (HTuple((*hv_SelectedObjectOut)[hv_Index])))
              {
                //Transform the whole scene or selected object only
                PoseToHomMat3d(hv_PoseIn, &hv_HomMat3DIn);
                HomMat3dTranslate(hv_HomMat3DIn, -HTuple(hv_TBCenter[0]), -HTuple(hv_TBCenter[1]), 
                    -HTuple(hv_TBCenter[2]), &hv_HomMat3DIn);
                HomMat3dCompose(hv_HomMat3DRotRel, hv_HomMat3DIn, &hv_HomMat3DIn);
                HomMat3dTranslate(hv_HomMat3DIn, HTuple(hv_TBCenter[0]), HTuple(hv_TBCenter[1]), 
                    HTuple(hv_TBCenter[2]), &hv_HomMat3DOut);
                HomMat3dToPose(hv_HomMat3DOut, &hv_PoseOut);
                SetScene3dInstancePose(hv_Scene3D, hv_Index, hv_PoseOut);
              }
              else
              {
                hv_PoseOut = hv_PoseIn;
              }
              (*hv_PosesOut) = (*hv_PosesOut).TupleConcat(hv_PoseOut);
            }
            }
          }
          else
          {
            TupleFind((*hv_SelectedObjectOut), 1, &hv_Indices);
            hv_PoseIn = hv_PosesIn.TupleSelectRange(HTuple(hv_Indices[0])*7,(HTuple(hv_Indices[0])*7)+6);
            PoseToHomMat3d(hv_PoseIn, &hv_HomMat3DIn);
            HomMat3dTranslate(hv_HomMat3DIn, -HTuple(hv_TBCenter[0]), -HTuple(hv_TBCenter[1]), 
                -HTuple(hv_TBCenter[2]), &hv_HomMat3DInTmp1);
            HomMat3dCompose(hv_HomMat3DRotRel, hv_HomMat3DInTmp1, &hv_HomMat3DInTmp);
            HomMat3dTranslate(hv_HomMat3DInTmp, HTuple(hv_TBCenter[0]), HTuple(hv_TBCenter[1]), 
                HTuple(hv_TBCenter[2]), &hv_HomMat3DOut);
            HomMat3dToPose(hv_HomMat3DOut, &hv_PoseOut);
            hv_Sequence = HTuple::TupleGenSequence(0,(hv_NumModels*7)-1,1);
            TupleMod(hv_Sequence, 7, &hv_Mod);
            hv_SequenceReal = HTuple::TupleGenSequence(0,hv_NumModels-(1.0/7.0),1.0/7.0);
            hv_Sequence2Int = hv_SequenceReal.TupleInt();
            TupleSelect((*hv_SelectedObjectOut), hv_Sequence2Int, &hv_Selected);
            hv_InvSelected = 1-hv_Selected;
            TupleSelect(hv_PoseOut, hv_Mod, &(*hv_PosesOut));
            hv_PosesOut2 = ((*hv_PosesOut)*hv_Selected)+(hv_PosesIn*hv_InvSelected);
            (*hv_PosesOut) = hv_PosesOut2;
            SetScene3dInstancePose(hv_Scene3D, HTuple::TupleGenSequence(0,hv_NumModels-1,1), 
                (*hv_PosesOut));
          }
          dump_image_output(ho_BackgroundImage, hv_WindowHandleBuffer, hv_Scene3D, 
              hv_AlphaOrig, hv_ObjectModel3DID, hv_GenParamName, hv_GenParamValue, 
              hv_CamParam, (*hv_PosesOut), hv_ColorImage, hv_Title, hv_Information, 
              hv_Labels, hv_VisualizeTB, "true", hv_TrackballCenterRow, hv_TrackballCenterCol, 
              hv_TBSize, (*hv_SelectedObjectOut), (*hv_WindowCenteredRotationOut), 
              hv_TBCenter);
          DumpWindowImage(&ho_ImageDump, hv_WindowHandleBuffer);
          HDevWindowStack::SetActive(hv_WindowHandle);
          if (HDevWindowStack::IsOpen())
            DispObj(ho_ImageDump, HDevWindowStack::GetActive());
          //
          hv_MRow1 = hv_Row;
          hv_MCol1 = hv_Column;
          hv_PosesIn = (*hv_PosesOut);
        }
        // catch (Exception) 
        catch (HException &HDevExpDefaultException)
        {
          HDevExpDefaultException.ToHTuple(&hv_Exception);
          //Keep waiting
        }
      }
    }
    (*hv_PosesOut) = hv_PosesIn;
  }
  return;
}

// Chapter: Calibration / Hand-Eye
// Short Description: Prepares the model to match and grasp. 
void prepare_poses_and_rectification_data_moving_cam (HTuple hv_ToolInBasePose, HTuple hv_ObjectHeight, 
    HTuple hv_RectifyImage, HTuple hv_HandEyeCalibData, HTuple *hv_Poses, HTuple *hv_RectificationData)
{

  // Local iconic variables
  HObject  ho_RegionGrid, ho_ContCircle, ho_ContCircleWorldPlane;
  HObject  ho_ImageArea, ho_RegionBorder, ho_RectificationMap;

  // Local control variables
  HTuple  hv_CamParam, hv_ToolInCamPose, hv_PlaneInBasePose0;
  HTuple  hv_OrderOfTransform, hv_OrderOfRotation, hv_ViewOfTransform;
  HTuple  hv_BaseInToolPose, hv_BaseInCamPose, hv_PlaneInCamPose0;
  HTuple  hv_PlaneInCamPose0Rot, hv_HomMat3D, hv_Qx, hv_Qy;
  HTuple  hv_CosAngleBetweenZAxis, hv_SwitchZDirection, hv_PlaneInCamPose1;
  HTuple  hv_PlaneInCamPose, hv_CamInBasePose, hv_PlaneInBasePose;
  HTuple  hv_MatchingPlaneInPlanePose, hv_MatchingPlaneInBasePose;
  HTuple  hv_MatchingPlaneInCamPose, hv_MatchingPlaneRectifiedPartInCamPose;
  HTuple  hv_ScaleRectification, hv_Width, hv_Height, hv_Rows;
  HTuple  hv_Columns, hv_Row, hv_Column, hv_Phi, hv_Radius1;
  HTuple  hv_Radius2, hv_StartPhi, hv_EndPhi, hv_PointOrder;
  HTuple  hv_ClipRegion, hv_BorderRows, hv_BorderColumns;
  HTuple  hv_BorderX, hv_BorderY, hv_MatchingPlaneRectifiedPartInMatchingPlanePose;
  HTuple  hv_WidthRect, hv_HeightRect, hv_ModelInPlanePose;
  HTuple  hv_PlaneInModelPose;

  //Prepare the needed poses to match and grasp, and compute the rectification map.
  //
  //RectifyImage Parameter can have one of the following 3 values:
  //'no_rectification', 'align_and_rectify', or 'only_rectify'
  //
  read_message_tuple(hv_HandEyeCalibData, "CamParam", &hv_CamParam);
  read_message_tuple(hv_HandEyeCalibData, "ToolInCamPose", &hv_ToolInCamPose);
  read_message_tuple(hv_HandEyeCalibData, "PlaneInBasePose0", &hv_PlaneInBasePose0);
  //
  //Check input
  if (0 != (hv_ObjectHeight<0.0))
  {
    throw HException("The parameter ObjectHeight cannot be negative");
  }
  if (0 != (HTuple(hv_CamParam[0])==HTuple("line_scan")))
  {
    throw HException("Line-scan cameras are not supported");
  }
  //
  //Keep track of the pose type used by the robot.
  GetPoseType(hv_ToolInBasePose, &hv_OrderOfTransform, &hv_OrderOfRotation, &hv_ViewOfTransform);
  //Convert to default pose type.
  ConvertPoseType(hv_ToolInBasePose, "Rp+T", "gba", "point", &hv_ToolInBasePose);
  ConvertPoseType(hv_ToolInCamPose, "Rp+T", "gba", "point", &hv_ToolInCamPose);
  ConvertPoseType(hv_PlaneInBasePose0, "Rp+T", "gba", "point", &hv_PlaneInBasePose0);
  //
  //Create the plane for matching and adapt the PlaneInBasePose0 such
  //that the z-axis of the plane points away from the reference camera,
  //and x/y coordinates are aligned with the current image, i.e.
  //PlaneInCamPose0 has Rot_z=0.
  PoseInvert(hv_ToolInBasePose, &hv_BaseInToolPose);
  PoseCompose(hv_ToolInCamPose, hv_BaseInToolPose, &hv_BaseInCamPose);
  PoseCompose(hv_BaseInCamPose, hv_PlaneInBasePose0, &hv_PlaneInCamPose0);
  //The z-axis of the plane should point away from the camera.
  hv_PlaneInCamPose0Rot = hv_PlaneInCamPose0;
  hv_PlaneInCamPose0Rot[HTuple::TupleGenSequence(0,2,1)] = ((HTuple(0).Append(0)).Append(0));
  PoseToHomMat3d(hv_PlaneInCamPose0Rot, &hv_HomMat3D);
  AffineTransPoint3d(hv_HomMat3D, 0, 0, 1, &hv_Qx, &hv_Qy, &hv_CosAngleBetweenZAxis);
  if (0 != (hv_CosAngleBetweenZAxis<0))
  {
    CreatePose(0, 0, 0, 180, 0, 0, "Rp+T", "gba", "point", &hv_SwitchZDirection);
    PoseCompose(hv_PlaneInCamPose0, hv_SwitchZDirection, &hv_PlaneInCamPose1);
    hv_PlaneInCamPose0 = hv_PlaneInCamPose1;
  }
  //Align with the current image.
  hv_PlaneInCamPose = hv_PlaneInCamPose0;
  hv_PlaneInCamPose[5] = 0.0;
  //Adapt the PlaneInBasePose.
  PoseInvert(hv_BaseInCamPose, &hv_CamInBasePose);
  PoseCompose(hv_CamInBasePose, hv_PlaneInCamPose, &hv_PlaneInBasePose);
  //
  //Create the plane for matching.
  CreatePose(0, 0, -hv_ObjectHeight, 0, 0, 0, "Rp+T", "gba", "point", &hv_MatchingPlaneInPlanePose);
  PoseCompose(hv_PlaneInBasePose, hv_MatchingPlaneInPlanePose, &hv_MatchingPlaneInBasePose);
  PoseCompose(hv_PlaneInCamPose, hv_MatchingPlaneInPlanePose, &hv_MatchingPlaneInCamPose);
  //
  if (0 != (hv_RectifyImage==HTuple("no_rectification")))
  {
    hv_MatchingPlaneRectifiedPartInCamPose = hv_MatchingPlaneInCamPose;
    hv_ScaleRectification = HTuple();
  }
  else if (0 != (HTuple(hv_RectifyImage==HTuple("only_rectify")).TupleOr(hv_RectifyImage==HTuple("align_and_rectify"))))
  {
    //Determine the scale such that the mapped image has at least
    //the same resolution as the current image.
    get_cam_par_data(hv_CamParam, "image_width", &hv_Width);
    get_cam_par_data(hv_CamParam, "image_height", &hv_Height);
    GenGridRegion(&ho_RegionGrid, 20, 20, "points", hv_Width, hv_Height);
    GetRegionPoints(ho_RegionGrid, &hv_Rows, &hv_Columns);
    GenCircleContourXld(&ho_ContCircle, hv_Rows, hv_Columns, HTuple(hv_Rows.TupleLength(),1.0), 
        0, 6.28318, "positive", 0.1);
    ContourToWorldPlaneXld(ho_ContCircle, &ho_ContCircleWorldPlane, hv_CamParam, 
        hv_MatchingPlaneInCamPose, "m");
    FitEllipseContourXld(ho_ContCircleWorldPlane, "fitzgibbon", -1, 0, 0, 200, 3, 
        2, &hv_Row, &hv_Column, &hv_Phi, &hv_Radius1, &hv_Radius2, &hv_StartPhi, 
        &hv_EndPhi, &hv_PointOrder);
    hv_ScaleRectification = hv_Radius2.TupleMin();
    //
    //Rectify the current image and create the shape model.
    //
    //The image dimensions should cover the entire original field
    //of view in the current rectification.
    //Look at border of the current image in the world plane.
    GetSystem("clip_region", &hv_ClipRegion);
    SetSystem("clip_region", "false");
    GenRectangle1(&ho_ImageArea, 0, 0, hv_Height-1, hv_Width-1);
    Boundary(ho_ImageArea, &ho_RegionBorder, "outer");
    SetSystem("clip_region", hv_ClipRegion);
    GetRegionPoints(ho_RegionBorder, &hv_BorderRows, &hv_BorderColumns);
    ImagePointsToWorldPlane(hv_CamParam, hv_MatchingPlaneInCamPose, hv_BorderRows, 
        hv_BorderColumns, "m", &hv_BorderX, &hv_BorderY);
    //Adapt parameters.
    CreatePose(hv_BorderX.TupleMin(), hv_BorderY.TupleMin(), 0, 0, 0, 0, "Rp+T", 
        "gba", "point", &hv_MatchingPlaneRectifiedPartInMatchingPlanePose);
    PoseCompose(hv_MatchingPlaneInCamPose, hv_MatchingPlaneRectifiedPartInMatchingPlanePose, 
        &hv_MatchingPlaneRectifiedPartInCamPose);
    hv_WidthRect = ((((hv_BorderX.TupleMax())-(hv_BorderX.TupleMin()))/hv_ScaleRectification)+0.5).TupleInt();
    hv_HeightRect = ((((hv_BorderY.TupleMax())-(hv_BorderY.TupleMin()))/hv_ScaleRectification)+0.5).TupleInt();
    //
    //Create a map for repeated use.
    GenImageToWorldPlaneMap(&ho_RectificationMap, hv_CamParam, hv_MatchingPlaneInCamPose, 
        hv_Width, hv_Height, hv_WidthRect, hv_HeightRect, hv_ScaleRectification, 
        "bilinear");
  }
  else
  {
    throw HException("Please set the parameter RectifyImage correctly");
  }
  //Convert to output pose type.
  ConvertPoseType(hv_PlaneInCamPose, hv_OrderOfTransform, hv_OrderOfRotation, hv_ViewOfTransform, 
      &hv_PlaneInCamPose);
  ConvertPoseType(hv_CamInBasePose, hv_OrderOfTransform, hv_OrderOfRotation, hv_ViewOfTransform, 
      &hv_CamInBasePose);
  ConvertPoseType(hv_PlaneInBasePose, hv_OrderOfTransform, hv_OrderOfRotation, hv_ViewOfTransform, 
      &hv_PlaneInBasePose);
  ConvertPoseType(hv_MatchingPlaneInCamPose, hv_OrderOfTransform, hv_OrderOfRotation, 
      hv_ViewOfTransform, &hv_MatchingPlaneInCamPose);
  ConvertPoseType(hv_MatchingPlaneInBasePose, hv_OrderOfTransform, hv_OrderOfRotation, 
      hv_ViewOfTransform, &hv_MatchingPlaneInBasePose);
  ConvertPoseType(hv_MatchingPlaneRectifiedPartInCamPose, hv_OrderOfTransform, hv_OrderOfRotation, 
      hv_ViewOfTransform, &hv_MatchingPlaneRectifiedPartInCamPose);
  //
  CreatePose(0, 0, hv_ObjectHeight, 180, 0, 0, "Rp+T", "gba", "point", &hv_ModelInPlanePose);
  //Remember the transformation.
  PoseInvert(hv_ModelInPlanePose, &hv_PlaneInModelPose);
  //
  //Create message for Poses.
  CreateMessage(&(*hv_Poses));
  SetMessageTuple((*hv_Poses), "PlaneInCamPose", hv_PlaneInCamPose);
  SetMessageTuple((*hv_Poses), "CamInBasePose", hv_CamInBasePose);
  SetMessageTuple((*hv_Poses), "PlaneInBasePose", hv_PlaneInBasePose);
  SetMessageTuple((*hv_Poses), "MatchingPlaneInCamPose", hv_MatchingPlaneInCamPose);
  SetMessageTuple((*hv_Poses), "MatchingPlaneInBasePose", hv_MatchingPlaneInBasePose);
  SetMessageTuple((*hv_Poses), "PlaneInModelPose", hv_PlaneInModelPose);
  //
  //Create message for rectification data.
  CreateMessage(&(*hv_RectificationData));
  SetMessageTuple((*hv_RectificationData), "RectifyImage", hv_RectifyImage);
  if (0 != (hv_RectifyImage!=HTuple("no_rectification")))
  {
    SetMessageTuple((*hv_RectificationData), "ScaleRectification", hv_ScaleRectification);
    SetMessageObj(ho_RectificationMap, (*hv_RectificationData), "RectificationMap");
  }
  SetMessageTuple((*hv_RectificationData), "MatchingPlaneRectifiedPartInCamPose", 
      hv_MatchingPlaneRectifiedPartInCamPose);
  return;
}

// Chapter: Graphics / Output
// Short Description: Determine the optimum distance of the object to obtain a reasonable visualization 
void determine_optimum_pose_distance (HTuple hv_ObjectModel3DID, HTuple hv_CamParam, 
    HTuple hv_ImageCoverage, HTuple hv_PoseIn, HTuple *hv_PoseOut)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_NumModels, hv_Rows, hv_Cols, hv_MinMinZ;
  HTuple  hv_BB, hv_Seq, hv_DXMax, hv_DYMax, hv_DZMax, hv_Diameter;
  HTuple  hv_ZAdd, hv_IBB, hv_BB0, hv_BB1, hv_BB2, hv_BB3;
  HTuple  hv_BB4, hv_BB5, hv_X, hv_Y, hv_Z, hv_PoseInter;
  HTuple  hv_HomMat3D, hv_QX, hv_QY, hv_QZ, hv_Cx, hv_Cy;
  HTuple  hv_DR, hv_DC, hv_MaxDist, hv_HomMat3DRotate, hv_ImageWidth;
  HTuple  hv_ImageHeight, hv_MinImageSize, hv_Zs, hv_ZDiff;
  HTuple  hv_ScaleZ, hv_ZNew;

  //Determine the optimum distance of the object to obtain
  //a reasonable visualization
  //
  hv_NumModels = hv_ObjectModel3DID.TupleLength();
  hv_Rows = HTuple();
  hv_Cols = HTuple();
  hv_MinMinZ = 1e30;
  GetObjectModel3dParams(hv_ObjectModel3DID, "bounding_box1", &hv_BB);
  //Calculate diameter over all objects to be visualized
  hv_Seq = HTuple::TupleGenSequence(0,(hv_BB.TupleLength())-1,6);
  hv_DXMax = (HTuple(hv_BB[hv_Seq+3]).TupleMax())-(HTuple(hv_BB[hv_Seq]).TupleMin());
  hv_DYMax = (HTuple(hv_BB[hv_Seq+4]).TupleMax())-(HTuple(hv_BB[hv_Seq+1]).TupleMin());
  hv_DZMax = (HTuple(hv_BB[hv_Seq+5]).TupleMax())-(HTuple(hv_BB[hv_Seq+2]).TupleMin());
  hv_Diameter = (((hv_DXMax*hv_DXMax)+(hv_DYMax*hv_DYMax))+(hv_DZMax*hv_DZMax)).TupleSqrt();
  if (0 != (((hv_BB.TupleAbs()).TupleSum())==0.0))
  {
    hv_BB.Clear();
    hv_BB.Append(-(HTuple(HTuple::TupleRand(3)*1e-20).TupleAbs()));
    hv_BB.Append(HTuple(HTuple::TupleRand(3)*1e-20).TupleAbs());
  }
  //Allow the visualization of single points or extremely small objects
  hv_ZAdd = 0.0;
  if (0 != ((hv_Diameter.TupleMax())<1e-10))
  {
    hv_ZAdd = 0.01;
  }
  //Set extremely small diameters to 1e-10 to avoid CZ == 0.0, which would lead
  //to projection errors
  if (0 != ((hv_Diameter.TupleMin())<1e-10))
  {
    hv_Diameter = hv_Diameter-(((((hv_Diameter-1e-10).TupleSgn())-1).TupleSgn())*1e-10);
  }
  hv_IBB = HTuple::TupleGenSequence(0,(hv_BB.TupleLength())-1,6);
  hv_BB0 = HTuple(hv_BB[hv_IBB]);
  hv_BB1 = HTuple(hv_BB[hv_IBB+1]);
  hv_BB2 = HTuple(hv_BB[hv_IBB+2]);
  hv_BB3 = HTuple(hv_BB[hv_IBB+3]);
  hv_BB4 = HTuple(hv_BB[hv_IBB+4]);
  hv_BB5 = HTuple(hv_BB[hv_IBB+5]);
  hv_X.Clear();
  hv_X.Append(hv_BB0);
  hv_X.Append(hv_BB3);
  hv_X.Append(hv_BB0);
  hv_X.Append(hv_BB0);
  hv_X.Append(hv_BB3);
  hv_X.Append(hv_BB3);
  hv_X.Append(hv_BB0);
  hv_X.Append(hv_BB3);
  hv_Y.Clear();
  hv_Y.Append(hv_BB1);
  hv_Y.Append(hv_BB1);
  hv_Y.Append(hv_BB4);
  hv_Y.Append(hv_BB1);
  hv_Y.Append(hv_BB4);
  hv_Y.Append(hv_BB1);
  hv_Y.Append(hv_BB4);
  hv_Y.Append(hv_BB4);
  hv_Z.Clear();
  hv_Z.Append(hv_BB2);
  hv_Z.Append(hv_BB2);
  hv_Z.Append(hv_BB2);
  hv_Z.Append(hv_BB5);
  hv_Z.Append(hv_BB2);
  hv_Z.Append(hv_BB5);
  hv_Z.Append(hv_BB5);
  hv_Z.Append(hv_BB5);
  hv_PoseInter = hv_PoseIn.TupleReplace(2,(-(hv_Z.TupleMin()))+(2*(hv_Diameter.TupleMax())));
  PoseToHomMat3d(hv_PoseInter, &hv_HomMat3D);
  //Determine the maximum extension of the projection
  AffineTransPoint3d(hv_HomMat3D, hv_X, hv_Y, hv_Z, &hv_QX, &hv_QY, &hv_QZ);
  Project3dPoint(hv_QX, hv_QY, hv_QZ, hv_CamParam, &hv_Rows, &hv_Cols);
  hv_MinMinZ = hv_QZ.TupleMin();
  get_cam_par_data(hv_CamParam, "cx", &hv_Cx);
  get_cam_par_data(hv_CamParam, "cy", &hv_Cy);
  hv_DR = hv_Rows-hv_Cy;
  hv_DC = hv_Cols-hv_Cx;
  hv_DR = (hv_DR.TupleMax())-(hv_DR.TupleMin());
  hv_DC = (hv_DC.TupleMax())-(hv_DC.TupleMin());
  hv_MaxDist = ((hv_DR*hv_DR)+(hv_DC*hv_DC)).TupleSqrt();
  //
  if (0 != (hv_MaxDist<1e-10))
  {
    //If the object has no extension in the above projection (looking along
    //a line), we determine the extension of the object in a rotated view
    HomMat3dRotateLocal(hv_HomMat3D, HTuple(90).TupleRad(), "x", &hv_HomMat3DRotate);
    AffineTransPoint3d(hv_HomMat3DRotate, hv_X, hv_Y, hv_Z, &hv_QX, &hv_QY, &hv_QZ);
    Project3dPoint(hv_QX, hv_QY, hv_QZ, hv_CamParam, &hv_Rows, &hv_Cols);
    hv_DR = hv_Rows-hv_Cy;
    hv_DC = hv_Cols-hv_Cx;
    hv_DR = (hv_DR.TupleMax())-(hv_DR.TupleMin());
    hv_DC = (hv_DC.TupleMax())-(hv_DC.TupleMin());
    hv_MaxDist = (hv_MaxDist.TupleConcat(((hv_DR*hv_DR)+(hv_DC*hv_DC)).TupleSqrt())).TupleMax();
  }
  //
  get_cam_par_data(hv_CamParam, "image_width", &hv_ImageWidth);
  get_cam_par_data(hv_CamParam, "image_height", &hv_ImageHeight);
  hv_MinImageSize = (hv_ImageWidth.TupleConcat(hv_ImageHeight)).TupleMin();
  //
  hv_Z = ((const HTuple&)hv_PoseInter)[2];
  hv_Zs = hv_MinMinZ;
  hv_ZDiff = hv_Z-hv_Zs;
  hv_ScaleZ = hv_MaxDist/(((0.5*hv_MinImageSize)*hv_ImageCoverage)*2.0);
  hv_ZNew = ((hv_ScaleZ*hv_Zs)+hv_ZDiff)+hv_ZAdd;
  (*hv_PoseOut) = hv_PoseInter.TupleReplace(2,hv_ZNew);
  //
  return;
}

// Chapter: 3D Object Model / Creation
// Short Description: Generate 3D object models which visualize the cameras of a stereo model. 
void gen_camera_setup_object_model_3d (HTuple hv_CameraSetupModelID, HTuple hv_CameraSize, 
    HTuple hv_ConeLength, HTuple *hv_ObjectModel3DCamera, HTuple *hv_ObjectModel3DCone)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_NumCameras, hv_AutoConeLength, hv_AllCameras;
  HTuple  hv_CurrentCamera, hv_ConcatZ, hv_OtherCameras, hv_Index;
  HTuple  hv_CamParam0, hv_Pose0, hv_CamParam1, hv_Pose1;
  HTuple  hv_PoseInvert, hv_RelPose, hv_CX0, hv_CY0, hv_CX1;
  HTuple  hv_CY1, hv_X, hv_Y, hv_Z, hv_Dist, hv_Exception;
  HTuple  hv_CameraType, hv_ObjectModel3DConeTmp, hv_ObjectModel3DCameraTmp;

  GetCameraSetupParam(hv_CameraSetupModelID, "general", "num_cameras", &hv_NumCameras);
  //
  //Consistency check:
  if (0 != (hv_NumCameras<1))
  {
    throw HException("No camera set.");
  }
  if (0 != (hv_CameraSize.TupleIsNumber()))
  {
    if (0 != (hv_CameraSize<=0.0))
    {
      throw HException("Invalid value for CameraSize. CameraSize must be positive or 'auto'.");
    }
  }
  else if (0 != (hv_CameraSize!=HTuple("auto")))
  {
    throw HException("Invalid value for CameraSize. CameraSize must be positive or 'auto'.");
  }
  if (0 != (hv_ConeLength.TupleIsNumber()))
  {
    if (0 != (hv_ConeLength<=0.0))
    {
      throw HException("Invalid value for ConeLength. ConeLength must be positive or 'auto'.");
    }
  }
  else if (0 != (hv_ConeLength!=HTuple("auto")))
  {
    throw HException("Invalid value for ConeLength. ConeLength must be positive or 'auto'.");
  }
  //
  hv_AutoConeLength = hv_ConeLength==HTuple("auto");
  //
  (*hv_ObjectModel3DCamera) = HTuple();
  (*hv_ObjectModel3DCone) = HTuple();
  hv_AllCameras = HTuple::TupleGenSequence(0,hv_NumCameras-1,1);
  {
  HTuple end_val26 = hv_NumCameras-1;
  HTuple step_val26 = 1;
  for (hv_CurrentCamera=0; hv_CurrentCamera.Continue(end_val26, step_val26); hv_CurrentCamera += step_val26)
  {
    hv_ConcatZ = HTuple();
    if (0 != hv_AutoConeLength)
    {
      if (0 != (hv_NumCameras<2))
      {
        throw HException("You need at least two cameras for ConeLength == auto.");
      }
      //Intersect the line of sight of each camera with all other cameras.
      hv_OtherCameras = hv_AllCameras.TupleRemove(hv_AllCameras.TupleFind(hv_CurrentCamera));
      {
      HTuple end_val34 = (hv_OtherCameras.TupleLength())-1;
      HTuple step_val34 = 1;
      for (hv_Index=0; hv_Index.Continue(end_val34, step_val34); hv_Index += step_val34)
      {
        GetCameraSetupParam(hv_CameraSetupModelID, hv_CurrentCamera, "params", &hv_CamParam0);
        GetCameraSetupParam(hv_CameraSetupModelID, hv_CurrentCamera, "pose", &hv_Pose0);
        GetCameraSetupParam(hv_CameraSetupModelID, HTuple(hv_OtherCameras[hv_Index]), 
            "params", &hv_CamParam1);
        GetCameraSetupParam(hv_CameraSetupModelID, HTuple(hv_OtherCameras[hv_Index]), 
            "pose", &hv_Pose1);
        //Intersect the lines of sight of the camera pair.
        PoseInvert(hv_Pose1, &hv_PoseInvert);
        PoseCompose(hv_PoseInvert, hv_Pose0, &hv_RelPose);
        get_cam_par_data(hv_CamParam0, "cx", &hv_CX0);
        get_cam_par_data(hv_CamParam0, "cy", &hv_CY0);
        get_cam_par_data(hv_CamParam1, "cx", &hv_CX1);
        get_cam_par_data(hv_CamParam1, "cy", &hv_CY1);
        try
        {
          IntersectLinesOfSight(hv_CamParam0, hv_CamParam1, hv_RelPose, hv_CY0, hv_CX0, 
              hv_CY1, hv_CX1, &hv_X, &hv_Y, &hv_Z, &hv_Dist);
        }
        // catch (Exception) 
        catch (HException &HDevExpDefaultException)
        {
          HDevExpDefaultException.ToHTuple(&hv_Exception);
          throw HException("Estimating a value for ConeLength automatically was not possible. Please use a number instead.");
        }
        hv_ConcatZ = hv_ConcatZ.TupleConcat(hv_Z);
      }
      }
      //Use the Z value of the determined coordinates as basis for the ConeLength.
      hv_ConeLength = (hv_ConcatZ.TupleMax())*1.05;
    }
    //
    //Create cone of sight 3D object models.
    //Distinguish cases with/without projection center.
    GetCameraSetupParam(hv_CameraSetupModelID, hv_CurrentCamera, "type", &hv_CameraType);
    if (0 != (hv_CameraType.TupleRegexpTest("telecentric")))
    {
      gen_cone_telecentric_object_model_3d(hv_CameraSetupModelID, hv_CurrentCamera, 
          hv_ConeLength, &hv_ObjectModel3DConeTmp);
    }
    else
    {
      gen_cone_perspective_object_model_3d(hv_CameraSetupModelID, hv_CurrentCamera, 
          hv_ConeLength, &hv_ObjectModel3DConeTmp);
    }
    (*hv_ObjectModel3DCone) = (*hv_ObjectModel3DCone).TupleConcat(hv_ObjectModel3DConeTmp);
    //
    //Create camera 3D object models.
    if (0 != (hv_CameraSize==HTuple("auto")))
    {
      //In auto mode, the camera size for all cameras
      //is defined by the first camera's cone length.
      hv_CameraSize = hv_ConeLength*0.1;
    }
    gen_camera_object_model_3d(hv_CameraSetupModelID, hv_CurrentCamera, hv_CameraSize, 
        &hv_ObjectModel3DCameraTmp);
    (*hv_ObjectModel3DCamera) = (*hv_ObjectModel3DCamera).TupleConcat(hv_ObjectModel3DCameraTmp);
  }
  }
  return;
}

// Chapter: 3D Object Model / Creation
// Short Description: Generate a 3D object model which visualizes the bounding box of a stereo model. 
void gen_bounding_box_object_model_3d (HTuple hv_StereoModelID, HTuple *hv_ObjectModel3DBoundingBox)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_BoundingBox, hv_PX, hv_PY, hv_PZ, hv_Index;
  HTuple  hv_Faces;
  HTupleVector  hvec_Points(1);

  //
  //Consistency check:
  GetStereoModelParam(hv_StereoModelID, "bounding_box", &hv_BoundingBox);
  if (0 != (HTuple(HTuple(HTuple(hv_BoundingBox[3])<HTuple(hv_BoundingBox[0])).TupleOr(HTuple(hv_BoundingBox[4])<HTuple(hv_BoundingBox[1]))).TupleOr(HTuple(hv_BoundingBox[5])<HTuple(hv_BoundingBox[2]))))
  {
    throw HException("Invalid bounding box or bounding box not set yet.");
  }
  //
  //Get the eight corner points from the min/max representation.
  hvec_Points = (HTupleVector(1).Insert(0,HTupleVector(HTuple())));
  hvec_Points[0] = HTupleVector((HTuple(hv_BoundingBox[0]).TupleConcat(HTuple(hv_BoundingBox[1]))).TupleConcat(HTuple(hv_BoundingBox[2])));
  hvec_Points[1] = HTupleVector((HTuple(hv_BoundingBox[3]).TupleConcat(HTuple(hv_BoundingBox[1]))).TupleConcat(HTuple(hv_BoundingBox[2])));
  hvec_Points[2] = HTupleVector((HTuple(hv_BoundingBox[3]).TupleConcat(HTuple(hv_BoundingBox[4]))).TupleConcat(HTuple(hv_BoundingBox[2])));
  hvec_Points[3] = HTupleVector((HTuple(hv_BoundingBox[0]).TupleConcat(HTuple(hv_BoundingBox[4]))).TupleConcat(HTuple(hv_BoundingBox[2])));
  hvec_Points[4] = HTupleVector((HTuple(hv_BoundingBox[0]).TupleConcat(HTuple(hv_BoundingBox[1]))).TupleConcat(HTuple(hv_BoundingBox[5])));
  hvec_Points[5] = HTupleVector((HTuple(hv_BoundingBox[3]).TupleConcat(HTuple(hv_BoundingBox[1]))).TupleConcat(HTuple(hv_BoundingBox[5])));
  hvec_Points[6] = HTupleVector((HTuple(hv_BoundingBox[3]).TupleConcat(HTuple(hv_BoundingBox[4]))).TupleConcat(HTuple(hv_BoundingBox[5])));
  hvec_Points[7] = HTupleVector((HTuple(hv_BoundingBox[0]).TupleConcat(HTuple(hv_BoundingBox[4]))).TupleConcat(HTuple(hv_BoundingBox[5])));
  //
  //Sort the corner points by coordinate direction.
  hv_PX = HTuple();
  hv_PY = HTuple();
  hv_PZ = HTuple();
  for (hv_Index=0; hv_Index<=7; hv_Index+=1)
  {
    hv_PX = hv_PX.TupleConcat(HTuple(hvec_Points[hv_Index].T()[0]));
    hv_PY = hv_PY.TupleConcat(HTuple(hvec_Points[hv_Index].T()[1]));
    hv_PZ = hv_PZ.TupleConcat(HTuple(hvec_Points[hv_Index].T()[2]));
  }
  GenObjectModel3dFromPoints(hv_PX, hv_PY, hv_PZ, &(*hv_ObjectModel3DBoundingBox));
  //
  //Set the sides of the cuboid.
  hv_Faces = HTuple();
  hv_Faces = hv_Faces.TupleConcat(((((HTuple(4).Append(0)).Append(1)).Append(5)).Append(4)));
  hv_Faces = hv_Faces.TupleConcat(((((HTuple(4).Append(1)).Append(2)).Append(6)).Append(5)));
  hv_Faces = hv_Faces.TupleConcat(((((HTuple(4).Append(2)).Append(3)).Append(7)).Append(6)));
  hv_Faces = hv_Faces.TupleConcat(((((HTuple(4).Append(3)).Append(0)).Append(4)).Append(7)));
  hv_Faces = hv_Faces.TupleConcat(((((HTuple(4).Append(0)).Append(1)).Append(2)).Append(3)));
  hv_Faces = hv_Faces.TupleConcat(((((HTuple(4).Append(4)).Append(5)).Append(6)).Append(7)));
  SetObjectModel3dAttribMod((*hv_ObjectModel3DBoundingBox), "polygons", HTuple(), 
      hv_Faces);
  return;
}


